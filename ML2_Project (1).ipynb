{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "sk4YCWRSIfEl",
        "UdsjBt9oAjY_",
        "pG4cUUuK3Q9B",
        "SLMTGerZ5qiT",
        "2qUorKcH7nvI",
        "QMEt4Wd1dfMN",
        "nrECciW0aO-5",
        "3mZn1IXZVA59",
        "0xOkb5_fT3F4",
        "HdWd3oCKlNYG",
        "ABzIRKAeYcta",
        "vsbsIrInanaa",
        "3Xy0zrbJa2Gh",
        "7ljHqW1sbBcl",
        "15DGvjxnbrfx",
        "VDRAmavflWfN",
        "xxCPdMVydAWy",
        "z-MLLgppdYJd",
        "hfXcTiYCoq0j",
        "xkSYK3Eag0xq",
        "BFPYdiGglflf",
        "Q2cpspUvg9p5",
        "FCGBCKO5hWLd",
        "RU5fmVqahtBr",
        "kGFlg-wg-5m6",
        "Ku-oYknK_GwX",
        "Qub32JNzBAJ1"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Welcome to the Formula 1 Project"
      ],
      "metadata": {
        "id": "fRh3PxYjDthZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, I need to import the formula 1 data. I have downloaded it from this githubhttps://github.com/toUpperCase78/formula1-datasets/blob/master/Formula1_2022season_raceResults.csv. It has data all the way up to the current summer break races of 2025."
      ],
      "metadata": {
        "id": "qBZUwoWyDzZ-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Tw12U3zDqyf",
        "outputId": "b061aa5e-7751-409b-ae63-cbe5c923e787"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Files"
      ],
      "metadata": {
        "id": "2u6Hwi0UGQCK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "\n",
        "import random\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "84LfktrIGciK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2022 = pd.read_csv('/content/drive/MyDrive/f1Project/2022.csv')\n",
        "df2023 = pd.read_csv('/content/drive/MyDrive/f1Project/2023.csv')\n",
        "df2024 = pd.read_csv('/content/drive/MyDrive/f1Project/2024.csv')\n",
        "df2025 = pd.read_csv('/content/drive/MyDrive/f1Project/2025.csv')"
      ],
      "metadata": {
        "id": "Lwgotn1YGYUW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2024.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "PnoR2gCGHBE_",
        "outputId": "036281bd-7a69-4c87-fda4-c07bac2ef7d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Track Position  No           Driver                        Team  \\\n",
              "0  Bahrain        1   1   Max Verstappen  Red Bull Racing Honda RBPT   \n",
              "1  Bahrain        2  11     Sergio Perez  Red Bull Racing Honda RBPT   \n",
              "2  Bahrain        3  55     Carlos Sainz                     Ferrari   \n",
              "3  Bahrain        4  16  Charles Leclerc                     Ferrari   \n",
              "4  Bahrain        5  63   George Russell                    Mercedes   \n",
              "\n",
              "   Starting Grid  Laps Time/Retired  Points Set Fastest Lap Fastest Lap Time  \n",
              "0              1    57  1:31:44.742      26             Yes         1:32.608  \n",
              "1              5    57      +22.457      18              No         1:34.364  \n",
              "2              4    57      +25.110      15              No         1:34.507  \n",
              "3              2    57      +39.669      12              No         1:34.090  \n",
              "4              3    57      +46.788      10              No         1:35.065  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9bbf9919-4e3d-4101-a21e-be9bc7e79ca9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Track</th>\n",
              "      <th>Position</th>\n",
              "      <th>No</th>\n",
              "      <th>Driver</th>\n",
              "      <th>Team</th>\n",
              "      <th>Starting Grid</th>\n",
              "      <th>Laps</th>\n",
              "      <th>Time/Retired</th>\n",
              "      <th>Points</th>\n",
              "      <th>Set Fastest Lap</th>\n",
              "      <th>Fastest Lap Time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bahrain</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Max Verstappen</td>\n",
              "      <td>Red Bull Racing Honda RBPT</td>\n",
              "      <td>1</td>\n",
              "      <td>57</td>\n",
              "      <td>1:31:44.742</td>\n",
              "      <td>26</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1:32.608</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Bahrain</td>\n",
              "      <td>2</td>\n",
              "      <td>11</td>\n",
              "      <td>Sergio Perez</td>\n",
              "      <td>Red Bull Racing Honda RBPT</td>\n",
              "      <td>5</td>\n",
              "      <td>57</td>\n",
              "      <td>+22.457</td>\n",
              "      <td>18</td>\n",
              "      <td>No</td>\n",
              "      <td>1:34.364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Bahrain</td>\n",
              "      <td>3</td>\n",
              "      <td>55</td>\n",
              "      <td>Carlos Sainz</td>\n",
              "      <td>Ferrari</td>\n",
              "      <td>4</td>\n",
              "      <td>57</td>\n",
              "      <td>+25.110</td>\n",
              "      <td>15</td>\n",
              "      <td>No</td>\n",
              "      <td>1:34.507</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Bahrain</td>\n",
              "      <td>4</td>\n",
              "      <td>16</td>\n",
              "      <td>Charles Leclerc</td>\n",
              "      <td>Ferrari</td>\n",
              "      <td>2</td>\n",
              "      <td>57</td>\n",
              "      <td>+39.669</td>\n",
              "      <td>12</td>\n",
              "      <td>No</td>\n",
              "      <td>1:34.090</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Bahrain</td>\n",
              "      <td>5</td>\n",
              "      <td>63</td>\n",
              "      <td>George Russell</td>\n",
              "      <td>Mercedes</td>\n",
              "      <td>3</td>\n",
              "      <td>57</td>\n",
              "      <td>+46.788</td>\n",
              "      <td>10</td>\n",
              "      <td>No</td>\n",
              "      <td>1:35.065</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9bbf9919-4e3d-4101-a21e-be9bc7e79ca9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9bbf9919-4e3d-4101-a21e-be9bc7e79ca9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9bbf9919-4e3d-4101-a21e-be9bc7e79ca9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-a976b9e4-edc0-44d9-b421-170df86aa9fa\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a976b9e4-edc0-44d9-b421-170df86aa9fa')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-a976b9e4-edc0-44d9-b421-170df86aa9fa button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df2024",
              "summary": "{\n  \"name\": \"df2024\",\n  \"rows\": 479,\n  \"fields\": [\n    {\n      \"column\": \"Track\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 24,\n        \"samples\": [\n          \"Canada\",\n          \"Azerbaijan\",\n          \"Bahrain\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Position\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 22,\n        \"samples\": [\n          \"1\",\n          \"14\",\n          \"9\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"No\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 23,\n        \"min\": 1,\n        \"max\": 81,\n        \"num_unique_values\": 25,\n        \"samples\": [\n          14,\n          31,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Driver\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 24,\n        \"samples\": [\n          \"Fernando Alonso\",\n          \"Esteban Ocon\",\n          \"Max Verstappen\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Team\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"Williams Mercedes\",\n          \"Ferrari\",\n          \"Kick Sauber Ferrari\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Starting Grid\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5,\n        \"min\": 1,\n        \"max\": 20,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          1,\n          20,\n          10\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Laps\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 16,\n        \"min\": 0,\n        \"max\": 78,\n        \"num_unique_values\": 43,\n        \"samples\": [\n          61,\n          70,\n          69\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Time/Retired\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 294,\n        \"samples\": [\n          \"+104.553\",\n          \"+93.216\",\n          \"1:38:01.989\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Points\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7,\n        \"min\": 0,\n        \"max\": 26,\n        \"num_unique_values\": 19,\n        \"samples\": [\n          26,\n          8,\n          25\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Set Fastest Lap\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"No\",\n          \"Yes\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Fastest Lap Time\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 458,\n        \"samples\": [\n          \"1:24.343\",\n          \"1:20.031\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2022['Track'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tGPcQwFNIKXk",
        "outputId": "264ae76b-7c34-45c3-f838-51417524c8d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Bahrain', 'Saudi Arabia', 'Australia', 'Emilia Romagna', 'Miami',\n",
              "       'Spain', 'Monaco', 'Azerbaijan', 'Canada', 'Great Britain',\n",
              "       'Austria', 'France', 'Hungary', 'Belgium', 'Netherlands', 'Italy',\n",
              "       'Singapore', 'Japan', 'United States', 'Mexico', 'Brazil',\n",
              "       'Abu Dhabi'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2023['Track'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0o23hP9jHFHP",
        "outputId": "eed2c622-ea95-4e02-cc9a-bf62dff4a3d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Bahrain', 'Saudi Arabia', 'Australia', 'Azerbaijan', 'Miami',\n",
              "       'Monaco', 'Spain', 'Canada', 'Austria', 'Great Britain', 'Hungary',\n",
              "       'Belgium', 'Netherlands', 'Italy', 'Singapore', 'Japan', 'Qatar',\n",
              "       'United States', 'Mexico', 'Brazil', 'Las Vegas', 'Abu Dhabi'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2024['Track'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rat24nCiHKOX",
        "outputId": "9f5279df-2674-4876-a45c-71372446e5ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Bahrain', 'Saudi Arabia', 'Australia', 'Japan', 'China', 'Miami',\n",
              "       'Emilia Romagna', 'Monaco', 'Canada', 'Spain', 'Austria',\n",
              "       'Great Britain', 'Hungary', 'Belgium', 'Netherlands', 'Italy',\n",
              "       'Azerbaijan', 'Singapore', 'United States', 'Mexico', 'Brazil',\n",
              "       'Las Vegas', 'Qatar', 'Abu Dhabi'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2025['Track'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iPw3ATjVIMlg",
        "outputId": "b276b23e-1ea4-4f05-9ed9-9e8b99fadefd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Australia', 'China', 'Japan', 'Bahrain', 'Saudi Arabia', 'Miami',\n",
              "       'Emilia-Romagna', 'Monaco', 'Spain', 'Canada', 'Austria',\n",
              "       'Great Britain', 'Belgium'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It's important to note that all races that occurred at the track United States is actually the race that occurs at the austin track."
      ],
      "metadata": {
        "id": "StihFL6pIV8_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The +1 Point is equivalent to the set Fastest Lap columns"
      ],
      "metadata": {
        "id": "rDqa_pBNJWeq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df2022.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sdp7vOtLJYfD",
        "outputId": "7a4fb846-1964-4bb6-dfb5-90256b8c87f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Track', 'Position', 'No', 'Driver', 'Team', 'Starting Grid', 'Laps',\n",
              "       'Time/Retired', 'Points', '+1 Pt', 'Fastest Lap'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2023.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sgN_HXn6Jcps",
        "outputId": "04c31b59-b3ab-4d9f-9cbd-ee41fd467812"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Track', 'Position', 'No', 'Driver', 'Team', 'Starting Grid', 'Laps',\n",
              "       'Time/Retired', 'Points', 'Set Fastest Lap', 'Fastest Lap Time'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "rename the +1 pt column to set fastest lap"
      ],
      "metadata": {
        "id": "z3bYVn0AJfvn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df2022.rename(columns = {'+1 Pt':'Set Fastest Lap'}, inplace = True)\n",
        "df2022.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ics8K0ShJl4N",
        "outputId": "9bf2f62e-8f2a-4b81-e05f-82f3154eeebf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Track', 'Position', 'No', 'Driver', 'Team', 'Starting Grid', 'Laps',\n",
              "       'Time/Retired', 'Points', 'Set Fastest Lap', 'Fastest Lap'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I need to add the year for the race years on the data sets."
      ],
      "metadata": {
        "id": "U8JSD7-mKgWO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df2022['Year'] = 2022\n",
        "df2023['Year'] = 2023\n",
        "df2024['Year'] = 2024\n",
        "df2025['Year'] = 2025"
      ],
      "metadata": {
        "id": "ag4CaLjSKlar"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2022.head(42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lnUnooc5DvT9",
        "outputId": "2b98c764-abe6-42a9-ba56-0b127067bc55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           Track Position  No            Driver                          Team  \\\n",
              "0        Bahrain        1  16   Charles Leclerc                       Ferrari   \n",
              "1        Bahrain        2  55      Carlos Sainz                       Ferrari   \n",
              "2        Bahrain        3  44    Lewis Hamilton                      Mercedes   \n",
              "3        Bahrain        4  63    George Russell                      Mercedes   \n",
              "4        Bahrain        5  20   Kevin Magnussen                  Haas Ferrari   \n",
              "5        Bahrain        6  77   Valtteri Bottas            Alfa Romeo Ferrari   \n",
              "6        Bahrain        7  31      Esteban Ocon                Alpine Renault   \n",
              "7        Bahrain        8  22      Yuki Tsunoda               AlphaTauri RBPT   \n",
              "8        Bahrain        9  14   Fernando Alonso                Alpine Renault   \n",
              "9        Bahrain       10  24       Guanyu Zhou            Alfa Romeo Ferrari   \n",
              "10       Bahrain       11  47   Mick Schumacher                  Haas Ferrari   \n",
              "11       Bahrain       12  18      Lance Stroll  Aston Martin Aramco Mercedes   \n",
              "12       Bahrain       13  23   Alexander Albon             Williams Mercedes   \n",
              "13       Bahrain       14   3  Daniel Ricciardo              McLaren Mercedes   \n",
              "14       Bahrain       15   4      Lando Norris              McLaren Mercedes   \n",
              "15       Bahrain       16   6   Nicholas Latifi             Williams Mercedes   \n",
              "16       Bahrain       17  27   Nico Hulkenberg  Aston Martin Aramco Mercedes   \n",
              "17       Bahrain       18  11      Sergio Perez          Red Bull Racing RBPT   \n",
              "18       Bahrain       19   1    Max Verstappen          Red Bull Racing RBPT   \n",
              "19       Bahrain       NC  10      Pierre Gasly               AlphaTauri RBPT   \n",
              "20  Saudi Arabia        1   1    Max Verstappen          Red Bull Racing RBPT   \n",
              "21  Saudi Arabia        2  16   Charles Leclerc                       Ferrari   \n",
              "22  Saudi Arabia        3  55      Carlos Sainz                       Ferrari   \n",
              "23  Saudi Arabia        4  11      Sergio Perez          Red Bull Racing RBPT   \n",
              "24  Saudi Arabia        5  63    George Russell                      Mercedes   \n",
              "25  Saudi Arabia        6  31      Esteban Ocon                Alpine Renault   \n",
              "26  Saudi Arabia        7   4      Lando Norris              McLaren Mercedes   \n",
              "27  Saudi Arabia        8  10      Pierre Gasly               AlphaTauri RBPT   \n",
              "28  Saudi Arabia        9  20   Kevin Magnussen                  Haas Ferrari   \n",
              "29  Saudi Arabia       10  44    Lewis Hamilton                      Mercedes   \n",
              "30  Saudi Arabia       11  24       Guanyu Zhou            Alfa Romeo Ferrari   \n",
              "31  Saudi Arabia       12  27   Nico Hulkenberg  Aston Martin Aramco Mercedes   \n",
              "32  Saudi Arabia       13  18      Lance Stroll  Aston Martin Aramco Mercedes   \n",
              "33  Saudi Arabia       14  23   Alexander Albon             Williams Mercedes   \n",
              "34  Saudi Arabia       NC  77   Valtteri Bottas            Alfa Romeo Ferrari   \n",
              "35  Saudi Arabia       NC  14   Fernando Alonso                Alpine Renault   \n",
              "36  Saudi Arabia       NC   3  Daniel Ricciardo              McLaren Mercedes   \n",
              "37  Saudi Arabia       NC   6   Nicholas Latifi             Williams Mercedes   \n",
              "38  Saudi Arabia       NC  22      Yuki Tsunoda               AlphaTauri RBPT   \n",
              "39  Saudi Arabia       NC  47   Mick Schumacher                  Haas Ferrari   \n",
              "40     Australia        1  16   Charles Leclerc                       Ferrari   \n",
              "41     Australia        2  11      Sergio Perez          Red Bull Racing RBPT   \n",
              "\n",
              "    Starting Grid  Laps Time/Retired  Points Set Fastest Lap Fastest Lap  Year  \n",
              "0               1    57  1:37:33.584      26             Yes    1:34.570  2022  \n",
              "1               3    57       +5.598      18              No    1:35.740  2022  \n",
              "2               5    57       +9.675      15              No    1:36.228  2022  \n",
              "3               9    57      +11.211      12              No    1:36.302  2022  \n",
              "4               7    57      +14.754      10              No    1:36.623  2022  \n",
              "5               6    57      +16.119       8              No    1:36.599  2022  \n",
              "6              11    57      +19.423       6              No    1:37.110  2022  \n",
              "7              16    57      +20.386       4              No    1:37.104  2022  \n",
              "8               8    57      +22.390       2              No    1:36.733  2022  \n",
              "9              15    57      +23.064       1              No    1:36.685  2022  \n",
              "10             12    57      +32.574       0              No    1:36.956  2022  \n",
              "11             19    57      +45.873       0              No    1:37.146  2022  \n",
              "12             14    57      +53.932       0              No    1:37.355  2022  \n",
              "13             18    57      +54.975       0              No    1:37.261  2022  \n",
              "14             13    57      +56.335       0              No    1:36.988  2022  \n",
              "15             20    57      +61.795       0              No    1:38.251  2022  \n",
              "16             17    57      +63.829       0              No    1:38.201  2022  \n",
              "17              4    56          DNF       0              No    1:36.089  2022  \n",
              "18              2    54          DNF       0              No    1:35.440  2022  \n",
              "19             10    44          DNF       0              No    1:37.324  2022  \n",
              "20              4    50  1:24:19.293      25              No    1:31.772  2022  \n",
              "21              2    50       +0.549      19             Yes    1:31.634  2022  \n",
              "22              3    50       +8.097      15              No    1:31.905  2022  \n",
              "23              1    50      +10.800      12              No    1:32.042  2022  \n",
              "24              6    50      +32.732      10              No    1:32.821  2022  \n",
              "25              5    50      +56.017       8              No    1:33.103  2022  \n",
              "26             11    50      +56.124       6              No    1:32.753  2022  \n",
              "27              9    50      +62.946       4              No    1:33.468  2022  \n",
              "28             10    50      +64.308       2              No    1:32.779  2022  \n",
              "29             15    50      +73.948       1              No    1:32.997  2022  \n",
              "30             12    50      +82.215       0              No    1:33.924  2022  \n",
              "31             17    50      +91.742       0              No    1:33.651  2022  \n",
              "32             13    49       +1 lap       0              No    1:34.446  2022  \n",
              "33             16    47          DNF       0              No    1:34.368  2022  \n",
              "34              8    36          DNF       0              No    1:33.979  2022  \n",
              "35              7    35          DNF       0              No    1:33.831  2022  \n",
              "36             14    35          DNF       0              No    1:34.487  2022  \n",
              "37             18    14          DNF       0              No    1:37.530  2022  \n",
              "38             19     0          DNS       0              No         NaN  2022  \n",
              "39             20     0          DNS       0              No         NaN  2022  \n",
              "40              1    58  1:27:46.548      26             Yes    1:20.260  2022  \n",
              "41              3    58      +20.524      18              No    1:21.094  2022  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f18c8b04-7ec3-41f6-b5b3-c4296e6c26e8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Track</th>\n",
              "      <th>Position</th>\n",
              "      <th>No</th>\n",
              "      <th>Driver</th>\n",
              "      <th>Team</th>\n",
              "      <th>Starting Grid</th>\n",
              "      <th>Laps</th>\n",
              "      <th>Time/Retired</th>\n",
              "      <th>Points</th>\n",
              "      <th>Set Fastest Lap</th>\n",
              "      <th>Fastest Lap</th>\n",
              "      <th>Year</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bahrain</td>\n",
              "      <td>1</td>\n",
              "      <td>16</td>\n",
              "      <td>Charles Leclerc</td>\n",
              "      <td>Ferrari</td>\n",
              "      <td>1</td>\n",
              "      <td>57</td>\n",
              "      <td>1:37:33.584</td>\n",
              "      <td>26</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1:34.570</td>\n",
              "      <td>2022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Bahrain</td>\n",
              "      <td>2</td>\n",
              "      <td>55</td>\n",
              "      <td>Carlos Sainz</td>\n",
              "      <td>Ferrari</td>\n",
              "      <td>3</td>\n",
              "      <td>57</td>\n",
              "      <td>+5.598</td>\n",
              "      <td>18</td>\n",
              "      <td>No</td>\n",
              "      <td>1:35.740</td>\n",
              "      <td>2022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Bahrain</td>\n",
              "      <td>3</td>\n",
              "      <td>44</td>\n",
              "      <td>Lewis Hamilton</td>\n",
              "      <td>Mercedes</td>\n",
              "      <td>5</td>\n",
              "      <td>57</td>\n",
              "      <td>+9.675</td>\n",
              "      <td>15</td>\n",
              "      <td>No</td>\n",
              "      <td>1:36.228</td>\n",
              "      <td>2022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Bahrain</td>\n",
              "      <td>4</td>\n",
              "      <td>63</td>\n",
              "      <td>George Russell</td>\n",
              "      <td>Mercedes</td>\n",
              "      <td>9</td>\n",
              "      <td>57</td>\n",
              "      <td>+11.211</td>\n",
              "      <td>12</td>\n",
              "      <td>No</td>\n",
              "      <td>1:36.302</td>\n",
              "      <td>2022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Bahrain</td>\n",
              "      <td>5</td>\n",
              "      <td>20</td>\n",
              "      <td>Kevin Magnussen</td>\n",
              "      <td>Haas Ferrari</td>\n",
              "      <td>7</td>\n",
              "      <td>57</td>\n",
              "      <td>+14.754</td>\n",
              "      <td>10</td>\n",
              "      <td>No</td>\n",
              "      <td>1:36.623</td>\n",
              "      <td>2022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Bahrain</td>\n",
              "      <td>6</td>\n",
              "      <td>77</td>\n",
              "      <td>Valtteri Bottas</td>\n",
              "      <td>Alfa Romeo Ferrari</td>\n",
              "      <td>6</td>\n",
              "      <td>57</td>\n",
              "      <td>+16.119</td>\n",
              "      <td>8</td>\n",
              "      <td>No</td>\n",
              "      <td>1:36.599</td>\n",
              "      <td>2022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Bahrain</td>\n",
              "      <td>7</td>\n",
              "      <td>31</td>\n",
              "      <td>Esteban Ocon</td>\n",
              "      <td>Alpine Renault</td>\n",
              "      <td>11</td>\n",
              "      <td>57</td>\n",
              "      <td>+19.423</td>\n",
              "      <td>6</td>\n",
              "      <td>No</td>\n",
              "      <td>1:37.110</td>\n",
              "      <td>2022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Bahrain</td>\n",
              "      <td>8</td>\n",
              "      <td>22</td>\n",
              "      <td>Yuki Tsunoda</td>\n",
              "      <td>AlphaTauri RBPT</td>\n",
              "      <td>16</td>\n",
              "      <td>57</td>\n",
              "      <td>+20.386</td>\n",
              "      <td>4</td>\n",
              "      <td>No</td>\n",
              "      <td>1:37.104</td>\n",
              "      <td>2022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Bahrain</td>\n",
              "      <td>9</td>\n",
              "      <td>14</td>\n",
              "      <td>Fernando Alonso</td>\n",
              "      <td>Alpine Renault</td>\n",
              "      <td>8</td>\n",
              "      <td>57</td>\n",
              "      <td>+22.390</td>\n",
              "      <td>2</td>\n",
              "      <td>No</td>\n",
              "      <td>1:36.733</td>\n",
              "      <td>2022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Bahrain</td>\n",
              "      <td>10</td>\n",
              "      <td>24</td>\n",
              "      <td>Guanyu Zhou</td>\n",
              "      <td>Alfa Romeo Ferrari</td>\n",
              "      <td>15</td>\n",
              "      <td>57</td>\n",
              "      <td>+23.064</td>\n",
              "      <td>1</td>\n",
              "      <td>No</td>\n",
              "      <td>1:36.685</td>\n",
              "      <td>2022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Bahrain</td>\n",
              "      <td>11</td>\n",
              "      <td>47</td>\n",
              "      <td>Mick Schumacher</td>\n",
              "      <td>Haas Ferrari</td>\n",
              "      <td>12</td>\n",
              "      <td>57</td>\n",
              "      <td>+32.574</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>1:36.956</td>\n",
              "      <td>2022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Bahrain</td>\n",
              "      <td>12</td>\n",
              "      <td>18</td>\n",
              "      <td>Lance Stroll</td>\n",
              "      <td>Aston Martin Aramco Mercedes</td>\n",
              "      <td>19</td>\n",
              "      <td>57</td>\n",
              "      <td>+45.873</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>1:37.146</td>\n",
              "      <td>2022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Bahrain</td>\n",
              "      <td>13</td>\n",
              "      <td>23</td>\n",
              "      <td>Alexander Albon</td>\n",
              "      <td>Williams Mercedes</td>\n",
              "      <td>14</td>\n",
              "      <td>57</td>\n",
              "      <td>+53.932</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>1:37.355</td>\n",
              "      <td>2022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Bahrain</td>\n",
              "      <td>14</td>\n",
              "      <td>3</td>\n",
              "      <td>Daniel Ricciardo</td>\n",
              "      <td>McLaren Mercedes</td>\n",
              "      <td>18</td>\n",
              "      <td>57</td>\n",
              "      <td>+54.975</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>1:37.261</td>\n",
              "      <td>2022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Bahrain</td>\n",
              "      <td>15</td>\n",
              "      <td>4</td>\n",
              "      <td>Lando Norris</td>\n",
              "      <td>McLaren Mercedes</td>\n",
              "      <td>13</td>\n",
              "      <td>57</td>\n",
              "      <td>+56.335</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>1:36.988</td>\n",
              "      <td>2022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Bahrain</td>\n",
              "      <td>16</td>\n",
              "      <td>6</td>\n",
              "      <td>Nicholas Latifi</td>\n",
              "      <td>Williams Mercedes</td>\n",
              "      <td>20</td>\n",
              "      <td>57</td>\n",
              "      <td>+61.795</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>1:38.251</td>\n",
              "      <td>2022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Bahrain</td>\n",
              "      <td>17</td>\n",
              "      <td>27</td>\n",
              "      <td>Nico Hulkenberg</td>\n",
              "      <td>Aston Martin Aramco Mercedes</td>\n",
              "      <td>17</td>\n",
              "      <td>57</td>\n",
              "      <td>+63.829</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>1:38.201</td>\n",
              "      <td>2022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Bahrain</td>\n",
              "      <td>18</td>\n",
              "      <td>11</td>\n",
              "      <td>Sergio Perez</td>\n",
              "      <td>Red Bull Racing RBPT</td>\n",
              "      <td>4</td>\n",
              "      <td>56</td>\n",
              "      <td>DNF</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>1:36.089</td>\n",
              "      <td>2022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Bahrain</td>\n",
              "      <td>19</td>\n",
              "      <td>1</td>\n",
              "      <td>Max Verstappen</td>\n",
              "      <td>Red Bull Racing RBPT</td>\n",
              "      <td>2</td>\n",
              "      <td>54</td>\n",
              "      <td>DNF</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>1:35.440</td>\n",
              "      <td>2022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Bahrain</td>\n",
              "      <td>NC</td>\n",
              "      <td>10</td>\n",
              "      <td>Pierre Gasly</td>\n",
              "      <td>AlphaTauri RBPT</td>\n",
              "      <td>10</td>\n",
              "      <td>44</td>\n",
              "      <td>DNF</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>1:37.324</td>\n",
              "      <td>2022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Saudi Arabia</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Max Verstappen</td>\n",
              "      <td>Red Bull Racing RBPT</td>\n",
              "      <td>4</td>\n",
              "      <td>50</td>\n",
              "      <td>1:24:19.293</td>\n",
              "      <td>25</td>\n",
              "      <td>No</td>\n",
              "      <td>1:31.772</td>\n",
              "      <td>2022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>Saudi Arabia</td>\n",
              "      <td>2</td>\n",
              "      <td>16</td>\n",
              "      <td>Charles Leclerc</td>\n",
              "      <td>Ferrari</td>\n",
              "      <td>2</td>\n",
              "      <td>50</td>\n",
              "      <td>+0.549</td>\n",
              "      <td>19</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1:31.634</td>\n",
              "      <td>2022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>Saudi Arabia</td>\n",
              "      <td>3</td>\n",
              "      <td>55</td>\n",
              "      <td>Carlos Sainz</td>\n",
              "      <td>Ferrari</td>\n",
              "      <td>3</td>\n",
              "      <td>50</td>\n",
              "      <td>+8.097</td>\n",
              "      <td>15</td>\n",
              "      <td>No</td>\n",
              "      <td>1:31.905</td>\n",
              "      <td>2022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Saudi Arabia</td>\n",
              "      <td>4</td>\n",
              "      <td>11</td>\n",
              "      <td>Sergio Perez</td>\n",
              "      <td>Red Bull Racing RBPT</td>\n",
              "      <td>1</td>\n",
              "      <td>50</td>\n",
              "      <td>+10.800</td>\n",
              "      <td>12</td>\n",
              "      <td>No</td>\n",
              "      <td>1:32.042</td>\n",
              "      <td>2022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>Saudi Arabia</td>\n",
              "      <td>5</td>\n",
              "      <td>63</td>\n",
              "      <td>George Russell</td>\n",
              "      <td>Mercedes</td>\n",
              "      <td>6</td>\n",
              "      <td>50</td>\n",
              "      <td>+32.732</td>\n",
              "      <td>10</td>\n",
              "      <td>No</td>\n",
              "      <td>1:32.821</td>\n",
              "      <td>2022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>Saudi Arabia</td>\n",
              "      <td>6</td>\n",
              "      <td>31</td>\n",
              "      <td>Esteban Ocon</td>\n",
              "      <td>Alpine Renault</td>\n",
              "      <td>5</td>\n",
              "      <td>50</td>\n",
              "      <td>+56.017</td>\n",
              "      <td>8</td>\n",
              "      <td>No</td>\n",
              "      <td>1:33.103</td>\n",
              "      <td>2022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>Saudi Arabia</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>Lando Norris</td>\n",
              "      <td>McLaren Mercedes</td>\n",
              "      <td>11</td>\n",
              "      <td>50</td>\n",
              "      <td>+56.124</td>\n",
              "      <td>6</td>\n",
              "      <td>No</td>\n",
              "      <td>1:32.753</td>\n",
              "      <td>2022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>Saudi Arabia</td>\n",
              "      <td>8</td>\n",
              "      <td>10</td>\n",
              "      <td>Pierre Gasly</td>\n",
              "      <td>AlphaTauri RBPT</td>\n",
              "      <td>9</td>\n",
              "      <td>50</td>\n",
              "      <td>+62.946</td>\n",
              "      <td>4</td>\n",
              "      <td>No</td>\n",
              "      <td>1:33.468</td>\n",
              "      <td>2022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>Saudi Arabia</td>\n",
              "      <td>9</td>\n",
              "      <td>20</td>\n",
              "      <td>Kevin Magnussen</td>\n",
              "      <td>Haas Ferrari</td>\n",
              "      <td>10</td>\n",
              "      <td>50</td>\n",
              "      <td>+64.308</td>\n",
              "      <td>2</td>\n",
              "      <td>No</td>\n",
              "      <td>1:32.779</td>\n",
              "      <td>2022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>Saudi Arabia</td>\n",
              "      <td>10</td>\n",
              "      <td>44</td>\n",
              "      <td>Lewis Hamilton</td>\n",
              "      <td>Mercedes</td>\n",
              "      <td>15</td>\n",
              "      <td>50</td>\n",
              "      <td>+73.948</td>\n",
              "      <td>1</td>\n",
              "      <td>No</td>\n",
              "      <td>1:32.997</td>\n",
              "      <td>2022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>Saudi Arabia</td>\n",
              "      <td>11</td>\n",
              "      <td>24</td>\n",
              "      <td>Guanyu Zhou</td>\n",
              "      <td>Alfa Romeo Ferrari</td>\n",
              "      <td>12</td>\n",
              "      <td>50</td>\n",
              "      <td>+82.215</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>1:33.924</td>\n",
              "      <td>2022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>Saudi Arabia</td>\n",
              "      <td>12</td>\n",
              "      <td>27</td>\n",
              "      <td>Nico Hulkenberg</td>\n",
              "      <td>Aston Martin Aramco Mercedes</td>\n",
              "      <td>17</td>\n",
              "      <td>50</td>\n",
              "      <td>+91.742</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>1:33.651</td>\n",
              "      <td>2022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>Saudi Arabia</td>\n",
              "      <td>13</td>\n",
              "      <td>18</td>\n",
              "      <td>Lance Stroll</td>\n",
              "      <td>Aston Martin Aramco Mercedes</td>\n",
              "      <td>13</td>\n",
              "      <td>49</td>\n",
              "      <td>+1 lap</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>1:34.446</td>\n",
              "      <td>2022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>Saudi Arabia</td>\n",
              "      <td>14</td>\n",
              "      <td>23</td>\n",
              "      <td>Alexander Albon</td>\n",
              "      <td>Williams Mercedes</td>\n",
              "      <td>16</td>\n",
              "      <td>47</td>\n",
              "      <td>DNF</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>1:34.368</td>\n",
              "      <td>2022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>Saudi Arabia</td>\n",
              "      <td>NC</td>\n",
              "      <td>77</td>\n",
              "      <td>Valtteri Bottas</td>\n",
              "      <td>Alfa Romeo Ferrari</td>\n",
              "      <td>8</td>\n",
              "      <td>36</td>\n",
              "      <td>DNF</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>1:33.979</td>\n",
              "      <td>2022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>Saudi Arabia</td>\n",
              "      <td>NC</td>\n",
              "      <td>14</td>\n",
              "      <td>Fernando Alonso</td>\n",
              "      <td>Alpine Renault</td>\n",
              "      <td>7</td>\n",
              "      <td>35</td>\n",
              "      <td>DNF</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>1:33.831</td>\n",
              "      <td>2022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>Saudi Arabia</td>\n",
              "      <td>NC</td>\n",
              "      <td>3</td>\n",
              "      <td>Daniel Ricciardo</td>\n",
              "      <td>McLaren Mercedes</td>\n",
              "      <td>14</td>\n",
              "      <td>35</td>\n",
              "      <td>DNF</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>1:34.487</td>\n",
              "      <td>2022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>Saudi Arabia</td>\n",
              "      <td>NC</td>\n",
              "      <td>6</td>\n",
              "      <td>Nicholas Latifi</td>\n",
              "      <td>Williams Mercedes</td>\n",
              "      <td>18</td>\n",
              "      <td>14</td>\n",
              "      <td>DNF</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>1:37.530</td>\n",
              "      <td>2022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>Saudi Arabia</td>\n",
              "      <td>NC</td>\n",
              "      <td>22</td>\n",
              "      <td>Yuki Tsunoda</td>\n",
              "      <td>AlphaTauri RBPT</td>\n",
              "      <td>19</td>\n",
              "      <td>0</td>\n",
              "      <td>DNS</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>Saudi Arabia</td>\n",
              "      <td>NC</td>\n",
              "      <td>47</td>\n",
              "      <td>Mick Schumacher</td>\n",
              "      <td>Haas Ferrari</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>DNS</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>Australia</td>\n",
              "      <td>1</td>\n",
              "      <td>16</td>\n",
              "      <td>Charles Leclerc</td>\n",
              "      <td>Ferrari</td>\n",
              "      <td>1</td>\n",
              "      <td>58</td>\n",
              "      <td>1:27:46.548</td>\n",
              "      <td>26</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1:20.260</td>\n",
              "      <td>2022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>Australia</td>\n",
              "      <td>2</td>\n",
              "      <td>11</td>\n",
              "      <td>Sergio Perez</td>\n",
              "      <td>Red Bull Racing RBPT</td>\n",
              "      <td>3</td>\n",
              "      <td>58</td>\n",
              "      <td>+20.524</td>\n",
              "      <td>18</td>\n",
              "      <td>No</td>\n",
              "      <td>1:21.094</td>\n",
              "      <td>2022</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f18c8b04-7ec3-41f6-b5b3-c4296e6c26e8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f18c8b04-7ec3-41f6-b5b3-c4296e6c26e8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f18c8b04-7ec3-41f6-b5b3-c4296e6c26e8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-40097fc1-d083-4dc0-970e-8c5d342fce4c\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-40097fc1-d083-4dc0-970e-8c5d342fce4c')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-40097fc1-d083-4dc0-970e-8c5d342fce4c button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df2022",
              "summary": "{\n  \"name\": \"df2022\",\n  \"rows\": 440,\n  \"fields\": [\n    {\n      \"column\": \"Track\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 22,\n        \"samples\": [\n          \"Bahrain\",\n          \"Belgium\",\n          \"Canada\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Position\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 21,\n        \"samples\": [\n          \"1\",\n          \"18\",\n          \"16\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"No\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 21,\n        \"min\": 1,\n        \"max\": 77,\n        \"num_unique_values\": 22,\n        \"samples\": [\n          16,\n          3,\n          14\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Driver\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 22,\n        \"samples\": [\n          \"Charles Leclerc\",\n          \"Daniel Ricciardo\",\n          \"Fernando Alonso\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Team\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"McLaren Mercedes\",\n          \"Mercedes\",\n          \"AlphaTauri RBPT\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Starting Grid\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5,\n        \"min\": 1,\n        \"max\": 20,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          1,\n          4,\n          20\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Laps\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 17,\n        \"min\": 0,\n        \"max\": 72,\n        \"num_unique_values\": 55,\n        \"samples\": [\n          23,\n          49,\n          21\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Time/Retired\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 282,\n        \"samples\": [\n          \"+20.823\",\n          \"+45.995\",\n          \"+18.754\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Points\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7,\n        \"min\": 0,\n        \"max\": 26,\n        \"num_unique_values\": 17,\n        \"samples\": [\n          26,\n          18,\n          8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Set Fastest Lap\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"No\",\n          \"Yes\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Fastest Lap\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 423,\n        \"samples\": [\n          \"1:48.179\",\n          \"1:15.165\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Year\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 2022,\n        \"max\": 2022,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          2022\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Need to add the ordinal order of each race"
      ],
      "metadata": {
        "id": "7nd7nCYpPPTn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df2025['Track'].unique())"
      ],
      "metadata": {
        "id": "IH5CE56JKXQs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5e22bb4-ce61-4faa-afb5-a0d3c674c166"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Australia' 'China' 'Japan' 'Bahrain' 'Saudi Arabia' 'Miami'\n",
            " 'Emilia-Romagna' 'Monaco' 'Spain' 'Canada' 'Austria' 'Great Britain'\n",
            " 'Belgium']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tracks2022 = df2022['Track'].unique()\n",
        "for i, track in enumerate(tracks2022, start=1):\n",
        "    df2022.loc[df2022['Track'] == track, 'TrackOrder'] = int(i)\n",
        "df2024.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQj3zjiJD3Cs",
        "outputId": "dad563c9-12af-47ef-9d8c-2357e1ac6f28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Track', 'Position', 'No', 'Driver', 'Team', 'Starting Grid', 'Laps',\n",
              "       'Time/Retired', 'Points', 'Set Fastest Lap', 'Fastest Lap Time',\n",
              "       'Year'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#do this for every race year\n",
        "def addTrackOrder(df):\n",
        "  tracks = df['Track'].unique()\n",
        "  for i, track in enumerate(tracks, start=1):\n",
        "    df.loc[df['Track'] == track, 'RaceOrder'] = int(i)\n",
        "addTrackOrder(df2022)\n",
        "addTrackOrder(df2023)\n",
        "addTrackOrder(df2024)\n",
        "addTrackOrder(df2025)\n",
        "df2025.head(43)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fITDEjL8EWHn",
        "outputId": "87570cae-41bb-455d-87af-2218ea923642"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Track Position  No             Driver                          Team  \\\n",
              "0   Australia        1   4       Lando Norris              McLaren Mercedes   \n",
              "1   Australia        2   1     Max Verstappen    Red Bull Racing Honda RBPT   \n",
              "2   Australia        3  63     George Russell                      Mercedes   \n",
              "3   Australia        4  12     Kimi Antonelli                      Mercedes   \n",
              "4   Australia        5  23    Alexander Albon             Williams Mercedes   \n",
              "5   Australia        6  18       Lance Stroll  Aston Martin Aramco Mercedes   \n",
              "6   Australia        7  27    Nico Hulkenberg           Kick Sauber Ferrari   \n",
              "7   Australia        8  16    Charles Leclerc                       Ferrari   \n",
              "8   Australia        9  81      Oscar Piastri              McLaren Mercedes   \n",
              "9   Australia       10  44     Lewis Hamilton                       Ferrari   \n",
              "10  Australia       11  10       Pierre Gasly                Alpine Renault   \n",
              "11  Australia       12  22       Yuki Tsunoda       Racing Bulls Honda RBPT   \n",
              "12  Australia       13  31       Esteban Ocon                  Haas Ferrari   \n",
              "13  Australia       14  87     Oliver Bearman                  Haas Ferrari   \n",
              "14  Australia       NC  30        Liam Lawson    Red Bull Racing Honda RBPT   \n",
              "15  Australia       NC   5  Gabriel Bortoleto           Kick Sauber Ferrari   \n",
              "16  Australia       NC  14    Fernando Alonso  Aston Martin Aramco Mercedes   \n",
              "17  Australia       NC  55       Carlos Sainz             Williams Mercedes   \n",
              "18  Australia       NC   7        Jack Doohan                Alpine Renault   \n",
              "19  Australia       NC   6       Isack Hadjar       Racing Bulls Honda RBPT   \n",
              "20      China        1  81      Oscar Piastri              McLaren Mercedes   \n",
              "21      China        2   4       Lando Norris              McLaren Mercedes   \n",
              "22      China        3  63     George Russell                      Mercedes   \n",
              "23      China        4   1     Max Verstappen    Red Bull Racing Honda RBPT   \n",
              "24      China        5  31       Esteban Ocon                  Haas Ferrari   \n",
              "25      China        6  12     Kimi Antonelli                      Mercedes   \n",
              "26      China        7  23    Alexander Albon             Williams Mercedes   \n",
              "27      China        8  87     Oliver Bearman                  Haas Ferrari   \n",
              "28      China        9  18       Lance Stroll  Aston Martin Aramco Mercedes   \n",
              "29      China       10  55       Carlos Sainz             Williams Mercedes   \n",
              "30      China       11   6       Isack Hadjar       Racing Bulls Honda RBPT   \n",
              "31      China       12  30        Liam Lawson    Red Bull Racing Honda RBPT   \n",
              "32      China       13   7        Jack Doohan                Alpine Renault   \n",
              "33      China       14   5  Gabriel Bortoleto           Kick Sauber Ferrari   \n",
              "34      China       15  27    Nico Hulkenberg           Kick Sauber Ferrari   \n",
              "35      China       16  22       Yuki Tsunoda       Racing Bulls Honda RBPT   \n",
              "36      China       NC  14    Fernando Alonso  Aston Martin Aramco Mercedes   \n",
              "37      China       DQ  16    Charles Leclerc                       Ferrari   \n",
              "38      China       DQ  44     Lewis Hamilton                       Ferrari   \n",
              "39      China       DQ  10       Pierre Gasly                Alpine Renault   \n",
              "40      Japan        1   1     Max Verstappen    Red Bull Racing Honda RBPT   \n",
              "41      Japan        2   4       Lando Norris              McLaren Mercedes   \n",
              "42      Japan        3  81      Oscar Piastri              McLaren Mercedes   \n",
              "\n",
              "    Starting Grid  Laps Time/Retired  Points Set Fastest Lap Fastest Lap Time  \\\n",
              "0               1    57  1:42:06.304      25             Yes         1:22.167   \n",
              "1               3    57       +0.895      18              No         1:23.081   \n",
              "2               4    57       +8.481      15              No         1:25.065   \n",
              "3              16    57      +10.135      12              No         1:24.901   \n",
              "4               6    57      +12.773      10              No         1:24.597   \n",
              "5              13    57      +17.413       8              No         1:25.538   \n",
              "6              17    57      +18.423       6              No         1:25.243   \n",
              "7               7    57      +19.826       4              No         1:25.271   \n",
              "8               2    57      +20.448       2              No         1:23.242   \n",
              "9               8    57      +22.473       1              No         1:24.218   \n",
              "10              9    57      +26.502       0              No         1:25.020   \n",
              "11              5    57      +29.884       0              No         1:24.194   \n",
              "12             19    57      +33.161       0              No         1:26.764   \n",
              "13             20    57      +40.351       0              No         1:27.603   \n",
              "14             18    46          DNF       0              No         1:22.970   \n",
              "15             15    45          DNF       0              No         1:24.192   \n",
              "16             12    32          DNF       0              No         1:28.819   \n",
              "17             10     0          DNF       0              No              NaN   \n",
              "18             14     0          DNF       0              No              NaN   \n",
              "19             11     0          DNF       0              No              NaN   \n",
              "20              1    56  1:30:55.026      25              No         1:35.520   \n",
              "21              3    56       +9.748      18              No         1:35.454   \n",
              "22              2    56      +11.097      15              No         1:35.816   \n",
              "23              4    56      +16.656      12              No         1:35.488   \n",
              "24             11    56      +49.969      10              No         1:35.740   \n",
              "25              8    56      +53.748       8              No         1:36.046   \n",
              "26             10    56      +56.321       6              No         1:36.254   \n",
              "27             17    56      +61.303       4              No         1:36.363   \n",
              "28             14    56      +70.204       2              No         1:36.044   \n",
              "29             15    56      +76.387       1              No         1:36.779   \n",
              "30              7    56      +78.875       0              No         1:35.868   \n",
              "31             20    56      +81.147       0              No         1:35.985   \n",
              "32             18    56      +88.401       0              No         1:36.424   \n",
              "33             19    55       +1 lap       0              No         1:35.874   \n",
              "34             12    55       +1 lap       0              No         1:37.275   \n",
              "35              9    55       +1 lap       0              No         1:35.871   \n",
              "36             13     4          DNF       0              No         1:39.256   \n",
              "37              6     0          DSQ       0              No         1:36.157   \n",
              "38              5     0          DSQ       0             Yes         1:35.069   \n",
              "39             16     0          DSQ       0              No         1:36.425   \n",
              "40              1    53  1:22:06.983      25              No         1:31.041   \n",
              "41              2    53       +1.423      18              No         1:31.116   \n",
              "42              3    53       +2.129      15              No         1:31.039   \n",
              "\n",
              "    Year  RaceOrder  \n",
              "0   2025        1.0  \n",
              "1   2025        1.0  \n",
              "2   2025        1.0  \n",
              "3   2025        1.0  \n",
              "4   2025        1.0  \n",
              "5   2025        1.0  \n",
              "6   2025        1.0  \n",
              "7   2025        1.0  \n",
              "8   2025        1.0  \n",
              "9   2025        1.0  \n",
              "10  2025        1.0  \n",
              "11  2025        1.0  \n",
              "12  2025        1.0  \n",
              "13  2025        1.0  \n",
              "14  2025        1.0  \n",
              "15  2025        1.0  \n",
              "16  2025        1.0  \n",
              "17  2025        1.0  \n",
              "18  2025        1.0  \n",
              "19  2025        1.0  \n",
              "20  2025        2.0  \n",
              "21  2025        2.0  \n",
              "22  2025        2.0  \n",
              "23  2025        2.0  \n",
              "24  2025        2.0  \n",
              "25  2025        2.0  \n",
              "26  2025        2.0  \n",
              "27  2025        2.0  \n",
              "28  2025        2.0  \n",
              "29  2025        2.0  \n",
              "30  2025        2.0  \n",
              "31  2025        2.0  \n",
              "32  2025        2.0  \n",
              "33  2025        2.0  \n",
              "34  2025        2.0  \n",
              "35  2025        2.0  \n",
              "36  2025        2.0  \n",
              "37  2025        2.0  \n",
              "38  2025        2.0  \n",
              "39  2025        2.0  \n",
              "40  2025        3.0  \n",
              "41  2025        3.0  \n",
              "42  2025        3.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0d83c2fb-0c35-40f6-9dd3-b018cfe592cc\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Track</th>\n",
              "      <th>Position</th>\n",
              "      <th>No</th>\n",
              "      <th>Driver</th>\n",
              "      <th>Team</th>\n",
              "      <th>Starting Grid</th>\n",
              "      <th>Laps</th>\n",
              "      <th>Time/Retired</th>\n",
              "      <th>Points</th>\n",
              "      <th>Set Fastest Lap</th>\n",
              "      <th>Fastest Lap Time</th>\n",
              "      <th>Year</th>\n",
              "      <th>RaceOrder</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Australia</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>Lando Norris</td>\n",
              "      <td>McLaren Mercedes</td>\n",
              "      <td>1</td>\n",
              "      <td>57</td>\n",
              "      <td>1:42:06.304</td>\n",
              "      <td>25</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1:22.167</td>\n",
              "      <td>2025</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Australia</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>Max Verstappen</td>\n",
              "      <td>Red Bull Racing Honda RBPT</td>\n",
              "      <td>3</td>\n",
              "      <td>57</td>\n",
              "      <td>+0.895</td>\n",
              "      <td>18</td>\n",
              "      <td>No</td>\n",
              "      <td>1:23.081</td>\n",
              "      <td>2025</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Australia</td>\n",
              "      <td>3</td>\n",
              "      <td>63</td>\n",
              "      <td>George Russell</td>\n",
              "      <td>Mercedes</td>\n",
              "      <td>4</td>\n",
              "      <td>57</td>\n",
              "      <td>+8.481</td>\n",
              "      <td>15</td>\n",
              "      <td>No</td>\n",
              "      <td>1:25.065</td>\n",
              "      <td>2025</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Australia</td>\n",
              "      <td>4</td>\n",
              "      <td>12</td>\n",
              "      <td>Kimi Antonelli</td>\n",
              "      <td>Mercedes</td>\n",
              "      <td>16</td>\n",
              "      <td>57</td>\n",
              "      <td>+10.135</td>\n",
              "      <td>12</td>\n",
              "      <td>No</td>\n",
              "      <td>1:24.901</td>\n",
              "      <td>2025</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Australia</td>\n",
              "      <td>5</td>\n",
              "      <td>23</td>\n",
              "      <td>Alexander Albon</td>\n",
              "      <td>Williams Mercedes</td>\n",
              "      <td>6</td>\n",
              "      <td>57</td>\n",
              "      <td>+12.773</td>\n",
              "      <td>10</td>\n",
              "      <td>No</td>\n",
              "      <td>1:24.597</td>\n",
              "      <td>2025</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Australia</td>\n",
              "      <td>6</td>\n",
              "      <td>18</td>\n",
              "      <td>Lance Stroll</td>\n",
              "      <td>Aston Martin Aramco Mercedes</td>\n",
              "      <td>13</td>\n",
              "      <td>57</td>\n",
              "      <td>+17.413</td>\n",
              "      <td>8</td>\n",
              "      <td>No</td>\n",
              "      <td>1:25.538</td>\n",
              "      <td>2025</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Australia</td>\n",
              "      <td>7</td>\n",
              "      <td>27</td>\n",
              "      <td>Nico Hulkenberg</td>\n",
              "      <td>Kick Sauber Ferrari</td>\n",
              "      <td>17</td>\n",
              "      <td>57</td>\n",
              "      <td>+18.423</td>\n",
              "      <td>6</td>\n",
              "      <td>No</td>\n",
              "      <td>1:25.243</td>\n",
              "      <td>2025</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Australia</td>\n",
              "      <td>8</td>\n",
              "      <td>16</td>\n",
              "      <td>Charles Leclerc</td>\n",
              "      <td>Ferrari</td>\n",
              "      <td>7</td>\n",
              "      <td>57</td>\n",
              "      <td>+19.826</td>\n",
              "      <td>4</td>\n",
              "      <td>No</td>\n",
              "      <td>1:25.271</td>\n",
              "      <td>2025</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Australia</td>\n",
              "      <td>9</td>\n",
              "      <td>81</td>\n",
              "      <td>Oscar Piastri</td>\n",
              "      <td>McLaren Mercedes</td>\n",
              "      <td>2</td>\n",
              "      <td>57</td>\n",
              "      <td>+20.448</td>\n",
              "      <td>2</td>\n",
              "      <td>No</td>\n",
              "      <td>1:23.242</td>\n",
              "      <td>2025</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Australia</td>\n",
              "      <td>10</td>\n",
              "      <td>44</td>\n",
              "      <td>Lewis Hamilton</td>\n",
              "      <td>Ferrari</td>\n",
              "      <td>8</td>\n",
              "      <td>57</td>\n",
              "      <td>+22.473</td>\n",
              "      <td>1</td>\n",
              "      <td>No</td>\n",
              "      <td>1:24.218</td>\n",
              "      <td>2025</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Australia</td>\n",
              "      <td>11</td>\n",
              "      <td>10</td>\n",
              "      <td>Pierre Gasly</td>\n",
              "      <td>Alpine Renault</td>\n",
              "      <td>9</td>\n",
              "      <td>57</td>\n",
              "      <td>+26.502</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>1:25.020</td>\n",
              "      <td>2025</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Australia</td>\n",
              "      <td>12</td>\n",
              "      <td>22</td>\n",
              "      <td>Yuki Tsunoda</td>\n",
              "      <td>Racing Bulls Honda RBPT</td>\n",
              "      <td>5</td>\n",
              "      <td>57</td>\n",
              "      <td>+29.884</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>1:24.194</td>\n",
              "      <td>2025</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Australia</td>\n",
              "      <td>13</td>\n",
              "      <td>31</td>\n",
              "      <td>Esteban Ocon</td>\n",
              "      <td>Haas Ferrari</td>\n",
              "      <td>19</td>\n",
              "      <td>57</td>\n",
              "      <td>+33.161</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>1:26.764</td>\n",
              "      <td>2025</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Australia</td>\n",
              "      <td>14</td>\n",
              "      <td>87</td>\n",
              "      <td>Oliver Bearman</td>\n",
              "      <td>Haas Ferrari</td>\n",
              "      <td>20</td>\n",
              "      <td>57</td>\n",
              "      <td>+40.351</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>1:27.603</td>\n",
              "      <td>2025</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Australia</td>\n",
              "      <td>NC</td>\n",
              "      <td>30</td>\n",
              "      <td>Liam Lawson</td>\n",
              "      <td>Red Bull Racing Honda RBPT</td>\n",
              "      <td>18</td>\n",
              "      <td>46</td>\n",
              "      <td>DNF</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>1:22.970</td>\n",
              "      <td>2025</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Australia</td>\n",
              "      <td>NC</td>\n",
              "      <td>5</td>\n",
              "      <td>Gabriel Bortoleto</td>\n",
              "      <td>Kick Sauber Ferrari</td>\n",
              "      <td>15</td>\n",
              "      <td>45</td>\n",
              "      <td>DNF</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>1:24.192</td>\n",
              "      <td>2025</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Australia</td>\n",
              "      <td>NC</td>\n",
              "      <td>14</td>\n",
              "      <td>Fernando Alonso</td>\n",
              "      <td>Aston Martin Aramco Mercedes</td>\n",
              "      <td>12</td>\n",
              "      <td>32</td>\n",
              "      <td>DNF</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>1:28.819</td>\n",
              "      <td>2025</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Australia</td>\n",
              "      <td>NC</td>\n",
              "      <td>55</td>\n",
              "      <td>Carlos Sainz</td>\n",
              "      <td>Williams Mercedes</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>DNF</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2025</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Australia</td>\n",
              "      <td>NC</td>\n",
              "      <td>7</td>\n",
              "      <td>Jack Doohan</td>\n",
              "      <td>Alpine Renault</td>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "      <td>DNF</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2025</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Australia</td>\n",
              "      <td>NC</td>\n",
              "      <td>6</td>\n",
              "      <td>Isack Hadjar</td>\n",
              "      <td>Racing Bulls Honda RBPT</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>DNF</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2025</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>China</td>\n",
              "      <td>1</td>\n",
              "      <td>81</td>\n",
              "      <td>Oscar Piastri</td>\n",
              "      <td>McLaren Mercedes</td>\n",
              "      <td>1</td>\n",
              "      <td>56</td>\n",
              "      <td>1:30:55.026</td>\n",
              "      <td>25</td>\n",
              "      <td>No</td>\n",
              "      <td>1:35.520</td>\n",
              "      <td>2025</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>China</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>Lando Norris</td>\n",
              "      <td>McLaren Mercedes</td>\n",
              "      <td>3</td>\n",
              "      <td>56</td>\n",
              "      <td>+9.748</td>\n",
              "      <td>18</td>\n",
              "      <td>No</td>\n",
              "      <td>1:35.454</td>\n",
              "      <td>2025</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>China</td>\n",
              "      <td>3</td>\n",
              "      <td>63</td>\n",
              "      <td>George Russell</td>\n",
              "      <td>Mercedes</td>\n",
              "      <td>2</td>\n",
              "      <td>56</td>\n",
              "      <td>+11.097</td>\n",
              "      <td>15</td>\n",
              "      <td>No</td>\n",
              "      <td>1:35.816</td>\n",
              "      <td>2025</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>China</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>Max Verstappen</td>\n",
              "      <td>Red Bull Racing Honda RBPT</td>\n",
              "      <td>4</td>\n",
              "      <td>56</td>\n",
              "      <td>+16.656</td>\n",
              "      <td>12</td>\n",
              "      <td>No</td>\n",
              "      <td>1:35.488</td>\n",
              "      <td>2025</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>China</td>\n",
              "      <td>5</td>\n",
              "      <td>31</td>\n",
              "      <td>Esteban Ocon</td>\n",
              "      <td>Haas Ferrari</td>\n",
              "      <td>11</td>\n",
              "      <td>56</td>\n",
              "      <td>+49.969</td>\n",
              "      <td>10</td>\n",
              "      <td>No</td>\n",
              "      <td>1:35.740</td>\n",
              "      <td>2025</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>China</td>\n",
              "      <td>6</td>\n",
              "      <td>12</td>\n",
              "      <td>Kimi Antonelli</td>\n",
              "      <td>Mercedes</td>\n",
              "      <td>8</td>\n",
              "      <td>56</td>\n",
              "      <td>+53.748</td>\n",
              "      <td>8</td>\n",
              "      <td>No</td>\n",
              "      <td>1:36.046</td>\n",
              "      <td>2025</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>China</td>\n",
              "      <td>7</td>\n",
              "      <td>23</td>\n",
              "      <td>Alexander Albon</td>\n",
              "      <td>Williams Mercedes</td>\n",
              "      <td>10</td>\n",
              "      <td>56</td>\n",
              "      <td>+56.321</td>\n",
              "      <td>6</td>\n",
              "      <td>No</td>\n",
              "      <td>1:36.254</td>\n",
              "      <td>2025</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>China</td>\n",
              "      <td>8</td>\n",
              "      <td>87</td>\n",
              "      <td>Oliver Bearman</td>\n",
              "      <td>Haas Ferrari</td>\n",
              "      <td>17</td>\n",
              "      <td>56</td>\n",
              "      <td>+61.303</td>\n",
              "      <td>4</td>\n",
              "      <td>No</td>\n",
              "      <td>1:36.363</td>\n",
              "      <td>2025</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>China</td>\n",
              "      <td>9</td>\n",
              "      <td>18</td>\n",
              "      <td>Lance Stroll</td>\n",
              "      <td>Aston Martin Aramco Mercedes</td>\n",
              "      <td>14</td>\n",
              "      <td>56</td>\n",
              "      <td>+70.204</td>\n",
              "      <td>2</td>\n",
              "      <td>No</td>\n",
              "      <td>1:36.044</td>\n",
              "      <td>2025</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>China</td>\n",
              "      <td>10</td>\n",
              "      <td>55</td>\n",
              "      <td>Carlos Sainz</td>\n",
              "      <td>Williams Mercedes</td>\n",
              "      <td>15</td>\n",
              "      <td>56</td>\n",
              "      <td>+76.387</td>\n",
              "      <td>1</td>\n",
              "      <td>No</td>\n",
              "      <td>1:36.779</td>\n",
              "      <td>2025</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>China</td>\n",
              "      <td>11</td>\n",
              "      <td>6</td>\n",
              "      <td>Isack Hadjar</td>\n",
              "      <td>Racing Bulls Honda RBPT</td>\n",
              "      <td>7</td>\n",
              "      <td>56</td>\n",
              "      <td>+78.875</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>1:35.868</td>\n",
              "      <td>2025</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>China</td>\n",
              "      <td>12</td>\n",
              "      <td>30</td>\n",
              "      <td>Liam Lawson</td>\n",
              "      <td>Red Bull Racing Honda RBPT</td>\n",
              "      <td>20</td>\n",
              "      <td>56</td>\n",
              "      <td>+81.147</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>1:35.985</td>\n",
              "      <td>2025</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>China</td>\n",
              "      <td>13</td>\n",
              "      <td>7</td>\n",
              "      <td>Jack Doohan</td>\n",
              "      <td>Alpine Renault</td>\n",
              "      <td>18</td>\n",
              "      <td>56</td>\n",
              "      <td>+88.401</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>1:36.424</td>\n",
              "      <td>2025</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>China</td>\n",
              "      <td>14</td>\n",
              "      <td>5</td>\n",
              "      <td>Gabriel Bortoleto</td>\n",
              "      <td>Kick Sauber Ferrari</td>\n",
              "      <td>19</td>\n",
              "      <td>55</td>\n",
              "      <td>+1 lap</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>1:35.874</td>\n",
              "      <td>2025</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>China</td>\n",
              "      <td>15</td>\n",
              "      <td>27</td>\n",
              "      <td>Nico Hulkenberg</td>\n",
              "      <td>Kick Sauber Ferrari</td>\n",
              "      <td>12</td>\n",
              "      <td>55</td>\n",
              "      <td>+1 lap</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>1:37.275</td>\n",
              "      <td>2025</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>China</td>\n",
              "      <td>16</td>\n",
              "      <td>22</td>\n",
              "      <td>Yuki Tsunoda</td>\n",
              "      <td>Racing Bulls Honda RBPT</td>\n",
              "      <td>9</td>\n",
              "      <td>55</td>\n",
              "      <td>+1 lap</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>1:35.871</td>\n",
              "      <td>2025</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>China</td>\n",
              "      <td>NC</td>\n",
              "      <td>14</td>\n",
              "      <td>Fernando Alonso</td>\n",
              "      <td>Aston Martin Aramco Mercedes</td>\n",
              "      <td>13</td>\n",
              "      <td>4</td>\n",
              "      <td>DNF</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>1:39.256</td>\n",
              "      <td>2025</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>China</td>\n",
              "      <td>DQ</td>\n",
              "      <td>16</td>\n",
              "      <td>Charles Leclerc</td>\n",
              "      <td>Ferrari</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>DSQ</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>1:36.157</td>\n",
              "      <td>2025</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>China</td>\n",
              "      <td>DQ</td>\n",
              "      <td>44</td>\n",
              "      <td>Lewis Hamilton</td>\n",
              "      <td>Ferrari</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>DSQ</td>\n",
              "      <td>0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1:35.069</td>\n",
              "      <td>2025</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>China</td>\n",
              "      <td>DQ</td>\n",
              "      <td>10</td>\n",
              "      <td>Pierre Gasly</td>\n",
              "      <td>Alpine Renault</td>\n",
              "      <td>16</td>\n",
              "      <td>0</td>\n",
              "      <td>DSQ</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>1:36.425</td>\n",
              "      <td>2025</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>Japan</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Max Verstappen</td>\n",
              "      <td>Red Bull Racing Honda RBPT</td>\n",
              "      <td>1</td>\n",
              "      <td>53</td>\n",
              "      <td>1:22:06.983</td>\n",
              "      <td>25</td>\n",
              "      <td>No</td>\n",
              "      <td>1:31.041</td>\n",
              "      <td>2025</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>Japan</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>Lando Norris</td>\n",
              "      <td>McLaren Mercedes</td>\n",
              "      <td>2</td>\n",
              "      <td>53</td>\n",
              "      <td>+1.423</td>\n",
              "      <td>18</td>\n",
              "      <td>No</td>\n",
              "      <td>1:31.116</td>\n",
              "      <td>2025</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>Japan</td>\n",
              "      <td>3</td>\n",
              "      <td>81</td>\n",
              "      <td>Oscar Piastri</td>\n",
              "      <td>McLaren Mercedes</td>\n",
              "      <td>3</td>\n",
              "      <td>53</td>\n",
              "      <td>+2.129</td>\n",
              "      <td>15</td>\n",
              "      <td>No</td>\n",
              "      <td>1:31.039</td>\n",
              "      <td>2025</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0d83c2fb-0c35-40f6-9dd3-b018cfe592cc')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0d83c2fb-0c35-40f6-9dd3-b018cfe592cc button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0d83c2fb-0c35-40f6-9dd3-b018cfe592cc');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-ac8378a6-e968-4fa4-b959-154343510d8c\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ac8378a6-e968-4fa4-b959-154343510d8c')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-ac8378a6-e968-4fa4-b959-154343510d8c button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df2025",
              "summary": "{\n  \"name\": \"df2025\",\n  \"rows\": 259,\n  \"fields\": [\n    {\n      \"column\": \"Track\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 13,\n        \"samples\": [\n          \"Great Britain\",\n          \"Canada\",\n          \"Australia\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Position\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 22,\n        \"samples\": [\n          \"1\",\n          \"14\",\n          \"9\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"No\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 24,\n        \"min\": 1,\n        \"max\": 87,\n        \"num_unique_values\": 21,\n        \"samples\": [\n          4,\n          55,\n          5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Driver\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 21,\n        \"samples\": [\n          \"Lando Norris\",\n          \"Carlos Sainz\",\n          \"Gabriel Bortoleto\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Team\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"Racing Bulls Honda RBPT\",\n          \"Red Bull Racing Honda RBPT\",\n          \"Kick Sauber Ferrari\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Starting Grid\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5,\n        \"min\": 1,\n        \"max\": 20,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          1,\n          10,\n          15\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Laps\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 17,\n        \"min\": 0,\n        \"max\": 78,\n        \"num_unique_values\": 33,\n        \"samples\": [\n          3,\n          27,\n          68\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Time/Retired\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 184,\n        \"samples\": [\n          \"+49.969\",\n          \"+62.122\",\n          \"+59.857\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Points\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7,\n        \"min\": 0,\n        \"max\": 25,\n        \"num_unique_values\": 11,\n        \"samples\": [\n          8,\n          25,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Set Fastest Lap\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"No\",\n          \"Yes\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Fastest Lap Time\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 246,\n        \"samples\": [\n          \"1:39.256\",\n          \"1:25.243\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Year\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 2025,\n        \"max\": 2025,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          2025\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"RaceOrder\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.7540595886705033,\n        \"min\": 1.0,\n        \"max\": 13.0,\n        \"num_unique_values\": 13,\n        \"samples\": [\n          12.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Combine and clean all of the data"
      ],
      "metadata": {
        "id": "sk4YCWRSIfEl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fullDf = pd.concat([df2022, df2023, df2024, df2025])"
      ],
      "metadata": {
        "id": "FYBpbZZ6ImqA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fullDf[fullDf['Year'] == 2023].head(20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y3W-QnE1JDca",
        "outputId": "98b894e1-bf07-447a-98fb-9b931439a0f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Track Position  No           Driver                          Team  \\\n",
              "0   Bahrain        1   1   Max Verstappen    Red Bull Racing Honda RBPT   \n",
              "1   Bahrain        2  11     Sergio Perez    Red Bull Racing Honda RBPT   \n",
              "2   Bahrain        3  14  Fernando Alonso  Aston Martin Aramco Mercedes   \n",
              "3   Bahrain        4  55     Carlos Sainz                       Ferrari   \n",
              "4   Bahrain        5  44   Lewis Hamilton                      Mercedes   \n",
              "5   Bahrain        6  18     Lance Stroll  Aston Martin Aramco Mercedes   \n",
              "6   Bahrain        7  63   George Russell                      Mercedes   \n",
              "7   Bahrain        8  77  Valtteri Bottas            Alfa Romeo Ferrari   \n",
              "8   Bahrain        9  10     Pierre Gasly                Alpine Renault   \n",
              "9   Bahrain       10  23  Alexander Albon             Williams Mercedes   \n",
              "10  Bahrain       11  22     Yuki Tsunoda         AlphaTauri Honda RBPT   \n",
              "11  Bahrain       12   2   Logan Sargeant             Williams Mercedes   \n",
              "12  Bahrain       13  20  Kevin Magnussen                  Haas Ferrari   \n",
              "13  Bahrain       14  21    Nyck De Vries         AlphaTauri Honda RBPT   \n",
              "14  Bahrain       15  27  Nico Hulkenberg                  Haas Ferrari   \n",
              "15  Bahrain       16  24      Guanyu Zhou            Alfa Romeo Ferrari   \n",
              "16  Bahrain       17   4     Lando Norris              McLaren Mercedes   \n",
              "17  Bahrain       NC  31     Esteban Ocon                Alpine Renault   \n",
              "18  Bahrain       NC  16  Charles Leclerc                       Ferrari   \n",
              "19  Bahrain       NC  81    Oscar Piastri              McLaren Mercedes   \n",
              "\n",
              "    Starting Grid  Laps Time/Retired  Points Set Fastest Lap Fastest Lap  \\\n",
              "0               1    57  1:33:56.736      25              No         NaN   \n",
              "1               2    57      +11.987      18              No         NaN   \n",
              "2               5    57      +38.637      15              No         NaN   \n",
              "3               4    57      +48.052      12              No         NaN   \n",
              "4               7    57      +50.977      10              No         NaN   \n",
              "5               8    57      +54.502       8              No         NaN   \n",
              "6               6    57      +55.873       6              No         NaN   \n",
              "7              12    57      +72.647       4              No         NaN   \n",
              "8              20    57      +73.753       2              No         NaN   \n",
              "9              15    57      +89.774       1              No         NaN   \n",
              "10             14    57      +90.870       0              No         NaN   \n",
              "11             16    56       +1 lap       0              No         NaN   \n",
              "12             17    56       +1 lap       0              No         NaN   \n",
              "13             19    56       +1 lap       0              No         NaN   \n",
              "14             10    56       +1 lap       0              No         NaN   \n",
              "15             13    56       +1 lap       0             Yes         NaN   \n",
              "16             11    55      +2 laps       0              No         NaN   \n",
              "17              9    41          DNF       0              No         NaN   \n",
              "18              3    39          DNF       0              No         NaN   \n",
              "19             18    13          DNF       0              No         NaN   \n",
              "\n",
              "    Year  TrackOrder  RaceOrder Fastest Lap Time  \n",
              "0   2023         NaN        1.0         1:36.236  \n",
              "1   2023         NaN        1.0         1:36.344  \n",
              "2   2023         NaN        1.0         1:36.156  \n",
              "3   2023         NaN        1.0         1:37.130  \n",
              "4   2023         NaN        1.0         1:36.546  \n",
              "5   2023         NaN        1.0         1:36.546  \n",
              "6   2023         NaN        1.0         1:37.221  \n",
              "7   2023         NaN        1.0         1:37.379  \n",
              "8   2023         NaN        1.0         1:35.068  \n",
              "9   2023         NaN        1.0         1:37.144  \n",
              "10  2023         NaN        1.0         1:36.637  \n",
              "11  2023         NaN        1.0         1:36.037  \n",
              "12  2023         NaN        1.0         1:36.471  \n",
              "13  2023         NaN        1.0         1:37.709  \n",
              "14  2023         NaN        1.0         1:36.616  \n",
              "15  2023         NaN        1.0         1:33.996  \n",
              "16  2023         NaN        1.0         1:35.822  \n",
              "17  2023         NaN        1.0         1:36.797  \n",
              "18  2023         NaN        1.0         1:37.170  \n",
              "19  2023         NaN        1.0         1:40.691  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-711ca268-73c2-429e-9eea-7bd799f2fdab\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Track</th>\n",
              "      <th>Position</th>\n",
              "      <th>No</th>\n",
              "      <th>Driver</th>\n",
              "      <th>Team</th>\n",
              "      <th>Starting Grid</th>\n",
              "      <th>Laps</th>\n",
              "      <th>Time/Retired</th>\n",
              "      <th>Points</th>\n",
              "      <th>Set Fastest Lap</th>\n",
              "      <th>Fastest Lap</th>\n",
              "      <th>Year</th>\n",
              "      <th>TrackOrder</th>\n",
              "      <th>RaceOrder</th>\n",
              "      <th>Fastest Lap Time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bahrain</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Max Verstappen</td>\n",
              "      <td>Red Bull Racing Honda RBPT</td>\n",
              "      <td>1</td>\n",
              "      <td>57</td>\n",
              "      <td>1:33:56.736</td>\n",
              "      <td>25</td>\n",
              "      <td>No</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2023</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1:36.236</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Bahrain</td>\n",
              "      <td>2</td>\n",
              "      <td>11</td>\n",
              "      <td>Sergio Perez</td>\n",
              "      <td>Red Bull Racing Honda RBPT</td>\n",
              "      <td>2</td>\n",
              "      <td>57</td>\n",
              "      <td>+11.987</td>\n",
              "      <td>18</td>\n",
              "      <td>No</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2023</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1:36.344</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Bahrain</td>\n",
              "      <td>3</td>\n",
              "      <td>14</td>\n",
              "      <td>Fernando Alonso</td>\n",
              "      <td>Aston Martin Aramco Mercedes</td>\n",
              "      <td>5</td>\n",
              "      <td>57</td>\n",
              "      <td>+38.637</td>\n",
              "      <td>15</td>\n",
              "      <td>No</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2023</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1:36.156</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Bahrain</td>\n",
              "      <td>4</td>\n",
              "      <td>55</td>\n",
              "      <td>Carlos Sainz</td>\n",
              "      <td>Ferrari</td>\n",
              "      <td>4</td>\n",
              "      <td>57</td>\n",
              "      <td>+48.052</td>\n",
              "      <td>12</td>\n",
              "      <td>No</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2023</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1:37.130</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Bahrain</td>\n",
              "      <td>5</td>\n",
              "      <td>44</td>\n",
              "      <td>Lewis Hamilton</td>\n",
              "      <td>Mercedes</td>\n",
              "      <td>7</td>\n",
              "      <td>57</td>\n",
              "      <td>+50.977</td>\n",
              "      <td>10</td>\n",
              "      <td>No</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2023</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1:36.546</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Bahrain</td>\n",
              "      <td>6</td>\n",
              "      <td>18</td>\n",
              "      <td>Lance Stroll</td>\n",
              "      <td>Aston Martin Aramco Mercedes</td>\n",
              "      <td>8</td>\n",
              "      <td>57</td>\n",
              "      <td>+54.502</td>\n",
              "      <td>8</td>\n",
              "      <td>No</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2023</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1:36.546</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Bahrain</td>\n",
              "      <td>7</td>\n",
              "      <td>63</td>\n",
              "      <td>George Russell</td>\n",
              "      <td>Mercedes</td>\n",
              "      <td>6</td>\n",
              "      <td>57</td>\n",
              "      <td>+55.873</td>\n",
              "      <td>6</td>\n",
              "      <td>No</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2023</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1:37.221</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Bahrain</td>\n",
              "      <td>8</td>\n",
              "      <td>77</td>\n",
              "      <td>Valtteri Bottas</td>\n",
              "      <td>Alfa Romeo Ferrari</td>\n",
              "      <td>12</td>\n",
              "      <td>57</td>\n",
              "      <td>+72.647</td>\n",
              "      <td>4</td>\n",
              "      <td>No</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2023</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1:37.379</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Bahrain</td>\n",
              "      <td>9</td>\n",
              "      <td>10</td>\n",
              "      <td>Pierre Gasly</td>\n",
              "      <td>Alpine Renault</td>\n",
              "      <td>20</td>\n",
              "      <td>57</td>\n",
              "      <td>+73.753</td>\n",
              "      <td>2</td>\n",
              "      <td>No</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2023</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1:35.068</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Bahrain</td>\n",
              "      <td>10</td>\n",
              "      <td>23</td>\n",
              "      <td>Alexander Albon</td>\n",
              "      <td>Williams Mercedes</td>\n",
              "      <td>15</td>\n",
              "      <td>57</td>\n",
              "      <td>+89.774</td>\n",
              "      <td>1</td>\n",
              "      <td>No</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2023</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1:37.144</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Bahrain</td>\n",
              "      <td>11</td>\n",
              "      <td>22</td>\n",
              "      <td>Yuki Tsunoda</td>\n",
              "      <td>AlphaTauri Honda RBPT</td>\n",
              "      <td>14</td>\n",
              "      <td>57</td>\n",
              "      <td>+90.870</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2023</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1:36.637</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Bahrain</td>\n",
              "      <td>12</td>\n",
              "      <td>2</td>\n",
              "      <td>Logan Sargeant</td>\n",
              "      <td>Williams Mercedes</td>\n",
              "      <td>16</td>\n",
              "      <td>56</td>\n",
              "      <td>+1 lap</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2023</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1:36.037</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Bahrain</td>\n",
              "      <td>13</td>\n",
              "      <td>20</td>\n",
              "      <td>Kevin Magnussen</td>\n",
              "      <td>Haas Ferrari</td>\n",
              "      <td>17</td>\n",
              "      <td>56</td>\n",
              "      <td>+1 lap</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2023</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1:36.471</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Bahrain</td>\n",
              "      <td>14</td>\n",
              "      <td>21</td>\n",
              "      <td>Nyck De Vries</td>\n",
              "      <td>AlphaTauri Honda RBPT</td>\n",
              "      <td>19</td>\n",
              "      <td>56</td>\n",
              "      <td>+1 lap</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2023</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1:37.709</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Bahrain</td>\n",
              "      <td>15</td>\n",
              "      <td>27</td>\n",
              "      <td>Nico Hulkenberg</td>\n",
              "      <td>Haas Ferrari</td>\n",
              "      <td>10</td>\n",
              "      <td>56</td>\n",
              "      <td>+1 lap</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2023</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1:36.616</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Bahrain</td>\n",
              "      <td>16</td>\n",
              "      <td>24</td>\n",
              "      <td>Guanyu Zhou</td>\n",
              "      <td>Alfa Romeo Ferrari</td>\n",
              "      <td>13</td>\n",
              "      <td>56</td>\n",
              "      <td>+1 lap</td>\n",
              "      <td>0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2023</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1:33.996</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Bahrain</td>\n",
              "      <td>17</td>\n",
              "      <td>4</td>\n",
              "      <td>Lando Norris</td>\n",
              "      <td>McLaren Mercedes</td>\n",
              "      <td>11</td>\n",
              "      <td>55</td>\n",
              "      <td>+2 laps</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2023</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1:35.822</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Bahrain</td>\n",
              "      <td>NC</td>\n",
              "      <td>31</td>\n",
              "      <td>Esteban Ocon</td>\n",
              "      <td>Alpine Renault</td>\n",
              "      <td>9</td>\n",
              "      <td>41</td>\n",
              "      <td>DNF</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2023</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1:36.797</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Bahrain</td>\n",
              "      <td>NC</td>\n",
              "      <td>16</td>\n",
              "      <td>Charles Leclerc</td>\n",
              "      <td>Ferrari</td>\n",
              "      <td>3</td>\n",
              "      <td>39</td>\n",
              "      <td>DNF</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2023</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1:37.170</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Bahrain</td>\n",
              "      <td>NC</td>\n",
              "      <td>81</td>\n",
              "      <td>Oscar Piastri</td>\n",
              "      <td>McLaren Mercedes</td>\n",
              "      <td>18</td>\n",
              "      <td>13</td>\n",
              "      <td>DNF</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2023</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1:40.691</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-711ca268-73c2-429e-9eea-7bd799f2fdab')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-711ca268-73c2-429e-9eea-7bd799f2fdab button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-711ca268-73c2-429e-9eea-7bd799f2fdab');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-75e9ff4b-a888-43f1-a395-39259bbc2b22\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-75e9ff4b-a888-43f1-a395-39259bbc2b22')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-75e9ff4b-a888-43f1-a395-39259bbc2b22 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "repr_error": "Out of range float values are not JSON compliant: nan"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make sure the same tracks have the same naming convention"
      ],
      "metadata": {
        "id": "GuHGLv73C7m8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fullDf['Track'] = np.where(\n",
        "    fullDf['Track'] == 'Emilia-Romagna',\n",
        "    'Emilia Romagna',\n",
        "    fullDf['Track']\n",
        ")\n"
      ],
      "metadata": {
        "id": "DvJVtE1zCgAe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fullDf['Track'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8fQ1OPpMCoZe",
        "outputId": "b1c5a3af-91bd-4a7c-d8bb-d96a9fda9f48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Bahrain', 'Saudi Arabia', 'Australia', 'Emilia Romagna', 'Miami',\n",
              "       'Spain', 'Monaco', 'Azerbaijan', 'Canada', 'Great Britain',\n",
              "       'Austria', 'France', 'Hungary', 'Belgium', 'Netherlands', 'Italy',\n",
              "       'Singapore', 'Japan', 'United States', 'Mexico', 'Brazil',\n",
              "       'Abu Dhabi', 'Qatar', 'Las Vegas', 'China'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Address teams that have gone by multiple names of the years, so they all have one name"
      ],
      "metadata": {
        "id": "tHWcjmPGC--R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Start with Haas"
      ],
      "metadata": {
        "id": "cNZJKJjGDEDQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fullDf['Team'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JKBUhSqdDF-L",
        "outputId": "7dda49de-0515-49f8-f5ec-a4c55e27da85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Ferrari', 'Mercedes', 'Haas Ferrari', 'Alfa Romeo Ferrari',\n",
              "       'Alpine Renault', 'AlphaTauri RBPT',\n",
              "       'Aston Martin Aramco Mercedes', 'Williams Mercedes',\n",
              "       'McLaren Mercedes', 'Red Bull Racing RBPT',\n",
              "       'Red Bull Racing Honda RBPT', 'AlphaTauri Honda RBPT',\n",
              "       'Kick Sauber Ferrari', 'RB Honda RBPT', 'Racing Bulls Honda RBPT'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fullDf['Team'] = np.where(\n",
        "    fullDf['Team'] == 'Haas Ferrari',\n",
        "    'Haas',\n",
        "    fullDf['Team']\n",
        ")"
      ],
      "metadata": {
        "id": "dVyGtQeWDLsk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fullDf['Team'] = np.where(\n",
        "    (fullDf['Team'] == 'Red Bull Racing RBPT') |\n",
        "    (fullDf['Team'] == 'Red Bull Racing Honda RBPT') |\n",
        "    (fullDf['Team'] == 'RB Honda RBPT'),\n",
        "    'Red Bull',\n",
        "    fullDf['Team']\n",
        ")\n"
      ],
      "metadata": {
        "id": "H_IfUNmFDSTw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fullDf['Team'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "twSn9yxLDVNN",
        "outputId": "27ca4beb-d771-40c1-c16c-f18431824a24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Ferrari', 'Mercedes', 'Haas', 'Alfa Romeo Ferrari',\n",
              "       'Alpine Renault', 'AlphaTauri RBPT',\n",
              "       'Aston Martin Aramco Mercedes', 'Williams Mercedes',\n",
              "       'McLaren Mercedes', 'Red Bull', 'AlphaTauri Honda RBPT',\n",
              "       'Kick Sauber Ferrari', 'Racing Bulls Honda RBPT'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now apply the same thing to alphatauri\n",
        "fullDf['Team'] = np.where(\n",
        "    (fullDf['Team'] == 'AlphaTauri Honda RBPT') |\n",
        "    (fullDf['Team'] == 'AlphaTauri RBPT') |\n",
        "    (fullDf['Team'] == 'Racing Bulls Honda RBPT'),\n",
        "    'Alpha Tauri',\n",
        "    fullDf['Team']\n",
        ")"
      ],
      "metadata": {
        "id": "u5nhpr79DzQr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fullDf['Team'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Py8jdJDEPOf",
        "outputId": "ad8629da-cbb2-407d-c68b-ad4813a8ad13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Ferrari', 'Mercedes', 'Haas', 'Alfa Romeo Ferrari',\n",
              "       'Alpine Renault', 'Alpha Tauri', 'Aston Martin Aramco Mercedes',\n",
              "       'Williams Mercedes', 'McLaren Mercedes', 'Red Bull',\n",
              "       'Kick Sauber Ferrari'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that I want to predic the results based on a few predictors which include track, Driver, team, year, and laps that track uses."
      ],
      "metadata": {
        "id": "_4t-pBiHJNFo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fullDf['Time/Retired'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w0_v7rX-K8tW",
        "outputId": "94053b43-f726-4daa-fe9b-13b41e953faf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['1:37:33.584', '+5.598', '+9.675', ..., '+87.924', '+92.024',\n",
              "       '+95.250'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fullDf[\"Position\"].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1yecweSBLOW9",
        "outputId": "e5d2af7f-dac6-4359-d47f-a42f6ce3b1a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12',\n",
              "       '13', '14', '15', '16', '17', '18', '19', 'NC', '20', 'DQ'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fullDf['Position'] = fullDf['Position'].replace('NC', 21)\n",
        "fullDf['Position'] = fullDf['Position'].replace('DQ', 21)"
      ],
      "metadata": {
        "id": "i66VwFgvLUkX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fullDf[\"Position\"] = fullDf[\"Position\"].astype(int)\n"
      ],
      "metadata": {
        "id": "hU8xQRmXK27g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fullDf[\"Position\"].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xCPI6sjYLexv",
        "outputId": "fd7bb585-01b3-4674-f8c2-8f0e92ee6476"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
              "       18, 19, 21, 20])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Let's build a naive model as proof of concept"
      ],
      "metadata": {
        "id": "UdsjBt9oAjY_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Because I am trying to predict winners there is certain information that I cannot assume to know such as grid position, lap times etc. I need to adjust this dataset to adjust for the factors I would know."
      ],
      "metadata": {
        "id": "_GbivfDcAmeI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "naiveDf = fullDf[['Track', 'Driver', 'Team', 'Year', 'Laps', 'Position', 'RaceOrder']]"
      ],
      "metadata": {
        "id": "MwXnZ4-1A1Jf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I now want to one hot encode the track, driver, team. I also want to solely predict the winner."
      ],
      "metadata": {
        "id": "BOEUVl7eBZz5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_encoded = pd.get_dummies(naiveDf, columns=['Track', 'Driver', 'Team', 'Year'])\n",
        "df_encoded.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZxjXnXgGBruR",
        "outputId": "3ec61eb4-0654-4a1a-b034-36754b915121"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Laps  Position  RaceOrder  Track_Abu Dhabi  Track_Australia  Track_Austria  \\\n",
              "0    57         1        1.0            False            False          False   \n",
              "1    57         2        1.0            False            False          False   \n",
              "2    57         3        1.0            False            False          False   \n",
              "3    57         4        1.0            False            False          False   \n",
              "4    57         5        1.0            False            False          False   \n",
              "\n",
              "   Track_Azerbaijan  Track_Bahrain  Track_Belgium  Track_Brazil  ...  \\\n",
              "0             False           True          False         False  ...   \n",
              "1             False           True          False         False  ...   \n",
              "2             False           True          False         False  ...   \n",
              "3             False           True          False         False  ...   \n",
              "4             False           True          False         False  ...   \n",
              "\n",
              "   Team_Haas  Team_Kick Sauber Ferrari  Team_McLaren Mercedes  Team_Mercedes  \\\n",
              "0      False                     False                  False          False   \n",
              "1      False                     False                  False          False   \n",
              "2      False                     False                  False           True   \n",
              "3      False                     False                  False           True   \n",
              "4       True                     False                  False          False   \n",
              "\n",
              "   Team_Red Bull  Team_Williams Mercedes  Year_2022  Year_2023  Year_2024  \\\n",
              "0          False                   False       True      False      False   \n",
              "1          False                   False       True      False      False   \n",
              "2          False                   False       True      False      False   \n",
              "3          False                   False       True      False      False   \n",
              "4          False                   False       True      False      False   \n",
              "\n",
              "   Year_2025  \n",
              "0      False  \n",
              "1      False  \n",
              "2      False  \n",
              "3      False  \n",
              "4      False  \n",
              "\n",
              "[5 rows x 74 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d506bdeb-0dff-449a-b141-da5432e0df1f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Laps</th>\n",
              "      <th>Position</th>\n",
              "      <th>RaceOrder</th>\n",
              "      <th>Track_Abu Dhabi</th>\n",
              "      <th>Track_Australia</th>\n",
              "      <th>Track_Austria</th>\n",
              "      <th>Track_Azerbaijan</th>\n",
              "      <th>Track_Bahrain</th>\n",
              "      <th>Track_Belgium</th>\n",
              "      <th>Track_Brazil</th>\n",
              "      <th>...</th>\n",
              "      <th>Team_Haas</th>\n",
              "      <th>Team_Kick Sauber Ferrari</th>\n",
              "      <th>Team_McLaren Mercedes</th>\n",
              "      <th>Team_Mercedes</th>\n",
              "      <th>Team_Red Bull</th>\n",
              "      <th>Team_Williams Mercedes</th>\n",
              "      <th>Year_2022</th>\n",
              "      <th>Year_2023</th>\n",
              "      <th>Year_2024</th>\n",
              "      <th>Year_2025</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>57</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>57</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>57</td>\n",
              "      <td>3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>57</td>\n",
              "      <td>4</td>\n",
              "      <td>1.0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>57</td>\n",
              "      <td>5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 74 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d506bdeb-0dff-449a-b141-da5432e0df1f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d506bdeb-0dff-449a-b141-da5432e0df1f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d506bdeb-0dff-449a-b141-da5432e0df1f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-55305f45-ed3b-46d2-b808-0880233337f5\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-55305f45-ed3b-46d2-b808-0880233337f5')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-55305f45-ed3b-46d2-b808-0880233337f5 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_encoded"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I want to add a column for year 2026"
      ],
      "metadata": {
        "id": "qJ6astiWCY-t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_encoded['Year_2026'] = 0"
      ],
      "metadata": {
        "id": "XCnhgwhBCboN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_encoded['win'] = np.where(df_encoded['Position'] == 1, 1, 0)"
      ],
      "metadata": {
        "id": "fumWJgd7GPBk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_encoded.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hr7PPmTHGTMx",
        "outputId": "32d17602-5833-40c4-8518-c61e55d1e740"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Laps  Position  RaceOrder  Track_Abu Dhabi  Track_Australia  Track_Austria  \\\n",
              "0    57         1        1.0            False            False          False   \n",
              "1    57         2        1.0            False            False          False   \n",
              "2    57         3        1.0            False            False          False   \n",
              "3    57         4        1.0            False            False          False   \n",
              "4    57         5        1.0            False            False          False   \n",
              "\n",
              "   Track_Azerbaijan  Track_Bahrain  Track_Belgium  Track_Brazil  ...  \\\n",
              "0             False           True          False         False  ...   \n",
              "1             False           True          False         False  ...   \n",
              "2             False           True          False         False  ...   \n",
              "3             False           True          False         False  ...   \n",
              "4             False           True          False         False  ...   \n",
              "\n",
              "   Team_McLaren Mercedes  Team_Mercedes  Team_Red Bull  \\\n",
              "0                  False          False          False   \n",
              "1                  False          False          False   \n",
              "2                  False           True          False   \n",
              "3                  False           True          False   \n",
              "4                  False          False          False   \n",
              "\n",
              "   Team_Williams Mercedes  Year_2022  Year_2023  Year_2024  Year_2025  \\\n",
              "0                   False       True      False      False      False   \n",
              "1                   False       True      False      False      False   \n",
              "2                   False       True      False      False      False   \n",
              "3                   False       True      False      False      False   \n",
              "4                   False       True      False      False      False   \n",
              "\n",
              "   Year_2026  win  \n",
              "0          0    1  \n",
              "1          0    0  \n",
              "2          0    0  \n",
              "3          0    0  \n",
              "4          0    0  \n",
              "\n",
              "[5 rows x 76 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-023d63c1-9ac2-4b14-b639-65bfb67ea051\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Laps</th>\n",
              "      <th>Position</th>\n",
              "      <th>RaceOrder</th>\n",
              "      <th>Track_Abu Dhabi</th>\n",
              "      <th>Track_Australia</th>\n",
              "      <th>Track_Austria</th>\n",
              "      <th>Track_Azerbaijan</th>\n",
              "      <th>Track_Bahrain</th>\n",
              "      <th>Track_Belgium</th>\n",
              "      <th>Track_Brazil</th>\n",
              "      <th>...</th>\n",
              "      <th>Team_McLaren Mercedes</th>\n",
              "      <th>Team_Mercedes</th>\n",
              "      <th>Team_Red Bull</th>\n",
              "      <th>Team_Williams Mercedes</th>\n",
              "      <th>Year_2022</th>\n",
              "      <th>Year_2023</th>\n",
              "      <th>Year_2024</th>\n",
              "      <th>Year_2025</th>\n",
              "      <th>Year_2026</th>\n",
              "      <th>win</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>57</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>57</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>57</td>\n",
              "      <td>3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>57</td>\n",
              "      <td>4</td>\n",
              "      <td>1.0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>57</td>\n",
              "      <td>5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 76 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-023d63c1-9ac2-4b14-b639-65bfb67ea051')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-023d63c1-9ac2-4b14-b639-65bfb67ea051 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-023d63c1-9ac2-4b14-b639-65bfb67ea051');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-8deff2cc-b3ad-4b44-ad38-1270325801c9\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8deff2cc-b3ad-4b44-ad38-1270325801c9')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-8deff2cc-b3ad-4b44-ad38-1270325801c9 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_encoded"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_encoded.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ADqgz5SHGWzx",
        "outputId": "3517c9f4-09e3-4138-a75d-ee2e334464f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 1618 entries, 0 to 258\n",
            "Data columns (total 76 columns):\n",
            " #   Column                             Non-Null Count  Dtype  \n",
            "---  ------                             --------------  -----  \n",
            " 0   Laps                               1618 non-null   int64  \n",
            " 1   Position                           1618 non-null   int64  \n",
            " 2   RaceOrder                          1618 non-null   float64\n",
            " 3   Track_Abu Dhabi                    1618 non-null   bool   \n",
            " 4   Track_Australia                    1618 non-null   bool   \n",
            " 5   Track_Austria                      1618 non-null   bool   \n",
            " 6   Track_Azerbaijan                   1618 non-null   bool   \n",
            " 7   Track_Bahrain                      1618 non-null   bool   \n",
            " 8   Track_Belgium                      1618 non-null   bool   \n",
            " 9   Track_Brazil                       1618 non-null   bool   \n",
            " 10  Track_Canada                       1618 non-null   bool   \n",
            " 11  Track_China                        1618 non-null   bool   \n",
            " 12  Track_Emilia Romagna               1618 non-null   bool   \n",
            " 13  Track_France                       1618 non-null   bool   \n",
            " 14  Track_Great Britain                1618 non-null   bool   \n",
            " 15  Track_Hungary                      1618 non-null   bool   \n",
            " 16  Track_Italy                        1618 non-null   bool   \n",
            " 17  Track_Japan                        1618 non-null   bool   \n",
            " 18  Track_Las Vegas                    1618 non-null   bool   \n",
            " 19  Track_Mexico                       1618 non-null   bool   \n",
            " 20  Track_Miami                        1618 non-null   bool   \n",
            " 21  Track_Monaco                       1618 non-null   bool   \n",
            " 22  Track_Netherlands                  1618 non-null   bool   \n",
            " 23  Track_Qatar                        1618 non-null   bool   \n",
            " 24  Track_Saudi Arabia                 1618 non-null   bool   \n",
            " 25  Track_Singapore                    1618 non-null   bool   \n",
            " 26  Track_Spain                        1618 non-null   bool   \n",
            " 27  Track_United States                1618 non-null   bool   \n",
            " 28  Driver_Alexander Albon             1618 non-null   bool   \n",
            " 29  Driver_Carlos Sainz                1618 non-null   bool   \n",
            " 30  Driver_Charles Leclerc             1618 non-null   bool   \n",
            " 31  Driver_Daniel Ricciardo            1618 non-null   bool   \n",
            " 32  Driver_Esteban Ocon                1618 non-null   bool   \n",
            " 33  Driver_Fernando Alonso             1618 non-null   bool   \n",
            " 34  Driver_Franco Colapinto            1618 non-null   bool   \n",
            " 35  Driver_Gabriel Bortoleto           1618 non-null   bool   \n",
            " 36  Driver_George Russell              1618 non-null   bool   \n",
            " 37  Driver_Guanyu Zhou                 1618 non-null   bool   \n",
            " 38  Driver_Isack Hadjar                1618 non-null   bool   \n",
            " 39  Driver_Jack Doohan                 1618 non-null   bool   \n",
            " 40  Driver_Kevin Magnussen             1618 non-null   bool   \n",
            " 41  Driver_Kimi Antonelli              1618 non-null   bool   \n",
            " 42  Driver_Lance Stroll                1618 non-null   bool   \n",
            " 43  Driver_Lando Norris                1618 non-null   bool   \n",
            " 44  Driver_Lewis Hamilton              1618 non-null   bool   \n",
            " 45  Driver_Liam Lawson                 1618 non-null   bool   \n",
            " 46  Driver_Logan Sargeant              1618 non-null   bool   \n",
            " 47  Driver_Max Verstappen              1618 non-null   bool   \n",
            " 48  Driver_Mick Schumacher             1618 non-null   bool   \n",
            " 49  Driver_Nicholas Latifi             1618 non-null   bool   \n",
            " 50  Driver_Nico Hulkenberg             1618 non-null   bool   \n",
            " 51  Driver_Nyck De Vries               1618 non-null   bool   \n",
            " 52  Driver_Oliver Bearman              1618 non-null   bool   \n",
            " 53  Driver_Oscar Piastri               1618 non-null   bool   \n",
            " 54  Driver_Pierre Gasly                1618 non-null   bool   \n",
            " 55  Driver_Sebastian Vettel            1618 non-null   bool   \n",
            " 56  Driver_Sergio Perez                1618 non-null   bool   \n",
            " 57  Driver_Valtteri Bottas             1618 non-null   bool   \n",
            " 58  Driver_Yuki Tsunoda                1618 non-null   bool   \n",
            " 59  Team_Alfa Romeo Ferrari            1618 non-null   bool   \n",
            " 60  Team_Alpha Tauri                   1618 non-null   bool   \n",
            " 61  Team_Alpine Renault                1618 non-null   bool   \n",
            " 62  Team_Aston Martin Aramco Mercedes  1618 non-null   bool   \n",
            " 63  Team_Ferrari                       1618 non-null   bool   \n",
            " 64  Team_Haas                          1618 non-null   bool   \n",
            " 65  Team_Kick Sauber Ferrari           1618 non-null   bool   \n",
            " 66  Team_McLaren Mercedes              1618 non-null   bool   \n",
            " 67  Team_Mercedes                      1618 non-null   bool   \n",
            " 68  Team_Red Bull                      1618 non-null   bool   \n",
            " 69  Team_Williams Mercedes             1618 non-null   bool   \n",
            " 70  Year_2022                          1618 non-null   bool   \n",
            " 71  Year_2023                          1618 non-null   bool   \n",
            " 72  Year_2024                          1618 non-null   bool   \n",
            " 73  Year_2025                          1618 non-null   bool   \n",
            " 74  Year_2026                          1618 non-null   int64  \n",
            " 75  win                                1618 non-null   int64  \n",
            "dtypes: bool(71), float64(1), int64(4)\n",
            "memory usage: 188.0 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#convert bools to ints\n",
        "df_encoded = df_encoded.astype(int)\n",
        "df_encoded.info()"
      ],
      "metadata": {
        "id": "EHoX_4w7NG8m",
        "outputId": "d45f005f-3633-4b38-d5bd-bac5aae97991",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 1618 entries, 0 to 258\n",
            "Data columns (total 76 columns):\n",
            " #   Column                             Non-Null Count  Dtype\n",
            "---  ------                             --------------  -----\n",
            " 0   Laps                               1618 non-null   int64\n",
            " 1   Position                           1618 non-null   int64\n",
            " 2   RaceOrder                          1618 non-null   int64\n",
            " 3   Track_Abu Dhabi                    1618 non-null   int64\n",
            " 4   Track_Australia                    1618 non-null   int64\n",
            " 5   Track_Austria                      1618 non-null   int64\n",
            " 6   Track_Azerbaijan                   1618 non-null   int64\n",
            " 7   Track_Bahrain                      1618 non-null   int64\n",
            " 8   Track_Belgium                      1618 non-null   int64\n",
            " 9   Track_Brazil                       1618 non-null   int64\n",
            " 10  Track_Canada                       1618 non-null   int64\n",
            " 11  Track_China                        1618 non-null   int64\n",
            " 12  Track_Emilia Romagna               1618 non-null   int64\n",
            " 13  Track_France                       1618 non-null   int64\n",
            " 14  Track_Great Britain                1618 non-null   int64\n",
            " 15  Track_Hungary                      1618 non-null   int64\n",
            " 16  Track_Italy                        1618 non-null   int64\n",
            " 17  Track_Japan                        1618 non-null   int64\n",
            " 18  Track_Las Vegas                    1618 non-null   int64\n",
            " 19  Track_Mexico                       1618 non-null   int64\n",
            " 20  Track_Miami                        1618 non-null   int64\n",
            " 21  Track_Monaco                       1618 non-null   int64\n",
            " 22  Track_Netherlands                  1618 non-null   int64\n",
            " 23  Track_Qatar                        1618 non-null   int64\n",
            " 24  Track_Saudi Arabia                 1618 non-null   int64\n",
            " 25  Track_Singapore                    1618 non-null   int64\n",
            " 26  Track_Spain                        1618 non-null   int64\n",
            " 27  Track_United States                1618 non-null   int64\n",
            " 28  Driver_Alexander Albon             1618 non-null   int64\n",
            " 29  Driver_Carlos Sainz                1618 non-null   int64\n",
            " 30  Driver_Charles Leclerc             1618 non-null   int64\n",
            " 31  Driver_Daniel Ricciardo            1618 non-null   int64\n",
            " 32  Driver_Esteban Ocon                1618 non-null   int64\n",
            " 33  Driver_Fernando Alonso             1618 non-null   int64\n",
            " 34  Driver_Franco Colapinto            1618 non-null   int64\n",
            " 35  Driver_Gabriel Bortoleto           1618 non-null   int64\n",
            " 36  Driver_George Russell              1618 non-null   int64\n",
            " 37  Driver_Guanyu Zhou                 1618 non-null   int64\n",
            " 38  Driver_Isack Hadjar                1618 non-null   int64\n",
            " 39  Driver_Jack Doohan                 1618 non-null   int64\n",
            " 40  Driver_Kevin Magnussen             1618 non-null   int64\n",
            " 41  Driver_Kimi Antonelli              1618 non-null   int64\n",
            " 42  Driver_Lance Stroll                1618 non-null   int64\n",
            " 43  Driver_Lando Norris                1618 non-null   int64\n",
            " 44  Driver_Lewis Hamilton              1618 non-null   int64\n",
            " 45  Driver_Liam Lawson                 1618 non-null   int64\n",
            " 46  Driver_Logan Sargeant              1618 non-null   int64\n",
            " 47  Driver_Max Verstappen              1618 non-null   int64\n",
            " 48  Driver_Mick Schumacher             1618 non-null   int64\n",
            " 49  Driver_Nicholas Latifi             1618 non-null   int64\n",
            " 50  Driver_Nico Hulkenberg             1618 non-null   int64\n",
            " 51  Driver_Nyck De Vries               1618 non-null   int64\n",
            " 52  Driver_Oliver Bearman              1618 non-null   int64\n",
            " 53  Driver_Oscar Piastri               1618 non-null   int64\n",
            " 54  Driver_Pierre Gasly                1618 non-null   int64\n",
            " 55  Driver_Sebastian Vettel            1618 non-null   int64\n",
            " 56  Driver_Sergio Perez                1618 non-null   int64\n",
            " 57  Driver_Valtteri Bottas             1618 non-null   int64\n",
            " 58  Driver_Yuki Tsunoda                1618 non-null   int64\n",
            " 59  Team_Alfa Romeo Ferrari            1618 non-null   int64\n",
            " 60  Team_Alpha Tauri                   1618 non-null   int64\n",
            " 61  Team_Alpine Renault                1618 non-null   int64\n",
            " 62  Team_Aston Martin Aramco Mercedes  1618 non-null   int64\n",
            " 63  Team_Ferrari                       1618 non-null   int64\n",
            " 64  Team_Haas                          1618 non-null   int64\n",
            " 65  Team_Kick Sauber Ferrari           1618 non-null   int64\n",
            " 66  Team_McLaren Mercedes              1618 non-null   int64\n",
            " 67  Team_Mercedes                      1618 non-null   int64\n",
            " 68  Team_Red Bull                      1618 non-null   int64\n",
            " 69  Team_Williams Mercedes             1618 non-null   int64\n",
            " 70  Year_2022                          1618 non-null   int64\n",
            " 71  Year_2023                          1618 non-null   int64\n",
            " 72  Year_2024                          1618 non-null   int64\n",
            " 73  Year_2025                          1618 non-null   int64\n",
            " 74  Year_2026                          1618 non-null   int64\n",
            " 75  win                                1618 non-null   int64\n",
            "dtypes: int64(76)\n",
            "memory usage: 973.3 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modelBase = df_encoded[(df_encoded['Year_2025'] == 0) & (df_encoded['Year_2024'] == 0)]\n",
        "\n",
        "x = modelBase.drop(columns=['win', 'Position', 'RaceOrder'])\n",
        "y = modelBase['win']"
      ],
      "metadata": {
        "id": "w4ljipNWGfyf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_valid, y_train, y_valid = train_test_split(x, y, test_size=0.2, random_state=42)\n",
        "df2024 = df_encoded[(df_encoded['Year_2024'] == 1)]\n",
        "x_test = df2024.drop(columns=['win', 'Position', 'RaceOrder'])\n",
        "y_test = df2024['win']"
      ],
      "metadata": {
        "id": "1cOOGpulIU8F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AuYIygv2KPmR",
        "outputId": "815cb6b1-bdf9-4034-a183-701f30d7f718"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 880 entries, 0 to 439\n",
            "Data columns (total 73 columns):\n",
            " #   Column                             Non-Null Count  Dtype\n",
            "---  ------                             --------------  -----\n",
            " 0   Laps                               880 non-null    int64\n",
            " 1   Track_Abu Dhabi                    880 non-null    int64\n",
            " 2   Track_Australia                    880 non-null    int64\n",
            " 3   Track_Austria                      880 non-null    int64\n",
            " 4   Track_Azerbaijan                   880 non-null    int64\n",
            " 5   Track_Bahrain                      880 non-null    int64\n",
            " 6   Track_Belgium                      880 non-null    int64\n",
            " 7   Track_Brazil                       880 non-null    int64\n",
            " 8   Track_Canada                       880 non-null    int64\n",
            " 9   Track_China                        880 non-null    int64\n",
            " 10  Track_Emilia Romagna               880 non-null    int64\n",
            " 11  Track_France                       880 non-null    int64\n",
            " 12  Track_Great Britain                880 non-null    int64\n",
            " 13  Track_Hungary                      880 non-null    int64\n",
            " 14  Track_Italy                        880 non-null    int64\n",
            " 15  Track_Japan                        880 non-null    int64\n",
            " 16  Track_Las Vegas                    880 non-null    int64\n",
            " 17  Track_Mexico                       880 non-null    int64\n",
            " 18  Track_Miami                        880 non-null    int64\n",
            " 19  Track_Monaco                       880 non-null    int64\n",
            " 20  Track_Netherlands                  880 non-null    int64\n",
            " 21  Track_Qatar                        880 non-null    int64\n",
            " 22  Track_Saudi Arabia                 880 non-null    int64\n",
            " 23  Track_Singapore                    880 non-null    int64\n",
            " 24  Track_Spain                        880 non-null    int64\n",
            " 25  Track_United States                880 non-null    int64\n",
            " 26  Driver_Alexander Albon             880 non-null    int64\n",
            " 27  Driver_Carlos Sainz                880 non-null    int64\n",
            " 28  Driver_Charles Leclerc             880 non-null    int64\n",
            " 29  Driver_Daniel Ricciardo            880 non-null    int64\n",
            " 30  Driver_Esteban Ocon                880 non-null    int64\n",
            " 31  Driver_Fernando Alonso             880 non-null    int64\n",
            " 32  Driver_Franco Colapinto            880 non-null    int64\n",
            " 33  Driver_Gabriel Bortoleto           880 non-null    int64\n",
            " 34  Driver_George Russell              880 non-null    int64\n",
            " 35  Driver_Guanyu Zhou                 880 non-null    int64\n",
            " 36  Driver_Isack Hadjar                880 non-null    int64\n",
            " 37  Driver_Jack Doohan                 880 non-null    int64\n",
            " 38  Driver_Kevin Magnussen             880 non-null    int64\n",
            " 39  Driver_Kimi Antonelli              880 non-null    int64\n",
            " 40  Driver_Lance Stroll                880 non-null    int64\n",
            " 41  Driver_Lando Norris                880 non-null    int64\n",
            " 42  Driver_Lewis Hamilton              880 non-null    int64\n",
            " 43  Driver_Liam Lawson                 880 non-null    int64\n",
            " 44  Driver_Logan Sargeant              880 non-null    int64\n",
            " 45  Driver_Max Verstappen              880 non-null    int64\n",
            " 46  Driver_Mick Schumacher             880 non-null    int64\n",
            " 47  Driver_Nicholas Latifi             880 non-null    int64\n",
            " 48  Driver_Nico Hulkenberg             880 non-null    int64\n",
            " 49  Driver_Nyck De Vries               880 non-null    int64\n",
            " 50  Driver_Oliver Bearman              880 non-null    int64\n",
            " 51  Driver_Oscar Piastri               880 non-null    int64\n",
            " 52  Driver_Pierre Gasly                880 non-null    int64\n",
            " 53  Driver_Sebastian Vettel            880 non-null    int64\n",
            " 54  Driver_Sergio Perez                880 non-null    int64\n",
            " 55  Driver_Valtteri Bottas             880 non-null    int64\n",
            " 56  Driver_Yuki Tsunoda                880 non-null    int64\n",
            " 57  Team_Alfa Romeo Ferrari            880 non-null    int64\n",
            " 58  Team_Alpha Tauri                   880 non-null    int64\n",
            " 59  Team_Alpine Renault                880 non-null    int64\n",
            " 60  Team_Aston Martin Aramco Mercedes  880 non-null    int64\n",
            " 61  Team_Ferrari                       880 non-null    int64\n",
            " 62  Team_Haas                          880 non-null    int64\n",
            " 63  Team_Kick Sauber Ferrari           880 non-null    int64\n",
            " 64  Team_McLaren Mercedes              880 non-null    int64\n",
            " 65  Team_Mercedes                      880 non-null    int64\n",
            " 66  Team_Red Bull                      880 non-null    int64\n",
            " 67  Team_Williams Mercedes             880 non-null    int64\n",
            " 68  Year_2022                          880 non-null    int64\n",
            " 69  Year_2023                          880 non-null    int64\n",
            " 70  Year_2024                          880 non-null    int64\n",
            " 71  Year_2025                          880 non-null    int64\n",
            " 72  Year_2026                          880 non-null    int64\n",
            "dtypes: int64(73)\n",
            "memory usage: 508.8 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's ensure the years included are correct"
      ],
      "metadata": {
        "id": "OHLNcCej2YzC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modelBase['Year_2025'].unique()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vz4l6GJ52d0H",
        "outputId": "f688f48e-5d08-4a96-eecd-4aa2555c484e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modelBase['Year_2026'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x9P2gt9A2irQ",
        "outputId": "dfc5a5b7-1ac6-4ba3-8ba6-fd83260d137f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modelBase['Year_2024'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EgvVHlv32koh",
        "outputId": "ef573e33-d54c-487e-be58-76c85cbe0822"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modelBase['Year_2023'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q99RpWAru0OH",
        "outputId": "1c533b7a-b107-4e7f-df1d-f6d5f87c3896"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modelBase['Year_2022'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0EAg0l2yu2Km",
        "outputId": "5224b8b1-0be4-49a2-c191-79dc44c58f7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[73, 1]),\n",
        "    keras.layers.Dense(30, activation=\"relu\"),\n",
        "    keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "model.compile(loss=\"mse\", optimizer=\"adam\", metrics = [\"accuracy\"])\n",
        "history = model.fit(x_train, y_train, epochs=20,\n",
        "                    validation_data=(x_valid, y_valid))\n",
        "model.evaluate(x_test, y_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UyCU02L5HAqq",
        "outputId": "b70da3d1-a9e3-4a19-d591-beefc5dd4649"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.0717 - loss: 159.8018 - val_accuracy: 0.0511 - val_loss: 57.2754\n",
            "Epoch 2/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0891 - loss: 37.6832 - val_accuracy: 0.0795 - val_loss: 5.9510\n",
            "Epoch 3/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.1983 - loss: 3.1494 - val_accuracy: 0.9261 - val_loss: 0.1123\n",
            "Epoch 4/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9288 - loss: 0.1672 - val_accuracy: 0.9716 - val_loss: 0.1338\n",
            "Epoch 5/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9485 - loss: 0.1621 - val_accuracy: 0.9602 - val_loss: 0.0947\n",
            "Epoch 6/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9243 - loss: 0.1283 - val_accuracy: 0.9432 - val_loss: 0.0962\n",
            "Epoch 7/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9204 - loss: 0.1257 - val_accuracy: 0.9545 - val_loss: 0.0897\n",
            "Epoch 8/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9284 - loss: 0.1191 - val_accuracy: 0.9432 - val_loss: 0.0895\n",
            "Epoch 9/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9318 - loss: 0.1137 - val_accuracy: 0.9602 - val_loss: 0.0805\n",
            "Epoch 10/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9379 - loss: 0.1068 - val_accuracy: 0.9545 - val_loss: 0.0773\n",
            "Epoch 11/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9370 - loss: 0.0988 - val_accuracy: 0.9659 - val_loss: 0.0694\n",
            "Epoch 12/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9420 - loss: 0.0873 - val_accuracy: 0.9659 - val_loss: 0.0616\n",
            "Epoch 13/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9429 - loss: 0.0752 - val_accuracy: 0.9716 - val_loss: 0.0527\n",
            "Epoch 14/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9453 - loss: 0.0643 - val_accuracy: 0.9716 - val_loss: 0.0439\n",
            "Epoch 15/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9517 - loss: 0.0539 - val_accuracy: 0.9716 - val_loss: 0.0367\n",
            "Epoch 16/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9556 - loss: 0.0449 - val_accuracy: 0.9830 - val_loss: 0.0311\n",
            "Epoch 17/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9636 - loss: 0.0380 - val_accuracy: 0.9830 - val_loss: 0.0272\n",
            "Epoch 18/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9758 - loss: 0.0330 - val_accuracy: 0.9886 - val_loss: 0.0244\n",
            "Epoch 19/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9768 - loss: 0.0294 - val_accuracy: 0.9886 - val_loss: 0.0220\n",
            "Epoch 20/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9834 - loss: 0.0263 - val_accuracy: 0.9886 - val_loss: 0.0206\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9389 - loss: 0.0807 \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.08830524235963821, 0.9394571781158447]"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "My first model I was able to achieve 94% accuracy. Now if baseline assumption is just guessing no for everyone, then I would achieve 95% accuracy. Let's see if I can improve my overall accuracy."
      ],
      "metadata": {
        "id": "XOKPXFN01Vn1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[73, 1]),\n",
        "    keras.layers.Dense(32, activation=\"relu\"),\n",
        "    keras.layers.Dense(64, activation=\"relu\"),\n",
        "    keras.layers.Dense(128, activation=\"relu\"),\n",
        "    keras.layers.Dense(64, activation=\"relu\"),\n",
        "    keras.layers.Dense(32, activation=\"relu\"),\n",
        "    keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "model.compile(loss=\"mse\", optimizer=\"adam\", metrics = [\"accuracy\"])\n",
        "history = model.fit(x_train, y_train, epochs=20,\n",
        "                    validation_data=(x_valid, y_valid))\n",
        "model.evaluate(x_test, y_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hp8BfL3B1mLq",
        "outputId": "5600cd84-f283-4784-942b-8e425bf21b68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.6826 - loss: 0.6526 - val_accuracy: 0.9716 - val_loss: 0.0431\n",
            "Epoch 2/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9521 - loss: 0.0606 - val_accuracy: 0.9716 - val_loss: 0.0271\n",
            "Epoch 3/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9521 - loss: 0.0446 - val_accuracy: 0.9716 - val_loss: 0.0302\n",
            "Epoch 4/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9521 - loss: 0.0445 - val_accuracy: 0.9716 - val_loss: 0.0318\n",
            "Epoch 5/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9521 - loss: 0.0444 - val_accuracy: 0.9716 - val_loss: 0.0310\n",
            "Epoch 6/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9521 - loss: 0.0430 - val_accuracy: 0.9716 - val_loss: 0.0253\n",
            "Epoch 7/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9521 - loss: 0.0394 - val_accuracy: 0.9716 - val_loss: 0.0222\n",
            "Epoch 8/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9521 - loss: 0.0357 - val_accuracy: 0.9716 - val_loss: 0.0206\n",
            "Epoch 9/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9521 - loss: 0.0324 - val_accuracy: 0.9716 - val_loss: 0.0190\n",
            "Epoch 10/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9521 - loss: 0.0291 - val_accuracy: 0.9716 - val_loss: 0.0179\n",
            "Epoch 11/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9548 - loss: 0.0262 - val_accuracy: 0.9830 - val_loss: 0.0181\n",
            "Epoch 12/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9721 - loss: 0.0241 - val_accuracy: 0.9886 - val_loss: 0.0186\n",
            "Epoch 13/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9786 - loss: 0.0221 - val_accuracy: 0.9886 - val_loss: 0.0146\n",
            "Epoch 14/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9832 - loss: 0.0197 - val_accuracy: 0.9886 - val_loss: 0.0160\n",
            "Epoch 15/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9832 - loss: 0.0194 - val_accuracy: 0.9886 - val_loss: 0.0161\n",
            "Epoch 16/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9834 - loss: 0.0187 - val_accuracy: 0.9886 - val_loss: 0.0153\n",
            "Epoch 17/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9834 - loss: 0.0184 - val_accuracy: 0.9886 - val_loss: 0.0150\n",
            "Epoch 18/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9834 - loss: 0.0170 - val_accuracy: 0.9886 - val_loss: 0.0125\n",
            "Epoch 19/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9834 - loss: 0.0171 - val_accuracy: 0.9886 - val_loss: 0.0140\n",
            "Epoch 20/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9834 - loss: 0.0179 - val_accuracy: 0.9886 - val_loss: 0.0140\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9586 - loss: 0.0421 \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.05499668046832085, 0.9394571781158447]"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "My accuracy with this model was 96.87 when using the 2022 and 2023 data to predict the 2024 season."
      ],
      "metadata": {
        "id": "OqOay_b21zPp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "How many of the seasons winners did I actually predict to win"
      ],
      "metadata": {
        "id": "hi_-_jESGZnC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "beuR1TzFHYtP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#extract the actual winning rows in the data and weather or not my model predicted them to win\n",
        "compare2024 = df_encoded[(df_encoded['Year_2024'] == 1)]\n",
        "\n",
        "#now the predictions are inputed for each row\n",
        "compare2024['predicted'] = model.predict(x_test)\n",
        "compare2024.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y5wxG_AhGdQU",
        "outputId": "a8dc6dcc-7ece-42e6-873f-4e27e0190899"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3205404776.py:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  compare2024['predicted'] = model.predict(x_test)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Laps  Position  RaceOrder  Track_Abu Dhabi  Track_Australia  Track_Austria  \\\n",
              "0    57         1          1                0                0              0   \n",
              "1    57         2          1                0                0              0   \n",
              "2    57         3          1                0                0              0   \n",
              "3    57         4          1                0                0              0   \n",
              "4    57         5          1                0                0              0   \n",
              "\n",
              "   Track_Azerbaijan  Track_Bahrain  Track_Belgium  Track_Brazil  ...  \\\n",
              "0                 0              1              0             0  ...   \n",
              "1                 0              1              0             0  ...   \n",
              "2                 0              1              0             0  ...   \n",
              "3                 0              1              0             0  ...   \n",
              "4                 0              1              0             0  ...   \n",
              "\n",
              "   Team_Mercedes  Team_Red Bull  Team_Williams Mercedes  Year_2022  Year_2023  \\\n",
              "0              0              1                       0          0          0   \n",
              "1              0              1                       0          0          0   \n",
              "2              0              0                       0          0          0   \n",
              "3              0              0                       0          0          0   \n",
              "4              1              0                       0          0          0   \n",
              "\n",
              "   Year_2024  Year_2025  Year_2026  win  predicted  \n",
              "0          1          0          0    1   0.723244  \n",
              "1          1          0          0    0   0.126216  \n",
              "2          1          0          0    0   0.054336  \n",
              "3          1          0          0    0   0.093771  \n",
              "4          1          0          0    0   0.026016  \n",
              "\n",
              "[5 rows x 77 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ac92ba43-4c61-422b-b993-7f8f2caca70c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Laps</th>\n",
              "      <th>Position</th>\n",
              "      <th>RaceOrder</th>\n",
              "      <th>Track_Abu Dhabi</th>\n",
              "      <th>Track_Australia</th>\n",
              "      <th>Track_Austria</th>\n",
              "      <th>Track_Azerbaijan</th>\n",
              "      <th>Track_Bahrain</th>\n",
              "      <th>Track_Belgium</th>\n",
              "      <th>Track_Brazil</th>\n",
              "      <th>...</th>\n",
              "      <th>Team_Mercedes</th>\n",
              "      <th>Team_Red Bull</th>\n",
              "      <th>Team_Williams Mercedes</th>\n",
              "      <th>Year_2022</th>\n",
              "      <th>Year_2023</th>\n",
              "      <th>Year_2024</th>\n",
              "      <th>Year_2025</th>\n",
              "      <th>Year_2026</th>\n",
              "      <th>win</th>\n",
              "      <th>predicted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>57</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.723244</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>57</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.126216</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>57</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.054336</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>57</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.093771</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>57</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.026016</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 77 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ac92ba43-4c61-422b-b993-7f8f2caca70c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ac92ba43-4c61-422b-b993-7f8f2caca70c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ac92ba43-4c61-422b-b993-7f8f2caca70c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-bd3cc30d-81fe-4329-9437-a83cf2838944\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bd3cc30d-81fe-4329-9437-a83cf2838944')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-bd3cc30d-81fe-4329-9437-a83cf2838944 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "compare2024"
            }
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model that has the highest predicted value for each race is the predicted winner of that race"
      ],
      "metadata": {
        "id": "1pEpXWlmHw2y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Identify one-hot columns\n",
        "track_cols = [c for c in compare2024.columns if c.startswith(\"Track_\")]\n",
        "year_cols = [c for c in compare2024.columns if c.startswith(\"Year_\")]\n",
        "team_cols = [c for c in compare2024.columns if c.startswith(\"Team_\")]\n",
        "driver_cols = [c for c in compare2024.columns if c.startswith(\"Driver_\")]\n",
        "\n",
        "# Recover track names from one-hot encoding\n",
        "compare2024[\"track\"] = compare2024[track_cols].idxmax(axis=1).str.replace(\"Track_\", \"\", regex=False)\n",
        "compare2024[\"Driver\"] = compare2024[driver_cols].idxmax(axis=1).str.replace(\"Driver_\", \"\", regex=False)\n",
        "\n",
        "# Sort so the highest prediction in each group comes first\n",
        "# Flag 1 for the row(s) with the highest predicted score per track, else 0\n",
        "compare2024[\"predicted_winner\"] = (\n",
        "    compare2024.groupby(\"track\")[\"predicted\"]\n",
        "               .transform(lambda x: x == x.max())\n",
        "               .astype(int)\n",
        ")\n",
        "\n",
        "df_sorted = compare2024.sort_values([\"track\", \"predicted\"], ascending=[True, False])\n",
        "\n",
        "\n",
        "# Keep only the top row per race\n",
        "#top_pred_per_race = df_sorted.groupby([\"track\"], as_index=False).head(1)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q3c4HQvqH3AD",
        "outputId": "9dfbea9a-31ed-42ed-ce45-1fd24df653a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2269690503.py:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  compare2024[\"track\"] = compare2024[track_cols].idxmax(axis=1).str.replace(\"Track_\", \"\", regex=False)\n",
            "/tmp/ipython-input-2269690503.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  compare2024[\"Driver\"] = compare2024[driver_cols].idxmax(axis=1).str.replace(\"Driver_\", \"\", regex=False)\n",
            "/tmp/ipython-input-2269690503.py:15: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  compare2024[\"predicted_winner\"] = (\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cols_to_drop = track_cols + year_cols + team_cols + driver_cols + ['Laps']\n",
        "df_show2024 = df_sorted.drop(cols_to_drop, axis=1)\n",
        "\n",
        "df_show2024.head(100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o9AIwjWhI5HI",
        "outputId": "7f9d4cb5-f8f0-46fa-b342-ccaebc3b0a2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Position  RaceOrder  win  predicted      track           Driver  \\\n",
              "464         6         24    0   0.731467  Abu Dhabi   Max Verstappen   \n",
              "470        12         24    0   0.268843  Abu Dhabi     Yuki Tsunoda   \n",
              "475        17         24    0   0.255245  Abu Dhabi      Liam Lawson   \n",
              "461         3         24    0   0.092358  Abu Dhabi  Charles Leclerc   \n",
              "471        13         24    0   0.075099  Abu Dhabi      Guanyu Zhou   \n",
              "..        ...        ...  ...        ...        ...              ...   \n",
              "11         12          1    0  -0.003204    Bahrain  Kevin Magnussen   \n",
              "17         18          1    0  -0.005698    Bahrain     Pierre Gasly   \n",
              "15         16          1    0  -0.013450    Bahrain  Nico Hulkenberg   \n",
              "6           7          1    0  -0.020421    Bahrain   Lewis Hamilton   \n",
              "263         4         14    0   0.683927    Belgium   Max Verstappen   \n",
              "\n",
              "     predicted_winner  \n",
              "464                 1  \n",
              "470                 0  \n",
              "475                 0  \n",
              "461                 0  \n",
              "471                 0  \n",
              "..                ...  \n",
              "11                  0  \n",
              "17                  0  \n",
              "15                  0  \n",
              "6                   0  \n",
              "263                 1  \n",
              "\n",
              "[100 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6a013d82-9642-4094-9863-636a8c1e705c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Position</th>\n",
              "      <th>RaceOrder</th>\n",
              "      <th>win</th>\n",
              "      <th>predicted</th>\n",
              "      <th>track</th>\n",
              "      <th>Driver</th>\n",
              "      <th>predicted_winner</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>464</th>\n",
              "      <td>6</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "      <td>0.731467</td>\n",
              "      <td>Abu Dhabi</td>\n",
              "      <td>Max Verstappen</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>470</th>\n",
              "      <td>12</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "      <td>0.268843</td>\n",
              "      <td>Abu Dhabi</td>\n",
              "      <td>Yuki Tsunoda</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>475</th>\n",
              "      <td>17</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "      <td>0.255245</td>\n",
              "      <td>Abu Dhabi</td>\n",
              "      <td>Liam Lawson</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>461</th>\n",
              "      <td>3</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "      <td>0.092358</td>\n",
              "      <td>Abu Dhabi</td>\n",
              "      <td>Charles Leclerc</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>471</th>\n",
              "      <td>13</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "      <td>0.075099</td>\n",
              "      <td>Abu Dhabi</td>\n",
              "      <td>Guanyu Zhou</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.003204</td>\n",
              "      <td>Bahrain</td>\n",
              "      <td>Kevin Magnussen</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>18</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.005698</td>\n",
              "      <td>Bahrain</td>\n",
              "      <td>Pierre Gasly</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>16</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.013450</td>\n",
              "      <td>Bahrain</td>\n",
              "      <td>Nico Hulkenberg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.020421</td>\n",
              "      <td>Bahrain</td>\n",
              "      <td>Lewis Hamilton</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>263</th>\n",
              "      <td>4</td>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "      <td>0.683927</td>\n",
              "      <td>Belgium</td>\n",
              "      <td>Max Verstappen</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 7 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6a013d82-9642-4094-9863-636a8c1e705c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6a013d82-9642-4094-9863-636a8c1e705c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6a013d82-9642-4094-9863-636a8c1e705c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-4ea44c87-7f63-468e-9d5d-23714b076931\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4ea44c87-7f63-468e-9d5d-23714b076931')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-4ea44c87-7f63-468e-9d5d-23714b076931 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_show2024",
              "summary": "{\n  \"name\": \"df_show2024\",\n  \"rows\": 479,\n  \"fields\": [\n    {\n      \"column\": \"Position\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6,\n        \"min\": 1,\n        \"max\": 21,\n        \"num_unique_values\": 21,\n        \"samples\": [\n          6,\n          7,\n          10\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"RaceOrder\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6,\n        \"min\": 1,\n        \"max\": 24,\n        \"num_unique_values\": 24,\n        \"samples\": [\n          5,\n          6,\n          24\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"win\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"predicted\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 479,\n        \"samples\": [\n          0.0021524578332901,\n          0.26558494567871094\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"track\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 24,\n        \"samples\": [\n          \"China\",\n          \"Miami\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Driver\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 24,\n        \"samples\": [\n          \"George Russell\",\n          \"Oscar Piastri\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"predicted_winner\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now calculate how many of the winners did it actually predict correctly"
      ],
      "metadata": {
        "id": "abkzvs3XKC3t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Count rows where model predicted winner AND they actually won\n",
        "totalAmountGuessedCorrectly = df_show2024[\n",
        "    (df_show2024['predicted_winner'] == 1) &\n",
        "    (df_show2024['win'] == 1)\n",
        "].shape[0]\n",
        "\n",
        "print(\"The amount guessed correctly:\", totalAmountGuessedCorrectly)\n",
        "\n",
        "# Calculate percentage of races predicted correctly\n",
        "# (assuming 'track' identifies unique races in your 2024 set)\n",
        "percentage_correct = totalAmountGuessedCorrectly / df_show2024['track'].nunique()\n",
        "print(\"The percentage guessed correctly:\", percentage_correct)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E6xLZ8S1KHQH",
        "outputId": "edd189d1-dbbb-4571-8aca-28ccb7f81947"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The amount guessed correctly: 9\n",
            "The percentage guessed correctly: 0.375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predicting the actual winner correctly 70% of the time is a major accomplishment. I shall now design the code to be more easily tailored for repitive iterations to help narrow down on the best model."
      ],
      "metadata": {
        "id": "eRMn66bZMDZQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Model Training Functions that allow you to easily adjust years you wan to train test and predict for"
      ],
      "metadata": {
        "id": "pG4cUUuK3Q9B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def createModel(x_train, y_train, x_valid, y_valid, x_test, y_test, activFunction, optimizer, epochsNum):\n",
        "    model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[73, 1]),\n",
        "    keras.layers.Dense(32, activation=\"relu\"),\n",
        "    keras.layers.Dense(64, activation=\"relu\"),\n",
        "    keras.layers.Dense(128, activation=\"relu\"),\n",
        "    keras.layers.Dense(64, activation=\"relu\"),\n",
        "    keras.layers.Dense(32, activation= activFunction),\n",
        "    keras.layers.Dense(1)\n",
        "    ])\n",
        "\n",
        "    model.compile(loss=\"mse\", optimizer=optimizer, metrics = [\"accuracy\"])\n",
        "    history = model.fit(x_train, y_train, epochs=epochsNum,\n",
        "                        validation_data=(x_valid, y_valid), shuffle = False)\n",
        "    model.evaluate(x_test, y_test)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "UoFjTJJNwJ2K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yearsTrain = ['2022', '2023']\n",
        "yearsPredict = ['2024']\n",
        "\n",
        "def trainModel(yearsTrain, yearsPredict, partyDf,  activFunction, optimizer, epochs):\n",
        "  # 1) Determinism\n",
        "  os.environ[\"PYTHONHASHSEED\"] = \"42\"\n",
        "  np.random.seed(42)\n",
        "  random.seed(42)\n",
        "  try:\n",
        "      tf.random.set_seed(42)\n",
        "      # TF 2.12+: deterministic ops\n",
        "      tf.config.experimental.enable_op_determinism(True)\n",
        "  except Exception:\n",
        "      pass\n",
        "\n",
        "\n",
        "  dfs = []\n",
        "  #get data from all training years\n",
        "  for year in yearsTrain:\n",
        "      dfs.append(partyDf[partyDf['Year_' + year] == 1])\n",
        "\n",
        "  # Combine all selected years into one DataFrame\n",
        "  trainDf = pd.concat(dfs, ignore_index=True)\n",
        "\n",
        "  x = trainDf.drop(columns=['win', 'Position', 'RaceOrder'])\n",
        "  y = trainDf['win']\n",
        "\n",
        "  #extract the columns that have a one included in the x df\n",
        "  year_cols = [c for c in x.columns if c.startswith(\"Year_\")]\n",
        "\n",
        "  includedTrainingYears = []\n",
        "  for col in year_cols:\n",
        "      if (x[col] == 1).any():   # check if there is any row with a 1 in this column\n",
        "          includedTrainingYears.append(col)\n",
        "\n",
        "  print(\"The years trained: \", includedTrainingYears)\n",
        "\n",
        "\n",
        "  #split the training data accordingly\n",
        "  x_train, x_valid, y_train, y_valid = train_test_split(x, y, test_size=0.2, random_state=42)\n",
        "  #get the test data, so the data for the next year you would want to predict\n",
        "  dfTest = partyDf[(partyDf['Year_'+ yearsPredict[0]] == 1)]\n",
        "  x_test = dfTest.drop(columns=['win', 'Position', 'RaceOrder'])\n",
        "  y_test = dfTest['win']\n",
        "\n",
        "  #extract the columns that have a one included in the x df\n",
        "\n",
        "  includedTestingYears = []\n",
        "  for col in year_cols:\n",
        "      if (x_test[col] == 1).any():   # check if there is any row with a 1 in this column\n",
        "          includedTestingYears.append(col)\n",
        "\n",
        "  print(\"The years tested: \", includedTestingYears)\n",
        "\n",
        "  model = createModel(x_train, y_train, x_valid, y_valid, x_test, y_test,  activFunction, optimizer, epochs)\n",
        "\n",
        "  #extract the actual winning rows in the data and weather or not my model predicted them to win\n",
        "  comparePredictions = partyDf[(partyDf['Year_'+ yearsPredict[0]] == 1)]\n",
        "\n",
        "  #now the predictions are inputed for each row\n",
        "  comparePredictions['predicted'] = model.predict(x_test)\n",
        "  # Identify one-hot columns\n",
        "  track_cols = [c for c in comparePredictions.columns if c.startswith(\"Track_\")]\n",
        "  year_cols = [c for c in comparePredictions.columns if c.startswith(\"Year_\")]\n",
        "  team_cols = [c for c in comparePredictions.columns if c.startswith(\"Team_\")]\n",
        "  driver_cols = [c for c in comparePredictions.columns if c.startswith(\"Driver_\")]\n",
        "\n",
        "  # Recover track names from one-hot encoding\n",
        "  comparePredictions[\"track\"] = comparePredictions[track_cols].idxmax(axis=1).str.replace(\"Track_\", \"\", regex=False)\n",
        "  comparePredictions[\"Driver\"] = comparePredictions[driver_cols].idxmax(axis=1).str.replace(\"Driver_\", \"\", regex=False)\n",
        "\n",
        "  # Sort so the highest prediction in each group comes first\n",
        "  # Flag 1 for the row(s) with the highest predicted score per track, else 0\n",
        "  comparePredictions[\"predicted_winner\"] = (\n",
        "      comparePredictions.groupby(\"track\")[\"predicted\"]\n",
        "                .transform(lambda x: x == x.max())\n",
        "                .astype(int)\n",
        "  )\n",
        "\n",
        "  sortedcomparePredictions = comparePredictions.sort_values([\"track\", \"predicted\"], ascending=[True, False])\n",
        "  #remove exess columns\n",
        "  cols_to_drop = track_cols + year_cols + team_cols + driver_cols + ['Laps']\n",
        "  finalResultsDf = sortedcomparePredictions.drop(cols_to_drop, axis=1)\n",
        "\n",
        "\n",
        "\n",
        "  # Count rows where model predicted winner AND they actually won\n",
        "  totalAmountGuessedCorrectly = finalResultsDf[\n",
        "      (finalResultsDf['predicted_winner'] == 1) &\n",
        "      (finalResultsDf['win'] == 1)\n",
        "  ].shape[0]\n",
        "\n",
        "  numRaces = finalResultsDf['track'].nunique()\n",
        "  print(\"The amount guessed correctly:\", totalAmountGuessedCorrectly, \" out of \", numRaces, \" races.\")\n",
        "\n",
        "\n",
        "  # Calculate percentage of races predicted correctly\n",
        "  # (assuming 'track' identifies unique races in your 2024 set)\n",
        "\n",
        "  percentage_correct = totalAmountGuessedCorrectly / numRaces\n",
        "  print(\"The percentage guessed correctly:\", percentage_correct)\n",
        "\n",
        "  smallerDf = finalResultsDf[(finalResultsDf['predicted_winner'] == 1 ) | (finalResultsDf['win'] == 1)].sort_values('track')\n",
        "\n",
        "\n",
        "  return finalResultsDf, smallerDf\n",
        "\n",
        "df, smallDf = trainModel(yearsTrain, yearsPredict, df_encoded, \"relu\", \"adam\", 20)\n",
        "smallDf.head(100)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2YHcovXlOv0K",
        "outputId": "71f8fbbc-879f-4425-d05b-2ea27ed81247"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The years trained:  ['Year_2022', 'Year_2023']\n",
            "The years tested:  ['Year_2024']\n",
            "Epoch 1/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7822 - loss: 0.2153 - val_accuracy: 0.9716 - val_loss: 0.0525\n",
            "Epoch 2/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0581 - val_accuracy: 0.9716 - val_loss: 0.0343\n",
            "Epoch 3/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0519 - val_accuracy: 0.9716 - val_loss: 0.0348\n",
            "Epoch 4/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9455 - loss: 0.0510 - val_accuracy: 0.9716 - val_loss: 0.0305\n",
            "Epoch 5/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0500 - val_accuracy: 0.9716 - val_loss: 0.0266\n",
            "Epoch 6/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9455 - loss: 0.0489 - val_accuracy: 0.9716 - val_loss: 0.0233\n",
            "Epoch 7/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0463 - val_accuracy: 0.9716 - val_loss: 0.0215\n",
            "Epoch 8/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9455 - loss: 0.0441 - val_accuracy: 0.9716 - val_loss: 0.0203\n",
            "Epoch 9/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9453 - loss: 0.0413 - val_accuracy: 0.9716 - val_loss: 0.0190\n",
            "Epoch 10/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0390 - val_accuracy: 0.9716 - val_loss: 0.0198\n",
            "Epoch 11/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9452 - loss: 0.0371 - val_accuracy: 0.9716 - val_loss: 0.0196\n",
            "Epoch 12/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9440 - loss: 0.0325 - val_accuracy: 0.9716 - val_loss: 0.0155\n",
            "Epoch 13/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9600 - loss: 0.0285 - val_accuracy: 0.9773 - val_loss: 0.0136\n",
            "Epoch 14/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9739 - loss: 0.0264 - val_accuracy: 0.9886 - val_loss: 0.0131\n",
            "Epoch 15/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9772 - loss: 0.0253 - val_accuracy: 0.9886 - val_loss: 0.0134\n",
            "Epoch 16/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9772 - loss: 0.0250 - val_accuracy: 0.9886 - val_loss: 0.0143\n",
            "Epoch 17/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9772 - loss: 0.0256 - val_accuracy: 0.9886 - val_loss: 0.0153\n",
            "Epoch 18/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9772 - loss: 0.0256 - val_accuracy: 0.9886 - val_loss: 0.0138\n",
            "Epoch 19/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9772 - loss: 0.0246 - val_accuracy: 0.9886 - val_loss: 0.0139\n",
            "Epoch 20/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9772 - loss: 0.0245 - val_accuracy: 0.9886 - val_loss: 0.0154\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9586 - loss: 0.0425 \n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "The amount guessed correctly: 9  out of  24  races.\n",
            "The percentage guessed correctly: 0.375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-68995368.py:61: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  comparePredictions['predicted'] = model.predict(x_test)\n",
            "/tmp/ipython-input-68995368.py:69: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  comparePredictions[\"track\"] = comparePredictions[track_cols].idxmax(axis=1).str.replace(\"Track_\", \"\", regex=False)\n",
            "/tmp/ipython-input-68995368.py:70: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  comparePredictions[\"Driver\"] = comparePredictions[driver_cols].idxmax(axis=1).str.replace(\"Driver_\", \"\", regex=False)\n",
            "/tmp/ipython-input-68995368.py:74: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  comparePredictions[\"predicted_winner\"] = (\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Position  RaceOrder  win  predicted           track            Driver  \\\n",
              "464         6         24    0   0.637293       Abu Dhabi    Max Verstappen   \n",
              "459         1         24    1  -0.045076       Abu Dhabi      Lando Norris   \n",
              "51         12          3    0   0.252568       Australia  Daniel Ricciardo   \n",
              "40          1          3    1  -0.002745       Australia      Carlos Sainz   \n",
              "203         5         11    0   0.636250         Austria    Max Verstappen   \n",
              "199         1         11    1  -0.006637         Austria    George Russell   \n",
              "323         5         17    0   0.636314      Azerbaijan    Max Verstappen   \n",
              "319         1         17    1  -0.055948      Azerbaijan     Oscar Piastri   \n",
              "0           1          1    1   0.619934         Bahrain    Max Verstappen   \n",
              "260         1         14    1  -0.054246         Belgium    Lewis Hamilton   \n",
              "263         4         14    0   0.620630         Belgium    Max Verstappen   \n",
              "399         1         21    1   0.634248          Brazil    Max Verstappen   \n",
              "159         1          9    1   0.646746          Canada    Max Verstappen   \n",
              "79          1          5    1   0.687984           China    Max Verstappen   \n",
              "119         1          7    1   0.648306  Emilia Romagna    Max Verstappen   \n",
              "220         2         12    0   0.640023   Great Britain    Max Verstappen   \n",
              "219         1         12    1  -0.042934   Great Britain    Lewis Hamilton   \n",
              "243         5         13    0   0.634754         Hungary    Max Verstappen   \n",
              "239         1         13    1  -0.066769         Hungary     Oscar Piastri   \n",
              "299         1         16    1   0.058185           Italy   Charles Leclerc   \n",
              "304         6         16    0   0.610261           Italy    Max Verstappen   \n",
              "59          1          4    1   0.672234           Japan    Max Verstappen   \n",
              "423         5         22    0   0.675711       Las Vegas    Max Verstappen   \n",
              "419         1         22    1   0.035229       Las Vegas    George Russell   \n",
              "384         6         20    0   0.637273          Mexico    Max Verstappen   \n",
              "379         1         20    1  -0.007456          Mexico      Carlos Sainz   \n",
              "100         2          6    0   0.654095           Miami    Max Verstappen   \n",
              "99          1          6    1  -0.035097           Miami      Lando Norris   \n",
              "139         1          8    1   0.011716          Monaco   Charles Leclerc   \n",
              "144         6          8    0   0.609005          Monaco    Max Verstappen   \n",
              "280         2         15    0   0.618411     Netherlands    Max Verstappen   \n",
              "279         1         15    1  -0.073317     Netherlands      Lando Norris   \n",
              "439         1         23    1   0.623769           Qatar    Max Verstappen   \n",
              "20          1          2    1   0.636148    Saudi Arabia    Max Verstappen   \n",
              "340         2         18    0   0.635725       Singapore    Max Verstappen   \n",
              "339         1         18    1  -0.057777       Singapore      Lando Norris   \n",
              "179         1         10    1   0.630772           Spain    Max Verstappen   \n",
              "361         3         19    0   0.632537   United States    Max Verstappen   \n",
              "359         1         19    1   0.073738   United States   Charles Leclerc   \n",
              "\n",
              "     predicted_winner  \n",
              "464                 1  \n",
              "459                 0  \n",
              "51                  1  \n",
              "40                  0  \n",
              "203                 1  \n",
              "199                 0  \n",
              "323                 1  \n",
              "319                 0  \n",
              "0                   1  \n",
              "260                 0  \n",
              "263                 1  \n",
              "399                 1  \n",
              "159                 1  \n",
              "79                  1  \n",
              "119                 1  \n",
              "220                 1  \n",
              "219                 0  \n",
              "243                 1  \n",
              "239                 0  \n",
              "299                 0  \n",
              "304                 1  \n",
              "59                  1  \n",
              "423                 1  \n",
              "419                 0  \n",
              "384                 1  \n",
              "379                 0  \n",
              "100                 1  \n",
              "99                  0  \n",
              "139                 0  \n",
              "144                 1  \n",
              "280                 1  \n",
              "279                 0  \n",
              "439                 1  \n",
              "20                  1  \n",
              "340                 1  \n",
              "339                 0  \n",
              "179                 1  \n",
              "361                 1  \n",
              "359                 0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ed91717b-5191-4a54-aa28-aecdce8a8a5a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Position</th>\n",
              "      <th>RaceOrder</th>\n",
              "      <th>win</th>\n",
              "      <th>predicted</th>\n",
              "      <th>track</th>\n",
              "      <th>Driver</th>\n",
              "      <th>predicted_winner</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>464</th>\n",
              "      <td>6</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "      <td>0.637293</td>\n",
              "      <td>Abu Dhabi</td>\n",
              "      <td>Max Verstappen</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>459</th>\n",
              "      <td>1</td>\n",
              "      <td>24</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.045076</td>\n",
              "      <td>Abu Dhabi</td>\n",
              "      <td>Lando Norris</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>12</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0.252568</td>\n",
              "      <td>Australia</td>\n",
              "      <td>Daniel Ricciardo</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.002745</td>\n",
              "      <td>Australia</td>\n",
              "      <td>Carlos Sainz</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>203</th>\n",
              "      <td>5</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>0.636250</td>\n",
              "      <td>Austria</td>\n",
              "      <td>Max Verstappen</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199</th>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.006637</td>\n",
              "      <td>Austria</td>\n",
              "      <td>George Russell</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>323</th>\n",
              "      <td>5</td>\n",
              "      <td>17</td>\n",
              "      <td>0</td>\n",
              "      <td>0.636314</td>\n",
              "      <td>Azerbaijan</td>\n",
              "      <td>Max Verstappen</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>319</th>\n",
              "      <td>1</td>\n",
              "      <td>17</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.055948</td>\n",
              "      <td>Azerbaijan</td>\n",
              "      <td>Oscar Piastri</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.619934</td>\n",
              "      <td>Bahrain</td>\n",
              "      <td>Max Verstappen</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>260</th>\n",
              "      <td>1</td>\n",
              "      <td>14</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.054246</td>\n",
              "      <td>Belgium</td>\n",
              "      <td>Lewis Hamilton</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>263</th>\n",
              "      <td>4</td>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "      <td>0.620630</td>\n",
              "      <td>Belgium</td>\n",
              "      <td>Max Verstappen</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>399</th>\n",
              "      <td>1</td>\n",
              "      <td>21</td>\n",
              "      <td>1</td>\n",
              "      <td>0.634248</td>\n",
              "      <td>Brazil</td>\n",
              "      <td>Max Verstappen</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159</th>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>0.646746</td>\n",
              "      <td>Canada</td>\n",
              "      <td>Max Verstappen</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79</th>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0.687984</td>\n",
              "      <td>China</td>\n",
              "      <td>Max Verstappen</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119</th>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>0.648306</td>\n",
              "      <td>Emilia Romagna</td>\n",
              "      <td>Max Verstappen</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>220</th>\n",
              "      <td>2</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>0.640023</td>\n",
              "      <td>Great Britain</td>\n",
              "      <td>Max Verstappen</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>219</th>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.042934</td>\n",
              "      <td>Great Britain</td>\n",
              "      <td>Lewis Hamilton</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>243</th>\n",
              "      <td>5</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>0.634754</td>\n",
              "      <td>Hungary</td>\n",
              "      <td>Max Verstappen</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>239</th>\n",
              "      <td>1</td>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.066769</td>\n",
              "      <td>Hungary</td>\n",
              "      <td>Oscar Piastri</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>299</th>\n",
              "      <td>1</td>\n",
              "      <td>16</td>\n",
              "      <td>1</td>\n",
              "      <td>0.058185</td>\n",
              "      <td>Italy</td>\n",
              "      <td>Charles Leclerc</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>304</th>\n",
              "      <td>6</td>\n",
              "      <td>16</td>\n",
              "      <td>0</td>\n",
              "      <td>0.610261</td>\n",
              "      <td>Italy</td>\n",
              "      <td>Max Verstappen</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0.672234</td>\n",
              "      <td>Japan</td>\n",
              "      <td>Max Verstappen</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>423</th>\n",
              "      <td>5</td>\n",
              "      <td>22</td>\n",
              "      <td>0</td>\n",
              "      <td>0.675711</td>\n",
              "      <td>Las Vegas</td>\n",
              "      <td>Max Verstappen</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>419</th>\n",
              "      <td>1</td>\n",
              "      <td>22</td>\n",
              "      <td>1</td>\n",
              "      <td>0.035229</td>\n",
              "      <td>Las Vegas</td>\n",
              "      <td>George Russell</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>384</th>\n",
              "      <td>6</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>0.637273</td>\n",
              "      <td>Mexico</td>\n",
              "      <td>Max Verstappen</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>379</th>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.007456</td>\n",
              "      <td>Mexico</td>\n",
              "      <td>Carlos Sainz</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100</th>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0.654095</td>\n",
              "      <td>Miami</td>\n",
              "      <td>Max Verstappen</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.035097</td>\n",
              "      <td>Miami</td>\n",
              "      <td>Lando Norris</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>139</th>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>0.011716</td>\n",
              "      <td>Monaco</td>\n",
              "      <td>Charles Leclerc</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>144</th>\n",
              "      <td>6</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>0.609005</td>\n",
              "      <td>Monaco</td>\n",
              "      <td>Max Verstappen</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>280</th>\n",
              "      <td>2</td>\n",
              "      <td>15</td>\n",
              "      <td>0</td>\n",
              "      <td>0.618411</td>\n",
              "      <td>Netherlands</td>\n",
              "      <td>Max Verstappen</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>279</th>\n",
              "      <td>1</td>\n",
              "      <td>15</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.073317</td>\n",
              "      <td>Netherlands</td>\n",
              "      <td>Lando Norris</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>439</th>\n",
              "      <td>1</td>\n",
              "      <td>23</td>\n",
              "      <td>1</td>\n",
              "      <td>0.623769</td>\n",
              "      <td>Qatar</td>\n",
              "      <td>Max Verstappen</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0.636148</td>\n",
              "      <td>Saudi Arabia</td>\n",
              "      <td>Max Verstappen</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>340</th>\n",
              "      <td>2</td>\n",
              "      <td>18</td>\n",
              "      <td>0</td>\n",
              "      <td>0.635725</td>\n",
              "      <td>Singapore</td>\n",
              "      <td>Max Verstappen</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>339</th>\n",
              "      <td>1</td>\n",
              "      <td>18</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.057777</td>\n",
              "      <td>Singapore</td>\n",
              "      <td>Lando Norris</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>179</th>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>0.630772</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Max Verstappen</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>361</th>\n",
              "      <td>3</td>\n",
              "      <td>19</td>\n",
              "      <td>0</td>\n",
              "      <td>0.632537</td>\n",
              "      <td>United States</td>\n",
              "      <td>Max Verstappen</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>359</th>\n",
              "      <td>1</td>\n",
              "      <td>19</td>\n",
              "      <td>1</td>\n",
              "      <td>0.073738</td>\n",
              "      <td>United States</td>\n",
              "      <td>Charles Leclerc</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ed91717b-5191-4a54-aa28-aecdce8a8a5a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ed91717b-5191-4a54-aa28-aecdce8a8a5a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ed91717b-5191-4a54-aa28-aecdce8a8a5a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-e8b9bb7c-a779-462e-962d-0ec16650f075\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e8b9bb7c-a779-462e-962d-0ec16650f075')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-e8b9bb7c-a779-462e-962d-0ec16650f075 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "smallDf",
              "summary": "{\n  \"name\": \"smallDf\",\n  \"rows\": 39,\n  \"fields\": [\n    {\n      \"column\": \"Position\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 1,\n        \"max\": 12,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          6,\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"RaceOrder\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6,\n        \"min\": 1,\n        \"max\": 24,\n        \"num_unique_values\": 24,\n        \"samples\": [\n          5,\n          6,\n          24\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"win\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"predicted\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 39,\n        \"samples\": [\n          0.6361477375030518,\n          0.6307718753814697\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"track\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 24,\n        \"samples\": [\n          \"China\",\n          \"Miami\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Driver\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"Lando Norris\",\n          \"Oscar Piastri\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"predicted_winner\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Apply results to the 2025 season. So use the data from 2023 and 2024 to predict 2025"
      ],
      "metadata": {
        "id": "SLMTGerZ5qiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "yearsTrain = ['2023', '2024']\n",
        "yearsPredict = ['2025']\n",
        "\n",
        "df, smallDf = trainModel(yearsTrain, yearsPredict, df_encoded, \"relu\", \"adam\", 20)\n",
        "smallDf.head(100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yAnJ5JK55v4S",
        "outputId": "d2549a46-bfa9-436c-b935-b0c2130ffa62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The years trained:  ['Year_2023', 'Year_2024']\n",
            "The years tested:  ['Year_2025']\n",
            "Epoch 1/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.8007 - loss: 0.1986 - val_accuracy: 0.9402 - val_loss: 0.0575\n",
            "Epoch 2/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0546 - val_accuracy: 0.9402 - val_loss: 0.0571\n",
            "Epoch 3/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0538 - val_accuracy: 0.9402 - val_loss: 0.0576\n",
            "Epoch 4/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0546 - val_accuracy: 0.9402 - val_loss: 0.0577\n",
            "Epoch 5/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9491 - loss: 0.0548 - val_accuracy: 0.9402 - val_loss: 0.0561\n",
            "Epoch 6/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9491 - loss: 0.0537 - val_accuracy: 0.9402 - val_loss: 0.0545\n",
            "Epoch 7/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9491 - loss: 0.0521 - val_accuracy: 0.9402 - val_loss: 0.0535\n",
            "Epoch 8/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9491 - loss: 0.0510 - val_accuracy: 0.9402 - val_loss: 0.0549\n",
            "Epoch 9/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9491 - loss: 0.0511 - val_accuracy: 0.9402 - val_loss: 0.0530\n",
            "Epoch 10/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9491 - loss: 0.0504 - val_accuracy: 0.9402 - val_loss: 0.0524\n",
            "Epoch 11/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9491 - loss: 0.0499 - val_accuracy: 0.9402 - val_loss: 0.0496\n",
            "Epoch 12/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9491 - loss: 0.0469 - val_accuracy: 0.9402 - val_loss: 0.0490\n",
            "Epoch 13/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9491 - loss: 0.0457 - val_accuracy: 0.9402 - val_loss: 0.0501\n",
            "Epoch 14/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9491 - loss: 0.0465 - val_accuracy: 0.9402 - val_loss: 0.0478\n",
            "Epoch 15/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0455 - val_accuracy: 0.9402 - val_loss: 0.0468\n",
            "Epoch 16/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0446 - val_accuracy: 0.9402 - val_loss: 0.0455\n",
            "Epoch 17/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0431 - val_accuracy: 0.9402 - val_loss: 0.0450\n",
            "Epoch 18/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0429 - val_accuracy: 0.9402 - val_loss: 0.0438\n",
            "Epoch 19/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0420 - val_accuracy: 0.9402 - val_loss: 0.0461\n",
            "Epoch 20/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0412 - val_accuracy: 0.9402 - val_loss: 0.0432\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9461 - loss: 0.0515 \n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "The amount guessed correctly: 2  out of  13  races.\n",
            "The percentage guessed correctly: 0.15384615384615385\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-68995368.py:61: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  comparePredictions['predicted'] = model.predict(x_test)\n",
            "/tmp/ipython-input-68995368.py:69: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  comparePredictions[\"track\"] = comparePredictions[track_cols].idxmax(axis=1).str.replace(\"Track_\", \"\", regex=False)\n",
            "/tmp/ipython-input-68995368.py:70: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  comparePredictions[\"Driver\"] = comparePredictions[driver_cols].idxmax(axis=1).str.replace(\"Driver_\", \"\", regex=False)\n",
            "/tmp/ipython-input-68995368.py:74: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  comparePredictions[\"predicted_winner\"] = (\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Position  RaceOrder  win  predicted           track          Driver  \\\n",
              "1           2          1    0   0.306284       Australia  Max Verstappen   \n",
              "0           1          1    1   0.061423       Australia    Lando Norris   \n",
              "214        16         11    0   0.107415         Austria    Yuki Tsunoda   \n",
              "199         1         11    1   0.067540         Austria    Lando Norris   \n",
              "65          6          4    0   0.316465         Bahrain  Max Verstappen   \n",
              "60          1          4    1   0.031376         Bahrain   Oscar Piastri   \n",
              "242         4         13    0   0.350422         Belgium  Max Verstappen   \n",
              "239         1         13    1   0.051523         Belgium   Oscar Piastri   \n",
              "180         2         10    0   0.312263          Canada  Max Verstappen   \n",
              "179         1         10    1   0.044073          Canada  George Russell   \n",
              "20          1          2    1   0.057967           China   Oscar Piastri   \n",
              "23          4          2    0   0.357826           China  Max Verstappen   \n",
              "120         1          7    1   0.312034  Emilia Romagna  Max Verstappen   \n",
              "223         5         12    0   0.335618   Great Britain  Max Verstappen   \n",
              "219         1         12    1   0.079682   Great Britain    Lando Norris   \n",
              "40          1          3    1   0.286860           Japan  Max Verstappen   \n",
              "103         4          6    0   0.313725           Miami  Max Verstappen   \n",
              "100         1          6    1   0.022946           Miami   Oscar Piastri   \n",
              "143         4          8    0   0.316208          Monaco  Max Verstappen   \n",
              "140         1          8    1   0.053435          Monaco    Lando Norris   \n",
              "81          2          5    0   0.314646    Saudi Arabia  Max Verstappen   \n",
              "80          1          5    1   0.018384    Saudi Arabia   Oscar Piastri   \n",
              "169        10          9    0   0.318042           Spain  Max Verstappen   \n",
              "160         1          9    1   0.025049           Spain   Oscar Piastri   \n",
              "\n",
              "     predicted_winner  \n",
              "1                   1  \n",
              "0                   0  \n",
              "214                 1  \n",
              "199                 0  \n",
              "65                  1  \n",
              "60                  0  \n",
              "242                 1  \n",
              "239                 0  \n",
              "180                 1  \n",
              "179                 0  \n",
              "20                  0  \n",
              "23                  1  \n",
              "120                 1  \n",
              "223                 1  \n",
              "219                 0  \n",
              "40                  1  \n",
              "103                 1  \n",
              "100                 0  \n",
              "143                 1  \n",
              "140                 0  \n",
              "81                  1  \n",
              "80                  0  \n",
              "169                 1  \n",
              "160                 0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8f320aa3-ede3-4c76-a77c-c6cc39e41f9d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Position</th>\n",
              "      <th>RaceOrder</th>\n",
              "      <th>win</th>\n",
              "      <th>predicted</th>\n",
              "      <th>track</th>\n",
              "      <th>Driver</th>\n",
              "      <th>predicted_winner</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.306284</td>\n",
              "      <td>Australia</td>\n",
              "      <td>Max Verstappen</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.061423</td>\n",
              "      <td>Australia</td>\n",
              "      <td>Lando Norris</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>214</th>\n",
              "      <td>16</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>0.107415</td>\n",
              "      <td>Austria</td>\n",
              "      <td>Yuki Tsunoda</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199</th>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>0.067540</td>\n",
              "      <td>Austria</td>\n",
              "      <td>Lando Norris</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65</th>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0.316465</td>\n",
              "      <td>Bahrain</td>\n",
              "      <td>Max Verstappen</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0.031376</td>\n",
              "      <td>Bahrain</td>\n",
              "      <td>Oscar Piastri</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>242</th>\n",
              "      <td>4</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>0.350422</td>\n",
              "      <td>Belgium</td>\n",
              "      <td>Max Verstappen</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>239</th>\n",
              "      <td>1</td>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "      <td>0.051523</td>\n",
              "      <td>Belgium</td>\n",
              "      <td>Oscar Piastri</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>180</th>\n",
              "      <td>2</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>0.312263</td>\n",
              "      <td>Canada</td>\n",
              "      <td>Max Verstappen</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>179</th>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>0.044073</td>\n",
              "      <td>Canada</td>\n",
              "      <td>George Russell</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0.057967</td>\n",
              "      <td>China</td>\n",
              "      <td>Oscar Piastri</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.357826</td>\n",
              "      <td>China</td>\n",
              "      <td>Max Verstappen</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120</th>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>0.312034</td>\n",
              "      <td>Emilia Romagna</td>\n",
              "      <td>Max Verstappen</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>223</th>\n",
              "      <td>5</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>0.335618</td>\n",
              "      <td>Great Britain</td>\n",
              "      <td>Max Verstappen</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>219</th>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>0.079682</td>\n",
              "      <td>Great Britain</td>\n",
              "      <td>Lando Norris</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0.286860</td>\n",
              "      <td>Japan</td>\n",
              "      <td>Max Verstappen</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103</th>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0.313725</td>\n",
              "      <td>Miami</td>\n",
              "      <td>Max Verstappen</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100</th>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>0.022946</td>\n",
              "      <td>Miami</td>\n",
              "      <td>Oscar Piastri</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>143</th>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>0.316208</td>\n",
              "      <td>Monaco</td>\n",
              "      <td>Max Verstappen</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>140</th>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>0.053435</td>\n",
              "      <td>Monaco</td>\n",
              "      <td>Lando Norris</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81</th>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0.314646</td>\n",
              "      <td>Saudi Arabia</td>\n",
              "      <td>Max Verstappen</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80</th>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0.018384</td>\n",
              "      <td>Saudi Arabia</td>\n",
              "      <td>Oscar Piastri</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>169</th>\n",
              "      <td>10</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0.318042</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Max Verstappen</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>160</th>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>0.025049</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Oscar Piastri</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8f320aa3-ede3-4c76-a77c-c6cc39e41f9d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8f320aa3-ede3-4c76-a77c-c6cc39e41f9d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8f320aa3-ede3-4c76-a77c-c6cc39e41f9d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-5da545d6-a98f-4b43-b053-8dd078265622\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5da545d6-a98f-4b43-b053-8dd078265622')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-5da545d6-a98f-4b43-b053-8dd078265622 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "smallDf",
              "summary": "{\n  \"name\": \"smallDf\",\n  \"rows\": 24,\n  \"fields\": [\n    {\n      \"column\": \"Position\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 1,\n        \"max\": 16,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          2,\n          1,\n          5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"RaceOrder\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 1,\n        \"max\": 13,\n        \"num_unique_values\": 13,\n        \"samples\": [\n          5,\n          6,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"win\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"predicted\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 24,\n        \"samples\": [\n          0.31226328015327454,\n          0.3137245774269104\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"track\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 13,\n        \"samples\": [\n          \"Saudi Arabia\",\n          \"Miami\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Driver\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Lando Norris\",\n          \"George Russell\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"predicted_winner\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "yearsTrain = ['2022', '2023', '2024']\n",
        "yearsPredict = ['2025']\n",
        "\n",
        "df, smallDf = trainModel(yearsTrain, yearsPredict, df_encoded, \"relu\", \"adam\", 20)\n",
        "smallDf.head(100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_32ls0GLYS6",
        "outputId": "4422a599-9108-4854-c066-23e386cd5bfe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The years trained:  ['Year_2022', 'Year_2023', 'Year_2024']\n",
            "The years tested:  ['Year_2025']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.8643 - loss: 0.1396 - val_accuracy: 0.9375 - val_loss: 0.0583\n",
            "Epoch 2/20\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9569 - loss: 0.0424 - val_accuracy: 0.9375 - val_loss: 0.0560\n",
            "Epoch 3/20\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9569 - loss: 0.0412 - val_accuracy: 0.9375 - val_loss: 0.0546\n",
            "Epoch 4/20\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9569 - loss: 0.0393 - val_accuracy: 0.9375 - val_loss: 0.0549\n",
            "Epoch 5/20\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9569 - loss: 0.0374 - val_accuracy: 0.9375 - val_loss: 0.0523\n",
            "Epoch 6/20\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9569 - loss: 0.0360 - val_accuracy: 0.9375 - val_loss: 0.0535\n",
            "Epoch 7/20\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9569 - loss: 0.0344 - val_accuracy: 0.9375 - val_loss: 0.0500\n",
            "Epoch 8/20\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9569 - loss: 0.0340 - val_accuracy: 0.9375 - val_loss: 0.0503\n",
            "Epoch 9/20\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9569 - loss: 0.0321 - val_accuracy: 0.9375 - val_loss: 0.0470\n",
            "Epoch 10/20\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9568 - loss: 0.0306 - val_accuracy: 0.9375 - val_loss: 0.0474\n",
            "Epoch 11/20\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9616 - loss: 0.0306 - val_accuracy: 0.9375 - val_loss: 0.0468\n",
            "Epoch 12/20\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9625 - loss: 0.0298 - val_accuracy: 0.9375 - val_loss: 0.0472\n",
            "Epoch 13/20\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9649 - loss: 0.0291 - val_accuracy: 0.9375 - val_loss: 0.0457\n",
            "Epoch 14/20\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9656 - loss: 0.0279 - val_accuracy: 0.9375 - val_loss: 0.0482\n",
            "Epoch 15/20\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9713 - loss: 0.0295 - val_accuracy: 0.9375 - val_loss: 0.0474\n",
            "Epoch 16/20\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9676 - loss: 0.0286 - val_accuracy: 0.9375 - val_loss: 0.0487\n",
            "Epoch 17/20\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9626 - loss: 0.0295 - val_accuracy: 0.9375 - val_loss: 0.0525\n",
            "Epoch 18/20\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9611 - loss: 0.0317 - val_accuracy: 0.9485 - val_loss: 0.0445\n",
            "Epoch 19/20\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9606 - loss: 0.0274 - val_accuracy: 0.9559 - val_loss: 0.0431\n",
            "Epoch 20/20\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9705 - loss: 0.0249 - val_accuracy: 0.9596 - val_loss: 0.0442\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9148 - loss: 0.0607 \n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "The amount guessed correctly: 2  out of  13  races.\n",
            "The percentage guessed correctly: 0.15384615384615385\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-68995368.py:61: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  comparePredictions['predicted'] = model.predict(x_test)\n",
            "/tmp/ipython-input-68995368.py:69: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  comparePredictions[\"track\"] = comparePredictions[track_cols].idxmax(axis=1).str.replace(\"Track_\", \"\", regex=False)\n",
            "/tmp/ipython-input-68995368.py:70: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  comparePredictions[\"Driver\"] = comparePredictions[driver_cols].idxmax(axis=1).str.replace(\"Driver_\", \"\", regex=False)\n",
            "/tmp/ipython-input-68995368.py:74: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  comparePredictions[\"predicted_winner\"] = (\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Position  RaceOrder  win  predicted           track          Driver  \\\n",
              "1           2          1    0   0.596789       Australia  Max Verstappen   \n",
              "0           1          1    1  -0.010161       Australia    Lando Norris   \n",
              "214        16         11    0   0.159541         Austria    Yuki Tsunoda   \n",
              "199         1         11    1  -0.021157         Austria    Lando Norris   \n",
              "65          6          4    0   0.604754         Bahrain  Max Verstappen   \n",
              "60          1          4    1   0.084195         Bahrain   Oscar Piastri   \n",
              "242         4         13    0   0.583828         Belgium  Max Verstappen   \n",
              "239         1         13    1   0.082990         Belgium   Oscar Piastri   \n",
              "180         2         10    0   0.624966          Canada  Max Verstappen   \n",
              "179         1         10    1   0.026466          Canada  George Russell   \n",
              "20          1          2    1   0.082944           China   Oscar Piastri   \n",
              "23          4          2    0   0.617768           China  Max Verstappen   \n",
              "120         1          7    1   0.608875  Emilia Romagna  Max Verstappen   \n",
              "223         5         12    0   0.568657   Great Britain  Max Verstappen   \n",
              "219         1         12    1  -0.022495   Great Britain    Lando Norris   \n",
              "40          1          3    1   0.602546           Japan  Max Verstappen   \n",
              "103         4          6    0   0.585236           Miami  Max Verstappen   \n",
              "100         1          6    1   0.057078           Miami   Oscar Piastri   \n",
              "143         4          8    0   0.630354          Monaco  Max Verstappen   \n",
              "140         1          8    1   0.000214          Monaco    Lando Norris   \n",
              "81          2          5    0   0.585326    Saudi Arabia  Max Verstappen   \n",
              "80          1          5    1   0.068562    Saudi Arabia   Oscar Piastri   \n",
              "169        10          9    0   0.609393           Spain  Max Verstappen   \n",
              "160         1          9    1   0.071796           Spain   Oscar Piastri   \n",
              "\n",
              "     predicted_winner  \n",
              "1                   1  \n",
              "0                   0  \n",
              "214                 1  \n",
              "199                 0  \n",
              "65                  1  \n",
              "60                  0  \n",
              "242                 1  \n",
              "239                 0  \n",
              "180                 1  \n",
              "179                 0  \n",
              "20                  0  \n",
              "23                  1  \n",
              "120                 1  \n",
              "223                 1  \n",
              "219                 0  \n",
              "40                  1  \n",
              "103                 1  \n",
              "100                 0  \n",
              "143                 1  \n",
              "140                 0  \n",
              "81                  1  \n",
              "80                  0  \n",
              "169                 1  \n",
              "160                 0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a52c8a22-ecb2-4ee5-9c80-84c3a03733ff\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Position</th>\n",
              "      <th>RaceOrder</th>\n",
              "      <th>win</th>\n",
              "      <th>predicted</th>\n",
              "      <th>track</th>\n",
              "      <th>Driver</th>\n",
              "      <th>predicted_winner</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.596789</td>\n",
              "      <td>Australia</td>\n",
              "      <td>Max Verstappen</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.010161</td>\n",
              "      <td>Australia</td>\n",
              "      <td>Lando Norris</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>214</th>\n",
              "      <td>16</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>0.159541</td>\n",
              "      <td>Austria</td>\n",
              "      <td>Yuki Tsunoda</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199</th>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.021157</td>\n",
              "      <td>Austria</td>\n",
              "      <td>Lando Norris</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65</th>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0.604754</td>\n",
              "      <td>Bahrain</td>\n",
              "      <td>Max Verstappen</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0.084195</td>\n",
              "      <td>Bahrain</td>\n",
              "      <td>Oscar Piastri</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>242</th>\n",
              "      <td>4</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>0.583828</td>\n",
              "      <td>Belgium</td>\n",
              "      <td>Max Verstappen</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>239</th>\n",
              "      <td>1</td>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "      <td>0.082990</td>\n",
              "      <td>Belgium</td>\n",
              "      <td>Oscar Piastri</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>180</th>\n",
              "      <td>2</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>0.624966</td>\n",
              "      <td>Canada</td>\n",
              "      <td>Max Verstappen</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>179</th>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>0.026466</td>\n",
              "      <td>Canada</td>\n",
              "      <td>George Russell</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0.082944</td>\n",
              "      <td>China</td>\n",
              "      <td>Oscar Piastri</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.617768</td>\n",
              "      <td>China</td>\n",
              "      <td>Max Verstappen</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120</th>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>0.608875</td>\n",
              "      <td>Emilia Romagna</td>\n",
              "      <td>Max Verstappen</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>223</th>\n",
              "      <td>5</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>0.568657</td>\n",
              "      <td>Great Britain</td>\n",
              "      <td>Max Verstappen</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>219</th>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.022495</td>\n",
              "      <td>Great Britain</td>\n",
              "      <td>Lando Norris</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0.602546</td>\n",
              "      <td>Japan</td>\n",
              "      <td>Max Verstappen</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103</th>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0.585236</td>\n",
              "      <td>Miami</td>\n",
              "      <td>Max Verstappen</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100</th>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>0.057078</td>\n",
              "      <td>Miami</td>\n",
              "      <td>Oscar Piastri</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>143</th>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>0.630354</td>\n",
              "      <td>Monaco</td>\n",
              "      <td>Max Verstappen</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>140</th>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000214</td>\n",
              "      <td>Monaco</td>\n",
              "      <td>Lando Norris</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81</th>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0.585326</td>\n",
              "      <td>Saudi Arabia</td>\n",
              "      <td>Max Verstappen</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80</th>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0.068562</td>\n",
              "      <td>Saudi Arabia</td>\n",
              "      <td>Oscar Piastri</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>169</th>\n",
              "      <td>10</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0.609393</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Max Verstappen</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>160</th>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>0.071796</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Oscar Piastri</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a52c8a22-ecb2-4ee5-9c80-84c3a03733ff')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a52c8a22-ecb2-4ee5-9c80-84c3a03733ff button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a52c8a22-ecb2-4ee5-9c80-84c3a03733ff');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-503f8e1f-1e1c-4773-bc6b-02b29ff2b762\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-503f8e1f-1e1c-4773-bc6b-02b29ff2b762')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-503f8e1f-1e1c-4773-bc6b-02b29ff2b762 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "smallDf",
              "summary": "{\n  \"name\": \"smallDf\",\n  \"rows\": 24,\n  \"fields\": [\n    {\n      \"column\": \"Position\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 1,\n        \"max\": 16,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          2,\n          1,\n          5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"RaceOrder\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 1,\n        \"max\": 13,\n        \"num_unique_values\": 13,\n        \"samples\": [\n          5,\n          6,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"win\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"predicted\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 24,\n        \"samples\": [\n          0.6249659657478333,\n          0.585235595703125\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"track\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 13,\n        \"samples\": [\n          \"Saudi Arabia\",\n          \"Miami\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Driver\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Lando Norris\",\n          \"George Russell\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"predicted_winner\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "yearsTrain = ['2024']\n",
        "yearsPredict = ['2025']\n",
        "\n",
        "df, smallDf = trainModel(yearsTrain, yearsPredict, df_encoded, \"relu\", \"adam\", 20)\n",
        "smallDf.head(100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mCJcqkxSL0a2",
        "outputId": "6f38d35c-bca4-417c-d4e4-396710b4c5de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The years trained:  ['Year_2024']\n",
            "The years tested:  ['Year_2025']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - accuracy: 0.7455 - loss: 0.2632 - val_accuracy: 0.9479 - val_loss: 0.0615\n",
            "Epoch 2/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9689 - loss: 0.0324 - val_accuracy: 0.9479 - val_loss: 0.0480\n",
            "Epoch 3/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9689 - loss: 0.0358 - val_accuracy: 0.9479 - val_loss: 0.0491\n",
            "Epoch 4/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0317 - val_accuracy: 0.9479 - val_loss: 0.0469\n",
            "Epoch 5/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9689 - loss: 0.0314 - val_accuracy: 0.9479 - val_loss: 0.0470\n",
            "Epoch 6/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0311 - val_accuracy: 0.9479 - val_loss: 0.0469\n",
            "Epoch 7/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0315 - val_accuracy: 0.9479 - val_loss: 0.0468\n",
            "Epoch 8/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0309 - val_accuracy: 0.9479 - val_loss: 0.0467\n",
            "Epoch 9/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0309 - val_accuracy: 0.9479 - val_loss: 0.0466\n",
            "Epoch 10/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0310 - val_accuracy: 0.9479 - val_loss: 0.0470\n",
            "Epoch 11/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0314 - val_accuracy: 0.9479 - val_loss: 0.0475\n",
            "Epoch 12/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0319 - val_accuracy: 0.9479 - val_loss: 0.0477\n",
            "Epoch 13/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0319 - val_accuracy: 0.9479 - val_loss: 0.0474\n",
            "Epoch 14/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0312 - val_accuracy: 0.9479 - val_loss: 0.0478\n",
            "Epoch 15/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0309 - val_accuracy: 0.9479 - val_loss: 0.0484\n",
            "Epoch 16/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0311 - val_accuracy: 0.9479 - val_loss: 0.0488\n",
            "Epoch 17/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0312 - val_accuracy: 0.9479 - val_loss: 0.0491\n",
            "Epoch 18/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0311 - val_accuracy: 0.9479 - val_loss: 0.0495\n",
            "Epoch 19/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0311 - val_accuracy: 0.9479 - val_loss: 0.0497\n",
            "Epoch 20/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0308 - val_accuracy: 0.9479 - val_loss: 0.0500\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9461 - loss: 0.0487  \n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "The amount guessed correctly: 4  out of  13  races.\n",
            "The percentage guessed correctly: 0.3076923076923077\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-68995368.py:61: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  comparePredictions['predicted'] = model.predict(x_test)\n",
            "/tmp/ipython-input-68995368.py:69: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  comparePredictions[\"track\"] = comparePredictions[track_cols].idxmax(axis=1).str.replace(\"Track_\", \"\", regex=False)\n",
            "/tmp/ipython-input-68995368.py:70: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  comparePredictions[\"Driver\"] = comparePredictions[driver_cols].idxmax(axis=1).str.replace(\"Driver_\", \"\", regex=False)\n",
            "/tmp/ipython-input-68995368.py:74: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  comparePredictions[\"predicted_winner\"] = (\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Position  RaceOrder  win  predicted           track          Driver  \\\n",
              "0           1          1    1   0.220817       Australia    Lando Norris   \n",
              "199         1         11    1   0.209566         Austria    Lando Norris   \n",
              "65          6          4    0   0.218537         Bahrain  Max Verstappen   \n",
              "60          1          4    1   0.154171         Bahrain   Oscar Piastri   \n",
              "242         4         13    0   0.230719         Belgium  Max Verstappen   \n",
              "239         1         13    1   0.166352         Belgium   Oscar Piastri   \n",
              "180         2         10    0   0.268267          Canada  Max Verstappen   \n",
              "179         1         10    1   0.126998          Canada  George Russell   \n",
              "23          4          2    0   0.213321           China  Max Verstappen   \n",
              "20          1          2    1   0.148954           China   Oscar Piastri   \n",
              "120         1          7    1   0.243333  Emilia Romagna  Max Verstappen   \n",
              "121         2          7    0   0.249843  Emilia Romagna    Lando Norris   \n",
              "219         1         12    1   0.221023   Great Britain    Lando Norris   \n",
              "40          1          3    1   0.216840           Japan  Max Verstappen   \n",
              "101         2          6    0   0.231838           Miami    Lando Norris   \n",
              "100         1          6    1   0.156133           Miami   Oscar Piastri   \n",
              "143         4          8    0   0.271915          Monaco  Max Verstappen   \n",
              "140         1          8    1   0.262141          Monaco    Lando Norris   \n",
              "83          4          5    0   0.234560    Saudi Arabia    Lando Norris   \n",
              "80          1          5    1   0.168598    Saudi Arabia   Oscar Piastri   \n",
              "161         2          9    0   0.272384           Spain    Lando Norris   \n",
              "160         1          9    1   0.205196           Spain   Oscar Piastri   \n",
              "\n",
              "     predicted_winner  \n",
              "0                   1  \n",
              "199                 1  \n",
              "65                  1  \n",
              "60                  0  \n",
              "242                 1  \n",
              "239                 0  \n",
              "180                 1  \n",
              "179                 0  \n",
              "23                  1  \n",
              "20                  0  \n",
              "120                 0  \n",
              "121                 1  \n",
              "219                 1  \n",
              "40                  1  \n",
              "101                 1  \n",
              "100                 0  \n",
              "143                 1  \n",
              "140                 0  \n",
              "83                  1  \n",
              "80                  0  \n",
              "161                 1  \n",
              "160                 0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a3d2a773-2362-40fa-9d07-93e5b5df9637\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Position</th>\n",
              "      <th>RaceOrder</th>\n",
              "      <th>win</th>\n",
              "      <th>predicted</th>\n",
              "      <th>track</th>\n",
              "      <th>Driver</th>\n",
              "      <th>predicted_winner</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.220817</td>\n",
              "      <td>Australia</td>\n",
              "      <td>Lando Norris</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199</th>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>0.209566</td>\n",
              "      <td>Austria</td>\n",
              "      <td>Lando Norris</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65</th>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0.218537</td>\n",
              "      <td>Bahrain</td>\n",
              "      <td>Max Verstappen</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0.154171</td>\n",
              "      <td>Bahrain</td>\n",
              "      <td>Oscar Piastri</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>242</th>\n",
              "      <td>4</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>0.230719</td>\n",
              "      <td>Belgium</td>\n",
              "      <td>Max Verstappen</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>239</th>\n",
              "      <td>1</td>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "      <td>0.166352</td>\n",
              "      <td>Belgium</td>\n",
              "      <td>Oscar Piastri</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>180</th>\n",
              "      <td>2</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>0.268267</td>\n",
              "      <td>Canada</td>\n",
              "      <td>Max Verstappen</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>179</th>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>0.126998</td>\n",
              "      <td>Canada</td>\n",
              "      <td>George Russell</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.213321</td>\n",
              "      <td>China</td>\n",
              "      <td>Max Verstappen</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0.148954</td>\n",
              "      <td>China</td>\n",
              "      <td>Oscar Piastri</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120</th>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>0.243333</td>\n",
              "      <td>Emilia Romagna</td>\n",
              "      <td>Max Verstappen</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>121</th>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0.249843</td>\n",
              "      <td>Emilia Romagna</td>\n",
              "      <td>Lando Norris</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>219</th>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>0.221023</td>\n",
              "      <td>Great Britain</td>\n",
              "      <td>Lando Norris</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0.216840</td>\n",
              "      <td>Japan</td>\n",
              "      <td>Max Verstappen</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101</th>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0.231838</td>\n",
              "      <td>Miami</td>\n",
              "      <td>Lando Norris</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100</th>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>0.156133</td>\n",
              "      <td>Miami</td>\n",
              "      <td>Oscar Piastri</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>143</th>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>0.271915</td>\n",
              "      <td>Monaco</td>\n",
              "      <td>Max Verstappen</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>140</th>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>0.262141</td>\n",
              "      <td>Monaco</td>\n",
              "      <td>Lando Norris</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>83</th>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0.234560</td>\n",
              "      <td>Saudi Arabia</td>\n",
              "      <td>Lando Norris</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80</th>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0.168598</td>\n",
              "      <td>Saudi Arabia</td>\n",
              "      <td>Oscar Piastri</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>161</th>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0.272384</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Lando Norris</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>160</th>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>0.205196</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Oscar Piastri</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a3d2a773-2362-40fa-9d07-93e5b5df9637')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a3d2a773-2362-40fa-9d07-93e5b5df9637 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a3d2a773-2362-40fa-9d07-93e5b5df9637');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-75c60da4-5f6a-448b-bf9d-da5bd2107242\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-75c60da4-5f6a-448b-bf9d-da5bd2107242')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-75c60da4-5f6a-448b-bf9d-da5bd2107242 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "smallDf",
              "summary": "{\n  \"name\": \"smallDf\",\n  \"rows\": 22,\n  \"fields\": [\n    {\n      \"column\": \"Position\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 6,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          6,\n          2,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"RaceOrder\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 1,\n        \"max\": 13,\n        \"num_unique_values\": 13,\n        \"samples\": [\n          5,\n          6,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"win\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"predicted\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 22,\n        \"samples\": [\n          0.2208167016506195,\n          0.21684014797210693\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"track\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 13,\n        \"samples\": [\n          \"Saudi Arabia\",\n          \"Miami\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Driver\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Max Verstappen\",\n          \"George Russell\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"predicted_winner\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create the Remainder of the 2025 Season Input data\n",
        "\n",
        "> Add blockquote\n",
        "\n"
      ],
      "metadata": {
        "id": "2qUorKcH7nvI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I need to add more data that will fill in those missing races:\n",
        "Dutch Grand Prix\n",
        "\n",
        "Italian Grand Prix\n",
        "\n",
        "Azerbaijan Grand Prix\n",
        "\n",
        "Singapore Grand Prix\n",
        "\n",
        "United States Grand Prix (Austin)\n",
        "\n",
        "Mexico City Grand Prix\n",
        "\n",
        "São Paulo Grand Prix\n",
        "\n",
        "Las Vegas Grand Prix\n",
        "\n",
        "Qatar Grand Prix\n",
        "\n",
        "Abu Dhabi Grand Prix"
      ],
      "metadata": {
        "id": "--ZCshOMEfSu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fullDf['Track'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JaOW2BnJEd_q",
        "outputId": "47d6ea13-8cc4-47b2-fda6-75e2c480407d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Bahrain', 'Saudi Arabia', 'Australia', 'Emilia Romagna', 'Miami',\n",
              "       'Spain', 'Monaco', 'Azerbaijan', 'Canada', 'Great Britain',\n",
              "       'Austria', 'France', 'Hungary', 'Belgium', 'Netherlands', 'Italy',\n",
              "       'Singapore', 'Japan', 'United States', 'Mexico', 'Brazil',\n",
              "       'Abu Dhabi', 'Qatar', 'Las Vegas', 'China'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "remainder2025Races = ['Netherlands', 'Italy',\n",
        "       'Azerbaijan','Singapore', 'United States', 'Mexico', 'Brazil', 'Las Vegas',\n",
        "       'Qatar', 'Abu Dhabi']"
      ],
      "metadata": {
        "id": "Qd6Q_-tbFBMy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "teamDriverCombos = df_encoded[ (df_encoded['Year_2025'] == 1) & (df_encoded['Track_Miami']==1)]\n",
        "teamDriverCombos.head(40)\n",
        "print(teamDriverCombos.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AxZcTkBdyBkd",
        "outputId": "d040b746-5e8f-4902-c2d3-57ac44f74099"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(20, 76)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "newTrackDfs = []\n",
        "raceOrderIndex = 1\n",
        "\n",
        "prevRace = 'Miami'\n",
        "# I need to replicate the remainder races for those races in the 2025 data\n",
        "for eachRace in remainder2025Races:\n",
        "  print(eachRace)\n",
        "  print(\"The race index: \", raceOrderIndex)\n",
        "  #get the 2024 track info to get the #of laps\n",
        "  newTrackDf = teamDriverCombos.copy()\n",
        "  trackInfo = df_encoded[(df_encoded['Track_' + eachRace] == 1) & (df_encoded['Year_2024'] == 1)]\n",
        "  trackLaps = max(trackInfo['Laps'].unique())\n",
        "  newTrackDf['Track_Miami'] = 0\n",
        "  newTrackDf['Track_' + eachRace] = 1\n",
        "  newTrackDf['Laps'] = trackLaps\n",
        "  newTrackDf['Year_2025'] = 1\n",
        "  newTrackDf['win'] = 0\n",
        "  newTrackDf['Position'] = 21\n",
        "  newTrackDf[\"RaceOrder\"] = np.where(newTrackDf['Track_' + prevRace] == 1, 0, newTrackDf[\"RaceOrder\"])\n",
        "  newTrackDf[\"RaceOrder\"] = np.where(newTrackDf['Track_' + eachRace] == 1, raceOrderIndex, newTrackDf[\"RaceOrder\"])\n",
        "  prevRace = eachRace\n",
        "  raceOrderIndex = raceOrderIndex + 1\n",
        "  newTrackDfs.append(newTrackDf)\n",
        "\n",
        "\n",
        "theNewDf = pd.concat(newTrackDfs, ignore_index=True)\n",
        "theNewDf.head(43)\n",
        "print(theNewDf.shape)\n",
        "theNewDf.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TfEWNR_nyP1M",
        "outputId": "65fc46bc-e1fb-46d9-ba2c-7de3a7f76f67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Netherlands\n",
            "The race index:  1\n",
            "Italy\n",
            "The race index:  2\n",
            "Azerbaijan\n",
            "The race index:  3\n",
            "Singapore\n",
            "The race index:  4\n",
            "United States\n",
            "The race index:  5\n",
            "Mexico\n",
            "The race index:  6\n",
            "Brazil\n",
            "The race index:  7\n",
            "Las Vegas\n",
            "The race index:  8\n",
            "Qatar\n",
            "The race index:  9\n",
            "Abu Dhabi\n",
            "The race index:  10\n",
            "(200, 76)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             Laps  Position   RaceOrder  Track_Abu Dhabi  Track_Australia  \\\n",
              "count  200.000000     200.0  200.000000       200.000000            200.0   \n",
              "mean    59.900000      21.0    5.500000         0.100000              0.0   \n",
              "std      7.822786       0.0    2.879489         0.300753              0.0   \n",
              "min     50.000000      21.0    1.000000         0.000000              0.0   \n",
              "25%     53.000000      21.0    3.000000         0.000000              0.0   \n",
              "50%     57.500000      21.0    5.500000         0.000000              0.0   \n",
              "75%     69.000000      21.0    8.000000         0.000000              0.0   \n",
              "max     72.000000      21.0   10.000000         1.000000              0.0   \n",
              "\n",
              "       Track_Austria  Track_Azerbaijan  Track_Bahrain  Track_Belgium  \\\n",
              "count          200.0        200.000000          200.0          200.0   \n",
              "mean             0.0          0.100000            0.0            0.0   \n",
              "std              0.0          0.300753            0.0            0.0   \n",
              "min              0.0          0.000000            0.0            0.0   \n",
              "25%              0.0          0.000000            0.0            0.0   \n",
              "50%              0.0          0.000000            0.0            0.0   \n",
              "75%              0.0          0.000000            0.0            0.0   \n",
              "max              0.0          1.000000            0.0            0.0   \n",
              "\n",
              "       Track_Brazil  ...  Team_McLaren Mercedes  Team_Mercedes  Team_Red Bull  \\\n",
              "count    200.000000  ...             200.000000     200.000000     200.000000   \n",
              "mean       0.100000  ...               0.100000       0.100000       0.100000   \n",
              "std        0.300753  ...               0.300753       0.300753       0.300753   \n",
              "min        0.000000  ...               0.000000       0.000000       0.000000   \n",
              "25%        0.000000  ...               0.000000       0.000000       0.000000   \n",
              "50%        0.000000  ...               0.000000       0.000000       0.000000   \n",
              "75%        0.000000  ...               0.000000       0.000000       0.000000   \n",
              "max        1.000000  ...               1.000000       1.000000       1.000000   \n",
              "\n",
              "       Team_Williams Mercedes  Year_2022  Year_2023  Year_2024  Year_2025  \\\n",
              "count              200.000000      200.0      200.0      200.0      200.0   \n",
              "mean                 0.100000        0.0        0.0        0.0        1.0   \n",
              "std                  0.300753        0.0        0.0        0.0        0.0   \n",
              "min                  0.000000        0.0        0.0        0.0        1.0   \n",
              "25%                  0.000000        0.0        0.0        0.0        1.0   \n",
              "50%                  0.000000        0.0        0.0        0.0        1.0   \n",
              "75%                  0.000000        0.0        0.0        0.0        1.0   \n",
              "max                  1.000000        0.0        0.0        0.0        1.0   \n",
              "\n",
              "       Year_2026    win  \n",
              "count      200.0  200.0  \n",
              "mean         0.0    0.0  \n",
              "std          0.0    0.0  \n",
              "min          0.0    0.0  \n",
              "25%          0.0    0.0  \n",
              "50%          0.0    0.0  \n",
              "75%          0.0    0.0  \n",
              "max          0.0    0.0  \n",
              "\n",
              "[8 rows x 76 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-12633657-6cd5-49ea-934f-a3b213e2803b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Laps</th>\n",
              "      <th>Position</th>\n",
              "      <th>RaceOrder</th>\n",
              "      <th>Track_Abu Dhabi</th>\n",
              "      <th>Track_Australia</th>\n",
              "      <th>Track_Austria</th>\n",
              "      <th>Track_Azerbaijan</th>\n",
              "      <th>Track_Bahrain</th>\n",
              "      <th>Track_Belgium</th>\n",
              "      <th>Track_Brazil</th>\n",
              "      <th>...</th>\n",
              "      <th>Team_McLaren Mercedes</th>\n",
              "      <th>Team_Mercedes</th>\n",
              "      <th>Team_Red Bull</th>\n",
              "      <th>Team_Williams Mercedes</th>\n",
              "      <th>Year_2022</th>\n",
              "      <th>Year_2023</th>\n",
              "      <th>Year_2024</th>\n",
              "      <th>Year_2025</th>\n",
              "      <th>Year_2026</th>\n",
              "      <th>win</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>200.000000</td>\n",
              "      <td>200.0</td>\n",
              "      <td>200.000000</td>\n",
              "      <td>200.000000</td>\n",
              "      <td>200.0</td>\n",
              "      <td>200.0</td>\n",
              "      <td>200.000000</td>\n",
              "      <td>200.0</td>\n",
              "      <td>200.0</td>\n",
              "      <td>200.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>200.000000</td>\n",
              "      <td>200.000000</td>\n",
              "      <td>200.000000</td>\n",
              "      <td>200.000000</td>\n",
              "      <td>200.0</td>\n",
              "      <td>200.0</td>\n",
              "      <td>200.0</td>\n",
              "      <td>200.0</td>\n",
              "      <td>200.0</td>\n",
              "      <td>200.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>59.900000</td>\n",
              "      <td>21.0</td>\n",
              "      <td>5.500000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>7.822786</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.879489</td>\n",
              "      <td>0.300753</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.300753</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.300753</td>\n",
              "      <td>...</td>\n",
              "      <td>0.300753</td>\n",
              "      <td>0.300753</td>\n",
              "      <td>0.300753</td>\n",
              "      <td>0.300753</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>50.000000</td>\n",
              "      <td>21.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>53.000000</td>\n",
              "      <td>21.0</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>57.500000</td>\n",
              "      <td>21.0</td>\n",
              "      <td>5.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>69.000000</td>\n",
              "      <td>21.0</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>72.000000</td>\n",
              "      <td>21.0</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 76 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-12633657-6cd5-49ea-934f-a3b213e2803b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-12633657-6cd5-49ea-934f-a3b213e2803b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-12633657-6cd5-49ea-934f-a3b213e2803b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-6867e335-af96-4330-bd21-9b8da69c0304\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6867e335-af96-4330-bd21-9b8da69c0304')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-6867e335-af96-4330-bd21-9b8da69c0304 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#add the remainder races to the 2025 season\n",
        "completed2025= pd.concat([df_encoded, theNewDf], ignore_index=True)\n",
        "\n",
        "print(df_encoded.shape)\n",
        "print(completed2025.shape)\n",
        "completed2025.describe()"
      ],
      "metadata": {
        "id": "Tka85hOaFi0I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ca36068-95ed-49c7-b6a8-6f8f6236b143"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1618, 76)\n",
            "(1818, 76)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              Laps     Position    RaceOrder  Track_Abu Dhabi  \\\n",
              "count  1818.000000  1818.000000  1818.000000      1818.000000   \n",
              "mean     55.163916    11.896040    10.466447         0.044004   \n",
              "std      16.169288     6.651782     6.409029         0.205161   \n",
              "min       0.000000     1.000000     1.000000         0.000000   \n",
              "25%      51.000000     6.000000     5.000000         0.000000   \n",
              "50%      57.000000    12.000000    10.000000         0.000000   \n",
              "75%      69.000000    18.000000    16.000000         0.000000   \n",
              "max      78.000000    21.000000    24.000000         1.000000   \n",
              "\n",
              "       Track_Australia  Track_Austria  Track_Azerbaijan  Track_Bahrain  \\\n",
              "count      1818.000000    1818.000000       1818.000000    1818.000000   \n",
              "mean          0.043454       0.044004          0.044004       0.044004   \n",
              "std           0.203934       0.205161          0.205161       0.205161   \n",
              "min           0.000000       0.000000          0.000000       0.000000   \n",
              "25%           0.000000       0.000000          0.000000       0.000000   \n",
              "50%           0.000000       0.000000          0.000000       0.000000   \n",
              "75%           0.000000       0.000000          0.000000       0.000000   \n",
              "max           1.000000       1.000000          1.000000       1.000000   \n",
              "\n",
              "       Track_Belgium  Track_Brazil  ...  Team_McLaren Mercedes  Team_Mercedes  \\\n",
              "count    1818.000000   1818.000000  ...            1818.000000    1818.000000   \n",
              "mean        0.044004      0.044004  ...               0.100110       0.100110   \n",
              "std         0.205161      0.205161  ...               0.300229       0.300229   \n",
              "min         0.000000      0.000000  ...               0.000000       0.000000   \n",
              "25%         0.000000      0.000000  ...               0.000000       0.000000   \n",
              "50%         0.000000      0.000000  ...               0.000000       0.000000   \n",
              "75%         0.000000      0.000000  ...               0.000000       0.000000   \n",
              "max         1.000000      1.000000  ...               1.000000       1.000000   \n",
              "\n",
              "       Team_Red Bull  Team_Williams Mercedes    Year_2022    Year_2023  \\\n",
              "count    1818.000000             1818.000000  1818.000000  1818.000000   \n",
              "mean        0.126513                0.099560     0.242024     0.242024   \n",
              "std         0.332518                0.299495     0.428427     0.428427   \n",
              "min         0.000000                0.000000     0.000000     0.000000   \n",
              "25%         0.000000                0.000000     0.000000     0.000000   \n",
              "50%         0.000000                0.000000     0.000000     0.000000   \n",
              "75%         0.000000                0.000000     0.000000     0.000000   \n",
              "max         1.000000                1.000000     1.000000     1.000000   \n",
              "\n",
              "         Year_2024    Year_2025  Year_2026          win  \n",
              "count  1818.000000  1818.000000     1818.0  1818.000000  \n",
              "mean      0.263476     0.252475        0.0     0.044554  \n",
              "std       0.440640     0.434552        0.0     0.206380  \n",
              "min       0.000000     0.000000        0.0     0.000000  \n",
              "25%       0.000000     0.000000        0.0     0.000000  \n",
              "50%       0.000000     0.000000        0.0     0.000000  \n",
              "75%       1.000000     1.000000        0.0     0.000000  \n",
              "max       1.000000     1.000000        0.0     1.000000  \n",
              "\n",
              "[8 rows x 76 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f27afd7c-603d-4791-be76-2ea257b54411\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Laps</th>\n",
              "      <th>Position</th>\n",
              "      <th>RaceOrder</th>\n",
              "      <th>Track_Abu Dhabi</th>\n",
              "      <th>Track_Australia</th>\n",
              "      <th>Track_Austria</th>\n",
              "      <th>Track_Azerbaijan</th>\n",
              "      <th>Track_Bahrain</th>\n",
              "      <th>Track_Belgium</th>\n",
              "      <th>Track_Brazil</th>\n",
              "      <th>...</th>\n",
              "      <th>Team_McLaren Mercedes</th>\n",
              "      <th>Team_Mercedes</th>\n",
              "      <th>Team_Red Bull</th>\n",
              "      <th>Team_Williams Mercedes</th>\n",
              "      <th>Year_2022</th>\n",
              "      <th>Year_2023</th>\n",
              "      <th>Year_2024</th>\n",
              "      <th>Year_2025</th>\n",
              "      <th>Year_2026</th>\n",
              "      <th>win</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1818.000000</td>\n",
              "      <td>1818.000000</td>\n",
              "      <td>1818.000000</td>\n",
              "      <td>1818.000000</td>\n",
              "      <td>1818.000000</td>\n",
              "      <td>1818.000000</td>\n",
              "      <td>1818.000000</td>\n",
              "      <td>1818.000000</td>\n",
              "      <td>1818.000000</td>\n",
              "      <td>1818.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1818.000000</td>\n",
              "      <td>1818.000000</td>\n",
              "      <td>1818.000000</td>\n",
              "      <td>1818.000000</td>\n",
              "      <td>1818.000000</td>\n",
              "      <td>1818.000000</td>\n",
              "      <td>1818.000000</td>\n",
              "      <td>1818.000000</td>\n",
              "      <td>1818.0</td>\n",
              "      <td>1818.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>55.163916</td>\n",
              "      <td>11.896040</td>\n",
              "      <td>10.466447</td>\n",
              "      <td>0.044004</td>\n",
              "      <td>0.043454</td>\n",
              "      <td>0.044004</td>\n",
              "      <td>0.044004</td>\n",
              "      <td>0.044004</td>\n",
              "      <td>0.044004</td>\n",
              "      <td>0.044004</td>\n",
              "      <td>...</td>\n",
              "      <td>0.100110</td>\n",
              "      <td>0.100110</td>\n",
              "      <td>0.126513</td>\n",
              "      <td>0.099560</td>\n",
              "      <td>0.242024</td>\n",
              "      <td>0.242024</td>\n",
              "      <td>0.263476</td>\n",
              "      <td>0.252475</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.044554</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>16.169288</td>\n",
              "      <td>6.651782</td>\n",
              "      <td>6.409029</td>\n",
              "      <td>0.205161</td>\n",
              "      <td>0.203934</td>\n",
              "      <td>0.205161</td>\n",
              "      <td>0.205161</td>\n",
              "      <td>0.205161</td>\n",
              "      <td>0.205161</td>\n",
              "      <td>0.205161</td>\n",
              "      <td>...</td>\n",
              "      <td>0.300229</td>\n",
              "      <td>0.300229</td>\n",
              "      <td>0.332518</td>\n",
              "      <td>0.299495</td>\n",
              "      <td>0.428427</td>\n",
              "      <td>0.428427</td>\n",
              "      <td>0.440640</td>\n",
              "      <td>0.434552</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.206380</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>51.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>57.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>69.000000</td>\n",
              "      <td>18.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>78.000000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 76 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f27afd7c-603d-4791-be76-2ea257b54411')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f27afd7c-603d-4791-be76-2ea257b54411 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f27afd7c-603d-4791-be76-2ea257b54411');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-d3beb8c6-2af2-41c2-8c7c-1f70f7d078f2\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d3beb8c6-2af2-41c2-8c7c-1f70f7d078f2')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-d3beb8c6-2af2-41c2-8c7c-1f70f7d078f2 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "yearsTrain = [ '2024']\n",
        "yearsPredict = ['2025']\n",
        "\n",
        "df, smallDf = trainModel(yearsTrain, yearsPredict, completed2025, \"relu\", \"adam\", 20)\n",
        "smallDf.head(100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aThBGCLw7nHE",
        "outputId": "eb6834ad-1473-4e75-81f3-555616e54d35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The years trained:  ['Year_2024']\n",
            "The years tested:  ['Year_2025']\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.7455 - loss: 0.2632 - val_accuracy: 0.9479 - val_loss: 0.0615\n",
            "Epoch 2/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0324 - val_accuracy: 0.9479 - val_loss: 0.0480\n",
            "Epoch 3/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9689 - loss: 0.0358 - val_accuracy: 0.9479 - val_loss: 0.0491\n",
            "Epoch 4/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0317 - val_accuracy: 0.9479 - val_loss: 0.0469\n",
            "Epoch 5/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0314 - val_accuracy: 0.9479 - val_loss: 0.0470\n",
            "Epoch 6/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0311 - val_accuracy: 0.9479 - val_loss: 0.0469\n",
            "Epoch 7/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9689 - loss: 0.0315 - val_accuracy: 0.9479 - val_loss: 0.0468\n",
            "Epoch 8/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0309 - val_accuracy: 0.9479 - val_loss: 0.0467\n",
            "Epoch 9/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0309 - val_accuracy: 0.9479 - val_loss: 0.0466\n",
            "Epoch 10/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0310 - val_accuracy: 0.9479 - val_loss: 0.0470\n",
            "Epoch 11/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0314 - val_accuracy: 0.9479 - val_loss: 0.0475\n",
            "Epoch 12/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0319 - val_accuracy: 0.9479 - val_loss: 0.0477\n",
            "Epoch 13/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0319 - val_accuracy: 0.9479 - val_loss: 0.0474\n",
            "Epoch 14/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9689 - loss: 0.0312 - val_accuracy: 0.9479 - val_loss: 0.0478\n",
            "Epoch 15/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0309 - val_accuracy: 0.9479 - val_loss: 0.0484\n",
            "Epoch 16/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9689 - loss: 0.0311 - val_accuracy: 0.9479 - val_loss: 0.0488\n",
            "Epoch 17/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0312 - val_accuracy: 0.9479 - val_loss: 0.0491\n",
            "Epoch 18/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9689 - loss: 0.0311 - val_accuracy: 0.9479 - val_loss: 0.0495\n",
            "Epoch 19/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9689 - loss: 0.0311 - val_accuracy: 0.9479 - val_loss: 0.0497\n",
            "Epoch 20/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0308 - val_accuracy: 0.9479 - val_loss: 0.0500\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9555 - loss: 0.0442  \n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
            "The amount guessed correctly: 4  out of  23  races.\n",
            "The percentage guessed correctly: 0.17391304347826086\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-68995368.py:61: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  comparePredictions['predicted'] = model.predict(x_test)\n",
            "/tmp/ipython-input-68995368.py:69: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  comparePredictions[\"track\"] = comparePredictions[track_cols].idxmax(axis=1).str.replace(\"Track_\", \"\", regex=False)\n",
            "/tmp/ipython-input-68995368.py:70: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  comparePredictions[\"Driver\"] = comparePredictions[driver_cols].idxmax(axis=1).str.replace(\"Driver_\", \"\", regex=False)\n",
            "/tmp/ipython-input-68995368.py:74: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  comparePredictions[\"predicted_winner\"] = (\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Position  RaceOrder  win  predicted           track          Driver  \\\n",
              "1801        21         10    0   0.228938       Abu Dhabi  Max Verstappen   \n",
              "1359         1          1    1   0.220817       Australia    Lando Norris   \n",
              "1558         1         11    1   0.209566         Austria    Lando Norris   \n",
              "1661        21          3    0   0.263026      Azerbaijan  Max Verstappen   \n",
              "1424         6          4    0   0.218537         Bahrain  Max Verstappen   \n",
              "1419         1          4    1   0.154171         Bahrain   Oscar Piastri   \n",
              "1601         4         13    0   0.230719         Belgium  Max Verstappen   \n",
              "1598         1         13    1   0.166352         Belgium   Oscar Piastri   \n",
              "1741        21          7    0   0.221371          Brazil  Max Verstappen   \n",
              "1539         2         10    0   0.268267          Canada  Max Verstappen   \n",
              "1538         1         10    1   0.126998          Canada  George Russell   \n",
              "1382         4          2    0   0.213321           China  Max Verstappen   \n",
              "1379         1          2    1   0.148954           China   Oscar Piastri   \n",
              "1480         2          7    0   0.249843  Emilia Romagna    Lando Norris   \n",
              "1479         1          7    1   0.243333  Emilia Romagna  Max Verstappen   \n",
              "1578         1         12    1   0.221023   Great Britain    Lando Norris   \n",
              "1641        21          2    0   0.242403           Italy  Max Verstappen   \n",
              "1399         1          3    1   0.216840           Japan  Max Verstappen   \n",
              "1761        21          8    0   0.205069       Las Vegas  Max Verstappen   \n",
              "1719        21          6    0   0.260509          Mexico    Lando Norris   \n",
              "1460         2          6    0   0.231838           Miami    Lando Norris   \n",
              "1459         1          6    1   0.156133           Miami   Oscar Piastri   \n",
              "1502         4          8    0   0.271915          Monaco  Max Verstappen   \n",
              "1499         1          8    1   0.262141          Monaco    Lando Norris   \n",
              "1619        21          1    0   0.272878     Netherlands    Lando Norris   \n",
              "1779        21          9    0   0.246371           Qatar    Lando Norris   \n",
              "1442         4          5    0   0.234560    Saudi Arabia    Lando Norris   \n",
              "1439         1          5    1   0.168598    Saudi Arabia   Oscar Piastri   \n",
              "1681        21          4    0   0.275965       Singapore  Max Verstappen   \n",
              "1520         2          9    0   0.272384           Spain    Lando Norris   \n",
              "1519         1          9    1   0.205196           Spain   Oscar Piastri   \n",
              "1701        21          5    0   0.236491   United States  Max Verstappen   \n",
              "\n",
              "      predicted_winner  \n",
              "1801                 1  \n",
              "1359                 1  \n",
              "1558                 1  \n",
              "1661                 1  \n",
              "1424                 1  \n",
              "1419                 0  \n",
              "1601                 1  \n",
              "1598                 0  \n",
              "1741                 1  \n",
              "1539                 1  \n",
              "1538                 0  \n",
              "1382                 1  \n",
              "1379                 0  \n",
              "1480                 1  \n",
              "1479                 0  \n",
              "1578                 1  \n",
              "1641                 1  \n",
              "1399                 1  \n",
              "1761                 1  \n",
              "1719                 1  \n",
              "1460                 1  \n",
              "1459                 0  \n",
              "1502                 1  \n",
              "1499                 0  \n",
              "1619                 1  \n",
              "1779                 1  \n",
              "1442                 1  \n",
              "1439                 0  \n",
              "1681                 1  \n",
              "1520                 1  \n",
              "1519                 0  \n",
              "1701                 1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-99c8ecfd-d5d8-463e-9993-ab74c8366de8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Position</th>\n",
              "      <th>RaceOrder</th>\n",
              "      <th>win</th>\n",
              "      <th>predicted</th>\n",
              "      <th>track</th>\n",
              "      <th>Driver</th>\n",
              "      <th>predicted_winner</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1801</th>\n",
              "      <td>21</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>0.228938</td>\n",
              "      <td>Abu Dhabi</td>\n",
              "      <td>Max Verstappen</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1359</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.220817</td>\n",
              "      <td>Australia</td>\n",
              "      <td>Lando Norris</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1558</th>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>0.209566</td>\n",
              "      <td>Austria</td>\n",
              "      <td>Lando Norris</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1661</th>\n",
              "      <td>21</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0.263026</td>\n",
              "      <td>Azerbaijan</td>\n",
              "      <td>Max Verstappen</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1424</th>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0.218537</td>\n",
              "      <td>Bahrain</td>\n",
              "      <td>Max Verstappen</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1419</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0.154171</td>\n",
              "      <td>Bahrain</td>\n",
              "      <td>Oscar Piastri</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1601</th>\n",
              "      <td>4</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>0.230719</td>\n",
              "      <td>Belgium</td>\n",
              "      <td>Max Verstappen</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1598</th>\n",
              "      <td>1</td>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "      <td>0.166352</td>\n",
              "      <td>Belgium</td>\n",
              "      <td>Oscar Piastri</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1741</th>\n",
              "      <td>21</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0.221371</td>\n",
              "      <td>Brazil</td>\n",
              "      <td>Max Verstappen</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1539</th>\n",
              "      <td>2</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>0.268267</td>\n",
              "      <td>Canada</td>\n",
              "      <td>Max Verstappen</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1538</th>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>0.126998</td>\n",
              "      <td>Canada</td>\n",
              "      <td>George Russell</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1382</th>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.213321</td>\n",
              "      <td>China</td>\n",
              "      <td>Max Verstappen</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1379</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0.148954</td>\n",
              "      <td>China</td>\n",
              "      <td>Oscar Piastri</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1480</th>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0.249843</td>\n",
              "      <td>Emilia Romagna</td>\n",
              "      <td>Lando Norris</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1479</th>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>0.243333</td>\n",
              "      <td>Emilia Romagna</td>\n",
              "      <td>Max Verstappen</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1578</th>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>0.221023</td>\n",
              "      <td>Great Britain</td>\n",
              "      <td>Lando Norris</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1641</th>\n",
              "      <td>21</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.242403</td>\n",
              "      <td>Italy</td>\n",
              "      <td>Max Verstappen</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1399</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0.216840</td>\n",
              "      <td>Japan</td>\n",
              "      <td>Max Verstappen</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1761</th>\n",
              "      <td>21</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>0.205069</td>\n",
              "      <td>Las Vegas</td>\n",
              "      <td>Max Verstappen</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1719</th>\n",
              "      <td>21</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0.260509</td>\n",
              "      <td>Mexico</td>\n",
              "      <td>Lando Norris</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1460</th>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0.231838</td>\n",
              "      <td>Miami</td>\n",
              "      <td>Lando Norris</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1459</th>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>0.156133</td>\n",
              "      <td>Miami</td>\n",
              "      <td>Oscar Piastri</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1502</th>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>0.271915</td>\n",
              "      <td>Monaco</td>\n",
              "      <td>Max Verstappen</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1499</th>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>0.262141</td>\n",
              "      <td>Monaco</td>\n",
              "      <td>Lando Norris</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1619</th>\n",
              "      <td>21</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.272878</td>\n",
              "      <td>Netherlands</td>\n",
              "      <td>Lando Norris</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1779</th>\n",
              "      <td>21</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0.246371</td>\n",
              "      <td>Qatar</td>\n",
              "      <td>Lando Norris</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1442</th>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0.234560</td>\n",
              "      <td>Saudi Arabia</td>\n",
              "      <td>Lando Norris</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1439</th>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0.168598</td>\n",
              "      <td>Saudi Arabia</td>\n",
              "      <td>Oscar Piastri</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1681</th>\n",
              "      <td>21</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0.275965</td>\n",
              "      <td>Singapore</td>\n",
              "      <td>Max Verstappen</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1520</th>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0.272384</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Lando Norris</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1519</th>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>0.205196</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Oscar Piastri</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1701</th>\n",
              "      <td>21</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0.236491</td>\n",
              "      <td>United States</td>\n",
              "      <td>Max Verstappen</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-99c8ecfd-d5d8-463e-9993-ab74c8366de8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-99c8ecfd-d5d8-463e-9993-ab74c8366de8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-99c8ecfd-d5d8-463e-9993-ab74c8366de8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-6c61fd1e-dd59-4089-8664-8fbbd76a9717\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6c61fd1e-dd59-4089-8664-8fbbd76a9717')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-6c61fd1e-dd59-4089-8664-8fbbd76a9717 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "smallDf",
              "summary": "{\n  \"name\": \"smallDf\",\n  \"rows\": 32,\n  \"fields\": [\n    {\n      \"column\": \"Position\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9,\n        \"min\": 1,\n        \"max\": 21,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1,\n          2,\n          6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"RaceOrder\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 1,\n        \"max\": 13,\n        \"num_unique_values\": 13,\n        \"samples\": [\n          9,\n          8,\n          10\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"win\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"predicted\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 32,\n        \"samples\": [\n          0.27238380908966064,\n          0.22102293372154236\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"track\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 23,\n        \"samples\": [\n          \"Miami\",\n          \"Emilia Romagna\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Driver\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Lando Norris\",\n          \"George Russell\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"predicted_winner\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create the 2026 Input Data"
      ],
      "metadata": {
        "id": "QMEt4Wd1dfMN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(fullDf['Track'].unique())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lIqSdKbK_jWi",
        "outputId": "4e77e049-61c7-4e22-ff1d-6326667ab691"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Bahrain' 'Saudi Arabia' 'Australia' 'Emilia Romagna' 'Miami' 'Spain'\n",
            " 'Monaco' 'Azerbaijan' 'Canada' 'Great Britain' 'Austria' 'France'\n",
            " 'Hungary' 'Belgium' 'Netherlands' 'Italy' 'Singapore' 'Japan'\n",
            " 'United States' 'Mexico' 'Brazil' 'Abu Dhabi' 'Qatar' 'Las Vegas' 'China']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get all of the races for the 2026 seasons. I use the emilia romagna as the replacement for the spanish track"
      ],
      "metadata": {
        "id": "gzCReF5Xd9u3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "races2026 = ['Australia', 'China', 'Japan', 'Bahrain', 'Saudi Arabia', 'Miami', 'Canada',\n",
        "             'Monaco',  'Emilia Romagna', 'Austria','Great Britain', 'Belgium', 'Hungary', 'Netherlands','Italy',\n",
        "              'Azerbaijan', 'Singapore', 'United States', 'Mexico', 'Brazil',\n",
        "             'Las Vegas', 'Qatar', 'Abu Dhabi']\n"
      ],
      "metadata": {
        "id": "Jg9NKNH4BYrJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new2026TrackDfs = []\n",
        "raceOrderIndex2026 = 1\n",
        "\n",
        "prevRace = 'Miami'\n",
        "# I need to replicate the remainder races for those races in the 2025 data\n",
        "for eachRace in races2026:\n",
        "  print(eachRace)\n",
        "  print(\"The race index: \", raceOrderIndex2026)\n",
        "  #get the 2024 track info to get the #of laps\n",
        "  new2026TrackDf = teamDriverCombos.copy()\n",
        "  trackInfo = df_encoded[(df_encoded['Track_' + eachRace] == 1) & (df_encoded['Year_2024'] == 1)]\n",
        "  trackLaps = max(trackInfo['Laps'].unique())\n",
        "  new2026TrackDf['Track_Miami'] = 0\n",
        "  new2026TrackDf['Track_' + eachRace] = 1\n",
        "  new2026TrackDf['Laps'] = trackLaps\n",
        "  new2026TrackDf['Year_2025'] = 0\n",
        "  new2026TrackDf['Year_2026'] = 1\n",
        "  new2026TrackDf['win'] = 0\n",
        "  new2026TrackDf['Position'] = 21\n",
        "  if eachRace != 'Austrailia':\n",
        "    new2026TrackDf[\"RaceOrder\"] = np.where(new2026TrackDf['Track_' + prevRace] == 1, 0, new2026TrackDf[\"RaceOrder\"])\n",
        "  new2026TrackDf[\"RaceOrder\"] = np.where(new2026TrackDf['Track_' + eachRace] == 1, raceOrderIndex2026, new2026TrackDf[\"RaceOrder\"])\n",
        "  prevRace = eachRace\n",
        "  raceOrderIndex2026 = raceOrderIndex2026 + 1\n",
        "  new2026TrackDfs.append(new2026TrackDf)\n",
        "\n",
        "\n",
        "theNew2026Df = pd.concat(new2026TrackDfs, ignore_index=True)\n",
        "theNew2026Df.head(43)\n",
        "print(theNew2026Df.shape)\n",
        "theNew2026Df.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JeyeBbTE5BBh",
        "outputId": "f6f13777-3577-49b5-c956-55d3bf05b7dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Australia\n",
            "The race index:  1\n",
            "China\n",
            "The race index:  2\n",
            "Japan\n",
            "The race index:  3\n",
            "Bahrain\n",
            "The race index:  4\n",
            "Saudi Arabia\n",
            "The race index:  5\n",
            "Miami\n",
            "The race index:  6\n",
            "Canada\n",
            "The race index:  7\n",
            "Monaco\n",
            "The race index:  8\n",
            "Emilia Romagna\n",
            "The race index:  9\n",
            "Austria\n",
            "The race index:  10\n",
            "Great Britain\n",
            "The race index:  11\n",
            "Belgium\n",
            "The race index:  12\n",
            "Hungary\n",
            "The race index:  13\n",
            "Netherlands\n",
            "The race index:  14\n",
            "Italy\n",
            "The race index:  15\n",
            "Azerbaijan\n",
            "The race index:  16\n",
            "Singapore\n",
            "The race index:  17\n",
            "United States\n",
            "The race index:  18\n",
            "Mexico\n",
            "The race index:  19\n",
            "Brazil\n",
            "The race index:  20\n",
            "Las Vegas\n",
            "The race index:  21\n",
            "Qatar\n",
            "The race index:  22\n",
            "Abu Dhabi\n",
            "The race index:  23\n",
            "(460, 76)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             Laps  Position   RaceOrder  Track_Abu Dhabi  Track_Australia  \\\n",
              "count  460.000000     460.0  460.000000       460.000000       460.000000   \n",
              "mean    59.913043      21.0   12.000000         0.043478         0.043478   \n",
              "std      8.781606       0.0    6.640471         0.204153         0.204153   \n",
              "min     44.000000      21.0    1.000000         0.000000         0.000000   \n",
              "25%     53.000000      21.0    6.000000         0.000000         0.000000   \n",
              "50%     57.000000      21.0   12.000000         0.000000         0.000000   \n",
              "75%     70.000000      21.0   18.000000         0.000000         0.000000   \n",
              "max     78.000000      21.0   23.000000         1.000000         1.000000   \n",
              "\n",
              "       Track_Austria  Track_Azerbaijan  Track_Bahrain  Track_Belgium  \\\n",
              "count     460.000000        460.000000     460.000000     460.000000   \n",
              "mean        0.043478          0.043478       0.043478       0.043478   \n",
              "std         0.204153          0.204153       0.204153       0.204153   \n",
              "min         0.000000          0.000000       0.000000       0.000000   \n",
              "25%         0.000000          0.000000       0.000000       0.000000   \n",
              "50%         0.000000          0.000000       0.000000       0.000000   \n",
              "75%         0.000000          0.000000       0.000000       0.000000   \n",
              "max         1.000000          1.000000       1.000000       1.000000   \n",
              "\n",
              "       Track_Brazil  ...  Team_McLaren Mercedes  Team_Mercedes  Team_Red Bull  \\\n",
              "count    460.000000  ...             460.000000     460.000000     460.000000   \n",
              "mean       0.043478  ...               0.100000       0.100000       0.100000   \n",
              "std        0.204153  ...               0.300327       0.300327       0.300327   \n",
              "min        0.000000  ...               0.000000       0.000000       0.000000   \n",
              "25%        0.000000  ...               0.000000       0.000000       0.000000   \n",
              "50%        0.000000  ...               0.000000       0.000000       0.000000   \n",
              "75%        0.000000  ...               0.000000       0.000000       0.000000   \n",
              "max        1.000000  ...               1.000000       1.000000       1.000000   \n",
              "\n",
              "       Team_Williams Mercedes  Year_2022  Year_2023  Year_2024  Year_2025  \\\n",
              "count              460.000000      460.0      460.0      460.0      460.0   \n",
              "mean                 0.100000        0.0        0.0        0.0        0.0   \n",
              "std                  0.300327        0.0        0.0        0.0        0.0   \n",
              "min                  0.000000        0.0        0.0        0.0        0.0   \n",
              "25%                  0.000000        0.0        0.0        0.0        0.0   \n",
              "50%                  0.000000        0.0        0.0        0.0        0.0   \n",
              "75%                  0.000000        0.0        0.0        0.0        0.0   \n",
              "max                  1.000000        0.0        0.0        0.0        0.0   \n",
              "\n",
              "       Year_2026    win  \n",
              "count      460.0  460.0  \n",
              "mean         1.0    0.0  \n",
              "std          0.0    0.0  \n",
              "min          1.0    0.0  \n",
              "25%          1.0    0.0  \n",
              "50%          1.0    0.0  \n",
              "75%          1.0    0.0  \n",
              "max          1.0    0.0  \n",
              "\n",
              "[8 rows x 76 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7a6b38dd-7b15-4917-83d8-3baaced24777\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Laps</th>\n",
              "      <th>Position</th>\n",
              "      <th>RaceOrder</th>\n",
              "      <th>Track_Abu Dhabi</th>\n",
              "      <th>Track_Australia</th>\n",
              "      <th>Track_Austria</th>\n",
              "      <th>Track_Azerbaijan</th>\n",
              "      <th>Track_Bahrain</th>\n",
              "      <th>Track_Belgium</th>\n",
              "      <th>Track_Brazil</th>\n",
              "      <th>...</th>\n",
              "      <th>Team_McLaren Mercedes</th>\n",
              "      <th>Team_Mercedes</th>\n",
              "      <th>Team_Red Bull</th>\n",
              "      <th>Team_Williams Mercedes</th>\n",
              "      <th>Year_2022</th>\n",
              "      <th>Year_2023</th>\n",
              "      <th>Year_2024</th>\n",
              "      <th>Year_2025</th>\n",
              "      <th>Year_2026</th>\n",
              "      <th>win</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>460.000000</td>\n",
              "      <td>460.0</td>\n",
              "      <td>460.000000</td>\n",
              "      <td>460.000000</td>\n",
              "      <td>460.000000</td>\n",
              "      <td>460.000000</td>\n",
              "      <td>460.000000</td>\n",
              "      <td>460.000000</td>\n",
              "      <td>460.000000</td>\n",
              "      <td>460.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>460.000000</td>\n",
              "      <td>460.000000</td>\n",
              "      <td>460.000000</td>\n",
              "      <td>460.000000</td>\n",
              "      <td>460.0</td>\n",
              "      <td>460.0</td>\n",
              "      <td>460.0</td>\n",
              "      <td>460.0</td>\n",
              "      <td>460.0</td>\n",
              "      <td>460.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>59.913043</td>\n",
              "      <td>21.0</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>0.043478</td>\n",
              "      <td>0.043478</td>\n",
              "      <td>0.043478</td>\n",
              "      <td>0.043478</td>\n",
              "      <td>0.043478</td>\n",
              "      <td>0.043478</td>\n",
              "      <td>0.043478</td>\n",
              "      <td>...</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>8.781606</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.640471</td>\n",
              "      <td>0.204153</td>\n",
              "      <td>0.204153</td>\n",
              "      <td>0.204153</td>\n",
              "      <td>0.204153</td>\n",
              "      <td>0.204153</td>\n",
              "      <td>0.204153</td>\n",
              "      <td>0.204153</td>\n",
              "      <td>...</td>\n",
              "      <td>0.300327</td>\n",
              "      <td>0.300327</td>\n",
              "      <td>0.300327</td>\n",
              "      <td>0.300327</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>44.000000</td>\n",
              "      <td>21.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>53.000000</td>\n",
              "      <td>21.0</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>57.000000</td>\n",
              "      <td>21.0</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>70.000000</td>\n",
              "      <td>21.0</td>\n",
              "      <td>18.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>78.000000</td>\n",
              "      <td>21.0</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 76 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7a6b38dd-7b15-4917-83d8-3baaced24777')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7a6b38dd-7b15-4917-83d8-3baaced24777 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7a6b38dd-7b15-4917-83d8-3baaced24777');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-4d059524-bc72-4512-a5ae-b5ac2c2fe50b\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4d059524-bc72-4512-a5ae-b5ac2c2fe50b')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-4d059524-bc72-4512-a5ae-b5ac2c2fe50b button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "theNew2026Df.head(100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2nByusBjSV9U",
        "outputId": "ac025cfe-371d-4840-a968-9a059282e943"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Laps  Position  RaceOrder  Track_Abu Dhabi  Track_Australia  \\\n",
              "0     58        21          1                0                1   \n",
              "1     58        21          1                0                1   \n",
              "2     58        21          1                0                1   \n",
              "3     58        21          1                0                1   \n",
              "4     58        21          1                0                1   \n",
              "..   ...       ...        ...              ...              ...   \n",
              "95    50        21          5                0                0   \n",
              "96    50        21          5                0                0   \n",
              "97    50        21          5                0                0   \n",
              "98    50        21          5                0                0   \n",
              "99    50        21          5                0                0   \n",
              "\n",
              "    Track_Austria  Track_Azerbaijan  Track_Bahrain  Track_Belgium  \\\n",
              "0               0                 0              0              0   \n",
              "1               0                 0              0              0   \n",
              "2               0                 0              0              0   \n",
              "3               0                 0              0              0   \n",
              "4               0                 0              0              0   \n",
              "..            ...               ...            ...            ...   \n",
              "95              0                 0              0              0   \n",
              "96              0                 0              0              0   \n",
              "97              0                 0              0              0   \n",
              "98              0                 0              0              0   \n",
              "99              0                 0              0              0   \n",
              "\n",
              "    Track_Brazil  ...  Team_McLaren Mercedes  Team_Mercedes  Team_Red Bull  \\\n",
              "0              0  ...                      1              0              0   \n",
              "1              0  ...                      1              0              0   \n",
              "2              0  ...                      0              1              0   \n",
              "3              0  ...                      0              0              1   \n",
              "4              0  ...                      0              0              0   \n",
              "..           ...  ...                    ...            ...            ...   \n",
              "95             0  ...                      0              0              0   \n",
              "96             0  ...                      0              0              0   \n",
              "97             0  ...                      0              0              0   \n",
              "98             0  ...                      0              0              0   \n",
              "99             0  ...                      0              0              0   \n",
              "\n",
              "    Team_Williams Mercedes  Year_2022  Year_2023  Year_2024  Year_2025  \\\n",
              "0                        0          0          0          0          0   \n",
              "1                        0          0          0          0          0   \n",
              "2                        0          0          0          0          0   \n",
              "3                        0          0          0          0          0   \n",
              "4                        1          0          0          0          0   \n",
              "..                     ...        ...        ...        ...        ...   \n",
              "95                       0          0          0          0          0   \n",
              "96                       0          0          0          0          0   \n",
              "97                       0          0          0          0          0   \n",
              "98                       0          0          0          0          0   \n",
              "99                       0          0          0          0          0   \n",
              "\n",
              "    Year_2026  win  \n",
              "0           1    0  \n",
              "1           1    0  \n",
              "2           1    0  \n",
              "3           1    0  \n",
              "4           1    0  \n",
              "..        ...  ...  \n",
              "95          1    0  \n",
              "96          1    0  \n",
              "97          1    0  \n",
              "98          1    0  \n",
              "99          1    0  \n",
              "\n",
              "[100 rows x 76 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4939909e-e062-4974-8638-a7b05239c05d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Laps</th>\n",
              "      <th>Position</th>\n",
              "      <th>RaceOrder</th>\n",
              "      <th>Track_Abu Dhabi</th>\n",
              "      <th>Track_Australia</th>\n",
              "      <th>Track_Austria</th>\n",
              "      <th>Track_Azerbaijan</th>\n",
              "      <th>Track_Bahrain</th>\n",
              "      <th>Track_Belgium</th>\n",
              "      <th>Track_Brazil</th>\n",
              "      <th>...</th>\n",
              "      <th>Team_McLaren Mercedes</th>\n",
              "      <th>Team_Mercedes</th>\n",
              "      <th>Team_Red Bull</th>\n",
              "      <th>Team_Williams Mercedes</th>\n",
              "      <th>Year_2022</th>\n",
              "      <th>Year_2023</th>\n",
              "      <th>Year_2024</th>\n",
              "      <th>Year_2025</th>\n",
              "      <th>Year_2026</th>\n",
              "      <th>win</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>58</td>\n",
              "      <td>21</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>58</td>\n",
              "      <td>21</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>58</td>\n",
              "      <td>21</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>58</td>\n",
              "      <td>21</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>58</td>\n",
              "      <td>21</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>50</td>\n",
              "      <td>21</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>50</td>\n",
              "      <td>21</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>50</td>\n",
              "      <td>21</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>50</td>\n",
              "      <td>21</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>50</td>\n",
              "      <td>21</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 76 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4939909e-e062-4974-8638-a7b05239c05d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4939909e-e062-4974-8638-a7b05239c05d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4939909e-e062-4974-8638-a7b05239c05d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-014c7427-229d-4e20-a660-60077df30fcf\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-014c7427-229d-4e20-a660-60077df30fcf')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-014c7427-229d-4e20-a660-60077df30fcf button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "theNew2026Df"
            }
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "completed2026 = pd.concat([df_encoded, theNew2026Df], ignore_index=True)\n",
        "\n",
        "print(df_encoded.shape)\n",
        "print(completed2026.shape)\n",
        "completed2026.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OKQyFSvZ-JvB",
        "outputId": "030310cf-b318-44f1-c616-7c4f23628b2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1618, 76)\n",
            "(2078, 76)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              Laps     Position    RaceOrder  Track_Abu Dhabi  \\\n",
              "count  2078.000000  2078.000000  2078.000000      2078.000000   \n",
              "mean     55.759384    13.035130    11.283927         0.038499   \n",
              "std      15.568472     6.912634     6.508558         0.192443   \n",
              "min       0.000000     1.000000     1.000000         0.000000   \n",
              "25%      51.000000     7.000000     6.000000         0.000000   \n",
              "50%      57.000000    13.000000    11.000000         0.000000   \n",
              "75%      69.000000    21.000000    17.000000         0.000000   \n",
              "max      78.000000    21.000000    24.000000         1.000000   \n",
              "\n",
              "       Track_Australia  Track_Austria  Track_Azerbaijan  Track_Bahrain  \\\n",
              "count      2078.000000    2078.000000       2078.000000    2078.000000   \n",
              "mean          0.047642       0.048123          0.038499       0.048123   \n",
              "std           0.213059       0.214078          0.192443       0.214078   \n",
              "min           0.000000       0.000000          0.000000       0.000000   \n",
              "25%           0.000000       0.000000          0.000000       0.000000   \n",
              "50%           0.000000       0.000000          0.000000       0.000000   \n",
              "75%           0.000000       0.000000          0.000000       0.000000   \n",
              "max           1.000000       1.000000          1.000000       1.000000   \n",
              "\n",
              "       Track_Belgium  Track_Brazil  ...  Team_McLaren Mercedes  Team_Mercedes  \\\n",
              "count    2078.000000   2078.000000  ...            2078.000000    2078.000000   \n",
              "mean        0.048123      0.038499  ...               0.100096       0.100096   \n",
              "std         0.214078      0.192443  ...               0.300201       0.300201   \n",
              "min         0.000000      0.000000  ...               0.000000       0.000000   \n",
              "25%         0.000000      0.000000  ...               0.000000       0.000000   \n",
              "50%         0.000000      0.000000  ...               0.000000       0.000000   \n",
              "75%         0.000000      0.000000  ...               0.000000       0.000000   \n",
              "max         1.000000      1.000000  ...               1.000000       1.000000   \n",
              "\n",
              "       Team_Red Bull  Team_Williams Mercedes    Year_2022    Year_2023  \\\n",
              "count    2078.000000             2078.000000  2078.000000  2078.000000   \n",
              "mean        0.123195                0.099615     0.211742     0.211742   \n",
              "std         0.328740                0.299558     0.408641     0.408641   \n",
              "min         0.000000                0.000000     0.000000     0.000000   \n",
              "25%         0.000000                0.000000     0.000000     0.000000   \n",
              "50%         0.000000                0.000000     0.000000     0.000000   \n",
              "75%         0.000000                0.000000     0.000000     0.000000   \n",
              "max         1.000000                1.000000     1.000000     1.000000   \n",
              "\n",
              "         Year_2024    Year_2025    Year_2026          win  \n",
              "count  2078.000000  2078.000000  2078.000000  2078.000000  \n",
              "mean      0.230510     0.124639     0.221367     0.038980  \n",
              "std       0.421261     0.330389     0.415267     0.193593  \n",
              "min       0.000000     0.000000     0.000000     0.000000  \n",
              "25%       0.000000     0.000000     0.000000     0.000000  \n",
              "50%       0.000000     0.000000     0.000000     0.000000  \n",
              "75%       0.000000     0.000000     0.000000     0.000000  \n",
              "max       1.000000     1.000000     1.000000     1.000000  \n",
              "\n",
              "[8 rows x 76 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-04df2212-571c-480e-a9ad-a145c9d4c67b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Laps</th>\n",
              "      <th>Position</th>\n",
              "      <th>RaceOrder</th>\n",
              "      <th>Track_Abu Dhabi</th>\n",
              "      <th>Track_Australia</th>\n",
              "      <th>Track_Austria</th>\n",
              "      <th>Track_Azerbaijan</th>\n",
              "      <th>Track_Bahrain</th>\n",
              "      <th>Track_Belgium</th>\n",
              "      <th>Track_Brazil</th>\n",
              "      <th>...</th>\n",
              "      <th>Team_McLaren Mercedes</th>\n",
              "      <th>Team_Mercedes</th>\n",
              "      <th>Team_Red Bull</th>\n",
              "      <th>Team_Williams Mercedes</th>\n",
              "      <th>Year_2022</th>\n",
              "      <th>Year_2023</th>\n",
              "      <th>Year_2024</th>\n",
              "      <th>Year_2025</th>\n",
              "      <th>Year_2026</th>\n",
              "      <th>win</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>2078.000000</td>\n",
              "      <td>2078.000000</td>\n",
              "      <td>2078.000000</td>\n",
              "      <td>2078.000000</td>\n",
              "      <td>2078.000000</td>\n",
              "      <td>2078.000000</td>\n",
              "      <td>2078.000000</td>\n",
              "      <td>2078.000000</td>\n",
              "      <td>2078.000000</td>\n",
              "      <td>2078.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>2078.000000</td>\n",
              "      <td>2078.000000</td>\n",
              "      <td>2078.000000</td>\n",
              "      <td>2078.000000</td>\n",
              "      <td>2078.000000</td>\n",
              "      <td>2078.000000</td>\n",
              "      <td>2078.000000</td>\n",
              "      <td>2078.000000</td>\n",
              "      <td>2078.000000</td>\n",
              "      <td>2078.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>55.759384</td>\n",
              "      <td>13.035130</td>\n",
              "      <td>11.283927</td>\n",
              "      <td>0.038499</td>\n",
              "      <td>0.047642</td>\n",
              "      <td>0.048123</td>\n",
              "      <td>0.038499</td>\n",
              "      <td>0.048123</td>\n",
              "      <td>0.048123</td>\n",
              "      <td>0.038499</td>\n",
              "      <td>...</td>\n",
              "      <td>0.100096</td>\n",
              "      <td>0.100096</td>\n",
              "      <td>0.123195</td>\n",
              "      <td>0.099615</td>\n",
              "      <td>0.211742</td>\n",
              "      <td>0.211742</td>\n",
              "      <td>0.230510</td>\n",
              "      <td>0.124639</td>\n",
              "      <td>0.221367</td>\n",
              "      <td>0.038980</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>15.568472</td>\n",
              "      <td>6.912634</td>\n",
              "      <td>6.508558</td>\n",
              "      <td>0.192443</td>\n",
              "      <td>0.213059</td>\n",
              "      <td>0.214078</td>\n",
              "      <td>0.192443</td>\n",
              "      <td>0.214078</td>\n",
              "      <td>0.214078</td>\n",
              "      <td>0.192443</td>\n",
              "      <td>...</td>\n",
              "      <td>0.300201</td>\n",
              "      <td>0.300201</td>\n",
              "      <td>0.328740</td>\n",
              "      <td>0.299558</td>\n",
              "      <td>0.408641</td>\n",
              "      <td>0.408641</td>\n",
              "      <td>0.421261</td>\n",
              "      <td>0.330389</td>\n",
              "      <td>0.415267</td>\n",
              "      <td>0.193593</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>51.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>57.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>69.000000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>78.000000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 76 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-04df2212-571c-480e-a9ad-a145c9d4c67b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-04df2212-571c-480e-a9ad-a145c9d4c67b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-04df2212-571c-480e-a9ad-a145c9d4c67b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-81f8959d-2420-4d18-83e4-9fb8d54f8489\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-81f8959d-2420-4d18-83e4-9fb8d54f8489')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-81f8959d-2420-4d18-83e4-9fb8d54f8489 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#predict the 2026 season\n",
        "yearsTrain = [ '2025']\n",
        "yearsPredict = ['2026']\n",
        "\n",
        "#add the 2026 data use only completed 2025 season\n",
        "completed2026= pd.concat([df_encoded, theNew2026Df], ignore_index=True)\n",
        "\n",
        "df, smallDf = trainModel(yearsTrain, yearsPredict, completed2026, \"relu\", \"adam\", 20)\n",
        "smallDf.head(100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-DsjdXyDS0p",
        "outputId": "ef3d9279-8fc6-4e76-da42-71fdb9fd97de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The years trained:  ['Year_2025']\n",
            "The years tested:  ['Year_2026']\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.6691 - loss: 0.2967 - val_accuracy: 0.9808 - val_loss: 0.1058\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9515 - loss: 0.0827 - val_accuracy: 0.9808 - val_loss: 0.0343\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9515 - loss: 0.0529 - val_accuracy: 0.9808 - val_loss: 0.0302\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9515 - loss: 0.0506 - val_accuracy: 0.9808 - val_loss: 0.0302\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9515 - loss: 0.0505 - val_accuracy: 0.9808 - val_loss: 0.0310\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9515 - loss: 0.0504 - val_accuracy: 0.9808 - val_loss: 0.0306\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9515 - loss: 0.0499 - val_accuracy: 0.9808 - val_loss: 0.0298\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9515 - loss: 0.0492 - val_accuracy: 0.9808 - val_loss: 0.0287\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9515 - loss: 0.0486 - val_accuracy: 0.9808 - val_loss: 0.0291\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9515 - loss: 0.0486 - val_accuracy: 0.9808 - val_loss: 0.0294\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9515 - loss: 0.0486 - val_accuracy: 0.9808 - val_loss: 0.0290\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9515 - loss: 0.0486 - val_accuracy: 0.9808 - val_loss: 0.0290\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9515 - loss: 0.0484 - val_accuracy: 0.9808 - val_loss: 0.0299\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9515 - loss: 0.0484 - val_accuracy: 0.9808 - val_loss: 0.0294\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9515 - loss: 0.0482 - val_accuracy: 0.9808 - val_loss: 0.0306\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9515 - loss: 0.0482 - val_accuracy: 0.9808 - val_loss: 0.0307\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9515 - loss: 0.0478 - val_accuracy: 0.9808 - val_loss: 0.0300\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9515 - loss: 0.0470 - val_accuracy: 0.9808 - val_loss: 0.0298\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9515 - loss: 0.0465 - val_accuracy: 0.9808 - val_loss: 0.0295\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9515 - loss: 0.0459 - val_accuracy: 0.9808 - val_loss: 0.0281\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0091 \n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "The amount guessed correctly: 0  out of  23  races.\n",
            "The percentage guessed correctly: 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-68995368.py:61: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  comparePredictions['predicted'] = model.predict(x_test)\n",
            "/tmp/ipython-input-68995368.py:69: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  comparePredictions[\"track\"] = comparePredictions[track_cols].idxmax(axis=1).str.replace(\"Track_\", \"\", regex=False)\n",
            "/tmp/ipython-input-68995368.py:70: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  comparePredictions[\"Driver\"] = comparePredictions[driver_cols].idxmax(axis=1).str.replace(\"Driver_\", \"\", regex=False)\n",
            "/tmp/ipython-input-68995368.py:74: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  comparePredictions[\"predicted_winner\"] = (\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Position  RaceOrder  win  predicted           track        Driver  \\\n",
              "2059        21         23    0   0.168246       Abu Dhabi  Lando Norris   \n",
              "1619        21          1    0   0.169670       Australia  Lando Norris   \n",
              "1799        21         10    0   0.229419         Austria  Lando Norris   \n",
              "1919        21         16    0   0.190443      Azerbaijan  Lando Norris   \n",
              "1679        21          4    0   0.216928         Bahrain  Lando Norris   \n",
              "1839        21         12    0   0.175946         Belgium  Lando Norris   \n",
              "1999        21         20    0   0.213749          Brazil  Lando Norris   \n",
              "1739        21          7    0   0.237155          Canada  Lando Norris   \n",
              "1639        21          2    0   0.222187           China  Lando Norris   \n",
              "1779        21          9    0   0.203202  Emilia Romagna  Lando Norris   \n",
              "1819        21         11    0   0.155606   Great Britain  Lando Norris   \n",
              "1859        21         13    0   0.201670         Hungary  Lando Norris   \n",
              "1899        21         15    0   0.171433           Italy  Lando Norris   \n",
              "1659        21          3    0   0.182850           Japan  Lando Norris   \n",
              "2019        21         21    0   0.190899       Las Vegas  Lando Norris   \n",
              "1979        21         19    0   0.211077          Mexico  Lando Norris   \n",
              "1719        21          6    0   0.167048           Miami  Lando Norris   \n",
              "1759        21          8    0   0.244870          Monaco  Lando Norris   \n",
              "1879        21         14    0   0.241944     Netherlands  Lando Norris   \n",
              "2039        21         22    0   0.163707           Qatar  Lando Norris   \n",
              "1699        21          5    0   0.176169    Saudi Arabia  Lando Norris   \n",
              "1939        21         17    0   0.239205       Singapore  Lando Norris   \n",
              "1959        21         18    0   0.176891   United States  Lando Norris   \n",
              "\n",
              "      predicted_winner  \n",
              "2059                 1  \n",
              "1619                 1  \n",
              "1799                 1  \n",
              "1919                 1  \n",
              "1679                 1  \n",
              "1839                 1  \n",
              "1999                 1  \n",
              "1739                 1  \n",
              "1639                 1  \n",
              "1779                 1  \n",
              "1819                 1  \n",
              "1859                 1  \n",
              "1899                 1  \n",
              "1659                 1  \n",
              "2019                 1  \n",
              "1979                 1  \n",
              "1719                 1  \n",
              "1759                 1  \n",
              "1879                 1  \n",
              "2039                 1  \n",
              "1699                 1  \n",
              "1939                 1  \n",
              "1959                 1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f42d614f-1868-4d7c-9a59-293f8d877df2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Position</th>\n",
              "      <th>RaceOrder</th>\n",
              "      <th>win</th>\n",
              "      <th>predicted</th>\n",
              "      <th>track</th>\n",
              "      <th>Driver</th>\n",
              "      <th>predicted_winner</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2059</th>\n",
              "      <td>21</td>\n",
              "      <td>23</td>\n",
              "      <td>0</td>\n",
              "      <td>0.168246</td>\n",
              "      <td>Abu Dhabi</td>\n",
              "      <td>Lando Norris</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1619</th>\n",
              "      <td>21</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.169670</td>\n",
              "      <td>Australia</td>\n",
              "      <td>Lando Norris</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1799</th>\n",
              "      <td>21</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>0.229419</td>\n",
              "      <td>Austria</td>\n",
              "      <td>Lando Norris</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1919</th>\n",
              "      <td>21</td>\n",
              "      <td>16</td>\n",
              "      <td>0</td>\n",
              "      <td>0.190443</td>\n",
              "      <td>Azerbaijan</td>\n",
              "      <td>Lando Norris</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1679</th>\n",
              "      <td>21</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0.216928</td>\n",
              "      <td>Bahrain</td>\n",
              "      <td>Lando Norris</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1839</th>\n",
              "      <td>21</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>0.175946</td>\n",
              "      <td>Belgium</td>\n",
              "      <td>Lando Norris</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1999</th>\n",
              "      <td>21</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>0.213749</td>\n",
              "      <td>Brazil</td>\n",
              "      <td>Lando Norris</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1739</th>\n",
              "      <td>21</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0.237155</td>\n",
              "      <td>Canada</td>\n",
              "      <td>Lando Norris</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1639</th>\n",
              "      <td>21</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.222187</td>\n",
              "      <td>China</td>\n",
              "      <td>Lando Norris</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1779</th>\n",
              "      <td>21</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0.203202</td>\n",
              "      <td>Emilia Romagna</td>\n",
              "      <td>Lando Norris</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1819</th>\n",
              "      <td>21</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>0.155606</td>\n",
              "      <td>Great Britain</td>\n",
              "      <td>Lando Norris</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1859</th>\n",
              "      <td>21</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>0.201670</td>\n",
              "      <td>Hungary</td>\n",
              "      <td>Lando Norris</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1899</th>\n",
              "      <td>21</td>\n",
              "      <td>15</td>\n",
              "      <td>0</td>\n",
              "      <td>0.171433</td>\n",
              "      <td>Italy</td>\n",
              "      <td>Lando Norris</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1659</th>\n",
              "      <td>21</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0.182850</td>\n",
              "      <td>Japan</td>\n",
              "      <td>Lando Norris</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019</th>\n",
              "      <td>21</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "      <td>0.190899</td>\n",
              "      <td>Las Vegas</td>\n",
              "      <td>Lando Norris</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1979</th>\n",
              "      <td>21</td>\n",
              "      <td>19</td>\n",
              "      <td>0</td>\n",
              "      <td>0.211077</td>\n",
              "      <td>Mexico</td>\n",
              "      <td>Lando Norris</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1719</th>\n",
              "      <td>21</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0.167048</td>\n",
              "      <td>Miami</td>\n",
              "      <td>Lando Norris</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1759</th>\n",
              "      <td>21</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>0.244870</td>\n",
              "      <td>Monaco</td>\n",
              "      <td>Lando Norris</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1879</th>\n",
              "      <td>21</td>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "      <td>0.241944</td>\n",
              "      <td>Netherlands</td>\n",
              "      <td>Lando Norris</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2039</th>\n",
              "      <td>21</td>\n",
              "      <td>22</td>\n",
              "      <td>0</td>\n",
              "      <td>0.163707</td>\n",
              "      <td>Qatar</td>\n",
              "      <td>Lando Norris</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1699</th>\n",
              "      <td>21</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0.176169</td>\n",
              "      <td>Saudi Arabia</td>\n",
              "      <td>Lando Norris</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1939</th>\n",
              "      <td>21</td>\n",
              "      <td>17</td>\n",
              "      <td>0</td>\n",
              "      <td>0.239205</td>\n",
              "      <td>Singapore</td>\n",
              "      <td>Lando Norris</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1959</th>\n",
              "      <td>21</td>\n",
              "      <td>18</td>\n",
              "      <td>0</td>\n",
              "      <td>0.176891</td>\n",
              "      <td>United States</td>\n",
              "      <td>Lando Norris</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f42d614f-1868-4d7c-9a59-293f8d877df2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f42d614f-1868-4d7c-9a59-293f8d877df2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f42d614f-1868-4d7c-9a59-293f8d877df2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-bfbbc39e-8582-4a3b-9c66-5a08dc85a0f2\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bfbbc39e-8582-4a3b-9c66-5a08dc85a0f2')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-bfbbc39e-8582-4a3b-9c66-5a08dc85a0f2 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "smallDf",
              "summary": "{\n  \"name\": \"smallDf\",\n  \"rows\": 23,\n  \"fields\": [\n    {\n      \"column\": \"Position\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 21,\n        \"max\": 21,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          21\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"RaceOrder\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6,\n        \"min\": 1,\n        \"max\": 23,\n        \"num_unique_values\": 23,\n        \"samples\": [\n          19\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"win\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"predicted\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 23,\n        \"samples\": [\n          0.21107733249664307\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"track\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 23,\n        \"samples\": [\n          \"Mexico\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Driver\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Lando Norris\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"predicted_winner\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 1,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tests that include confidence intervals and p-values"
      ],
      "metadata": {
        "id": "puxF7GfapldK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "\n",
        "def createSimpleModel(x_train, y_train, x_valid, y_valid, x_test, y_test,\n",
        "                      activFunction, optimizer, epochsNum):\n",
        "    model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[73, 1]),\n",
        "    keras.layers.Dense(32, activation=\"relu\"),\n",
        "    keras.layers.Dense(64, activation=\"relu\"),\n",
        "    keras.layers.Dense(128, activation=\"relu\"),\n",
        "    keras.layers.Dense(32, activation= activFunction),\n",
        "    keras.layers.Dense(1)\n",
        "    ])\n",
        "\n",
        "    model.compile(loss=\"mse\", optimizer=optimizer, metrics = [\"accuracy\"])\n",
        "    history = model.fit(x_train, y_train, epochs=epochsNum,\n",
        "                        validation_data=(x_valid, y_valid), shuffle = False)\n",
        "    model.evaluate(x_test, y_test)\n",
        "\n",
        "    return model, history\n"
      ],
      "metadata": {
        "id": "2FE3XeR9poH5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def createMediumModel(x_train, y_train, x_valid, y_valid, x_test, y_test, activFunction, optimizer, epochsNum):\n",
        "    model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[73, 1]),\n",
        "    keras.layers.Dense(32, activation=\"relu\"),\n",
        "    keras.layers.Dense(64, activation=\"relu\"),\n",
        "    keras.layers.Dense(128, activation=\"relu\"),\n",
        "    keras.layers.Dense(32, activation= activFunction),\n",
        "    keras.layers.Dense(1)\n",
        "    ])\n",
        "\n",
        "    model.compile(loss=\"mse\", optimizer=optimizer, metrics = [\"accuracy\"])\n",
        "    history = model.fit(x_train, y_train, epochs=epochsNum,\n",
        "                        validation_data=(x_valid, y_valid), shuffle = False)\n",
        "    model.evaluate(x_test, y_test)\n",
        "\n",
        "    return model, history"
      ],
      "metadata": {
        "id": "_Ubgqwajbozq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def createHighModel(x_train, y_train, x_valid, y_valid, x_test, y_test, activFunction, optimizer, epochsNum):\n",
        "    model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[73, 1]),\n",
        "    keras.layers.Dense(32, activation=\"relu\"),\n",
        "    keras.layers.Dense(64, activation=\"relu\"),\n",
        "    keras.layers.Dense(128, activation=\"relu\"),\n",
        "    keras.layers.Dense(256, activation=\"relu\"),\n",
        "    keras.layers.Dense(128, activation=\"relu\"),\n",
        "    keras.layers.Dense(64, activation=\"relu\"),\n",
        "    keras.layers.Dense(32, activation= activFunction),\n",
        "    keras.layers.Dense(1)\n",
        "    ])\n",
        "\n",
        "    model.compile(loss=\"mse\", optimizer=optimizer, metrics = [\"accuracy\"])\n",
        "    history = model.fit(x_train, y_train, epochs=epochsNum,\n",
        "                        validation_data=(x_valid, y_valid), shuffle = False)\n",
        "    model.evaluate(x_test, y_test)\n",
        "\n",
        "    return model, history"
      ],
      "metadata": {
        "id": "dBGhpbIOce8S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from statsmodels.stats.proportion import proportions_ztest, proportion_confint\n",
        "\n",
        "def _wilson_ci(k, n, alpha=0.05):\n",
        "    low, high = proportion_confint(count=k, nobs=n, alpha=alpha, method=\"wilson\")\n",
        "    return float(low), float(high)\n",
        "\n",
        "def _two_prop_pvalue(model_p, base_p, n_model, n_base=None, alternative=\"larger\"):\n",
        "    if n_base is None: n_base = n_model\n",
        "    k_model = int(round(model_p * n_model))\n",
        "    k_base  = int(round(base_p  * n_base))\n",
        "    k_model = max(0, min(k_model, n_model))\n",
        "    k_base  = max(0, min(k_base,  n_base))\n",
        "    stat, p = proportions_ztest([k_model, k_base], [n_model, n_base], alternative=alternative)\n",
        "    return float(p), float(stat)\n",
        "\n",
        "def _race_level_sensitivity(df_with_preds, track_prefix=\"Track_\", driver_prefix=\"Driver_\"):\n",
        "    track_cols  = [c for c in df_with_preds.columns if c.startswith(track_prefix)]\n",
        "    driver_cols = [c for c in df_with_preds.columns if c.startswith(driver_prefix)]\n",
        "    tmp = df_with_preds.copy()\n",
        "    if \"track\" not in tmp.columns:\n",
        "        tmp[\"track\"] = tmp[track_cols].idxmax(axis=1).str.replace(track_prefix, \"\", regex=False)\n",
        "    if \"Driver\" not in tmp.columns and driver_cols:\n",
        "        tmp[\"Driver\"] = tmp[driver_cols].idxmax(axis=1).str.replace(driver_prefix, \"\", regex=False)\n",
        "    picks = tmp.loc[tmp.groupby(\"track\")[\"predicted\"].idxmax()].copy()\n",
        "    k_correct = int((picks[\"win\"] == 1).sum())\n",
        "    n_races   = picks[\"track\"].nunique()\n",
        "    sens = k_correct / n_races if n_races > 0 else 0.0\n",
        "    return sens, k_correct, n_races, picks\n"
      ],
      "metadata": {
        "id": "UWm3-NbgbL8Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def trainSimpleModelMetrics(yearsTrain, yearsPredict, partyDf, activFunction, optimizer, epochs):\n",
        "    # 1) Determinism\n",
        "    os.environ[\"PYTHONHASHSEED\"] = \"42\"\n",
        "    np.random.seed(42)\n",
        "    random.seed(42)\n",
        "    try:\n",
        "        tf.random.set_seed(42)\n",
        "        # TF 2.12+: deterministic ops\n",
        "        tf.config.experimental.enable_op_determinism(True)\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "\n",
        "    dfs = []\n",
        "    #get data from all training years\n",
        "    for year in yearsTrain:\n",
        "        dfs.append(partyDf[partyDf['Year_' + year] == 1])\n",
        "\n",
        "    # Combine all selected years into one DataFrame\n",
        "    trainDf = pd.concat(dfs, ignore_index=True)\n",
        "\n",
        "    x = trainDf.drop(columns=['win', 'Position', 'RaceOrder'])\n",
        "    y = trainDf['win']\n",
        "\n",
        "    #extract the columns that have a one included in the x df\n",
        "    year_cols = [c for c in x.columns if c.startswith(\"Year_\")]\n",
        "\n",
        "    includedTrainingYears = []\n",
        "    for col in year_cols:\n",
        "        if (x[col] == 1).any():   # check if there is any row with a 1 in this column\n",
        "            includedTrainingYears.append(col)\n",
        "\n",
        "    print(\"The years trained: \", includedTrainingYears)\n",
        "\n",
        "\n",
        "    #split the training data accordingly\n",
        "    x_train, x_valid, y_train, y_valid = train_test_split(x, y, test_size=0.2, random_state=42)\n",
        "    #get the test data, so the data for the next year you would want to predict\n",
        "    dfTest = partyDf[(partyDf['Year_'+ yearsPredict[0]] == 1)]\n",
        "    x_test = dfTest.drop(columns=['win', 'Position', 'RaceOrder'])\n",
        "    y_test = dfTest['win']\n",
        "\n",
        "    # #### this where you call the type of architecture you need\n",
        "    model, history = createSimpleModel(\n",
        "        x_train.values, y_train.values,\n",
        "        x_valid.values, y_valid.values,\n",
        "        x_test.values, y_test.values,\n",
        "        activFunction, optimizer, epochs\n",
        "    )\n",
        "\n",
        "    #get prediction info\n",
        "    y_valid_pred_prob = model.predict(x_valid.values, verbose=0).ravel()\n",
        "\n",
        "    # race-level validation sensitivity + CI + p-value\n",
        "    df_valid = x_valid.copy()\n",
        "    df_valid[\"win\"] = y_valid.values\n",
        "    df_valid[\"predicted\"] = y_valid_pred_prob\n",
        "\n",
        "    val_sens, val_k, val_n, _ = _race_level_sensitivity(df_valid)\n",
        "    val_ci_low, val_ci_high = _wilson_ci(val_k, val_n)\n",
        "\n",
        "    # baseline for validation so biggest winner validation is the biggest each year\n",
        "    if yearsTrain[0] == '2022':\n",
        "      baseline_val_p = 19 / 22.0\n",
        "    elif yearsTrain[0] == '2023':\n",
        "      baseline_val_p = 9 / 24.0\n",
        "    else:\n",
        "       baseline_val_p = 9 / 24.0\n",
        "\n",
        "    val_p_value, val_z = _two_prop_pvalue(val_sens, baseline_val_p, n_model=val_n, alternative=\"larger\")\n",
        "    # (Optional) also surface val acc from Keras history, last epoch:\n",
        "    hist_val_acc = float(history.history.get(\"val_accuracy\", [np.nan])[-1])\n",
        "\n",
        "    print(f\"[VALID] acc={hist_val_acc:.3f} | sens={val_sens:.3f} \"\n",
        "          f\"(k={val_k}/{val_n}, CI95=[{val_ci_low:.3f},{val_ci_high:.3f}]) \"\n",
        "          f\"vs base {baseline_val_p:.3f} p={val_p_value:.4f}\")\n",
        "\n",
        "    # These were all the metrics I wanted so really just sensitivty\n",
        "    comparePredictions = partyDf[(partyDf['Year_'+ yearsPredict[0]] == 1)].copy()\n",
        "    comparePredictions['predicted'] = model.predict(x_test.values, verbose=0)\n",
        "\n",
        "    track_cols = [c for c in comparePredictions.columns if c.startswith(\"Track_\")]\n",
        "    year_cols  = [c for c in comparePredictions.columns if c.startswith(\"Year_\")]\n",
        "    team_cols  = [c for c in comparePredictions.columns if c.startswith(\"Team_\")]\n",
        "    driver_cols= [c for c in comparePredictions.columns if c.startswith(\"Driver_\")]\n",
        "\n",
        "    comparePredictions[\"track\"]  = comparePredictions[track_cols].idxmax(axis=1).str.replace(\"Track_\", \"\", regex=False)\n",
        "    comparePredictions[\"Driver\"] = comparePredictions[driver_cols].idxmax(axis=1).str.replace(\"Driver_\", \"\", regex=False)\n",
        "\n",
        "    comparePredictions[\"predicted_winner\"] = (\n",
        "        comparePredictions.groupby(\"track\")[\"predicted\"]\n",
        "                          .transform(lambda x: x == x.max())\n",
        "                          .astype(int)\n",
        "    )\n",
        "\n",
        "    # This is how I know which driver I said would win the race in a neat orderly fashion\n",
        "    sortedcomparePredictions = comparePredictions.sort_values([\"track\", \"predicted\"], ascending=[True, False])\n",
        "    cols_to_drop = track_cols + year_cols + team_cols + driver_cols + ['Laps']\n",
        "    finalResultsDf = sortedcomparePredictions.drop(cols_to_drop, axis=1)\n",
        "\n",
        "    totalAmountGuessedCorrectly = finalResultsDf[\n",
        "        (finalResultsDf['predicted_winner'] == 1) & (finalResultsDf['win'] == 1)\n",
        "    ].shape[0]\n",
        "\n",
        "    numRaces = finalResultsDf['track'].nunique()\n",
        "    percentage_correct = totalAmountGuessedCorrectly / numRaces if numRaces > 0 else 0.0\n",
        "\n",
        "    # test CI + p-value\n",
        "    test_k = int(totalAmountGuessedCorrectly)\n",
        "    test_n = int(numRaces)\n",
        "    test_sens = float(percentage_correct)\n",
        "    test_ci_low, test_ci_high = _wilson_ci(test_k, test_n)\n",
        "    if yearsPredict[0] == '2024':\n",
        "      baseline_test_p = 9 / 24.0\n",
        "    else:\n",
        "      baseline_test_p = 2 / 23\n",
        "\n",
        "    test_p_value, test_z = _two_prop_pvalue(test_sens, baseline_test_p, n_model=test_n, alternative=\"larger\")\n",
        "\n",
        "    print(f\"[TEST ] sens={test_sens:.3f} (k={test_k}/{test_n}, CI95=[{test_ci_low:.3f},{test_ci_high:.3f}]) \"\n",
        "          f\"vs base {baseline_test_p:.3f} p={test_p_value:.4f}\")\n",
        "\n",
        "    metrics = {\n",
        "        #\"val_accuracy_row\": val_accuracy,              # row-level acc (thresholded)\n",
        "        \"val_accuracy\": hist_val_acc,            # Keras-reported val accuracy\n",
        "        \"val_sensitivity\": val_sens,\n",
        "        \"val_ci_low\": val_ci_low, \"val_ci_high\": val_ci_high,\n",
        "        #\"val_p_value_vs_baseline\": val_p_value,\n",
        "        \"test_sensitivity\": test_sens,\n",
        "        \"test_ci_low\": test_ci_low, \"test_ci_high\": test_ci_high,\n",
        "        \"test_p_value_vs_baseline\": test_p_value\n",
        "        #\"val_races\": val_n, \"test_races\": test_n\n",
        "    }\n",
        "\n",
        "    return finalResultsDf, finalResultsDf[(finalResultsDf['predicted_winner']==1)|(finalResultsDf['win']==1)].sort_values('track'), metrics\n"
      ],
      "metadata": {
        "id": "HbFTZvxWe-LO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def trainMediumModelMetrics(yearsTrain, yearsPredict, partyDf, activFunction, optimizer, epochs):\n",
        "    # 1) Determinism\n",
        "    os.environ[\"PYTHONHASHSEED\"] = \"42\"\n",
        "    np.random.seed(42)\n",
        "    random.seed(42)\n",
        "    try:\n",
        "        tf.random.set_seed(42)\n",
        "        # TF 2.12+: deterministic ops\n",
        "        tf.config.experimental.enable_op_determinism(True)\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "\n",
        "    dfs = []\n",
        "    #get data from all training years\n",
        "    for year in yearsTrain:\n",
        "        dfs.append(partyDf[partyDf['Year_' + year] == 1])\n",
        "\n",
        "    # Combine all selected years into one DataFrame\n",
        "    trainDf = pd.concat(dfs, ignore_index=True)\n",
        "\n",
        "    x = trainDf.drop(columns=['win', 'Position', 'RaceOrder'])\n",
        "    y = trainDf['win']\n",
        "\n",
        "    #extract the columns that have a one included in the x df\n",
        "    year_cols = [c for c in x.columns if c.startswith(\"Year_\")]\n",
        "\n",
        "    includedTrainingYears = []\n",
        "    for col in year_cols:\n",
        "        if (x[col] == 1).any():   # check if there is any row with a 1 in this column\n",
        "            includedTrainingYears.append(col)\n",
        "\n",
        "    print(\"The years trained: \", includedTrainingYears)\n",
        "\n",
        "\n",
        "    #split the training data accordingly\n",
        "    x_train, x_valid, y_train, y_valid = train_test_split(x, y, test_size=0.2, random_state=42)\n",
        "    #get the test data, so the data for the next year you would want to predict\n",
        "    dfTest = partyDf[(partyDf['Year_'+ yearsPredict[0]] == 1)]\n",
        "    x_test = dfTest.drop(columns=['win', 'Position', 'RaceOrder'])\n",
        "    y_test = dfTest['win']\n",
        "\n",
        "    # #### this where you call the type of architecture you need\n",
        "    model, history = createMediumModel(\n",
        "        x_train.values, y_train.values,\n",
        "        x_valid.values, y_valid.values,\n",
        "        x_test.values, y_test.values,\n",
        "        activFunction, optimizer, epochs\n",
        "    )\n",
        "\n",
        "    #get prediction info\n",
        "    y_valid_pred_prob = model.predict(x_valid.values, verbose=0).ravel()\n",
        "\n",
        "    # race-level validation sensitivity + CI + p-value\n",
        "    df_valid = x_valid.copy()\n",
        "    df_valid[\"win\"] = y_valid.values\n",
        "    df_valid[\"predicted\"] = y_valid_pred_prob\n",
        "\n",
        "    val_sens, val_k, val_n, _ = _race_level_sensitivity(df_valid)\n",
        "    val_ci_low, val_ci_high = _wilson_ci(val_k, val_n)\n",
        "\n",
        "    # baseline for validation so biggest winner validation is the biggest each year\n",
        "    if yearsTrain[0] == '2022':\n",
        "      baseline_val_p = (19+15) / (22.0+23)\n",
        "    elif yearsTrain[0] == '2023':\n",
        "      baseline_val_p = (19+9) / (24.0+22)\n",
        "    else:\n",
        "       baseline_val_p = 9 / 24.0\n",
        "\n",
        "    val_p_value, val_z = _two_prop_pvalue(val_sens, baseline_val_p, n_model=val_n, alternative=\"larger\")\n",
        "    # (Optional) also surface val acc from Keras history, last epoch:\n",
        "    hist_val_acc = float(history.history.get(\"val_accuracy\", [np.nan])[-1])\n",
        "\n",
        "    print(f\"[VALID] acc={hist_val_acc:.3f} | sens={val_sens:.3f} \"\n",
        "          f\"(k={val_k}/{val_n}, CI95=[{val_ci_low:.3f},{val_ci_high:.3f}]) \"\n",
        "          f\"vs base {baseline_val_p:.3f} p={val_p_value:.4f}\")\n",
        "\n",
        "    # These were all the metrics I wanted so really just sensitivty\n",
        "    comparePredictions = partyDf[(partyDf['Year_'+ yearsPredict[0]] == 1)].copy()\n",
        "    comparePredictions['predicted'] = model.predict(x_test.values, verbose=0)\n",
        "\n",
        "    track_cols = [c for c in comparePredictions.columns if c.startswith(\"Track_\")]\n",
        "    year_cols  = [c for c in comparePredictions.columns if c.startswith(\"Year_\")]\n",
        "    team_cols  = [c for c in comparePredictions.columns if c.startswith(\"Team_\")]\n",
        "    driver_cols= [c for c in comparePredictions.columns if c.startswith(\"Driver_\")]\n",
        "\n",
        "    comparePredictions[\"track\"]  = comparePredictions[track_cols].idxmax(axis=1).str.replace(\"Track_\", \"\", regex=False)\n",
        "    comparePredictions[\"Driver\"] = comparePredictions[driver_cols].idxmax(axis=1).str.replace(\"Driver_\", \"\", regex=False)\n",
        "\n",
        "    comparePredictions[\"predicted_winner\"] = (\n",
        "        comparePredictions.groupby(\"track\")[\"predicted\"]\n",
        "                          .transform(lambda x: x == x.max())\n",
        "                          .astype(int)\n",
        "    )\n",
        "\n",
        "    # This is how I know which driver I said would win the race in a neat orderly fashion\n",
        "    sortedcomparePredictions = comparePredictions.sort_values([\"track\", \"predicted\"], ascending=[True, False])\n",
        "    cols_to_drop = track_cols + year_cols + team_cols + driver_cols + ['Laps']\n",
        "    finalResultsDf = sortedcomparePredictions.drop(cols_to_drop, axis=1)\n",
        "\n",
        "    totalAmountGuessedCorrectly = finalResultsDf[\n",
        "        (finalResultsDf['predicted_winner'] == 1) & (finalResultsDf['win'] == 1)\n",
        "    ].shape[0]\n",
        "\n",
        "    numRaces = finalResultsDf['track'].nunique()\n",
        "    percentage_correct = totalAmountGuessedCorrectly / numRaces if numRaces > 0 else 0.0\n",
        "\n",
        "    # test CI + p-value\n",
        "    test_k = int(totalAmountGuessedCorrectly)\n",
        "    test_n = int(numRaces)\n",
        "    test_sens = float(percentage_correct)\n",
        "    test_ci_low, test_ci_high = _wilson_ci(test_k, test_n)\n",
        "    if yearsPredict[0] == '2024':\n",
        "      baseline_test_p = 9 / 24.0\n",
        "    else:\n",
        "      baseline_test_p = 2 / 23\n",
        "\n",
        "    test_p_value, test_z = _two_prop_pvalue(test_sens, baseline_test_p, n_model=test_n, alternative=\"larger\")\n",
        "    # (Optional) also surface val acc from Keras history, last epoch:\n",
        "    hist_val_acc = float(history.history.get(\"val_accuracy\", [np.nan])[-1])\n",
        "\n",
        "\n",
        "    print(f\"[TEST ] sens={test_sens:.3f} (k={test_k}/{test_n}, CI95=[{test_ci_low:.3f},{test_ci_high:.3f}]) \"\n",
        "          f\"vs base {baseline_test_p:.3f} p={test_p_value:.4f}\")\n",
        "\n",
        "    metrics = {\n",
        "        #\"val_accuracy_row\": val_accuracy,              # row-level acc (thresholded)\n",
        "        \"val_accuracy\": hist_val_acc,            # Keras-reported val accuracy\n",
        "        \"val_sensitivity\": val_sens,\n",
        "        \"val_ci_low\": val_ci_low, \"val_ci_high\": val_ci_high,\n",
        "        #\"val_p_value_vs_baseline\": val_p_value,\n",
        "        \"test_sensitivity\": test_sens,\n",
        "        \"test_ci_low\": test_ci_low, \"test_ci_high\": test_ci_high,\n",
        "        \"test_p_value_vs_baseline\": test_p_value\n",
        "        #\"val_races\": val_n, \"test_races\": test_n\n",
        "    }\n",
        "\n",
        "    return finalResultsDf, finalResultsDf[(finalResultsDf['predicted_winner']==1)|(finalResultsDf['win']==1)].sort_values('track'), metrics\n"
      ],
      "metadata": {
        "id": "qflQn5LXfBQZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def trainHighModelMetrics(yearsTrain, yearsPredict, partyDf, activFunction, optimizer, epochs):\n",
        "    # 1) Determinism\n",
        "    os.environ[\"PYTHONHASHSEED\"] = \"42\"\n",
        "    np.random.seed(42)\n",
        "    random.seed(42)\n",
        "    try:\n",
        "        tf.random.set_seed(42)\n",
        "        # TF 2.12+: deterministic ops\n",
        "        tf.config.experimental.enable_op_determinism(True)\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "\n",
        "    dfs = []\n",
        "    #get data from all training years\n",
        "    for year in yearsTrain:\n",
        "        dfs.append(partyDf[partyDf['Year_' + year] == 1])\n",
        "\n",
        "    # Combine all selected years into one DataFrame\n",
        "    trainDf = pd.concat(dfs, ignore_index=True)\n",
        "\n",
        "    x = trainDf.drop(columns=['win', 'Position', 'RaceOrder'])\n",
        "    y = trainDf['win']\n",
        "\n",
        "    #extract the columns that have a one included in the x df\n",
        "    year_cols = [c for c in x.columns if c.startswith(\"Year_\")]\n",
        "\n",
        "    includedTrainingYears = []\n",
        "    for col in year_cols:\n",
        "        if (x[col] == 1).any():   # check if there is any row with a 1 in this column\n",
        "            includedTrainingYears.append(col)\n",
        "\n",
        "    print(\"The years trained: \", includedTrainingYears)\n",
        "\n",
        "\n",
        "    #split the training data accordingly\n",
        "    x_train, x_valid, y_train, y_valid = train_test_split(x, y, test_size=0.2, random_state=42)\n",
        "    #get the test data, so the data for the next year you would want to predict\n",
        "    dfTest = partyDf[(partyDf['Year_'+ yearsPredict[0]] == 1)]\n",
        "    x_test = dfTest.drop(columns=['win', 'Position', 'RaceOrder'])\n",
        "    y_test = dfTest['win']\n",
        "\n",
        "    # #### this where you call the type of architecture you need\n",
        "    model, history = createHighModel(\n",
        "        x_train.values, y_train.values,\n",
        "        x_valid.values, y_valid.values,\n",
        "        x_test.values, y_test.values,\n",
        "        activFunction, optimizer, epochs\n",
        "    )\n",
        "\n",
        "    #get prediction info\n",
        "    y_valid_pred_prob = model.predict(x_valid.values, verbose=0).ravel()\n",
        "\n",
        "    # race-level validation sensitivity + CI + p-value\n",
        "    df_valid = x_valid.copy()\n",
        "    df_valid[\"win\"] = y_valid.values\n",
        "    df_valid[\"predicted\"] = y_valid_pred_prob\n",
        "\n",
        "    val_sens, val_k, val_n, _ = _race_level_sensitivity(df_valid)\n",
        "    val_ci_low, val_ci_high = _wilson_ci(val_k, val_n)\n",
        "\n",
        "    # baseline for validation so biggest winner validation is the biggest each year\n",
        "    if yearsTrain[0] == '2022':\n",
        "      baseline_val_p = 19 / 22.0\n",
        "    elif yearsTrain[0] == '2023':\n",
        "      baseline_val_p = 9 / 24.0\n",
        "    else:\n",
        "       baseline_val_p = 9 / 24.0\n",
        "\n",
        "    val_p_value, val_z = _two_prop_pvalue(val_sens, baseline_val_p, n_model=val_n, alternative=\"larger\")\n",
        "    # (Optional) also surface val acc from Keras history, last epoch:\n",
        "    hist_val_acc = float(history.history.get(\"val_accuracy\", [np.nan])[-1])\n",
        "\n",
        "    print(f\"[VALID] acc={hist_val_acc:.3f} | sens={val_sens:.3f} \"\n",
        "          f\"(k={val_k}/{val_n}, CI95=[{val_ci_low:.3f},{val_ci_high:.3f}]) \"\n",
        "          f\"vs base {baseline_val_p:.3f} p={val_p_value:.4f}\")\n",
        "\n",
        "    # These were all the metrics I wanted so really just sensitivty\n",
        "    comparePredictions = partyDf[(partyDf['Year_'+ yearsPredict[0]] == 1)].copy()\n",
        "    comparePredictions['predicted'] = model.predict(x_test.values, verbose=0)\n",
        "\n",
        "    track_cols = [c for c in comparePredictions.columns if c.startswith(\"Track_\")]\n",
        "    year_cols  = [c for c in comparePredictions.columns if c.startswith(\"Year_\")]\n",
        "    team_cols  = [c for c in comparePredictions.columns if c.startswith(\"Team_\")]\n",
        "    driver_cols= [c for c in comparePredictions.columns if c.startswith(\"Driver_\")]\n",
        "\n",
        "    comparePredictions[\"track\"]  = comparePredictions[track_cols].idxmax(axis=1).str.replace(\"Track_\", \"\", regex=False)\n",
        "    comparePredictions[\"Driver\"] = comparePredictions[driver_cols].idxmax(axis=1).str.replace(\"Driver_\", \"\", regex=False)\n",
        "\n",
        "    comparePredictions[\"predicted_winner\"] = (\n",
        "        comparePredictions.groupby(\"track\")[\"predicted\"]\n",
        "                          .transform(lambda x: x == x.max())\n",
        "                          .astype(int)\n",
        "    )\n",
        "\n",
        "    # This is how I know which driver I said would win the race in a neat orderly fashion\n",
        "    sortedcomparePredictions = comparePredictions.sort_values([\"track\", \"predicted\"], ascending=[True, False])\n",
        "    cols_to_drop = track_cols + year_cols + team_cols + driver_cols + ['Laps']\n",
        "    finalResultsDf = sortedcomparePredictions.drop(cols_to_drop, axis=1)\n",
        "\n",
        "    totalAmountGuessedCorrectly = finalResultsDf[\n",
        "        (finalResultsDf['predicted_winner'] == 1) & (finalResultsDf['win'] == 1)\n",
        "    ].shape[0]\n",
        "\n",
        "    numRaces = finalResultsDf['track'].nunique()\n",
        "    percentage_correct = totalAmountGuessedCorrectly / numRaces if numRaces > 0 else 0.0\n",
        "\n",
        "    # test CI + p-value\n",
        "    test_k = int(totalAmountGuessedCorrectly)\n",
        "    test_n = int(numRaces)\n",
        "    test_sens = float(percentage_correct)\n",
        "    test_ci_low, test_ci_high = _wilson_ci(test_k, test_n)\n",
        "    if yearsPredict[0] == '2024':\n",
        "      baseline_test_p = 9 / 24.0\n",
        "    else:\n",
        "      baseline_test_p = 2 / 23\n",
        "\n",
        "    test_p_value, test_z = _two_prop_pvalue(test_sens, baseline_test_p, n_model=test_n, alternative=\"larger\")\n",
        "\n",
        "    print(f\"[TEST ] sens={test_sens:.3f} (k={test_k}/{test_n}, CI95=[{test_ci_low:.3f},{test_ci_high:.3f}]) \"\n",
        "          f\"vs base {baseline_test_p:.3f} p={test_p_value:.4f}\")\n",
        "\n",
        "    metrics = {\n",
        "        #\"val_accuracy_row\": val_accuracy,              # row-level acc (thresholded)\n",
        "        \"val_accuracy\": hist_val_acc,            # Keras-reported val accuracy\n",
        "        \"val_sensitivity\": val_sens,\n",
        "        \"val_ci_low\": val_ci_low, \"val_ci_high\": val_ci_high,\n",
        "        #\"val_p_value_vs_baseline\": val_p_value,\n",
        "        \"test_sensitivity\": test_sens,\n",
        "        \"test_ci_low\": test_ci_low, \"test_ci_high\": test_ci_high,\n",
        "        \"test_p_value_vs_baseline\": test_p_value\n",
        "        #\"val_races\": val_n, \"test_races\": test_n\n",
        "    }\n",
        "\n",
        "    return finalResultsDf, finalResultsDf[(finalResultsDf['predicted_winner']==1)|(finalResultsDf['win']==1)].sort_values('track'), metrics\n"
      ],
      "metadata": {
        "id": "ifkELcN1fHki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yearsTrain = ['2024']\n",
        "yearsPredict = ['2025']\n",
        "df, smallDf, metrics = trainMediumModelMetrics(yearsTrain, yearsPredict, completed2025, \"sigmoid\", \"adam\", 100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wg8RrEJEl4ri",
        "outputId": "c92e9cb7-90fb-4503-a069-29de9235c7b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The years trained:  ['Year_2024']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 49ms/step - accuracy: 0.9609 - loss: 0.2001 - val_accuracy: 0.9479 - val_loss: 0.0808\n",
            "Epoch 2/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9689 - loss: 0.0435 - val_accuracy: 0.9479 - val_loss: 0.0593\n",
            "Epoch 3/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9689 - loss: 0.0390 - val_accuracy: 0.9479 - val_loss: 0.0512\n",
            "Epoch 4/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.9689 - loss: 0.0321 - val_accuracy: 0.9479 - val_loss: 0.0508\n",
            "Epoch 5/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.9689 - loss: 0.0308 - val_accuracy: 0.9479 - val_loss: 0.0511\n",
            "Epoch 6/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9689 - loss: 0.0325 - val_accuracy: 0.9479 - val_loss: 0.0507\n",
            "Epoch 7/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.9689 - loss: 0.0318 - val_accuracy: 0.9479 - val_loss: 0.0504\n",
            "Epoch 8/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9689 - loss: 0.0317 - val_accuracy: 0.9479 - val_loss: 0.0502\n",
            "Epoch 9/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9689 - loss: 0.0317 - val_accuracy: 0.9479 - val_loss: 0.0501\n",
            "Epoch 10/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9689 - loss: 0.0316 - val_accuracy: 0.9479 - val_loss: 0.0500\n",
            "Epoch 11/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.9689 - loss: 0.0316 - val_accuracy: 0.9479 - val_loss: 0.0500\n",
            "Epoch 12/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9689 - loss: 0.0316 - val_accuracy: 0.9479 - val_loss: 0.0499\n",
            "Epoch 13/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0316 - val_accuracy: 0.9479 - val_loss: 0.0499\n",
            "Epoch 14/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0316 - val_accuracy: 0.9479 - val_loss: 0.0499\n",
            "Epoch 15/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0317 - val_accuracy: 0.9479 - val_loss: 0.0499\n",
            "Epoch 16/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0317 - val_accuracy: 0.9479 - val_loss: 0.0500\n",
            "Epoch 17/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0317 - val_accuracy: 0.9479 - val_loss: 0.0500\n",
            "Epoch 18/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9689 - loss: 0.0318 - val_accuracy: 0.9479 - val_loss: 0.0501\n",
            "Epoch 19/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0318 - val_accuracy: 0.9479 - val_loss: 0.0503\n",
            "Epoch 20/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0320 - val_accuracy: 0.9479 - val_loss: 0.0505\n",
            "Epoch 21/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0321 - val_accuracy: 0.9479 - val_loss: 0.0507\n",
            "Epoch 22/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9689 - loss: 0.0322 - val_accuracy: 0.9479 - val_loss: 0.0509\n",
            "Epoch 23/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0322 - val_accuracy: 0.9479 - val_loss: 0.0512\n",
            "Epoch 24/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9689 - loss: 0.0324 - val_accuracy: 0.9479 - val_loss: 0.0514\n",
            "Epoch 25/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0325 - val_accuracy: 0.9479 - val_loss: 0.0518\n",
            "Epoch 26/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0326 - val_accuracy: 0.9479 - val_loss: 0.0519\n",
            "Epoch 27/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9689 - loss: 0.0326 - val_accuracy: 0.9479 - val_loss: 0.0520\n",
            "Epoch 28/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0326 - val_accuracy: 0.9479 - val_loss: 0.0521\n",
            "Epoch 29/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9689 - loss: 0.0323 - val_accuracy: 0.9479 - val_loss: 0.0529\n",
            "Epoch 30/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0327 - val_accuracy: 0.9479 - val_loss: 0.0529\n",
            "Epoch 31/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0324 - val_accuracy: 0.9479 - val_loss: 0.0541\n",
            "Epoch 32/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0330 - val_accuracy: 0.9479 - val_loss: 0.0527\n",
            "Epoch 33/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0317 - val_accuracy: 0.9479 - val_loss: 0.0547\n",
            "Epoch 34/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9689 - loss: 0.0327 - val_accuracy: 0.9479 - val_loss: 0.0552\n",
            "Epoch 35/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9689 - loss: 0.0332 - val_accuracy: 0.9479 - val_loss: 0.0550\n",
            "Epoch 36/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0335 - val_accuracy: 0.9479 - val_loss: 0.0539\n",
            "Epoch 37/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0329 - val_accuracy: 0.9479 - val_loss: 0.0519\n",
            "Epoch 38/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0312 - val_accuracy: 0.9479 - val_loss: 0.0539\n",
            "Epoch 39/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0317 - val_accuracy: 0.9479 - val_loss: 0.0540\n",
            "Epoch 40/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0321 - val_accuracy: 0.9479 - val_loss: 0.0538\n",
            "Epoch 41/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0318 - val_accuracy: 0.9479 - val_loss: 0.0522\n",
            "Epoch 42/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9689 - loss: 0.0306 - val_accuracy: 0.9479 - val_loss: 0.0526\n",
            "Epoch 43/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9689 - loss: 0.0302 - val_accuracy: 0.9479 - val_loss: 0.0525\n",
            "Epoch 44/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0297 - val_accuracy: 0.9479 - val_loss: 0.0536\n",
            "Epoch 45/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0303 - val_accuracy: 0.9479 - val_loss: 0.0524\n",
            "Epoch 46/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0288 - val_accuracy: 0.9479 - val_loss: 0.0564\n",
            "Epoch 47/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0304 - val_accuracy: 0.9479 - val_loss: 0.0569\n",
            "Epoch 48/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0313 - val_accuracy: 0.9479 - val_loss: 0.0565\n",
            "Epoch 49/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0311 - val_accuracy: 0.9479 - val_loss: 0.0592\n",
            "Epoch 50/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0323 - val_accuracy: 0.9479 - val_loss: 0.0550\n",
            "Epoch 51/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9689 - loss: 0.0305 - val_accuracy: 0.9479 - val_loss: 0.0554\n",
            "Epoch 52/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9689 - loss: 0.0303 - val_accuracy: 0.9479 - val_loss: 0.0537\n",
            "Epoch 53/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0295 - val_accuracy: 0.9479 - val_loss: 0.0534\n",
            "Epoch 54/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0284 - val_accuracy: 0.9479 - val_loss: 0.0532\n",
            "Epoch 55/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0278 - val_accuracy: 0.9479 - val_loss: 0.0543\n",
            "Epoch 56/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0283 - val_accuracy: 0.9479 - val_loss: 0.0539\n",
            "Epoch 57/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9689 - loss: 0.0280 - val_accuracy: 0.9479 - val_loss: 0.0552\n",
            "Epoch 58/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0286 - val_accuracy: 0.9479 - val_loss: 0.0541\n",
            "Epoch 59/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0280 - val_accuracy: 0.9479 - val_loss: 0.0555\n",
            "Epoch 60/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0283 - val_accuracy: 0.9479 - val_loss: 0.0541\n",
            "Epoch 61/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0276 - val_accuracy: 0.9479 - val_loss: 0.0561\n",
            "Epoch 62/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0282 - val_accuracy: 0.9479 - val_loss: 0.0543\n",
            "Epoch 63/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0274 - val_accuracy: 0.9479 - val_loss: 0.0563\n",
            "Epoch 64/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0279 - val_accuracy: 0.9479 - val_loss: 0.0546\n",
            "Epoch 65/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0271 - val_accuracy: 0.9479 - val_loss: 0.0563\n",
            "Epoch 66/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0276 - val_accuracy: 0.9479 - val_loss: 0.0549\n",
            "Epoch 67/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0269 - val_accuracy: 0.9479 - val_loss: 0.0567\n",
            "Epoch 68/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0275 - val_accuracy: 0.9479 - val_loss: 0.0550\n",
            "Epoch 69/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0267 - val_accuracy: 0.9479 - val_loss: 0.0570\n",
            "Epoch 70/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9689 - loss: 0.0272 - val_accuracy: 0.9479 - val_loss: 0.0557\n",
            "Epoch 71/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9689 - loss: 0.0267 - val_accuracy: 0.9479 - val_loss: 0.0572\n",
            "Epoch 72/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9689 - loss: 0.0271 - val_accuracy: 0.9479 - val_loss: 0.0561\n",
            "Epoch 73/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9689 - loss: 0.0267 - val_accuracy: 0.9479 - val_loss: 0.0569\n",
            "Epoch 74/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9689 - loss: 0.0267 - val_accuracy: 0.9479 - val_loss: 0.0566\n",
            "Epoch 75/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9689 - loss: 0.0265 - val_accuracy: 0.9479 - val_loss: 0.0569\n",
            "Epoch 76/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9689 - loss: 0.0264 - val_accuracy: 0.9375 - val_loss: 0.0571\n",
            "Epoch 77/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9689 - loss: 0.0265 - val_accuracy: 0.9375 - val_loss: 0.0571\n",
            "Epoch 78/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9689 - loss: 0.0263 - val_accuracy: 0.9375 - val_loss: 0.0572\n",
            "Epoch 79/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9689 - loss: 0.0261 - val_accuracy: 0.9375 - val_loss: 0.0582\n",
            "Epoch 80/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9689 - loss: 0.0265 - val_accuracy: 0.9375 - val_loss: 0.0573\n",
            "Epoch 81/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9689 - loss: 0.0260 - val_accuracy: 0.9375 - val_loss: 0.0586\n",
            "Epoch 82/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9689 - loss: 0.0264 - val_accuracy: 0.9375 - val_loss: 0.0578\n",
            "Epoch 83/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9689 - loss: 0.0259 - val_accuracy: 0.9375 - val_loss: 0.0584\n",
            "Epoch 84/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0260 - val_accuracy: 0.9375 - val_loss: 0.0585\n",
            "Epoch 85/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0259 - val_accuracy: 0.9375 - val_loss: 0.0590\n",
            "Epoch 86/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9722 - loss: 0.0260 - val_accuracy: 0.9375 - val_loss: 0.0586\n",
            "Epoch 87/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0258 - val_accuracy: 0.9375 - val_loss: 0.0594\n",
            "Epoch 88/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9722 - loss: 0.0260 - val_accuracy: 0.9375 - val_loss: 0.0592\n",
            "Epoch 89/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9722 - loss: 0.0258 - val_accuracy: 0.9375 - val_loss: 0.0591\n",
            "Epoch 90/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9722 - loss: 0.0256 - val_accuracy: 0.9375 - val_loss: 0.0603\n",
            "Epoch 91/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9722 - loss: 0.0260 - val_accuracy: 0.9375 - val_loss: 0.0595\n",
            "Epoch 92/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9722 - loss: 0.0257 - val_accuracy: 0.9375 - val_loss: 0.0601\n",
            "Epoch 93/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9722 - loss: 0.0257 - val_accuracy: 0.9375 - val_loss: 0.0608\n",
            "Epoch 94/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9722 - loss: 0.0259 - val_accuracy: 0.9375 - val_loss: 0.0600\n",
            "Epoch 95/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9722 - loss: 0.0256 - val_accuracy: 0.9375 - val_loss: 0.0606\n",
            "Epoch 96/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9722 - loss: 0.0255 - val_accuracy: 0.9271 - val_loss: 0.0615\n",
            "Epoch 97/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9722 - loss: 0.0257 - val_accuracy: 0.9271 - val_loss: 0.0608\n",
            "Epoch 98/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9722 - loss: 0.0255 - val_accuracy: 0.9271 - val_loss: 0.0614\n",
            "Epoch 99/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9722 - loss: 0.0256 - val_accuracy: 0.9167 - val_loss: 0.0617\n",
            "Epoch 100/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9722 - loss: 0.0255 - val_accuracy: 0.9271 - val_loss: 0.0617\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9465 - loss: 0.0464  \n",
            "[VALID] acc=0.927 | sens=0.167 (k=4/24, CI95=[0.067,0.359]) vs base 0.375 p=0.9478\n",
            "[TEST ] sens=0.130 (k=3/23, CI95=[0.045,0.321]) vs base 0.087 p=0.3179\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(metrics)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k9dotTEz6pbL",
        "outputId": "3ebff7e9-9401-4153-bed5-eb39aafbbe1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'val_accuracy': 0.9886363744735718, 'val_sensitivity': 0.16666666666666666, 'val_ci_low': 0.06678676328632946, 'val_ci_high': 0.3585307064969907, 'test_sensitivity': 0.375, 'test_ci_low': 0.21159367559548778, 'test_ci_high': 0.5729003755732573, 'test_p_value_vs_baseline': 0.5}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def createSeasonalDf(yearsTrain, yearsPredict, passDf):\n",
        "    optimizers  = ['adam', 'adagrad']\n",
        "    activations = ['relu', 'tanh', 'sigmoid']\n",
        "    complexities = ['Simple', 'Medium', 'High']\n",
        "    layers_map = {'Simple': 2, 'Medium': 4, 'High': 8}\n",
        "\n",
        "\n",
        "    rows = []\n",
        "\n",
        "    for optimizer in optimizers:\n",
        "        for complexity in complexities:\n",
        "            bestAct = 'relu'\n",
        "            bestActSens = 0\n",
        "            for activation in activations:\n",
        "                # Train the right model family\n",
        "                if complexity == 'Simple':\n",
        "                    df, smallDf, metrics = trainSimpleModelMetrics(\n",
        "                        yearsTrain, yearsPredict, passDf, activation, optimizer, 20\n",
        "                    )\n",
        "                elif complexity == 'Medium':\n",
        "                    df, smallDf, metrics = trainMediumModelMetrics(\n",
        "                        yearsTrain, yearsPredict, passDf, activation, optimizer, 20\n",
        "                    )\n",
        "                else:  # High\n",
        "                    df, smallDf, metrics = trainHighModelMetrics(\n",
        "                        yearsTrain, yearsPredict, passDf, activation, optimizer, 20\n",
        "                    )\n",
        "                if bestActSens < metrics.get(\"test_sensitivity\", np.nan):\n",
        "                  bestActSens = metrics.get(\"test_sensitivity\", np.nan)\n",
        "                  bestAct = activation\n",
        "\n",
        "                # Build one results row (use .get to avoid KeyErrors)\n",
        "                row = {\n",
        "                    \"Model Complexity\": complexity,\n",
        "                    \"Layers\": layers_map.get(complexity, np.nan),\n",
        "                    \"Epochs\": 20,\n",
        "                    \"Optimizer\": optimizer,\n",
        "                    \"Activation\": activation,\n",
        "\n",
        "                    # Validation metrics\n",
        "                    \"val_accuracy\":     metrics.get(\"val_accuracy\", np.nan),\n",
        "                    \"val_sensitivity\":      metrics.get(\"val_sensitivity\", np.nan),\n",
        "                    \"val_ci_low\":           metrics.get(\"val_ci_low\", np.nan),\n",
        "                    \"val_ci_high\":          metrics.get(\"val_ci_high\", np.nan),\n",
        "\n",
        "\n",
        "                    # Test metrics\n",
        "                    \"test_sensitivity\":     metrics.get(\"test_sensitivity\", np.nan),\n",
        "                    \"test_ci_low\":          metrics.get(\"test_ci_low\", np.nan),\n",
        "                    \"test_ci_high\":         metrics.get(\"test_ci_high\", np.nan),\n",
        "                    \"test_p_value_vs_baseline\": metrics.get(\"test_p_value_vs_baseline\", np.nan),\n",
        "\n",
        "                }\n",
        "\n",
        "                rows.append(row)\n",
        "\n",
        "            if complexity == 'Simple':\n",
        "                  df, smallDf, metrics = trainSimpleModelMetrics(\n",
        "                      yearsTrain, yearsPredict, passDf, bestAct, optimizer, 100\n",
        "                  )\n",
        "            elif complexity == 'Medium':\n",
        "                df, smallDf, metrics = trainMediumModelMetrics(\n",
        "                    yearsTrain, yearsPredict, passDf, bestAct, optimizer, 100\n",
        "                )\n",
        "            else:  # High\n",
        "                df, smallDf, metrics = trainHighModelMetrics(\n",
        "                    yearsTrain, yearsPredict, passDf, bestAct, optimizer, 100\n",
        "                )\n",
        "\n",
        "            # Build one results row (use .get to avoid KeyErrors)\n",
        "            row = {\n",
        "                \"Model Complexity\": complexity,\n",
        "                \"Layers\": layers_map.get(complexity, np.nan),\n",
        "                \"Epochs\": 100,\n",
        "                \"Optimizer\": optimizer,\n",
        "                \"Activation\": bestAct,\n",
        "\n",
        "                # Validation metrics\n",
        "                \"val_accuracy\":     metrics.get(\"val_accuracy\", np.nan),\n",
        "                \"val_sensitivity\":      metrics.get(\"val_sensitivity\", np.nan),\n",
        "                \"val_ci_low\":           metrics.get(\"val_ci_low\", np.nan),\n",
        "                \"val_ci_high\":          metrics.get(\"val_ci_high\", np.nan),\n",
        "\n",
        "\n",
        "                # Test metrics\n",
        "                \"test_sensitivity\":     metrics.get(\"test_sensitivity\", np.nan),\n",
        "                \"test_ci_low\":          metrics.get(\"test_ci_low\", np.nan),\n",
        "                \"test_ci_high\":         metrics.get(\"test_ci_high\", np.nan),\n",
        "                \"test_p_value_vs_baseline\": metrics.get(\"test_p_value_vs_baseline\", np.nan),\n",
        "\n",
        "            }\n",
        "\n",
        "            rows.append(row)\n",
        "\n",
        "\n",
        "    displayDf = pd.DataFrame(rows)\n",
        "\n",
        "    # Optional: enforce a column order\n",
        "    cols_order = [\n",
        "        \"Model Complexity\",\"Layers\",\"Epochs\",\"Optimizer\",\"Activation\",\n",
        "        \"val_accuracy\",\"val_sensitivity\",\"val_ci_low\",\"val_ci_high\",\n",
        "\n",
        "        \"test_sensitivity\",\"test_ci_low\",\"test_ci_high\",\"test_p_value_vs_baseline\",\n",
        "\n",
        "    ]\n",
        "    displayDf = displayDf[[c for c in cols_order if c in displayDf.columns]]\n",
        "\n",
        "    return displayDf\n"
      ],
      "metadata": {
        "id": "LZWaPkhskR0S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yearsTrain = ['2024']\n",
        "yearsPredict = ['2025']\n",
        "display2425Df = createSeasonalDf(yearsTrain, yearsPredict, completed2025)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G6i6WuY0kTCa",
        "outputId": "22039d0b-d548-46d3-9b7c-498734f14c6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The years trained:  ['Year_2024']\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 0.7413 - loss: 0.3032 - val_accuracy: 0.9479 - val_loss: 0.1018\n",
            "Epoch 2/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0663 - val_accuracy: 0.9479 - val_loss: 0.0579\n",
            "Epoch 3/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9689 - loss: 0.0349 - val_accuracy: 0.9479 - val_loss: 0.0514\n",
            "Epoch 4/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9689 - loss: 0.0374 - val_accuracy: 0.9479 - val_loss: 0.0542\n",
            "Epoch 5/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0324 - val_accuracy: 0.9479 - val_loss: 0.0503\n",
            "Epoch 6/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0338 - val_accuracy: 0.9479 - val_loss: 0.0508\n",
            "Epoch 7/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0317 - val_accuracy: 0.9479 - val_loss: 0.0499\n",
            "Epoch 8/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0325 - val_accuracy: 0.9479 - val_loss: 0.0498\n",
            "Epoch 9/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0324 - val_accuracy: 0.9479 - val_loss: 0.0497\n",
            "Epoch 10/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0322 - val_accuracy: 0.9479 - val_loss: 0.0499\n",
            "Epoch 11/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0324 - val_accuracy: 0.9479 - val_loss: 0.0506\n",
            "Epoch 12/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0333 - val_accuracy: 0.9479 - val_loss: 0.0513\n",
            "Epoch 13/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0337 - val_accuracy: 0.9479 - val_loss: 0.0521\n",
            "Epoch 14/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9689 - loss: 0.0341 - val_accuracy: 0.9479 - val_loss: 0.0535\n",
            "Epoch 15/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0347 - val_accuracy: 0.9479 - val_loss: 0.0549\n",
            "Epoch 16/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0350 - val_accuracy: 0.9479 - val_loss: 0.0555\n",
            "Epoch 17/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0347 - val_accuracy: 0.9479 - val_loss: 0.0559\n",
            "Epoch 18/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0345 - val_accuracy: 0.9479 - val_loss: 0.0546\n",
            "Epoch 19/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0330 - val_accuracy: 0.9479 - val_loss: 0.0554\n",
            "Epoch 20/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0330 - val_accuracy: 0.9479 - val_loss: 0.0557\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9555 - loss: 0.0428  \n",
            "[VALID] acc=0.948 | sens=0.125 (k=3/24, CI95=[0.043,0.310]) vs base 0.375 p=0.9772\n",
            "[TEST ] sens=0.174 (k=4/23, CI95=[0.070,0.371]) vs base 0.087 p=0.1906\n",
            "The years trained:  ['Year_2024']\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.8638 - loss: 0.1514 - val_accuracy: 0.9479 - val_loss: 0.0724\n",
            "Epoch 2/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9689 - loss: 0.0521 - val_accuracy: 0.9479 - val_loss: 0.0487\n",
            "Epoch 3/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0318 - val_accuracy: 0.9479 - val_loss: 0.0485\n",
            "Epoch 4/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9689 - loss: 0.0313 - val_accuracy: 0.9479 - val_loss: 0.0487\n",
            "Epoch 5/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0309 - val_accuracy: 0.9479 - val_loss: 0.0488\n",
            "Epoch 6/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0307 - val_accuracy: 0.9479 - val_loss: 0.0488\n",
            "Epoch 7/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9689 - loss: 0.0307 - val_accuracy: 0.9479 - val_loss: 0.0488\n",
            "Epoch 8/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0307 - val_accuracy: 0.9479 - val_loss: 0.0488\n",
            "Epoch 9/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0308 - val_accuracy: 0.9479 - val_loss: 0.0488\n",
            "Epoch 10/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9689 - loss: 0.0307 - val_accuracy: 0.9479 - val_loss: 0.0489\n",
            "Epoch 11/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0309 - val_accuracy: 0.9479 - val_loss: 0.0489\n",
            "Epoch 12/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0308 - val_accuracy: 0.9479 - val_loss: 0.0489\n",
            "Epoch 13/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0309 - val_accuracy: 0.9479 - val_loss: 0.0489\n",
            "Epoch 14/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0309 - val_accuracy: 0.9479 - val_loss: 0.0490\n",
            "Epoch 15/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0310 - val_accuracy: 0.9479 - val_loss: 0.0490\n",
            "Epoch 16/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0311 - val_accuracy: 0.9479 - val_loss: 0.0491\n",
            "Epoch 17/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9689 - loss: 0.0314 - val_accuracy: 0.9479 - val_loss: 0.0490\n",
            "Epoch 18/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9689 - loss: 0.0313 - val_accuracy: 0.9479 - val_loss: 0.0494\n",
            "Epoch 19/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0317 - val_accuracy: 0.9479 - val_loss: 0.0494\n",
            "Epoch 20/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0318 - val_accuracy: 0.9479 - val_loss: 0.0497\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9555 - loss: 0.0443  \n",
            "[VALID] acc=0.948 | sens=0.125 (k=3/24, CI95=[0.043,0.310]) vs base 0.375 p=0.9772\n",
            "[TEST ] sens=0.000 (k=0/23, CI95=[0.000,0.143]) vs base 0.087 p=0.9259\n",
            "The years trained:  ['Year_2024']\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 0.9609 - loss: 0.2001 - val_accuracy: 0.9479 - val_loss: 0.0808\n",
            "Epoch 2/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0435 - val_accuracy: 0.9479 - val_loss: 0.0593\n",
            "Epoch 3/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0390 - val_accuracy: 0.9479 - val_loss: 0.0512\n",
            "Epoch 4/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0321 - val_accuracy: 0.9479 - val_loss: 0.0508\n",
            "Epoch 5/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0308 - val_accuracy: 0.9479 - val_loss: 0.0511\n",
            "Epoch 6/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9689 - loss: 0.0325 - val_accuracy: 0.9479 - val_loss: 0.0507\n",
            "Epoch 7/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0318 - val_accuracy: 0.9479 - val_loss: 0.0504\n",
            "Epoch 8/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0317 - val_accuracy: 0.9479 - val_loss: 0.0502\n",
            "Epoch 9/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0317 - val_accuracy: 0.9479 - val_loss: 0.0501\n",
            "Epoch 10/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0316 - val_accuracy: 0.9479 - val_loss: 0.0500\n",
            "Epoch 11/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0316 - val_accuracy: 0.9479 - val_loss: 0.0500\n",
            "Epoch 12/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0316 - val_accuracy: 0.9479 - val_loss: 0.0499\n",
            "Epoch 13/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0316 - val_accuracy: 0.9479 - val_loss: 0.0499\n",
            "Epoch 14/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9689 - loss: 0.0316 - val_accuracy: 0.9479 - val_loss: 0.0499\n",
            "Epoch 15/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0317 - val_accuracy: 0.9479 - val_loss: 0.0499\n",
            "Epoch 16/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0317 - val_accuracy: 0.9479 - val_loss: 0.0500\n",
            "Epoch 17/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0317 - val_accuracy: 0.9479 - val_loss: 0.0500\n",
            "Epoch 18/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0318 - val_accuracy: 0.9479 - val_loss: 0.0501\n",
            "Epoch 19/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0318 - val_accuracy: 0.9479 - val_loss: 0.0503\n",
            "Epoch 20/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9689 - loss: 0.0320 - val_accuracy: 0.9479 - val_loss: 0.0505\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9555 - loss: 0.0442  \n",
            "[VALID] acc=0.948 | sens=0.125 (k=3/24, CI95=[0.043,0.310]) vs base 0.375 p=0.9772\n",
            "[TEST ] sens=0.174 (k=4/23, CI95=[0.070,0.371]) vs base 0.087 p=0.1906\n",
            "The years trained:  ['Year_2024']\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.7413 - loss: 0.3032 - val_accuracy: 0.9479 - val_loss: 0.1018\n",
            "Epoch 2/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9689 - loss: 0.0663 - val_accuracy: 0.9479 - val_loss: 0.0579\n",
            "Epoch 3/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9689 - loss: 0.0349 - val_accuracy: 0.9479 - val_loss: 0.0514\n",
            "Epoch 4/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0374 - val_accuracy: 0.9479 - val_loss: 0.0542\n",
            "Epoch 5/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9689 - loss: 0.0324 - val_accuracy: 0.9479 - val_loss: 0.0503\n",
            "Epoch 6/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0338 - val_accuracy: 0.9479 - val_loss: 0.0508\n",
            "Epoch 7/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0317 - val_accuracy: 0.9479 - val_loss: 0.0499\n",
            "Epoch 8/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0325 - val_accuracy: 0.9479 - val_loss: 0.0498\n",
            "Epoch 9/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9689 - loss: 0.0324 - val_accuracy: 0.9479 - val_loss: 0.0497\n",
            "Epoch 10/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0322 - val_accuracy: 0.9479 - val_loss: 0.0499\n",
            "Epoch 11/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0324 - val_accuracy: 0.9479 - val_loss: 0.0506\n",
            "Epoch 12/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0333 - val_accuracy: 0.9479 - val_loss: 0.0513\n",
            "Epoch 13/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0337 - val_accuracy: 0.9479 - val_loss: 0.0521\n",
            "Epoch 14/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9689 - loss: 0.0341 - val_accuracy: 0.9479 - val_loss: 0.0535\n",
            "Epoch 15/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0347 - val_accuracy: 0.9479 - val_loss: 0.0549\n",
            "Epoch 16/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0350 - val_accuracy: 0.9479 - val_loss: 0.0555\n",
            "Epoch 17/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0347 - val_accuracy: 0.9479 - val_loss: 0.0559\n",
            "Epoch 18/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9689 - loss: 0.0345 - val_accuracy: 0.9479 - val_loss: 0.0546\n",
            "Epoch 19/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0330 - val_accuracy: 0.9479 - val_loss: 0.0554\n",
            "Epoch 20/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0330 - val_accuracy: 0.9479 - val_loss: 0.0557\n",
            "Epoch 21/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0329 - val_accuracy: 0.9479 - val_loss: 0.0564\n",
            "Epoch 22/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9689 - loss: 0.0328 - val_accuracy: 0.9479 - val_loss: 0.0559\n",
            "Epoch 23/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0322 - val_accuracy: 0.9479 - val_loss: 0.0558\n",
            "Epoch 24/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0318 - val_accuracy: 0.9479 - val_loss: 0.0559\n",
            "Epoch 25/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0316 - val_accuracy: 0.9479 - val_loss: 0.0552\n",
            "Epoch 26/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0310 - val_accuracy: 0.9479 - val_loss: 0.0550\n",
            "Epoch 27/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0307 - val_accuracy: 0.9479 - val_loss: 0.0540\n",
            "Epoch 28/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9689 - loss: 0.0297 - val_accuracy: 0.9479 - val_loss: 0.0540\n",
            "Epoch 29/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0300 - val_accuracy: 0.9479 - val_loss: 0.0553\n",
            "Epoch 30/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9689 - loss: 0.0303 - val_accuracy: 0.9479 - val_loss: 0.0540\n",
            "Epoch 31/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9689 - loss: 0.0294 - val_accuracy: 0.9479 - val_loss: 0.0541\n",
            "Epoch 32/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9689 - loss: 0.0293 - val_accuracy: 0.9479 - val_loss: 0.0536\n",
            "Epoch 33/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0287 - val_accuracy: 0.9479 - val_loss: 0.0539\n",
            "Epoch 34/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0290 - val_accuracy: 0.9479 - val_loss: 0.0540\n",
            "Epoch 35/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0292 - val_accuracy: 0.9479 - val_loss: 0.0523\n",
            "Epoch 36/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0275 - val_accuracy: 0.9479 - val_loss: 0.0537\n",
            "Epoch 37/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9689 - loss: 0.0285 - val_accuracy: 0.9479 - val_loss: 0.0537\n",
            "Epoch 38/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0284 - val_accuracy: 0.9479 - val_loss: 0.0530\n",
            "Epoch 39/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0278 - val_accuracy: 0.9479 - val_loss: 0.0536\n",
            "Epoch 40/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0282 - val_accuracy: 0.9479 - val_loss: 0.0530\n",
            "Epoch 41/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0277 - val_accuracy: 0.9479 - val_loss: 0.0532\n",
            "Epoch 42/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9689 - loss: 0.0278 - val_accuracy: 0.9479 - val_loss: 0.0526\n",
            "Epoch 43/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0274 - val_accuracy: 0.9479 - val_loss: 0.0525\n",
            "Epoch 44/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0274 - val_accuracy: 0.9479 - val_loss: 0.0522\n",
            "Epoch 45/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0272 - val_accuracy: 0.9479 - val_loss: 0.0527\n",
            "Epoch 46/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0274 - val_accuracy: 0.9479 - val_loss: 0.0514\n",
            "Epoch 47/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0268 - val_accuracy: 0.9479 - val_loss: 0.0522\n",
            "Epoch 48/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0271 - val_accuracy: 0.9479 - val_loss: 0.0520\n",
            "Epoch 49/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9689 - loss: 0.0268 - val_accuracy: 0.9479 - val_loss: 0.0529\n",
            "Epoch 50/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9689 - loss: 0.0275 - val_accuracy: 0.9479 - val_loss: 0.0512\n",
            "Epoch 51/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0262 - val_accuracy: 0.9479 - val_loss: 0.0521\n",
            "Epoch 52/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0266 - val_accuracy: 0.9479 - val_loss: 0.0518\n",
            "Epoch 53/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0266 - val_accuracy: 0.9479 - val_loss: 0.0518\n",
            "Epoch 54/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0263 - val_accuracy: 0.9479 - val_loss: 0.0516\n",
            "Epoch 55/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0263 - val_accuracy: 0.9479 - val_loss: 0.0517\n",
            "Epoch 56/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0265 - val_accuracy: 0.9479 - val_loss: 0.0504\n",
            "Epoch 57/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0256 - val_accuracy: 0.9479 - val_loss: 0.0521\n",
            "Epoch 58/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0265 - val_accuracy: 0.9479 - val_loss: 0.0505\n",
            "Epoch 59/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0261 - val_accuracy: 0.9479 - val_loss: 0.0512\n",
            "Epoch 60/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9689 - loss: 0.0256 - val_accuracy: 0.9479 - val_loss: 0.0510\n",
            "Epoch 61/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0261 - val_accuracy: 0.9479 - val_loss: 0.0506\n",
            "Epoch 62/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0255 - val_accuracy: 0.9479 - val_loss: 0.0510\n",
            "Epoch 63/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0258 - val_accuracy: 0.9479 - val_loss: 0.0501\n",
            "Epoch 64/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0249 - val_accuracy: 0.9479 - val_loss: 0.0513\n",
            "Epoch 65/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0259 - val_accuracy: 0.9479 - val_loss: 0.0493\n",
            "Epoch 66/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0248 - val_accuracy: 0.9479 - val_loss: 0.0511\n",
            "Epoch 67/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0257 - val_accuracy: 0.9479 - val_loss: 0.0499\n",
            "Epoch 68/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9689 - loss: 0.0249 - val_accuracy: 0.9479 - val_loss: 0.0498\n",
            "Epoch 69/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9693 - loss: 0.0246 - val_accuracy: 0.9479 - val_loss: 0.0494\n",
            "Epoch 70/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9693 - loss: 0.0248 - val_accuracy: 0.9479 - val_loss: 0.0508\n",
            "Epoch 71/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9693 - loss: 0.0247 - val_accuracy: 0.9479 - val_loss: 0.0501\n",
            "Epoch 72/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9693 - loss: 0.0248 - val_accuracy: 0.9479 - val_loss: 0.0500\n",
            "Epoch 73/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9693 - loss: 0.0246 - val_accuracy: 0.9479 - val_loss: 0.0497\n",
            "Epoch 74/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9693 - loss: 0.0244 - val_accuracy: 0.9479 - val_loss: 0.0495\n",
            "Epoch 75/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9693 - loss: 0.0239 - val_accuracy: 0.9375 - val_loss: 0.0499\n",
            "Epoch 76/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9715 - loss: 0.0240 - val_accuracy: 0.9479 - val_loss: 0.0496\n",
            "Epoch 77/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9693 - loss: 0.0239 - val_accuracy: 0.9375 - val_loss: 0.0502\n",
            "Epoch 78/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9715 - loss: 0.0240 - val_accuracy: 0.9479 - val_loss: 0.0495\n",
            "Epoch 79/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9693 - loss: 0.0235 - val_accuracy: 0.9375 - val_loss: 0.0512\n",
            "Epoch 80/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9715 - loss: 0.0244 - val_accuracy: 0.9479 - val_loss: 0.0493\n",
            "Epoch 81/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9733 - loss: 0.0237 - val_accuracy: 0.9375 - val_loss: 0.0504\n",
            "Epoch 82/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9715 - loss: 0.0249 - val_accuracy: 0.9271 - val_loss: 0.0500\n",
            "Epoch 83/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9733 - loss: 0.0235 - val_accuracy: 0.9375 - val_loss: 0.0501\n",
            "Epoch 84/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9715 - loss: 0.0236 - val_accuracy: 0.9271 - val_loss: 0.0500\n",
            "Epoch 85/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9733 - loss: 0.0234 - val_accuracy: 0.9271 - val_loss: 0.0501\n",
            "Epoch 86/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9733 - loss: 0.0233 - val_accuracy: 0.9271 - val_loss: 0.0517\n",
            "Epoch 87/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9715 - loss: 0.0239 - val_accuracy: 0.9375 - val_loss: 0.0504\n",
            "Epoch 88/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9733 - loss: 0.0240 - val_accuracy: 0.9271 - val_loss: 0.0504\n",
            "Epoch 89/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9733 - loss: 0.0235 - val_accuracy: 0.9375 - val_loss: 0.0500\n",
            "Epoch 90/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9733 - loss: 0.0231 - val_accuracy: 0.9167 - val_loss: 0.0515\n",
            "Epoch 91/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9733 - loss: 0.0239 - val_accuracy: 0.9271 - val_loss: 0.0501\n",
            "Epoch 92/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9733 - loss: 0.0232 - val_accuracy: 0.9271 - val_loss: 0.0511\n",
            "Epoch 93/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9733 - loss: 0.0235 - val_accuracy: 0.9271 - val_loss: 0.0500\n",
            "Epoch 94/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9733 - loss: 0.0228 - val_accuracy: 0.9271 - val_loss: 0.0527\n",
            "Epoch 95/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9733 - loss: 0.0240 - val_accuracy: 0.9271 - val_loss: 0.0504\n",
            "Epoch 96/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9733 - loss: 0.0229 - val_accuracy: 0.9271 - val_loss: 0.0537\n",
            "Epoch 97/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9733 - loss: 0.0246 - val_accuracy: 0.9375 - val_loss: 0.0514\n",
            "Epoch 98/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9733 - loss: 0.0237 - val_accuracy: 0.9375 - val_loss: 0.0537\n",
            "Epoch 99/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9733 - loss: 0.0246 - val_accuracy: 0.9271 - val_loss: 0.0544\n",
            "Epoch 100/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9733 - loss: 0.0247 - val_accuracy: 0.9271 - val_loss: 0.0553\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9555 - loss: 0.0536  \n",
            "[VALID] acc=0.927 | sens=0.167 (k=4/24, CI95=[0.067,0.359]) vs base 0.375 p=0.9478\n",
            "[TEST ] sens=0.087 (k=2/23, CI95=[0.024,0.268]) vs base 0.087 p=0.5000\n",
            "The years trained:  ['Year_2024']\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.7413 - loss: 0.3032 - val_accuracy: 0.9479 - val_loss: 0.1018\n",
            "Epoch 2/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9689 - loss: 0.0663 - val_accuracy: 0.9479 - val_loss: 0.0579\n",
            "Epoch 3/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0349 - val_accuracy: 0.9479 - val_loss: 0.0514\n",
            "Epoch 4/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0374 - val_accuracy: 0.9479 - val_loss: 0.0542\n",
            "Epoch 5/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0324 - val_accuracy: 0.9479 - val_loss: 0.0503\n",
            "Epoch 6/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9689 - loss: 0.0338 - val_accuracy: 0.9479 - val_loss: 0.0508\n",
            "Epoch 7/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9689 - loss: 0.0317 - val_accuracy: 0.9479 - val_loss: 0.0499\n",
            "Epoch 8/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0325 - val_accuracy: 0.9479 - val_loss: 0.0498\n",
            "Epoch 9/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0324 - val_accuracy: 0.9479 - val_loss: 0.0497\n",
            "Epoch 10/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9689 - loss: 0.0322 - val_accuracy: 0.9479 - val_loss: 0.0499\n",
            "Epoch 11/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0324 - val_accuracy: 0.9479 - val_loss: 0.0506\n",
            "Epoch 12/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9689 - loss: 0.0333 - val_accuracy: 0.9479 - val_loss: 0.0513\n",
            "Epoch 13/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0337 - val_accuracy: 0.9479 - val_loss: 0.0521\n",
            "Epoch 14/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0341 - val_accuracy: 0.9479 - val_loss: 0.0535\n",
            "Epoch 15/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0347 - val_accuracy: 0.9479 - val_loss: 0.0549\n",
            "Epoch 16/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9689 - loss: 0.0350 - val_accuracy: 0.9479 - val_loss: 0.0555\n",
            "Epoch 17/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0347 - val_accuracy: 0.9479 - val_loss: 0.0559\n",
            "Epoch 18/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9689 - loss: 0.0345 - val_accuracy: 0.9479 - val_loss: 0.0546\n",
            "Epoch 19/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0330 - val_accuracy: 0.9479 - val_loss: 0.0554\n",
            "Epoch 20/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0330 - val_accuracy: 0.9479 - val_loss: 0.0557\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9555 - loss: 0.0428  \n",
            "[VALID] acc=0.948 | sens=0.125 (k=3/24, CI95=[0.043,0.310]) vs base 0.375 p=0.9772\n",
            "[TEST ] sens=0.174 (k=4/23, CI95=[0.070,0.371]) vs base 0.087 p=0.1906\n",
            "The years trained:  ['Year_2024']\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.8638 - loss: 0.1514 - val_accuracy: 0.9479 - val_loss: 0.0724\n",
            "Epoch 2/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0521 - val_accuracy: 0.9479 - val_loss: 0.0487\n",
            "Epoch 3/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0318 - val_accuracy: 0.9479 - val_loss: 0.0485\n",
            "Epoch 4/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0313 - val_accuracy: 0.9479 - val_loss: 0.0487\n",
            "Epoch 5/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0309 - val_accuracy: 0.9479 - val_loss: 0.0488\n",
            "Epoch 6/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0307 - val_accuracy: 0.9479 - val_loss: 0.0488\n",
            "Epoch 7/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0307 - val_accuracy: 0.9479 - val_loss: 0.0488\n",
            "Epoch 8/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9689 - loss: 0.0307 - val_accuracy: 0.9479 - val_loss: 0.0488\n",
            "Epoch 9/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0308 - val_accuracy: 0.9479 - val_loss: 0.0488\n",
            "Epoch 10/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0307 - val_accuracy: 0.9479 - val_loss: 0.0489\n",
            "Epoch 11/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0309 - val_accuracy: 0.9479 - val_loss: 0.0489\n",
            "Epoch 12/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0308 - val_accuracy: 0.9479 - val_loss: 0.0489\n",
            "Epoch 13/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0309 - val_accuracy: 0.9479 - val_loss: 0.0489\n",
            "Epoch 14/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0309 - val_accuracy: 0.9479 - val_loss: 0.0490\n",
            "Epoch 15/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9689 - loss: 0.0310 - val_accuracy: 0.9479 - val_loss: 0.0490\n",
            "Epoch 16/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0311 - val_accuracy: 0.9479 - val_loss: 0.0491\n",
            "Epoch 17/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0314 - val_accuracy: 0.9479 - val_loss: 0.0490\n",
            "Epoch 18/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0313 - val_accuracy: 0.9479 - val_loss: 0.0494\n",
            "Epoch 19/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9689 - loss: 0.0317 - val_accuracy: 0.9479 - val_loss: 0.0494\n",
            "Epoch 20/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0318 - val_accuracy: 0.9479 - val_loss: 0.0497\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9555 - loss: 0.0443  \n",
            "[VALID] acc=0.948 | sens=0.125 (k=3/24, CI95=[0.043,0.310]) vs base 0.375 p=0.9772\n",
            "[TEST ] sens=0.000 (k=0/23, CI95=[0.000,0.143]) vs base 0.087 p=0.9259\n",
            "The years trained:  ['Year_2024']\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.9609 - loss: 0.2001 - val_accuracy: 0.9479 - val_loss: 0.0808\n",
            "Epoch 2/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0435 - val_accuracy: 0.9479 - val_loss: 0.0593\n",
            "Epoch 3/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9689 - loss: 0.0390 - val_accuracy: 0.9479 - val_loss: 0.0512\n",
            "Epoch 4/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0321 - val_accuracy: 0.9479 - val_loss: 0.0508\n",
            "Epoch 5/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0308 - val_accuracy: 0.9479 - val_loss: 0.0511\n",
            "Epoch 6/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0325 - val_accuracy: 0.9479 - val_loss: 0.0507\n",
            "Epoch 7/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0318 - val_accuracy: 0.9479 - val_loss: 0.0504\n",
            "Epoch 8/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0317 - val_accuracy: 0.9479 - val_loss: 0.0502\n",
            "Epoch 9/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0317 - val_accuracy: 0.9479 - val_loss: 0.0501\n",
            "Epoch 10/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9689 - loss: 0.0316 - val_accuracy: 0.9479 - val_loss: 0.0500\n",
            "Epoch 11/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0316 - val_accuracy: 0.9479 - val_loss: 0.0500\n",
            "Epoch 12/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0316 - val_accuracy: 0.9479 - val_loss: 0.0499\n",
            "Epoch 13/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0316 - val_accuracy: 0.9479 - val_loss: 0.0499\n",
            "Epoch 14/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0316 - val_accuracy: 0.9479 - val_loss: 0.0499\n",
            "Epoch 15/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9689 - loss: 0.0317 - val_accuracy: 0.9479 - val_loss: 0.0499\n",
            "Epoch 16/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0317 - val_accuracy: 0.9479 - val_loss: 0.0500\n",
            "Epoch 17/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9689 - loss: 0.0317 - val_accuracy: 0.9479 - val_loss: 0.0500\n",
            "Epoch 18/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0318 - val_accuracy: 0.9479 - val_loss: 0.0501\n",
            "Epoch 19/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9689 - loss: 0.0318 - val_accuracy: 0.9479 - val_loss: 0.0503\n",
            "Epoch 20/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9689 - loss: 0.0320 - val_accuracy: 0.9479 - val_loss: 0.0505\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9555 - loss: 0.0442  \n",
            "[VALID] acc=0.948 | sens=0.125 (k=3/24, CI95=[0.043,0.310]) vs base 0.375 p=0.9772\n",
            "[TEST ] sens=0.174 (k=4/23, CI95=[0.070,0.371]) vs base 0.087 p=0.1906\n",
            "The years trained:  ['Year_2024']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - accuracy: 0.7413 - loss: 0.3032 - val_accuracy: 0.9479 - val_loss: 0.1018\n",
            "Epoch 2/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9689 - loss: 0.0663 - val_accuracy: 0.9479 - val_loss: 0.0579\n",
            "Epoch 3/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0349 - val_accuracy: 0.9479 - val_loss: 0.0514\n",
            "Epoch 4/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0374 - val_accuracy: 0.9479 - val_loss: 0.0542\n",
            "Epoch 5/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0324 - val_accuracy: 0.9479 - val_loss: 0.0503\n",
            "Epoch 6/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0338 - val_accuracy: 0.9479 - val_loss: 0.0508\n",
            "Epoch 7/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0317 - val_accuracy: 0.9479 - val_loss: 0.0499\n",
            "Epoch 8/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0325 - val_accuracy: 0.9479 - val_loss: 0.0498\n",
            "Epoch 9/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0324 - val_accuracy: 0.9479 - val_loss: 0.0497\n",
            "Epoch 10/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9689 - loss: 0.0322 - val_accuracy: 0.9479 - val_loss: 0.0499\n",
            "Epoch 11/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0324 - val_accuracy: 0.9479 - val_loss: 0.0506\n",
            "Epoch 12/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0333 - val_accuracy: 0.9479 - val_loss: 0.0513\n",
            "Epoch 13/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0337 - val_accuracy: 0.9479 - val_loss: 0.0521\n",
            "Epoch 14/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0341 - val_accuracy: 0.9479 - val_loss: 0.0535\n",
            "Epoch 15/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0347 - val_accuracy: 0.9479 - val_loss: 0.0549\n",
            "Epoch 16/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0350 - val_accuracy: 0.9479 - val_loss: 0.0555\n",
            "Epoch 17/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0347 - val_accuracy: 0.9479 - val_loss: 0.0559\n",
            "Epoch 18/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0345 - val_accuracy: 0.9479 - val_loss: 0.0546\n",
            "Epoch 19/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0330 - val_accuracy: 0.9479 - val_loss: 0.0554\n",
            "Epoch 20/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0330 - val_accuracy: 0.9479 - val_loss: 0.0557\n",
            "Epoch 21/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0329 - val_accuracy: 0.9479 - val_loss: 0.0564\n",
            "Epoch 22/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0328 - val_accuracy: 0.9479 - val_loss: 0.0559\n",
            "Epoch 23/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0322 - val_accuracy: 0.9479 - val_loss: 0.0558\n",
            "Epoch 24/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0318 - val_accuracy: 0.9479 - val_loss: 0.0559\n",
            "Epoch 25/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0316 - val_accuracy: 0.9479 - val_loss: 0.0552\n",
            "Epoch 26/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9689 - loss: 0.0310 - val_accuracy: 0.9479 - val_loss: 0.0550\n",
            "Epoch 27/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0307 - val_accuracy: 0.9479 - val_loss: 0.0540\n",
            "Epoch 28/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0297 - val_accuracy: 0.9479 - val_loss: 0.0540\n",
            "Epoch 29/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0300 - val_accuracy: 0.9479 - val_loss: 0.0553\n",
            "Epoch 30/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0303 - val_accuracy: 0.9479 - val_loss: 0.0540\n",
            "Epoch 31/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0294 - val_accuracy: 0.9479 - val_loss: 0.0541\n",
            "Epoch 32/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9689 - loss: 0.0293 - val_accuracy: 0.9479 - val_loss: 0.0536\n",
            "Epoch 33/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0287 - val_accuracy: 0.9479 - val_loss: 0.0539\n",
            "Epoch 34/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0290 - val_accuracy: 0.9479 - val_loss: 0.0540\n",
            "Epoch 35/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0292 - val_accuracy: 0.9479 - val_loss: 0.0523\n",
            "Epoch 36/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0275 - val_accuracy: 0.9479 - val_loss: 0.0537\n",
            "Epoch 37/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9689 - loss: 0.0285 - val_accuracy: 0.9479 - val_loss: 0.0537\n",
            "Epoch 38/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0284 - val_accuracy: 0.9479 - val_loss: 0.0530\n",
            "Epoch 39/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0278 - val_accuracy: 0.9479 - val_loss: 0.0536\n",
            "Epoch 40/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0282 - val_accuracy: 0.9479 - val_loss: 0.0530\n",
            "Epoch 41/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0277 - val_accuracy: 0.9479 - val_loss: 0.0532\n",
            "Epoch 42/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0278 - val_accuracy: 0.9479 - val_loss: 0.0526\n",
            "Epoch 43/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0274 - val_accuracy: 0.9479 - val_loss: 0.0525\n",
            "Epoch 44/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9689 - loss: 0.0274 - val_accuracy: 0.9479 - val_loss: 0.0522\n",
            "Epoch 45/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0272 - val_accuracy: 0.9479 - val_loss: 0.0527\n",
            "Epoch 46/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0274 - val_accuracy: 0.9479 - val_loss: 0.0514\n",
            "Epoch 47/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0268 - val_accuracy: 0.9479 - val_loss: 0.0522\n",
            "Epoch 48/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0271 - val_accuracy: 0.9479 - val_loss: 0.0520\n",
            "Epoch 49/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9689 - loss: 0.0268 - val_accuracy: 0.9479 - val_loss: 0.0529\n",
            "Epoch 50/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9689 - loss: 0.0275 - val_accuracy: 0.9479 - val_loss: 0.0512\n",
            "Epoch 51/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9689 - loss: 0.0262 - val_accuracy: 0.9479 - val_loss: 0.0521\n",
            "Epoch 52/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9689 - loss: 0.0266 - val_accuracy: 0.9479 - val_loss: 0.0518\n",
            "Epoch 53/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0266 - val_accuracy: 0.9479 - val_loss: 0.0518\n",
            "Epoch 54/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0263 - val_accuracy: 0.9479 - val_loss: 0.0516\n",
            "Epoch 55/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0263 - val_accuracy: 0.9479 - val_loss: 0.0517\n",
            "Epoch 56/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9689 - loss: 0.0265 - val_accuracy: 0.9479 - val_loss: 0.0504\n",
            "Epoch 57/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0256 - val_accuracy: 0.9479 - val_loss: 0.0521\n",
            "Epoch 58/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0265 - val_accuracy: 0.9479 - val_loss: 0.0505\n",
            "Epoch 59/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0261 - val_accuracy: 0.9479 - val_loss: 0.0512\n",
            "Epoch 60/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0256 - val_accuracy: 0.9479 - val_loss: 0.0510\n",
            "Epoch 61/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0261 - val_accuracy: 0.9479 - val_loss: 0.0506\n",
            "Epoch 62/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0255 - val_accuracy: 0.9479 - val_loss: 0.0510\n",
            "Epoch 63/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0258 - val_accuracy: 0.9479 - val_loss: 0.0501\n",
            "Epoch 64/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0249 - val_accuracy: 0.9479 - val_loss: 0.0513\n",
            "Epoch 65/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9689 - loss: 0.0259 - val_accuracy: 0.9479 - val_loss: 0.0493\n",
            "Epoch 66/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9689 - loss: 0.0248 - val_accuracy: 0.9479 - val_loss: 0.0511\n",
            "Epoch 67/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9689 - loss: 0.0257 - val_accuracy: 0.9479 - val_loss: 0.0499\n",
            "Epoch 68/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9689 - loss: 0.0249 - val_accuracy: 0.9479 - val_loss: 0.0498\n",
            "Epoch 69/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9693 - loss: 0.0246 - val_accuracy: 0.9479 - val_loss: 0.0494\n",
            "Epoch 70/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9693 - loss: 0.0248 - val_accuracy: 0.9479 - val_loss: 0.0508\n",
            "Epoch 71/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9693 - loss: 0.0247 - val_accuracy: 0.9479 - val_loss: 0.0501\n",
            "Epoch 72/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9693 - loss: 0.0248 - val_accuracy: 0.9479 - val_loss: 0.0500\n",
            "Epoch 73/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9693 - loss: 0.0246 - val_accuracy: 0.9479 - val_loss: 0.0497\n",
            "Epoch 74/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9693 - loss: 0.0244 - val_accuracy: 0.9479 - val_loss: 0.0495\n",
            "Epoch 75/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9693 - loss: 0.0239 - val_accuracy: 0.9375 - val_loss: 0.0499\n",
            "Epoch 76/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9715 - loss: 0.0240 - val_accuracy: 0.9479 - val_loss: 0.0496\n",
            "Epoch 77/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9693 - loss: 0.0239 - val_accuracy: 0.9375 - val_loss: 0.0502\n",
            "Epoch 78/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9715 - loss: 0.0240 - val_accuracy: 0.9479 - val_loss: 0.0495\n",
            "Epoch 79/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9693 - loss: 0.0235 - val_accuracy: 0.9375 - val_loss: 0.0512\n",
            "Epoch 80/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9715 - loss: 0.0244 - val_accuracy: 0.9479 - val_loss: 0.0493\n",
            "Epoch 81/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9733 - loss: 0.0237 - val_accuracy: 0.9375 - val_loss: 0.0504\n",
            "Epoch 82/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9715 - loss: 0.0249 - val_accuracy: 0.9271 - val_loss: 0.0500\n",
            "Epoch 83/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9733 - loss: 0.0235 - val_accuracy: 0.9375 - val_loss: 0.0501\n",
            "Epoch 84/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9715 - loss: 0.0236 - val_accuracy: 0.9271 - val_loss: 0.0500\n",
            "Epoch 85/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9733 - loss: 0.0234 - val_accuracy: 0.9271 - val_loss: 0.0501\n",
            "Epoch 86/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9733 - loss: 0.0233 - val_accuracy: 0.9271 - val_loss: 0.0517\n",
            "Epoch 87/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9715 - loss: 0.0239 - val_accuracy: 0.9375 - val_loss: 0.0504\n",
            "Epoch 88/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9733 - loss: 0.0240 - val_accuracy: 0.9271 - val_loss: 0.0504\n",
            "Epoch 89/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9733 - loss: 0.0235 - val_accuracy: 0.9375 - val_loss: 0.0500\n",
            "Epoch 90/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9733 - loss: 0.0231 - val_accuracy: 0.9167 - val_loss: 0.0515\n",
            "Epoch 91/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9733 - loss: 0.0239 - val_accuracy: 0.9271 - val_loss: 0.0501\n",
            "Epoch 92/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9733 - loss: 0.0232 - val_accuracy: 0.9271 - val_loss: 0.0511\n",
            "Epoch 93/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9733 - loss: 0.0235 - val_accuracy: 0.9271 - val_loss: 0.0500\n",
            "Epoch 94/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9733 - loss: 0.0228 - val_accuracy: 0.9271 - val_loss: 0.0527\n",
            "Epoch 95/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9733 - loss: 0.0240 - val_accuracy: 0.9271 - val_loss: 0.0504\n",
            "Epoch 96/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9733 - loss: 0.0229 - val_accuracy: 0.9271 - val_loss: 0.0537\n",
            "Epoch 97/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9733 - loss: 0.0246 - val_accuracy: 0.9375 - val_loss: 0.0514\n",
            "Epoch 98/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9733 - loss: 0.0237 - val_accuracy: 0.9375 - val_loss: 0.0537\n",
            "Epoch 99/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9733 - loss: 0.0246 - val_accuracy: 0.9271 - val_loss: 0.0544\n",
            "Epoch 100/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9733 - loss: 0.0247 - val_accuracy: 0.9271 - val_loss: 0.0553\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9555 - loss: 0.0536  \n",
            "[VALID] acc=0.927 | sens=0.167 (k=4/24, CI95=[0.067,0.359]) vs base 0.375 p=0.9478\n",
            "[TEST ] sens=0.087 (k=2/23, CI95=[0.024,0.268]) vs base 0.087 p=0.5000\n",
            "The years trained:  ['Year_2024']\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 0.7544 - loss: 0.1626 - val_accuracy: 0.9479 - val_loss: 0.0531\n",
            "Epoch 2/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9689 - loss: 0.0390 - val_accuracy: 0.9479 - val_loss: 0.0549\n",
            "Epoch 3/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0306 - val_accuracy: 0.9479 - val_loss: 0.0500\n",
            "Epoch 4/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0319 - val_accuracy: 0.9479 - val_loss: 0.0515\n",
            "Epoch 5/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9689 - loss: 0.0310 - val_accuracy: 0.9479 - val_loss: 0.0506\n",
            "Epoch 6/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9689 - loss: 0.0311 - val_accuracy: 0.9479 - val_loss: 0.0508\n",
            "Epoch 7/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9689 - loss: 0.0307 - val_accuracy: 0.9479 - val_loss: 0.0501\n",
            "Epoch 8/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9689 - loss: 0.0310 - val_accuracy: 0.9479 - val_loss: 0.0502\n",
            "Epoch 9/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9689 - loss: 0.0313 - val_accuracy: 0.9479 - val_loss: 0.0503\n",
            "Epoch 10/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0315 - val_accuracy: 0.9479 - val_loss: 0.0501\n",
            "Epoch 11/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0320 - val_accuracy: 0.9479 - val_loss: 0.0494\n",
            "Epoch 12/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0335 - val_accuracy: 0.9479 - val_loss: 0.0487\n",
            "Epoch 13/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9689 - loss: 0.0359 - val_accuracy: 0.9479 - val_loss: 0.0531\n",
            "Epoch 14/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9689 - loss: 0.0407 - val_accuracy: 0.9479 - val_loss: 0.0634\n",
            "Epoch 15/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9689 - loss: 0.0442 - val_accuracy: 0.9479 - val_loss: 0.0542\n",
            "Epoch 16/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9689 - loss: 0.0389 - val_accuracy: 0.9479 - val_loss: 0.0509\n",
            "Epoch 17/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9689 - loss: 0.0291 - val_accuracy: 0.9479 - val_loss: 0.0509\n",
            "Epoch 18/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9689 - loss: 0.0338 - val_accuracy: 0.9479 - val_loss: 0.0505\n",
            "Epoch 19/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9689 - loss: 0.0341 - val_accuracy: 0.9479 - val_loss: 0.0489\n",
            "Epoch 20/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9689 - loss: 0.0299 - val_accuracy: 0.9479 - val_loss: 0.0490\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9555 - loss: 0.0407  \n",
            "[VALID] acc=0.948 | sens=0.125 (k=3/24, CI95=[0.043,0.310]) vs base 0.375 p=0.9772\n",
            "[TEST ] sens=0.087 (k=2/23, CI95=[0.024,0.268]) vs base 0.087 p=0.5000\n",
            "The years trained:  ['Year_2024']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.8408 - loss: 0.6720 - val_accuracy: 0.9479 - val_loss: 0.0641\n",
            "Epoch 2/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9689 - loss: 0.0416 - val_accuracy: 0.9479 - val_loss: 0.0558\n",
            "Epoch 3/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0302 - val_accuracy: 0.9479 - val_loss: 0.0497\n",
            "Epoch 4/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0316 - val_accuracy: 0.9479 - val_loss: 0.0497\n",
            "Epoch 5/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9689 - loss: 0.0327 - val_accuracy: 0.9479 - val_loss: 0.0498\n",
            "Epoch 6/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0337 - val_accuracy: 0.9479 - val_loss: 0.0508\n",
            "Epoch 7/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9689 - loss: 0.0350 - val_accuracy: 0.9479 - val_loss: 0.0524\n",
            "Epoch 8/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9689 - loss: 0.0362 - val_accuracy: 0.9479 - val_loss: 0.0538\n",
            "Epoch 9/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0372 - val_accuracy: 0.9479 - val_loss: 0.0544\n",
            "Epoch 10/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0375 - val_accuracy: 0.9479 - val_loss: 0.0538\n",
            "Epoch 11/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9689 - loss: 0.0371 - val_accuracy: 0.9479 - val_loss: 0.0527\n",
            "Epoch 12/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0362 - val_accuracy: 0.9479 - val_loss: 0.0519\n",
            "Epoch 13/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0354 - val_accuracy: 0.9479 - val_loss: 0.0515\n",
            "Epoch 14/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0350 - val_accuracy: 0.9479 - val_loss: 0.0514\n",
            "Epoch 15/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0348 - val_accuracy: 0.9479 - val_loss: 0.0514\n",
            "Epoch 16/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0349 - val_accuracy: 0.9479 - val_loss: 0.0515\n",
            "Epoch 17/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0350 - val_accuracy: 0.9479 - val_loss: 0.0516\n",
            "Epoch 18/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9689 - loss: 0.0350 - val_accuracy: 0.9479 - val_loss: 0.0517\n",
            "Epoch 19/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0351 - val_accuracy: 0.9479 - val_loss: 0.0518\n",
            "Epoch 20/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9689 - loss: 0.0352 - val_accuracy: 0.9479 - val_loss: 0.0518\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9555 - loss: 0.0469  \n",
            "[VALID] acc=0.948 | sens=0.125 (k=3/24, CI95=[0.043,0.310]) vs base 0.375 p=0.9772\n",
            "[TEST ] sens=0.000 (k=0/23, CI95=[0.000,0.143]) vs base 0.087 p=0.9259\n",
            "The years trained:  ['Year_2024']\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.6820 - loss: 0.3159 - val_accuracy: 0.8438 - val_loss: 0.1231\n",
            "Epoch 2/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9123 - loss: 0.0769 - val_accuracy: 0.8438 - val_loss: 0.0949\n",
            "Epoch 3/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9309 - loss: 0.0555 - val_accuracy: 0.9479 - val_loss: 0.0590\n",
            "Epoch 4/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9689 - loss: 0.0342 - val_accuracy: 0.9479 - val_loss: 0.0518\n",
            "Epoch 5/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9689 - loss: 0.0338 - val_accuracy: 0.9479 - val_loss: 0.0528\n",
            "Epoch 6/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9689 - loss: 0.0323 - val_accuracy: 0.9479 - val_loss: 0.0508\n",
            "Epoch 7/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9689 - loss: 0.0323 - val_accuracy: 0.9479 - val_loss: 0.0502\n",
            "Epoch 8/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9689 - loss: 0.0330 - val_accuracy: 0.9479 - val_loss: 0.0518\n",
            "Epoch 9/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9689 - loss: 0.0344 - val_accuracy: 0.9479 - val_loss: 0.0547\n",
            "Epoch 10/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9689 - loss: 0.0363 - val_accuracy: 0.9479 - val_loss: 0.0534\n",
            "Epoch 11/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9689 - loss: 0.0359 - val_accuracy: 0.9479 - val_loss: 0.0510\n",
            "Epoch 12/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9689 - loss: 0.0332 - val_accuracy: 0.9479 - val_loss: 0.0500\n",
            "Epoch 13/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9689 - loss: 0.0315 - val_accuracy: 0.9479 - val_loss: 0.0497\n",
            "Epoch 14/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0317 - val_accuracy: 0.9479 - val_loss: 0.0506\n",
            "Epoch 15/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0327 - val_accuracy: 0.9479 - val_loss: 0.0521\n",
            "Epoch 16/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0341 - val_accuracy: 0.9479 - val_loss: 0.0519\n",
            "Epoch 17/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0342 - val_accuracy: 0.9479 - val_loss: 0.0500\n",
            "Epoch 18/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0322 - val_accuracy: 0.9479 - val_loss: 0.0496\n",
            "Epoch 19/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0310 - val_accuracy: 0.9479 - val_loss: 0.0505\n",
            "Epoch 20/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9689 - loss: 0.0321 - val_accuracy: 0.9479 - val_loss: 0.0518\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9555 - loss: 0.0488  \n",
            "[VALID] acc=0.948 | sens=0.125 (k=3/24, CI95=[0.043,0.310]) vs base 0.375 p=0.9772\n",
            "[TEST ] sens=0.043 (k=1/23, CI95=[0.008,0.210]) vs base 0.087 p=0.7248\n",
            "The years trained:  ['Year_2024']\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 64ms/step - accuracy: 0.7544 - loss: 0.1626 - val_accuracy: 0.9479 - val_loss: 0.0531\n",
            "Epoch 2/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9689 - loss: 0.0390 - val_accuracy: 0.9479 - val_loss: 0.0549\n",
            "Epoch 3/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9689 - loss: 0.0306 - val_accuracy: 0.9479 - val_loss: 0.0500\n",
            "Epoch 4/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9689 - loss: 0.0319 - val_accuracy: 0.9479 - val_loss: 0.0515\n",
            "Epoch 5/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9689 - loss: 0.0310 - val_accuracy: 0.9479 - val_loss: 0.0506\n",
            "Epoch 6/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9689 - loss: 0.0311 - val_accuracy: 0.9479 - val_loss: 0.0508\n",
            "Epoch 7/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9689 - loss: 0.0307 - val_accuracy: 0.9479 - val_loss: 0.0501\n",
            "Epoch 8/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9689 - loss: 0.0310 - val_accuracy: 0.9479 - val_loss: 0.0502\n",
            "Epoch 9/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9689 - loss: 0.0313 - val_accuracy: 0.9479 - val_loss: 0.0503\n",
            "Epoch 10/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9689 - loss: 0.0315 - val_accuracy: 0.9479 - val_loss: 0.0501\n",
            "Epoch 11/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9689 - loss: 0.0320 - val_accuracy: 0.9479 - val_loss: 0.0494\n",
            "Epoch 12/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9689 - loss: 0.0335 - val_accuracy: 0.9479 - val_loss: 0.0487\n",
            "Epoch 13/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9689 - loss: 0.0359 - val_accuracy: 0.9479 - val_loss: 0.0531\n",
            "Epoch 14/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9689 - loss: 0.0407 - val_accuracy: 0.9479 - val_loss: 0.0634\n",
            "Epoch 15/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9689 - loss: 0.0442 - val_accuracy: 0.9479 - val_loss: 0.0542\n",
            "Epoch 16/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9689 - loss: 0.0389 - val_accuracy: 0.9479 - val_loss: 0.0509\n",
            "Epoch 17/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9689 - loss: 0.0291 - val_accuracy: 0.9479 - val_loss: 0.0509\n",
            "Epoch 18/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9689 - loss: 0.0338 - val_accuracy: 0.9479 - val_loss: 0.0505\n",
            "Epoch 19/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9689 - loss: 0.0341 - val_accuracy: 0.9479 - val_loss: 0.0489\n",
            "Epoch 20/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9689 - loss: 0.0299 - val_accuracy: 0.9479 - val_loss: 0.0490\n",
            "Epoch 21/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9689 - loss: 0.0293 - val_accuracy: 0.9479 - val_loss: 0.0496\n",
            "Epoch 22/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9689 - loss: 0.0301 - val_accuracy: 0.9479 - val_loss: 0.0498\n",
            "Epoch 23/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9689 - loss: 0.0299 - val_accuracy: 0.9479 - val_loss: 0.0498\n",
            "Epoch 24/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9689 - loss: 0.0294 - val_accuracy: 0.9479 - val_loss: 0.0506\n",
            "Epoch 25/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9689 - loss: 0.0295 - val_accuracy: 0.9479 - val_loss: 0.0509\n",
            "Epoch 26/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9689 - loss: 0.0294 - val_accuracy: 0.9479 - val_loss: 0.0505\n",
            "Epoch 27/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9689 - loss: 0.0283 - val_accuracy: 0.9479 - val_loss: 0.0528\n",
            "Epoch 28/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9689 - loss: 0.0285 - val_accuracy: 0.9479 - val_loss: 0.0550\n",
            "Epoch 29/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9689 - loss: 0.0308 - val_accuracy: 0.9479 - val_loss: 0.0561\n",
            "Epoch 30/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9689 - loss: 0.0322 - val_accuracy: 0.9479 - val_loss: 0.0514\n",
            "Epoch 31/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9689 - loss: 0.0277 - val_accuracy: 0.9479 - val_loss: 0.0519\n",
            "Epoch 32/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9689 - loss: 0.0264 - val_accuracy: 0.9479 - val_loss: 0.0535\n",
            "Epoch 33/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9689 - loss: 0.0280 - val_accuracy: 0.9479 - val_loss: 0.0543\n",
            "Epoch 34/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9689 - loss: 0.0286 - val_accuracy: 0.9479 - val_loss: 0.0537\n",
            "Epoch 35/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9689 - loss: 0.0285 - val_accuracy: 0.9479 - val_loss: 0.0556\n",
            "Epoch 36/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9689 - loss: 0.0298 - val_accuracy: 0.9479 - val_loss: 0.0532\n",
            "Epoch 37/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9689 - loss: 0.0273 - val_accuracy: 0.9479 - val_loss: 0.0533\n",
            "Epoch 38/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9689 - loss: 0.0264 - val_accuracy: 0.9479 - val_loss: 0.0534\n",
            "Epoch 39/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9689 - loss: 0.0268 - val_accuracy: 0.9479 - val_loss: 0.0543\n",
            "Epoch 40/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9689 - loss: 0.0267 - val_accuracy: 0.9479 - val_loss: 0.0544\n",
            "Epoch 41/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9689 - loss: 0.0264 - val_accuracy: 0.9479 - val_loss: 0.0550\n",
            "Epoch 42/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9689 - loss: 0.0268 - val_accuracy: 0.9479 - val_loss: 0.0544\n",
            "Epoch 43/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9689 - loss: 0.0263 - val_accuracy: 0.9479 - val_loss: 0.0551\n",
            "Epoch 44/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9689 - loss: 0.0267 - val_accuracy: 0.9479 - val_loss: 0.0545\n",
            "Epoch 45/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9689 - loss: 0.0263 - val_accuracy: 0.9479 - val_loss: 0.0547\n",
            "Epoch 46/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9689 - loss: 0.0264 - val_accuracy: 0.9479 - val_loss: 0.0548\n",
            "Epoch 47/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9689 - loss: 0.0261 - val_accuracy: 0.9479 - val_loss: 0.0550\n",
            "Epoch 48/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9689 - loss: 0.0261 - val_accuracy: 0.9479 - val_loss: 0.0558\n",
            "Epoch 49/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9689 - loss: 0.0265 - val_accuracy: 0.9479 - val_loss: 0.0557\n",
            "Epoch 50/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9675 - loss: 0.0261 - val_accuracy: 0.9479 - val_loss: 0.0559\n",
            "Epoch 51/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9675 - loss: 0.0262 - val_accuracy: 0.9479 - val_loss: 0.0569\n",
            "Epoch 52/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9675 - loss: 0.0264 - val_accuracy: 0.9479 - val_loss: 0.0568\n",
            "Epoch 53/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9675 - loss: 0.0264 - val_accuracy: 0.9479 - val_loss: 0.0565\n",
            "Epoch 54/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9683 - loss: 0.0263 - val_accuracy: 0.9271 - val_loss: 0.0582\n",
            "Epoch 55/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9689 - loss: 0.0276 - val_accuracy: 0.9271 - val_loss: 0.0631\n",
            "Epoch 56/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9636 - loss: 0.0295 - val_accuracy: 0.9479 - val_loss: 0.0562\n",
            "Epoch 57/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9689 - loss: 0.0269 - val_accuracy: 0.9375 - val_loss: 0.0567\n",
            "Epoch 58/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9683 - loss: 0.0275 - val_accuracy: 0.9375 - val_loss: 0.0563\n",
            "Epoch 59/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9683 - loss: 0.0279 - val_accuracy: 0.8958 - val_loss: 0.0641\n",
            "Epoch 60/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9630 - loss: 0.0309 - val_accuracy: 0.8958 - val_loss: 0.0653\n",
            "Epoch 61/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9636 - loss: 0.0320 - val_accuracy: 0.9479 - val_loss: 0.0526\n",
            "Epoch 62/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9683 - loss: 0.0286 - val_accuracy: 0.9062 - val_loss: 0.0701\n",
            "Epoch 63/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9636 - loss: 0.0316 - val_accuracy: 0.9479 - val_loss: 0.0586\n",
            "Epoch 64/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9689 - loss: 0.0299 - val_accuracy: 0.8958 - val_loss: 0.0720\n",
            "Epoch 65/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9636 - loss: 0.0336 - val_accuracy: 0.9479 - val_loss: 0.0513\n",
            "Epoch 66/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9689 - loss: 0.0250 - val_accuracy: 0.9062 - val_loss: 0.0651\n",
            "Epoch 67/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9636 - loss: 0.0291 - val_accuracy: 0.9062 - val_loss: 0.0659\n",
            "Epoch 68/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9681 - loss: 0.0321 - val_accuracy: 0.8958 - val_loss: 0.0729\n",
            "Epoch 69/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9669 - loss: 0.0352 - val_accuracy: 0.9479 - val_loss: 0.0500\n",
            "Epoch 70/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9689 - loss: 0.0256 - val_accuracy: 0.9062 - val_loss: 0.0647\n",
            "Epoch 71/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9636 - loss: 0.0315 - val_accuracy: 0.9479 - val_loss: 0.0576\n",
            "Epoch 72/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9689 - loss: 0.0293 - val_accuracy: 0.9479 - val_loss: 0.0558\n",
            "Epoch 73/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9677 - loss: 0.0286 - val_accuracy: 0.9479 - val_loss: 0.0546\n",
            "Epoch 74/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9689 - loss: 0.0263 - val_accuracy: 0.9479 - val_loss: 0.0544\n",
            "Epoch 75/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9689 - loss: 0.0253 - val_accuracy: 0.9479 - val_loss: 0.0572\n",
            "Epoch 76/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9689 - loss: 0.0259 - val_accuracy: 0.9167 - val_loss: 0.0604\n",
            "Epoch 77/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9669 - loss: 0.0274 - val_accuracy: 0.9479 - val_loss: 0.0565\n",
            "Epoch 78/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9711 - loss: 0.0254 - val_accuracy: 0.9479 - val_loss: 0.0574\n",
            "Epoch 79/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9711 - loss: 0.0251 - val_accuracy: 0.9167 - val_loss: 0.0601\n",
            "Epoch 80/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9784 - loss: 0.0257 - val_accuracy: 0.9167 - val_loss: 0.0606\n",
            "Epoch 81/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9743 - loss: 0.0261 - val_accuracy: 0.9375 - val_loss: 0.0590\n",
            "Epoch 82/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9784 - loss: 0.0258 - val_accuracy: 0.9375 - val_loss: 0.0579\n",
            "Epoch 83/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9743 - loss: 0.0246 - val_accuracy: 0.9062 - val_loss: 0.0628\n",
            "Epoch 84/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9743 - loss: 0.0256 - val_accuracy: 0.9062 - val_loss: 0.0638\n",
            "Epoch 85/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9743 - loss: 0.0267 - val_accuracy: 0.9375 - val_loss: 0.0604\n",
            "Epoch 86/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9784 - loss: 0.0256 - val_accuracy: 0.9375 - val_loss: 0.0602\n",
            "Epoch 87/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9743 - loss: 0.0245 - val_accuracy: 0.9062 - val_loss: 0.0637\n",
            "Epoch 88/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9784 - loss: 0.0248 - val_accuracy: 0.9062 - val_loss: 0.0655\n",
            "Epoch 89/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9743 - loss: 0.0256 - val_accuracy: 0.9062 - val_loss: 0.0645\n",
            "Epoch 90/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9743 - loss: 0.0254 - val_accuracy: 0.9167 - val_loss: 0.0633\n",
            "Epoch 91/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9784 - loss: 0.0248 - val_accuracy: 0.9167 - val_loss: 0.0638\n",
            "Epoch 92/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9788 - loss: 0.0239 - val_accuracy: 0.8958 - val_loss: 0.0700\n",
            "Epoch 93/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9747 - loss: 0.0252 - val_accuracy: 0.8958 - val_loss: 0.0715\n",
            "Epoch 94/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9747 - loss: 0.0257 - val_accuracy: 0.8958 - val_loss: 0.0712\n",
            "Epoch 95/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9711 - loss: 0.0258 - val_accuracy: 0.9167 - val_loss: 0.0643\n",
            "Epoch 96/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9784 - loss: 0.0243 - val_accuracy: 0.9167 - val_loss: 0.0655\n",
            "Epoch 97/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9788 - loss: 0.0237 - val_accuracy: 0.8958 - val_loss: 0.0716\n",
            "Epoch 98/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9788 - loss: 0.0237 - val_accuracy: 0.8958 - val_loss: 0.0784\n",
            "Epoch 99/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9747 - loss: 0.0242 - val_accuracy: 0.8854 - val_loss: 0.0922\n",
            "Epoch 100/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9726 - loss: 0.0250 - val_accuracy: 0.8542 - val_loss: 0.1188\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9068 - loss: 0.0755\n",
            "[VALID] acc=0.854 | sens=0.125 (k=3/24, CI95=[0.043,0.310]) vs base 0.375 p=0.9772\n",
            "[TEST ] sens=0.130 (k=3/23, CI95=[0.045,0.321]) vs base 0.087 p=0.3179\n",
            "The years trained:  ['Year_2024']\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.8322 - loss: 0.2056 - val_accuracy: 0.9479 - val_loss: 0.0534\n",
            "Epoch 2/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9689 - loss: 0.0392 - val_accuracy: 0.9479 - val_loss: 0.0534\n",
            "Epoch 3/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0389 - val_accuracy: 0.9479 - val_loss: 0.0533\n",
            "Epoch 4/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0387 - val_accuracy: 0.9479 - val_loss: 0.0532\n",
            "Epoch 5/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0385 - val_accuracy: 0.9479 - val_loss: 0.0531\n",
            "Epoch 6/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0383 - val_accuracy: 0.9479 - val_loss: 0.0531\n",
            "Epoch 7/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0382 - val_accuracy: 0.9479 - val_loss: 0.0530\n",
            "Epoch 8/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9689 - loss: 0.0380 - val_accuracy: 0.9479 - val_loss: 0.0530\n",
            "Epoch 9/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9689 - loss: 0.0379 - val_accuracy: 0.9479 - val_loss: 0.0529\n",
            "Epoch 10/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9689 - loss: 0.0378 - val_accuracy: 0.9479 - val_loss: 0.0528\n",
            "Epoch 11/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0377 - val_accuracy: 0.9479 - val_loss: 0.0527\n",
            "Epoch 12/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9689 - loss: 0.0375 - val_accuracy: 0.9479 - val_loss: 0.0527\n",
            "Epoch 13/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9689 - loss: 0.0374 - val_accuracy: 0.9479 - val_loss: 0.0526\n",
            "Epoch 14/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0373 - val_accuracy: 0.9479 - val_loss: 0.0526\n",
            "Epoch 15/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9689 - loss: 0.0372 - val_accuracy: 0.9479 - val_loss: 0.0525\n",
            "Epoch 16/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0372 - val_accuracy: 0.9479 - val_loss: 0.0525\n",
            "Epoch 17/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0371 - val_accuracy: 0.9479 - val_loss: 0.0524\n",
            "Epoch 18/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9689 - loss: 0.0370 - val_accuracy: 0.9479 - val_loss: 0.0523\n",
            "Epoch 19/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0369 - val_accuracy: 0.9479 - val_loss: 0.0523\n",
            "Epoch 20/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9689 - loss: 0.0369 - val_accuracy: 0.9479 - val_loss: 0.0522\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9555 - loss: 0.0427  \n",
            "[VALID] acc=0.948 | sens=0.000 (k=0/24, CI95=[0.000,0.138]) vs base 0.375 p=0.9996\n",
            "[TEST ] sens=0.087 (k=2/23, CI95=[0.024,0.268]) vs base 0.087 p=0.5000\n",
            "The years trained:  ['Year_2024']\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9689 - loss: 0.0956 - val_accuracy: 0.9479 - val_loss: 0.0514\n",
            "Epoch 2/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0367 - val_accuracy: 0.9479 - val_loss: 0.0510\n",
            "Epoch 3/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0357 - val_accuracy: 0.9479 - val_loss: 0.0508\n",
            "Epoch 4/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9689 - loss: 0.0350 - val_accuracy: 0.9479 - val_loss: 0.0507\n",
            "Epoch 5/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9689 - loss: 0.0346 - val_accuracy: 0.9479 - val_loss: 0.0507\n",
            "Epoch 6/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9689 - loss: 0.0342 - val_accuracy: 0.9479 - val_loss: 0.0506\n",
            "Epoch 7/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9689 - loss: 0.0340 - val_accuracy: 0.9479 - val_loss: 0.0506\n",
            "Epoch 8/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9689 - loss: 0.0338 - val_accuracy: 0.9479 - val_loss: 0.0506\n",
            "Epoch 9/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9689 - loss: 0.0337 - val_accuracy: 0.9479 - val_loss: 0.0506\n",
            "Epoch 10/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9689 - loss: 0.0335 - val_accuracy: 0.9479 - val_loss: 0.0506\n",
            "Epoch 11/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9689 - loss: 0.0334 - val_accuracy: 0.9479 - val_loss: 0.0506\n",
            "Epoch 12/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9689 - loss: 0.0334 - val_accuracy: 0.9479 - val_loss: 0.0506\n",
            "Epoch 13/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9689 - loss: 0.0333 - val_accuracy: 0.9479 - val_loss: 0.0506\n",
            "Epoch 14/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9689 - loss: 0.0332 - val_accuracy: 0.9479 - val_loss: 0.0506\n",
            "Epoch 15/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0331 - val_accuracy: 0.9479 - val_loss: 0.0505\n",
            "Epoch 16/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0331 - val_accuracy: 0.9479 - val_loss: 0.0505\n",
            "Epoch 17/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9689 - loss: 0.0330 - val_accuracy: 0.9479 - val_loss: 0.0505\n",
            "Epoch 18/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9689 - loss: 0.0329 - val_accuracy: 0.9479 - val_loss: 0.0504\n",
            "Epoch 19/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0329 - val_accuracy: 0.9479 - val_loss: 0.0504\n",
            "Epoch 20/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9689 - loss: 0.0328 - val_accuracy: 0.9479 - val_loss: 0.0503\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9555 - loss: 0.0448  \n",
            "[VALID] acc=0.948 | sens=0.042 (k=1/24, CI95=[0.007,0.202]) vs base 0.375 p=0.9978\n",
            "[TEST ] sens=0.000 (k=0/23, CI95=[0.000,0.143]) vs base 0.087 p=0.9259\n",
            "The years trained:  ['Year_2024']\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9689 - loss: 0.2234 - val_accuracy: 0.9479 - val_loss: 0.0635\n",
            "Epoch 2/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9689 - loss: 0.0398 - val_accuracy: 0.9479 - val_loss: 0.0627\n",
            "Epoch 3/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9689 - loss: 0.0400 - val_accuracy: 0.9479 - val_loss: 0.0623\n",
            "Epoch 4/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0396 - val_accuracy: 0.9479 - val_loss: 0.0618\n",
            "Epoch 5/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9689 - loss: 0.0393 - val_accuracy: 0.9479 - val_loss: 0.0614\n",
            "Epoch 6/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0390 - val_accuracy: 0.9479 - val_loss: 0.0611\n",
            "Epoch 7/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0387 - val_accuracy: 0.9479 - val_loss: 0.0607\n",
            "Epoch 8/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0385 - val_accuracy: 0.9479 - val_loss: 0.0604\n",
            "Epoch 9/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9689 - loss: 0.0382 - val_accuracy: 0.9479 - val_loss: 0.0600\n",
            "Epoch 10/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9689 - loss: 0.0380 - val_accuracy: 0.9479 - val_loss: 0.0597\n",
            "Epoch 11/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9689 - loss: 0.0377 - val_accuracy: 0.9479 - val_loss: 0.0595\n",
            "Epoch 12/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0375 - val_accuracy: 0.9479 - val_loss: 0.0592\n",
            "Epoch 13/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0373 - val_accuracy: 0.9479 - val_loss: 0.0589\n",
            "Epoch 14/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0371 - val_accuracy: 0.9479 - val_loss: 0.0587\n",
            "Epoch 15/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0369 - val_accuracy: 0.9479 - val_loss: 0.0584\n",
            "Epoch 16/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0368 - val_accuracy: 0.9479 - val_loss: 0.0582\n",
            "Epoch 17/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9689 - loss: 0.0366 - val_accuracy: 0.9479 - val_loss: 0.0580\n",
            "Epoch 18/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9689 - loss: 0.0364 - val_accuracy: 0.9479 - val_loss: 0.0578\n",
            "Epoch 19/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9689 - loss: 0.0363 - val_accuracy: 0.9479 - val_loss: 0.0576\n",
            "Epoch 20/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9689 - loss: 0.0361 - val_accuracy: 0.9479 - val_loss: 0.0574\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9555 - loss: 0.0496  \n",
            "[VALID] acc=0.948 | sens=0.042 (k=1/24, CI95=[0.007,0.202]) vs base 0.375 p=0.9978\n",
            "[TEST ] sens=0.174 (k=4/23, CI95=[0.070,0.371]) vs base 0.087 p=0.1906\n",
            "The years trained:  ['Year_2024']\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 56ms/step - accuracy: 0.9689 - loss: 0.2234 - val_accuracy: 0.9479 - val_loss: 0.0635\n",
            "Epoch 2/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9689 - loss: 0.0398 - val_accuracy: 0.9479 - val_loss: 0.0627\n",
            "Epoch 3/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9689 - loss: 0.0400 - val_accuracy: 0.9479 - val_loss: 0.0623\n",
            "Epoch 4/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9689 - loss: 0.0396 - val_accuracy: 0.9479 - val_loss: 0.0618\n",
            "Epoch 5/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9689 - loss: 0.0393 - val_accuracy: 0.9479 - val_loss: 0.0614\n",
            "Epoch 6/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9689 - loss: 0.0390 - val_accuracy: 0.9479 - val_loss: 0.0611\n",
            "Epoch 7/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9689 - loss: 0.0387 - val_accuracy: 0.9479 - val_loss: 0.0607\n",
            "Epoch 8/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9689 - loss: 0.0385 - val_accuracy: 0.9479 - val_loss: 0.0604\n",
            "Epoch 9/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9689 - loss: 0.0382 - val_accuracy: 0.9479 - val_loss: 0.0600\n",
            "Epoch 10/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9689 - loss: 0.0380 - val_accuracy: 0.9479 - val_loss: 0.0597\n",
            "Epoch 11/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9689 - loss: 0.0377 - val_accuracy: 0.9479 - val_loss: 0.0595\n",
            "Epoch 12/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9689 - loss: 0.0375 - val_accuracy: 0.9479 - val_loss: 0.0592\n",
            "Epoch 13/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9689 - loss: 0.0373 - val_accuracy: 0.9479 - val_loss: 0.0589\n",
            "Epoch 14/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9689 - loss: 0.0371 - val_accuracy: 0.9479 - val_loss: 0.0587\n",
            "Epoch 15/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9689 - loss: 0.0369 - val_accuracy: 0.9479 - val_loss: 0.0584\n",
            "Epoch 16/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9689 - loss: 0.0368 - val_accuracy: 0.9479 - val_loss: 0.0582\n",
            "Epoch 17/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9689 - loss: 0.0366 - val_accuracy: 0.9479 - val_loss: 0.0580\n",
            "Epoch 18/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9689 - loss: 0.0364 - val_accuracy: 0.9479 - val_loss: 0.0578\n",
            "Epoch 19/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9689 - loss: 0.0363 - val_accuracy: 0.9479 - val_loss: 0.0576\n",
            "Epoch 20/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9689 - loss: 0.0361 - val_accuracy: 0.9479 - val_loss: 0.0574\n",
            "Epoch 21/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9689 - loss: 0.0360 - val_accuracy: 0.9479 - val_loss: 0.0572\n",
            "Epoch 22/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9689 - loss: 0.0359 - val_accuracy: 0.9479 - val_loss: 0.0570\n",
            "Epoch 23/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9689 - loss: 0.0357 - val_accuracy: 0.9479 - val_loss: 0.0568\n",
            "Epoch 24/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0356 - val_accuracy: 0.9479 - val_loss: 0.0567\n",
            "Epoch 25/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9689 - loss: 0.0355 - val_accuracy: 0.9479 - val_loss: 0.0565\n",
            "Epoch 26/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9689 - loss: 0.0354 - val_accuracy: 0.9479 - val_loss: 0.0564\n",
            "Epoch 27/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0353 - val_accuracy: 0.9479 - val_loss: 0.0562\n",
            "Epoch 28/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9689 - loss: 0.0352 - val_accuracy: 0.9479 - val_loss: 0.0561\n",
            "Epoch 29/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9689 - loss: 0.0351 - val_accuracy: 0.9479 - val_loss: 0.0559\n",
            "Epoch 30/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0350 - val_accuracy: 0.9479 - val_loss: 0.0558\n",
            "Epoch 31/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0349 - val_accuracy: 0.9479 - val_loss: 0.0557\n",
            "Epoch 32/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0348 - val_accuracy: 0.9479 - val_loss: 0.0555\n",
            "Epoch 33/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9689 - loss: 0.0347 - val_accuracy: 0.9479 - val_loss: 0.0554\n",
            "Epoch 34/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9689 - loss: 0.0346 - val_accuracy: 0.9479 - val_loss: 0.0553\n",
            "Epoch 35/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9689 - loss: 0.0346 - val_accuracy: 0.9479 - val_loss: 0.0552\n",
            "Epoch 36/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9689 - loss: 0.0345 - val_accuracy: 0.9479 - val_loss: 0.0551\n",
            "Epoch 37/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9689 - loss: 0.0344 - val_accuracy: 0.9479 - val_loss: 0.0550\n",
            "Epoch 38/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9689 - loss: 0.0343 - val_accuracy: 0.9479 - val_loss: 0.0549\n",
            "Epoch 39/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9689 - loss: 0.0343 - val_accuracy: 0.9479 - val_loss: 0.0548\n",
            "Epoch 40/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9689 - loss: 0.0342 - val_accuracy: 0.9479 - val_loss: 0.0547\n",
            "Epoch 41/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9689 - loss: 0.0341 - val_accuracy: 0.9479 - val_loss: 0.0546\n",
            "Epoch 42/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9689 - loss: 0.0341 - val_accuracy: 0.9479 - val_loss: 0.0545\n",
            "Epoch 43/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9689 - loss: 0.0340 - val_accuracy: 0.9479 - val_loss: 0.0544\n",
            "Epoch 44/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9689 - loss: 0.0340 - val_accuracy: 0.9479 - val_loss: 0.0543\n",
            "Epoch 45/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9689 - loss: 0.0339 - val_accuracy: 0.9479 - val_loss: 0.0542\n",
            "Epoch 46/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9689 - loss: 0.0339 - val_accuracy: 0.9479 - val_loss: 0.0541\n",
            "Epoch 47/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9689 - loss: 0.0338 - val_accuracy: 0.9479 - val_loss: 0.0541\n",
            "Epoch 48/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9689 - loss: 0.0338 - val_accuracy: 0.9479 - val_loss: 0.0540\n",
            "Epoch 49/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9689 - loss: 0.0337 - val_accuracy: 0.9479 - val_loss: 0.0539\n",
            "Epoch 50/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9689 - loss: 0.0337 - val_accuracy: 0.9479 - val_loss: 0.0538\n",
            "Epoch 51/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9689 - loss: 0.0336 - val_accuracy: 0.9479 - val_loss: 0.0537\n",
            "Epoch 52/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9689 - loss: 0.0336 - val_accuracy: 0.9479 - val_loss: 0.0537\n",
            "Epoch 53/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9689 - loss: 0.0335 - val_accuracy: 0.9479 - val_loss: 0.0536\n",
            "Epoch 54/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9689 - loss: 0.0335 - val_accuracy: 0.9479 - val_loss: 0.0535\n",
            "Epoch 55/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9689 - loss: 0.0334 - val_accuracy: 0.9479 - val_loss: 0.0535\n",
            "Epoch 56/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9689 - loss: 0.0334 - val_accuracy: 0.9479 - val_loss: 0.0534\n",
            "Epoch 57/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9689 - loss: 0.0334 - val_accuracy: 0.9479 - val_loss: 0.0534\n",
            "Epoch 58/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9689 - loss: 0.0333 - val_accuracy: 0.9479 - val_loss: 0.0533\n",
            "Epoch 59/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9689 - loss: 0.0333 - val_accuracy: 0.9479 - val_loss: 0.0532\n",
            "Epoch 60/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9689 - loss: 0.0332 - val_accuracy: 0.9479 - val_loss: 0.0532\n",
            "Epoch 61/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0332 - val_accuracy: 0.9479 - val_loss: 0.0531\n",
            "Epoch 62/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9689 - loss: 0.0332 - val_accuracy: 0.9479 - val_loss: 0.0531\n",
            "Epoch 63/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0331 - val_accuracy: 0.9479 - val_loss: 0.0530\n",
            "Epoch 64/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9689 - loss: 0.0331 - val_accuracy: 0.9479 - val_loss: 0.0530\n",
            "Epoch 65/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0331 - val_accuracy: 0.9479 - val_loss: 0.0529\n",
            "Epoch 66/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0330 - val_accuracy: 0.9479 - val_loss: 0.0528\n",
            "Epoch 67/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0330 - val_accuracy: 0.9479 - val_loss: 0.0528\n",
            "Epoch 68/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9689 - loss: 0.0330 - val_accuracy: 0.9479 - val_loss: 0.0527\n",
            "Epoch 69/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9689 - loss: 0.0329 - val_accuracy: 0.9479 - val_loss: 0.0527\n",
            "Epoch 70/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9689 - loss: 0.0329 - val_accuracy: 0.9479 - val_loss: 0.0527\n",
            "Epoch 71/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0329 - val_accuracy: 0.9479 - val_loss: 0.0526\n",
            "Epoch 72/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0329 - val_accuracy: 0.9479 - val_loss: 0.0526\n",
            "Epoch 73/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0328 - val_accuracy: 0.9479 - val_loss: 0.0525\n",
            "Epoch 74/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0328 - val_accuracy: 0.9479 - val_loss: 0.0525\n",
            "Epoch 75/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0328 - val_accuracy: 0.9479 - val_loss: 0.0524\n",
            "Epoch 76/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0327 - val_accuracy: 0.9479 - val_loss: 0.0524\n",
            "Epoch 77/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0327 - val_accuracy: 0.9479 - val_loss: 0.0523\n",
            "Epoch 78/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9689 - loss: 0.0327 - val_accuracy: 0.9479 - val_loss: 0.0523\n",
            "Epoch 79/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0327 - val_accuracy: 0.9479 - val_loss: 0.0523\n",
            "Epoch 80/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0326 - val_accuracy: 0.9479 - val_loss: 0.0522\n",
            "Epoch 81/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0326 - val_accuracy: 0.9479 - val_loss: 0.0522\n",
            "Epoch 82/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0326 - val_accuracy: 0.9479 - val_loss: 0.0521\n",
            "Epoch 83/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0326 - val_accuracy: 0.9479 - val_loss: 0.0521\n",
            "Epoch 84/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0326 - val_accuracy: 0.9479 - val_loss: 0.0521\n",
            "Epoch 85/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0325 - val_accuracy: 0.9479 - val_loss: 0.0520\n",
            "Epoch 86/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0325 - val_accuracy: 0.9479 - val_loss: 0.0520\n",
            "Epoch 87/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0325 - val_accuracy: 0.9479 - val_loss: 0.0520\n",
            "Epoch 88/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0325 - val_accuracy: 0.9479 - val_loss: 0.0519\n",
            "Epoch 89/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9689 - loss: 0.0324 - val_accuracy: 0.9479 - val_loss: 0.0519\n",
            "Epoch 90/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0324 - val_accuracy: 0.9479 - val_loss: 0.0518\n",
            "Epoch 91/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0324 - val_accuracy: 0.9479 - val_loss: 0.0518\n",
            "Epoch 92/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0324 - val_accuracy: 0.9479 - val_loss: 0.0518\n",
            "Epoch 93/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0324 - val_accuracy: 0.9479 - val_loss: 0.0518\n",
            "Epoch 94/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0324 - val_accuracy: 0.9479 - val_loss: 0.0517\n",
            "Epoch 95/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0323 - val_accuracy: 0.9479 - val_loss: 0.0517\n",
            "Epoch 96/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0323 - val_accuracy: 0.9479 - val_loss: 0.0517\n",
            "Epoch 97/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0323 - val_accuracy: 0.9479 - val_loss: 0.0516\n",
            "Epoch 98/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0323 - val_accuracy: 0.9479 - val_loss: 0.0516\n",
            "Epoch 99/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9689 - loss: 0.0323 - val_accuracy: 0.9479 - val_loss: 0.0516\n",
            "Epoch 100/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0322 - val_accuracy: 0.9479 - val_loss: 0.0515\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9555 - loss: 0.0443  \n",
            "[VALID] acc=0.948 | sens=0.000 (k=0/24, CI95=[0.000,0.138]) vs base 0.375 p=0.9996\n",
            "[TEST ] sens=0.217 (k=5/23, CI95=[0.097,0.419]) vs base 0.087 p=0.1091\n",
            "The years trained:  ['Year_2024']\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.8322 - loss: 0.2056 - val_accuracy: 0.9479 - val_loss: 0.0534\n",
            "Epoch 2/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9689 - loss: 0.0392 - val_accuracy: 0.9479 - val_loss: 0.0534\n",
            "Epoch 3/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9689 - loss: 0.0389 - val_accuracy: 0.9479 - val_loss: 0.0533\n",
            "Epoch 4/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9689 - loss: 0.0387 - val_accuracy: 0.9479 - val_loss: 0.0532\n",
            "Epoch 5/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9689 - loss: 0.0385 - val_accuracy: 0.9479 - val_loss: 0.0531\n",
            "Epoch 6/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9689 - loss: 0.0383 - val_accuracy: 0.9479 - val_loss: 0.0531\n",
            "Epoch 7/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9689 - loss: 0.0382 - val_accuracy: 0.9479 - val_loss: 0.0530\n",
            "Epoch 8/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9689 - loss: 0.0380 - val_accuracy: 0.9479 - val_loss: 0.0530\n",
            "Epoch 9/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9689 - loss: 0.0379 - val_accuracy: 0.9479 - val_loss: 0.0529\n",
            "Epoch 10/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0378 - val_accuracy: 0.9479 - val_loss: 0.0528\n",
            "Epoch 11/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0377 - val_accuracy: 0.9479 - val_loss: 0.0527\n",
            "Epoch 12/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9689 - loss: 0.0375 - val_accuracy: 0.9479 - val_loss: 0.0527\n",
            "Epoch 13/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9689 - loss: 0.0374 - val_accuracy: 0.9479 - val_loss: 0.0526\n",
            "Epoch 14/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9689 - loss: 0.0373 - val_accuracy: 0.9479 - val_loss: 0.0526\n",
            "Epoch 15/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9689 - loss: 0.0372 - val_accuracy: 0.9479 - val_loss: 0.0525\n",
            "Epoch 16/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0372 - val_accuracy: 0.9479 - val_loss: 0.0525\n",
            "Epoch 17/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0371 - val_accuracy: 0.9479 - val_loss: 0.0524\n",
            "Epoch 18/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9689 - loss: 0.0370 - val_accuracy: 0.9479 - val_loss: 0.0523\n",
            "Epoch 19/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9689 - loss: 0.0369 - val_accuracy: 0.9479 - val_loss: 0.0523\n",
            "Epoch 20/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0369 - val_accuracy: 0.9479 - val_loss: 0.0522\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9555 - loss: 0.0427  \n",
            "[VALID] acc=0.948 | sens=0.000 (k=0/24, CI95=[0.000,0.138]) vs base 0.375 p=0.9996\n",
            "[TEST ] sens=0.087 (k=2/23, CI95=[0.024,0.268]) vs base 0.087 p=0.5000\n",
            "The years trained:  ['Year_2024']\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.9689 - loss: 0.0956 - val_accuracy: 0.9479 - val_loss: 0.0514\n",
            "Epoch 2/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0367 - val_accuracy: 0.9479 - val_loss: 0.0510\n",
            "Epoch 3/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0357 - val_accuracy: 0.9479 - val_loss: 0.0508\n",
            "Epoch 4/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9689 - loss: 0.0350 - val_accuracy: 0.9479 - val_loss: 0.0507\n",
            "Epoch 5/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0346 - val_accuracy: 0.9479 - val_loss: 0.0507\n",
            "Epoch 6/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0342 - val_accuracy: 0.9479 - val_loss: 0.0506\n",
            "Epoch 7/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0340 - val_accuracy: 0.9479 - val_loss: 0.0506\n",
            "Epoch 8/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0338 - val_accuracy: 0.9479 - val_loss: 0.0506\n",
            "Epoch 9/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9689 - loss: 0.0337 - val_accuracy: 0.9479 - val_loss: 0.0506\n",
            "Epoch 10/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0335 - val_accuracy: 0.9479 - val_loss: 0.0506\n",
            "Epoch 11/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9689 - loss: 0.0334 - val_accuracy: 0.9479 - val_loss: 0.0506\n",
            "Epoch 12/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0334 - val_accuracy: 0.9479 - val_loss: 0.0506\n",
            "Epoch 13/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0333 - val_accuracy: 0.9479 - val_loss: 0.0506\n",
            "Epoch 14/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0332 - val_accuracy: 0.9479 - val_loss: 0.0506\n",
            "Epoch 15/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0331 - val_accuracy: 0.9479 - val_loss: 0.0505\n",
            "Epoch 16/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0331 - val_accuracy: 0.9479 - val_loss: 0.0505\n",
            "Epoch 17/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0330 - val_accuracy: 0.9479 - val_loss: 0.0505\n",
            "Epoch 18/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9689 - loss: 0.0329 - val_accuracy: 0.9479 - val_loss: 0.0504\n",
            "Epoch 19/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0329 - val_accuracy: 0.9479 - val_loss: 0.0504\n",
            "Epoch 20/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0328 - val_accuracy: 0.9479 - val_loss: 0.0503\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9555 - loss: 0.0448  \n",
            "[VALID] acc=0.948 | sens=0.042 (k=1/24, CI95=[0.007,0.202]) vs base 0.375 p=0.9978\n",
            "[TEST ] sens=0.000 (k=0/23, CI95=[0.000,0.143]) vs base 0.087 p=0.9259\n",
            "The years trained:  ['Year_2024']\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.9689 - loss: 0.2234 - val_accuracy: 0.9479 - val_loss: 0.0635\n",
            "Epoch 2/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9689 - loss: 0.0398 - val_accuracy: 0.9479 - val_loss: 0.0627\n",
            "Epoch 3/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9689 - loss: 0.0400 - val_accuracy: 0.9479 - val_loss: 0.0623\n",
            "Epoch 4/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9689 - loss: 0.0396 - val_accuracy: 0.9479 - val_loss: 0.0618\n",
            "Epoch 5/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9689 - loss: 0.0393 - val_accuracy: 0.9479 - val_loss: 0.0614\n",
            "Epoch 6/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9689 - loss: 0.0390 - val_accuracy: 0.9479 - val_loss: 0.0611\n",
            "Epoch 7/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9689 - loss: 0.0387 - val_accuracy: 0.9479 - val_loss: 0.0607\n",
            "Epoch 8/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9689 - loss: 0.0385 - val_accuracy: 0.9479 - val_loss: 0.0604\n",
            "Epoch 9/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9689 - loss: 0.0382 - val_accuracy: 0.9479 - val_loss: 0.0600\n",
            "Epoch 10/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9689 - loss: 0.0380 - val_accuracy: 0.9479 - val_loss: 0.0597\n",
            "Epoch 11/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0377 - val_accuracy: 0.9479 - val_loss: 0.0595\n",
            "Epoch 12/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9689 - loss: 0.0375 - val_accuracy: 0.9479 - val_loss: 0.0592\n",
            "Epoch 13/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0373 - val_accuracy: 0.9479 - val_loss: 0.0589\n",
            "Epoch 14/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0371 - val_accuracy: 0.9479 - val_loss: 0.0587\n",
            "Epoch 15/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0369 - val_accuracy: 0.9479 - val_loss: 0.0584\n",
            "Epoch 16/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0368 - val_accuracy: 0.9479 - val_loss: 0.0582\n",
            "Epoch 17/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0366 - val_accuracy: 0.9479 - val_loss: 0.0580\n",
            "Epoch 18/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9689 - loss: 0.0364 - val_accuracy: 0.9479 - val_loss: 0.0578\n",
            "Epoch 19/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0363 - val_accuracy: 0.9479 - val_loss: 0.0576\n",
            "Epoch 20/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0361 - val_accuracy: 0.9479 - val_loss: 0.0574\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9555 - loss: 0.0496  \n",
            "[VALID] acc=0.948 | sens=0.042 (k=1/24, CI95=[0.007,0.202]) vs base 0.375 p=0.9978\n",
            "[TEST ] sens=0.174 (k=4/23, CI95=[0.070,0.371]) vs base 0.087 p=0.1906\n",
            "The years trained:  ['Year_2024']\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9689 - loss: 0.2234 - val_accuracy: 0.9479 - val_loss: 0.0635\n",
            "Epoch 2/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0398 - val_accuracy: 0.9479 - val_loss: 0.0627\n",
            "Epoch 3/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0400 - val_accuracy: 0.9479 - val_loss: 0.0623\n",
            "Epoch 4/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0396 - val_accuracy: 0.9479 - val_loss: 0.0618\n",
            "Epoch 5/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0393 - val_accuracy: 0.9479 - val_loss: 0.0614\n",
            "Epoch 6/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0390 - val_accuracy: 0.9479 - val_loss: 0.0611\n",
            "Epoch 7/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0387 - val_accuracy: 0.9479 - val_loss: 0.0607\n",
            "Epoch 8/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0385 - val_accuracy: 0.9479 - val_loss: 0.0604\n",
            "Epoch 9/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0382 - val_accuracy: 0.9479 - val_loss: 0.0600\n",
            "Epoch 10/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9689 - loss: 0.0380 - val_accuracy: 0.9479 - val_loss: 0.0597\n",
            "Epoch 11/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0377 - val_accuracy: 0.9479 - val_loss: 0.0595\n",
            "Epoch 12/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0375 - val_accuracy: 0.9479 - val_loss: 0.0592\n",
            "Epoch 13/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0373 - val_accuracy: 0.9479 - val_loss: 0.0589\n",
            "Epoch 14/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0371 - val_accuracy: 0.9479 - val_loss: 0.0587\n",
            "Epoch 15/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0369 - val_accuracy: 0.9479 - val_loss: 0.0584\n",
            "Epoch 16/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9689 - loss: 0.0368 - val_accuracy: 0.9479 - val_loss: 0.0582\n",
            "Epoch 17/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0366 - val_accuracy: 0.9479 - val_loss: 0.0580\n",
            "Epoch 18/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0364 - val_accuracy: 0.9479 - val_loss: 0.0578\n",
            "Epoch 19/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0363 - val_accuracy: 0.9479 - val_loss: 0.0576\n",
            "Epoch 20/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0361 - val_accuracy: 0.9479 - val_loss: 0.0574\n",
            "Epoch 21/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0360 - val_accuracy: 0.9479 - val_loss: 0.0572\n",
            "Epoch 22/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9689 - loss: 0.0359 - val_accuracy: 0.9479 - val_loss: 0.0570\n",
            "Epoch 23/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9689 - loss: 0.0357 - val_accuracy: 0.9479 - val_loss: 0.0568\n",
            "Epoch 24/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0356 - val_accuracy: 0.9479 - val_loss: 0.0567\n",
            "Epoch 25/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0355 - val_accuracy: 0.9479 - val_loss: 0.0565\n",
            "Epoch 26/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0354 - val_accuracy: 0.9479 - val_loss: 0.0564\n",
            "Epoch 27/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0353 - val_accuracy: 0.9479 - val_loss: 0.0562\n",
            "Epoch 28/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9689 - loss: 0.0352 - val_accuracy: 0.9479 - val_loss: 0.0561\n",
            "Epoch 29/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0351 - val_accuracy: 0.9479 - val_loss: 0.0559\n",
            "Epoch 30/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0350 - val_accuracy: 0.9479 - val_loss: 0.0558\n",
            "Epoch 31/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0349 - val_accuracy: 0.9479 - val_loss: 0.0557\n",
            "Epoch 32/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0348 - val_accuracy: 0.9479 - val_loss: 0.0555\n",
            "Epoch 33/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0347 - val_accuracy: 0.9479 - val_loss: 0.0554\n",
            "Epoch 34/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0346 - val_accuracy: 0.9479 - val_loss: 0.0553\n",
            "Epoch 35/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0346 - val_accuracy: 0.9479 - val_loss: 0.0552\n",
            "Epoch 36/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9689 - loss: 0.0345 - val_accuracy: 0.9479 - val_loss: 0.0551\n",
            "Epoch 37/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9689 - loss: 0.0344 - val_accuracy: 0.9479 - val_loss: 0.0550\n",
            "Epoch 38/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9689 - loss: 0.0343 - val_accuracy: 0.9479 - val_loss: 0.0549\n",
            "Epoch 39/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9689 - loss: 0.0343 - val_accuracy: 0.9479 - val_loss: 0.0548\n",
            "Epoch 40/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9689 - loss: 0.0342 - val_accuracy: 0.9479 - val_loss: 0.0547\n",
            "Epoch 41/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9689 - loss: 0.0341 - val_accuracy: 0.9479 - val_loss: 0.0546\n",
            "Epoch 42/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9689 - loss: 0.0341 - val_accuracy: 0.9479 - val_loss: 0.0545\n",
            "Epoch 43/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9689 - loss: 0.0340 - val_accuracy: 0.9479 - val_loss: 0.0544\n",
            "Epoch 44/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9689 - loss: 0.0340 - val_accuracy: 0.9479 - val_loss: 0.0543\n",
            "Epoch 45/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9689 - loss: 0.0339 - val_accuracy: 0.9479 - val_loss: 0.0542\n",
            "Epoch 46/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9689 - loss: 0.0339 - val_accuracy: 0.9479 - val_loss: 0.0541\n",
            "Epoch 47/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9689 - loss: 0.0338 - val_accuracy: 0.9479 - val_loss: 0.0541\n",
            "Epoch 48/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9689 - loss: 0.0338 - val_accuracy: 0.9479 - val_loss: 0.0540\n",
            "Epoch 49/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0337 - val_accuracy: 0.9479 - val_loss: 0.0539\n",
            "Epoch 50/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0337 - val_accuracy: 0.9479 - val_loss: 0.0538\n",
            "Epoch 51/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0336 - val_accuracy: 0.9479 - val_loss: 0.0537\n",
            "Epoch 52/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0336 - val_accuracy: 0.9479 - val_loss: 0.0537\n",
            "Epoch 53/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0335 - val_accuracy: 0.9479 - val_loss: 0.0536\n",
            "Epoch 54/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0335 - val_accuracy: 0.9479 - val_loss: 0.0535\n",
            "Epoch 55/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9689 - loss: 0.0334 - val_accuracy: 0.9479 - val_loss: 0.0535\n",
            "Epoch 56/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0334 - val_accuracy: 0.9479 - val_loss: 0.0534\n",
            "Epoch 57/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0334 - val_accuracy: 0.9479 - val_loss: 0.0534\n",
            "Epoch 58/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0333 - val_accuracy: 0.9479 - val_loss: 0.0533\n",
            "Epoch 59/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0333 - val_accuracy: 0.9479 - val_loss: 0.0532\n",
            "Epoch 60/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0332 - val_accuracy: 0.9479 - val_loss: 0.0532\n",
            "Epoch 61/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9689 - loss: 0.0332 - val_accuracy: 0.9479 - val_loss: 0.0531\n",
            "Epoch 62/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0332 - val_accuracy: 0.9479 - val_loss: 0.0531\n",
            "Epoch 63/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0331 - val_accuracy: 0.9479 - val_loss: 0.0530\n",
            "Epoch 64/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0331 - val_accuracy: 0.9479 - val_loss: 0.0530\n",
            "Epoch 65/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0331 - val_accuracy: 0.9479 - val_loss: 0.0529\n",
            "Epoch 66/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0330 - val_accuracy: 0.9479 - val_loss: 0.0528\n",
            "Epoch 67/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0330 - val_accuracy: 0.9479 - val_loss: 0.0528\n",
            "Epoch 68/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0330 - val_accuracy: 0.9479 - val_loss: 0.0527\n",
            "Epoch 69/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0329 - val_accuracy: 0.9479 - val_loss: 0.0527\n",
            "Epoch 70/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0329 - val_accuracy: 0.9479 - val_loss: 0.0527\n",
            "Epoch 71/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0329 - val_accuracy: 0.9479 - val_loss: 0.0526\n",
            "Epoch 72/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0329 - val_accuracy: 0.9479 - val_loss: 0.0526\n",
            "Epoch 73/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0328 - val_accuracy: 0.9479 - val_loss: 0.0525\n",
            "Epoch 74/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0328 - val_accuracy: 0.9479 - val_loss: 0.0525\n",
            "Epoch 75/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0328 - val_accuracy: 0.9479 - val_loss: 0.0524\n",
            "Epoch 76/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9689 - loss: 0.0327 - val_accuracy: 0.9479 - val_loss: 0.0524\n",
            "Epoch 77/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0327 - val_accuracy: 0.9479 - val_loss: 0.0523\n",
            "Epoch 78/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0327 - val_accuracy: 0.9479 - val_loss: 0.0523\n",
            "Epoch 79/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0327 - val_accuracy: 0.9479 - val_loss: 0.0523\n",
            "Epoch 80/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0326 - val_accuracy: 0.9479 - val_loss: 0.0522\n",
            "Epoch 81/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0326 - val_accuracy: 0.9479 - val_loss: 0.0522\n",
            "Epoch 82/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9689 - loss: 0.0326 - val_accuracy: 0.9479 - val_loss: 0.0521\n",
            "Epoch 83/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0326 - val_accuracy: 0.9479 - val_loss: 0.0521\n",
            "Epoch 84/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0326 - val_accuracy: 0.9479 - val_loss: 0.0521\n",
            "Epoch 85/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0325 - val_accuracy: 0.9479 - val_loss: 0.0520\n",
            "Epoch 86/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0325 - val_accuracy: 0.9479 - val_loss: 0.0520\n",
            "Epoch 87/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0325 - val_accuracy: 0.9479 - val_loss: 0.0520\n",
            "Epoch 88/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9689 - loss: 0.0325 - val_accuracy: 0.9479 - val_loss: 0.0519\n",
            "Epoch 89/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0324 - val_accuracy: 0.9479 - val_loss: 0.0519\n",
            "Epoch 90/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0324 - val_accuracy: 0.9479 - val_loss: 0.0518\n",
            "Epoch 91/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0324 - val_accuracy: 0.9479 - val_loss: 0.0518\n",
            "Epoch 92/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0324 - val_accuracy: 0.9479 - val_loss: 0.0518\n",
            "Epoch 93/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9689 - loss: 0.0324 - val_accuracy: 0.9479 - val_loss: 0.0518\n",
            "Epoch 94/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0324 - val_accuracy: 0.9479 - val_loss: 0.0517\n",
            "Epoch 95/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0323 - val_accuracy: 0.9479 - val_loss: 0.0517\n",
            "Epoch 96/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0323 - val_accuracy: 0.9479 - val_loss: 0.0517\n",
            "Epoch 97/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0323 - val_accuracy: 0.9479 - val_loss: 0.0516\n",
            "Epoch 98/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0323 - val_accuracy: 0.9479 - val_loss: 0.0516\n",
            "Epoch 99/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0323 - val_accuracy: 0.9479 - val_loss: 0.0516\n",
            "Epoch 100/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9689 - loss: 0.0322 - val_accuracy: 0.9479 - val_loss: 0.0515\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9555 - loss: 0.0443\n",
            "[VALID] acc=0.948 | sens=0.000 (k=0/24, CI95=[0.000,0.138]) vs base 0.375 p=0.9996\n",
            "[TEST ] sens=0.217 (k=5/23, CI95=[0.097,0.419]) vs base 0.087 p=0.1091\n",
            "The years trained:  ['Year_2024']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.7544 - loss: 0.1347 - val_accuracy: 0.9479 - val_loss: 0.0500\n",
            "Epoch 2/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0313 - val_accuracy: 0.9479 - val_loss: 0.0499\n",
            "Epoch 3/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0312 - val_accuracy: 0.9479 - val_loss: 0.0500\n",
            "Epoch 4/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0312 - val_accuracy: 0.9479 - val_loss: 0.0504\n",
            "Epoch 5/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9689 - loss: 0.0315 - val_accuracy: 0.9479 - val_loss: 0.0499\n",
            "Epoch 6/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0311 - val_accuracy: 0.9479 - val_loss: 0.0498\n",
            "Epoch 7/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0310 - val_accuracy: 0.9479 - val_loss: 0.0498\n",
            "Epoch 8/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9689 - loss: 0.0309 - val_accuracy: 0.9479 - val_loss: 0.0498\n",
            "Epoch 9/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9689 - loss: 0.0310 - val_accuracy: 0.9479 - val_loss: 0.0499\n",
            "Epoch 10/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9689 - loss: 0.0310 - val_accuracy: 0.9479 - val_loss: 0.0498\n",
            "Epoch 11/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0310 - val_accuracy: 0.9479 - val_loss: 0.0499\n",
            "Epoch 12/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0310 - val_accuracy: 0.9479 - val_loss: 0.0498\n",
            "Epoch 13/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0308 - val_accuracy: 0.9479 - val_loss: 0.0498\n",
            "Epoch 14/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9689 - loss: 0.0309 - val_accuracy: 0.9479 - val_loss: 0.0498\n",
            "Epoch 15/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9689 - loss: 0.0309 - val_accuracy: 0.9479 - val_loss: 0.0498\n",
            "Epoch 16/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0308 - val_accuracy: 0.9479 - val_loss: 0.0500\n",
            "Epoch 17/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0310 - val_accuracy: 0.9479 - val_loss: 0.0498\n",
            "Epoch 18/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9689 - loss: 0.0309 - val_accuracy: 0.9479 - val_loss: 0.0498\n",
            "Epoch 19/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9689 - loss: 0.0308 - val_accuracy: 0.9479 - val_loss: 0.0499\n",
            "Epoch 20/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9689 - loss: 0.0308 - val_accuracy: 0.9479 - val_loss: 0.0498\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9555 - loss: 0.0429  \n",
            "[VALID] acc=0.948 | sens=0.125 (k=3/24, CI95=[0.043,0.310]) vs base 0.375 p=0.9772\n",
            "[TEST ] sens=0.000 (k=0/23, CI95=[0.000,0.143]) vs base 0.087 p=0.9259\n",
            "The years trained:  ['Year_2024']\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.8472 - loss: 0.2041 - val_accuracy: 0.9479 - val_loss: 0.0511\n",
            "Epoch 2/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0326 - val_accuracy: 0.9479 - val_loss: 0.0511\n",
            "Epoch 3/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9689 - loss: 0.0325 - val_accuracy: 0.9479 - val_loss: 0.0511\n",
            "Epoch 4/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9689 - loss: 0.0323 - val_accuracy: 0.9479 - val_loss: 0.0511\n",
            "Epoch 5/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9689 - loss: 0.0323 - val_accuracy: 0.9479 - val_loss: 0.0510\n",
            "Epoch 6/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0322 - val_accuracy: 0.9479 - val_loss: 0.0510\n",
            "Epoch 7/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0321 - val_accuracy: 0.9479 - val_loss: 0.0508\n",
            "Epoch 8/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0320 - val_accuracy: 0.9479 - val_loss: 0.0509\n",
            "Epoch 9/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0320 - val_accuracy: 0.9479 - val_loss: 0.0508\n",
            "Epoch 10/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0318 - val_accuracy: 0.9479 - val_loss: 0.0508\n",
            "Epoch 11/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9689 - loss: 0.0319 - val_accuracy: 0.9479 - val_loss: 0.0506\n",
            "Epoch 12/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0317 - val_accuracy: 0.9479 - val_loss: 0.0510\n",
            "Epoch 13/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9689 - loss: 0.0319 - val_accuracy: 0.9479 - val_loss: 0.0507\n",
            "Epoch 14/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0316 - val_accuracy: 0.9479 - val_loss: 0.0509\n",
            "Epoch 15/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0318 - val_accuracy: 0.9479 - val_loss: 0.0509\n",
            "Epoch 16/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0317 - val_accuracy: 0.9479 - val_loss: 0.0507\n",
            "Epoch 17/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9689 - loss: 0.0315 - val_accuracy: 0.9479 - val_loss: 0.0507\n",
            "Epoch 18/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0315 - val_accuracy: 0.9479 - val_loss: 0.0507\n",
            "Epoch 19/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9689 - loss: 0.0315 - val_accuracy: 0.9479 - val_loss: 0.0507\n",
            "Epoch 20/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9689 - loss: 0.0315 - val_accuracy: 0.9479 - val_loss: 0.0506\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9555 - loss: 0.0445\n",
            "[VALID] acc=0.948 | sens=0.042 (k=1/24, CI95=[0.007,0.202]) vs base 0.375 p=0.9978\n",
            "[TEST ] sens=0.000 (k=0/23, CI95=[0.000,0.143]) vs base 0.087 p=0.9259\n",
            "The years trained:  ['Year_2024']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.4435 - loss: 0.4000 - val_accuracy: 0.8438 - val_loss: 0.1402\n",
            "Epoch 2/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9042 - loss: 0.0913 - val_accuracy: 0.8438 - val_loss: 0.1282\n",
            "Epoch 3/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9109 - loss: 0.0828 - val_accuracy: 0.8438 - val_loss: 0.1258\n",
            "Epoch 4/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9109 - loss: 0.0810 - val_accuracy: 0.8438 - val_loss: 0.1241\n",
            "Epoch 5/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9109 - loss: 0.0798 - val_accuracy: 0.8438 - val_loss: 0.1227\n",
            "Epoch 6/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9109 - loss: 0.0787 - val_accuracy: 0.8438 - val_loss: 0.1213\n",
            "Epoch 7/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9109 - loss: 0.0778 - val_accuracy: 0.8438 - val_loss: 0.1200\n",
            "Epoch 8/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9109 - loss: 0.0768 - val_accuracy: 0.8438 - val_loss: 0.1187\n",
            "Epoch 9/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9109 - loss: 0.0759 - val_accuracy: 0.8438 - val_loss: 0.1174\n",
            "Epoch 10/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9109 - loss: 0.0750 - val_accuracy: 0.8438 - val_loss: 0.1162\n",
            "Epoch 11/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9109 - loss: 0.0741 - val_accuracy: 0.8438 - val_loss: 0.1150\n",
            "Epoch 12/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9109 - loss: 0.0733 - val_accuracy: 0.8438 - val_loss: 0.1138\n",
            "Epoch 13/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9123 - loss: 0.0724 - val_accuracy: 0.8438 - val_loss: 0.1127\n",
            "Epoch 14/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9123 - loss: 0.0716 - val_accuracy: 0.8438 - val_loss: 0.1116\n",
            "Epoch 15/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9123 - loss: 0.0709 - val_accuracy: 0.8438 - val_loss: 0.1105\n",
            "Epoch 16/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9123 - loss: 0.0701 - val_accuracy: 0.8438 - val_loss: 0.1095\n",
            "Epoch 17/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9123 - loss: 0.0694 - val_accuracy: 0.8438 - val_loss: 0.1085\n",
            "Epoch 18/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9123 - loss: 0.0687 - val_accuracy: 0.8438 - val_loss: 0.1075\n",
            "Epoch 19/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9123 - loss: 0.0680 - val_accuracy: 0.8438 - val_loss: 0.1065\n",
            "Epoch 20/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9123 - loss: 0.0674 - val_accuracy: 0.8438 - val_loss: 0.1056\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8880 - loss: 0.0847  \n",
            "[VALID] acc=0.844 | sens=0.083 (k=2/24, CI95=[0.023,0.258]) vs base 0.375 p=0.9919\n",
            "[TEST ] sens=0.000 (k=0/23, CI95=[0.000,0.143]) vs base 0.087 p=0.9259\n",
            "The years trained:  ['Year_2024']\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.7544 - loss: 0.1347 - val_accuracy: 0.9479 - val_loss: 0.0500\n",
            "Epoch 2/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0313 - val_accuracy: 0.9479 - val_loss: 0.0499\n",
            "Epoch 3/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9689 - loss: 0.0312 - val_accuracy: 0.9479 - val_loss: 0.0500\n",
            "Epoch 4/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0312 - val_accuracy: 0.9479 - val_loss: 0.0504\n",
            "Epoch 5/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9689 - loss: 0.0315 - val_accuracy: 0.9479 - val_loss: 0.0499\n",
            "Epoch 6/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9689 - loss: 0.0311 - val_accuracy: 0.9479 - val_loss: 0.0498\n",
            "Epoch 7/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9689 - loss: 0.0310 - val_accuracy: 0.9479 - val_loss: 0.0498\n",
            "Epoch 8/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9689 - loss: 0.0309 - val_accuracy: 0.9479 - val_loss: 0.0498\n",
            "Epoch 9/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0310 - val_accuracy: 0.9479 - val_loss: 0.0499\n",
            "Epoch 10/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0310 - val_accuracy: 0.9479 - val_loss: 0.0498\n",
            "Epoch 11/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0310 - val_accuracy: 0.9479 - val_loss: 0.0499\n",
            "Epoch 12/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9689 - loss: 0.0310 - val_accuracy: 0.9479 - val_loss: 0.0498\n",
            "Epoch 13/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0308 - val_accuracy: 0.9479 - val_loss: 0.0498\n",
            "Epoch 14/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0309 - val_accuracy: 0.9479 - val_loss: 0.0498\n",
            "Epoch 15/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0309 - val_accuracy: 0.9479 - val_loss: 0.0498\n",
            "Epoch 16/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9689 - loss: 0.0308 - val_accuracy: 0.9479 - val_loss: 0.0500\n",
            "Epoch 17/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9689 - loss: 0.0310 - val_accuracy: 0.9479 - val_loss: 0.0498\n",
            "Epoch 18/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9689 - loss: 0.0309 - val_accuracy: 0.9479 - val_loss: 0.0498\n",
            "Epoch 19/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9689 - loss: 0.0308 - val_accuracy: 0.9479 - val_loss: 0.0499\n",
            "Epoch 20/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9689 - loss: 0.0308 - val_accuracy: 0.9479 - val_loss: 0.0498\n",
            "Epoch 21/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9689 - loss: 0.0308 - val_accuracy: 0.9479 - val_loss: 0.0498\n",
            "Epoch 22/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9689 - loss: 0.0308 - val_accuracy: 0.9479 - val_loss: 0.0498\n",
            "Epoch 23/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9689 - loss: 0.0307 - val_accuracy: 0.9479 - val_loss: 0.0498\n",
            "Epoch 24/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9689 - loss: 0.0307 - val_accuracy: 0.9479 - val_loss: 0.0498\n",
            "Epoch 25/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9689 - loss: 0.0307 - val_accuracy: 0.9479 - val_loss: 0.0498\n",
            "Epoch 26/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9689 - loss: 0.0307 - val_accuracy: 0.9479 - val_loss: 0.0498\n",
            "Epoch 27/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9689 - loss: 0.0307 - val_accuracy: 0.9479 - val_loss: 0.0498\n",
            "Epoch 28/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9689 - loss: 0.0307 - val_accuracy: 0.9479 - val_loss: 0.0498\n",
            "Epoch 29/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9689 - loss: 0.0307 - val_accuracy: 0.9479 - val_loss: 0.0498\n",
            "Epoch 30/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0307 - val_accuracy: 0.9479 - val_loss: 0.0498\n",
            "Epoch 31/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0307 - val_accuracy: 0.9479 - val_loss: 0.0498\n",
            "Epoch 32/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0307 - val_accuracy: 0.9479 - val_loss: 0.0498\n",
            "Epoch 33/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9689 - loss: 0.0307 - val_accuracy: 0.9479 - val_loss: 0.0498\n",
            "Epoch 34/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0307 - val_accuracy: 0.9479 - val_loss: 0.0498\n",
            "Epoch 35/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0307 - val_accuracy: 0.9479 - val_loss: 0.0498\n",
            "Epoch 36/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0307 - val_accuracy: 0.9479 - val_loss: 0.0497\n",
            "Epoch 37/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9689 - loss: 0.0307 - val_accuracy: 0.9479 - val_loss: 0.0497\n",
            "Epoch 38/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0306 - val_accuracy: 0.9479 - val_loss: 0.0497\n",
            "Epoch 39/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0306 - val_accuracy: 0.9479 - val_loss: 0.0497\n",
            "Epoch 40/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0306 - val_accuracy: 0.9479 - val_loss: 0.0498\n",
            "Epoch 41/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0307 - val_accuracy: 0.9479 - val_loss: 0.0497\n",
            "Epoch 42/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9689 - loss: 0.0306 - val_accuracy: 0.9479 - val_loss: 0.0497\n",
            "Epoch 43/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0306 - val_accuracy: 0.9479 - val_loss: 0.0497\n",
            "Epoch 44/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0306 - val_accuracy: 0.9479 - val_loss: 0.0497\n",
            "Epoch 45/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0306 - val_accuracy: 0.9479 - val_loss: 0.0497\n",
            "Epoch 46/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0306 - val_accuracy: 0.9479 - val_loss: 0.0497\n",
            "Epoch 47/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0306 - val_accuracy: 0.9479 - val_loss: 0.0497\n",
            "Epoch 48/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9689 - loss: 0.0306 - val_accuracy: 0.9479 - val_loss: 0.0497\n",
            "Epoch 49/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0306 - val_accuracy: 0.9479 - val_loss: 0.0497\n",
            "Epoch 50/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0306 - val_accuracy: 0.9479 - val_loss: 0.0497\n",
            "Epoch 51/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9689 - loss: 0.0306 - val_accuracy: 0.9479 - val_loss: 0.0497\n",
            "Epoch 52/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9689 - loss: 0.0306 - val_accuracy: 0.9479 - val_loss: 0.0497\n",
            "Epoch 53/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0306 - val_accuracy: 0.9479 - val_loss: 0.0497\n",
            "Epoch 54/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0306 - val_accuracy: 0.9479 - val_loss: 0.0497\n",
            "Epoch 55/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0306 - val_accuracy: 0.9479 - val_loss: 0.0497\n",
            "Epoch 56/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0306 - val_accuracy: 0.9479 - val_loss: 0.0496\n",
            "Epoch 57/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0306 - val_accuracy: 0.9479 - val_loss: 0.0497\n",
            "Epoch 58/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9689 - loss: 0.0305 - val_accuracy: 0.9479 - val_loss: 0.0497\n",
            "Epoch 59/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0305 - val_accuracy: 0.9479 - val_loss: 0.0496\n",
            "Epoch 60/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9689 - loss: 0.0305 - val_accuracy: 0.9479 - val_loss: 0.0496\n",
            "Epoch 61/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9689 - loss: 0.0306 - val_accuracy: 0.9479 - val_loss: 0.0496\n",
            "Epoch 62/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9689 - loss: 0.0306 - val_accuracy: 0.9479 - val_loss: 0.0496\n",
            "Epoch 63/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0306 - val_accuracy: 0.9479 - val_loss: 0.0495\n",
            "Epoch 64/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9689 - loss: 0.0305 - val_accuracy: 0.9479 - val_loss: 0.0497\n",
            "Epoch 65/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9689 - loss: 0.0306 - val_accuracy: 0.9479 - val_loss: 0.0496\n",
            "Epoch 66/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9689 - loss: 0.0305 - val_accuracy: 0.9479 - val_loss: 0.0497\n",
            "Epoch 67/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9689 - loss: 0.0306 - val_accuracy: 0.9479 - val_loss: 0.0496\n",
            "Epoch 68/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0305 - val_accuracy: 0.9479 - val_loss: 0.0496\n",
            "Epoch 69/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0305 - val_accuracy: 0.9479 - val_loss: 0.0495\n",
            "Epoch 70/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9689 - loss: 0.0305 - val_accuracy: 0.9479 - val_loss: 0.0495\n",
            "Epoch 71/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0305 - val_accuracy: 0.9479 - val_loss: 0.0497\n",
            "Epoch 72/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0306 - val_accuracy: 0.9479 - val_loss: 0.0496\n",
            "Epoch 73/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0305 - val_accuracy: 0.9479 - val_loss: 0.0496\n",
            "Epoch 74/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0305 - val_accuracy: 0.9479 - val_loss: 0.0496\n",
            "Epoch 75/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9689 - loss: 0.0304 - val_accuracy: 0.9479 - val_loss: 0.0496\n",
            "Epoch 76/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9689 - loss: 0.0305 - val_accuracy: 0.9479 - val_loss: 0.0495\n",
            "Epoch 77/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9689 - loss: 0.0305 - val_accuracy: 0.9479 - val_loss: 0.0496\n",
            "Epoch 78/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9689 - loss: 0.0304 - val_accuracy: 0.9479 - val_loss: 0.0496\n",
            "Epoch 79/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9689 - loss: 0.0305 - val_accuracy: 0.9479 - val_loss: 0.0497\n",
            "Epoch 80/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9689 - loss: 0.0306 - val_accuracy: 0.9479 - val_loss: 0.0496\n",
            "Epoch 81/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9689 - loss: 0.0305 - val_accuracy: 0.9479 - val_loss: 0.0496\n",
            "Epoch 82/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9689 - loss: 0.0304 - val_accuracy: 0.9479 - val_loss: 0.0496\n",
            "Epoch 83/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9689 - loss: 0.0305 - val_accuracy: 0.9479 - val_loss: 0.0496\n",
            "Epoch 84/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9689 - loss: 0.0305 - val_accuracy: 0.9479 - val_loss: 0.0496\n",
            "Epoch 85/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9689 - loss: 0.0304 - val_accuracy: 0.9479 - val_loss: 0.0496\n",
            "Epoch 86/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9689 - loss: 0.0305 - val_accuracy: 0.9479 - val_loss: 0.0496\n",
            "Epoch 87/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9689 - loss: 0.0305 - val_accuracy: 0.9479 - val_loss: 0.0496\n",
            "Epoch 88/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9689 - loss: 0.0304 - val_accuracy: 0.9479 - val_loss: 0.0496\n",
            "Epoch 89/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9689 - loss: 0.0305 - val_accuracy: 0.9479 - val_loss: 0.0495\n",
            "Epoch 90/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9689 - loss: 0.0304 - val_accuracy: 0.9479 - val_loss: 0.0495\n",
            "Epoch 91/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0304 - val_accuracy: 0.9479 - val_loss: 0.0495\n",
            "Epoch 92/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9689 - loss: 0.0304 - val_accuracy: 0.9479 - val_loss: 0.0495\n",
            "Epoch 93/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9689 - loss: 0.0304 - val_accuracy: 0.9479 - val_loss: 0.0496\n",
            "Epoch 94/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9689 - loss: 0.0304 - val_accuracy: 0.9479 - val_loss: 0.0495\n",
            "Epoch 95/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0304 - val_accuracy: 0.9479 - val_loss: 0.0495\n",
            "Epoch 96/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9689 - loss: 0.0304 - val_accuracy: 0.9479 - val_loss: 0.0495\n",
            "Epoch 97/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0304 - val_accuracy: 0.9479 - val_loss: 0.0496\n",
            "Epoch 98/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0304 - val_accuracy: 0.9479 - val_loss: 0.0495\n",
            "Epoch 99/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0304 - val_accuracy: 0.9479 - val_loss: 0.0495\n",
            "Epoch 100/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.0304 - val_accuracy: 0.9479 - val_loss: 0.0495\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9555 - loss: 0.0424  \n",
            "[VALID] acc=0.948 | sens=0.125 (k=3/24, CI95=[0.043,0.310]) vs base 0.375 p=0.9772\n",
            "[TEST ] sens=0.000 (k=0/23, CI95=[0.000,0.143]) vs base 0.087 p=0.9259\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display2425Df.head(20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 713
        },
        "id": "S-U4YOcFlIb5",
        "outputId": "2b99fecb-9821-47a2-9be9-7a0e6af4a6cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Model Complexity  Layers  Epochs Optimizer Activation  val_accuracy  \\\n",
              "0            Simple       2      20      adam       relu      0.947917   \n",
              "1            Simple       2      20      adam       tanh      0.947917   \n",
              "2            Simple       2      20      adam    sigmoid      0.947917   \n",
              "3            Simple       2     100      adam       relu      0.927083   \n",
              "4            Medium       4      20      adam       relu      0.947917   \n",
              "5            Medium       4      20      adam       tanh      0.947917   \n",
              "6            Medium       4      20      adam    sigmoid      0.947917   \n",
              "7            Medium       4     100      adam       relu      0.927083   \n",
              "8              High       8      20      adam       relu      0.947917   \n",
              "9              High       8      20      adam       tanh      0.947917   \n",
              "10             High       8      20      adam    sigmoid      0.947917   \n",
              "11             High       8     100      adam       relu      0.854167   \n",
              "12           Simple       2      20   adagrad       relu      0.947917   \n",
              "13           Simple       2      20   adagrad       tanh      0.947917   \n",
              "14           Simple       2      20   adagrad    sigmoid      0.947917   \n",
              "15           Simple       2     100   adagrad    sigmoid      0.947917   \n",
              "16           Medium       4      20   adagrad       relu      0.947917   \n",
              "17           Medium       4      20   adagrad       tanh      0.947917   \n",
              "18           Medium       4      20   adagrad    sigmoid      0.947917   \n",
              "19           Medium       4     100   adagrad    sigmoid      0.947917   \n",
              "\n",
              "    val_sensitivity  val_ci_low  val_ci_high  test_sensitivity  test_ci_low  \\\n",
              "0          0.125000    0.043443     0.310039          0.173913     0.069787   \n",
              "1          0.125000    0.043443     0.310039          0.000000     0.000000   \n",
              "2          0.125000    0.043443     0.310039          0.173913     0.069787   \n",
              "3          0.166667    0.066787     0.358531          0.086957     0.024180   \n",
              "4          0.125000    0.043443     0.310039          0.173913     0.069787   \n",
              "5          0.125000    0.043443     0.310039          0.000000     0.000000   \n",
              "6          0.125000    0.043443     0.310039          0.173913     0.069787   \n",
              "7          0.166667    0.066787     0.358531          0.086957     0.024180   \n",
              "8          0.125000    0.043443     0.310039          0.086957     0.024180   \n",
              "9          0.125000    0.043443     0.310039          0.000000     0.000000   \n",
              "10         0.125000    0.043443     0.310039          0.043478     0.007717   \n",
              "11         0.125000    0.043443     0.310039          0.130435     0.045377   \n",
              "12         0.000000    0.000000     0.137976          0.086957     0.024180   \n",
              "13         0.041667    0.007393     0.202418          0.000000     0.000000   \n",
              "14         0.041667    0.007393     0.202418          0.173913     0.069787   \n",
              "15         0.000000    0.000000     0.137976          0.217391     0.096640   \n",
              "16         0.000000    0.000000     0.137976          0.086957     0.024180   \n",
              "17         0.041667    0.007393     0.202418          0.000000     0.000000   \n",
              "18         0.041667    0.007393     0.202418          0.173913     0.069787   \n",
              "19         0.000000    0.000000     0.137976          0.217391     0.096640   \n",
              "\n",
              "    test_ci_high  test_p_value_vs_baseline  \n",
              "0       0.371376                  0.190625  \n",
              "1       0.143117                  0.925911  \n",
              "2       0.371376                  0.190625  \n",
              "3       0.267960                  0.500000  \n",
              "4       0.371376                  0.190625  \n",
              "5       0.143117                  0.925911  \n",
              "6       0.371376                  0.190625  \n",
              "7       0.267960                  0.500000  \n",
              "8       0.267960                  0.500000  \n",
              "9       0.143117                  0.925911  \n",
              "10      0.209912                  0.724797  \n",
              "11      0.321275                  0.317857  \n",
              "12      0.267960                  0.500000  \n",
              "13      0.143117                  0.925911  \n",
              "14      0.371376                  0.190625  \n",
              "15      0.419035                  0.109076  \n",
              "16      0.267960                  0.500000  \n",
              "17      0.143117                  0.925911  \n",
              "18      0.371376                  0.190625  \n",
              "19      0.419035                  0.109076  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-82bd1a86-e085-45b8-8c62-aa3027080336\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model Complexity</th>\n",
              "      <th>Layers</th>\n",
              "      <th>Epochs</th>\n",
              "      <th>Optimizer</th>\n",
              "      <th>Activation</th>\n",
              "      <th>val_accuracy</th>\n",
              "      <th>val_sensitivity</th>\n",
              "      <th>val_ci_low</th>\n",
              "      <th>val_ci_high</th>\n",
              "      <th>test_sensitivity</th>\n",
              "      <th>test_ci_low</th>\n",
              "      <th>test_ci_high</th>\n",
              "      <th>test_p_value_vs_baseline</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Simple</td>\n",
              "      <td>2</td>\n",
              "      <td>20</td>\n",
              "      <td>adam</td>\n",
              "      <td>relu</td>\n",
              "      <td>0.947917</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.043443</td>\n",
              "      <td>0.310039</td>\n",
              "      <td>0.173913</td>\n",
              "      <td>0.069787</td>\n",
              "      <td>0.371376</td>\n",
              "      <td>0.190625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Simple</td>\n",
              "      <td>2</td>\n",
              "      <td>20</td>\n",
              "      <td>adam</td>\n",
              "      <td>tanh</td>\n",
              "      <td>0.947917</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.043443</td>\n",
              "      <td>0.310039</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.143117</td>\n",
              "      <td>0.925911</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Simple</td>\n",
              "      <td>2</td>\n",
              "      <td>20</td>\n",
              "      <td>adam</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>0.947917</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.043443</td>\n",
              "      <td>0.310039</td>\n",
              "      <td>0.173913</td>\n",
              "      <td>0.069787</td>\n",
              "      <td>0.371376</td>\n",
              "      <td>0.190625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Simple</td>\n",
              "      <td>2</td>\n",
              "      <td>100</td>\n",
              "      <td>adam</td>\n",
              "      <td>relu</td>\n",
              "      <td>0.927083</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.066787</td>\n",
              "      <td>0.358531</td>\n",
              "      <td>0.086957</td>\n",
              "      <td>0.024180</td>\n",
              "      <td>0.267960</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Medium</td>\n",
              "      <td>4</td>\n",
              "      <td>20</td>\n",
              "      <td>adam</td>\n",
              "      <td>relu</td>\n",
              "      <td>0.947917</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.043443</td>\n",
              "      <td>0.310039</td>\n",
              "      <td>0.173913</td>\n",
              "      <td>0.069787</td>\n",
              "      <td>0.371376</td>\n",
              "      <td>0.190625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Medium</td>\n",
              "      <td>4</td>\n",
              "      <td>20</td>\n",
              "      <td>adam</td>\n",
              "      <td>tanh</td>\n",
              "      <td>0.947917</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.043443</td>\n",
              "      <td>0.310039</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.143117</td>\n",
              "      <td>0.925911</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Medium</td>\n",
              "      <td>4</td>\n",
              "      <td>20</td>\n",
              "      <td>adam</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>0.947917</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.043443</td>\n",
              "      <td>0.310039</td>\n",
              "      <td>0.173913</td>\n",
              "      <td>0.069787</td>\n",
              "      <td>0.371376</td>\n",
              "      <td>0.190625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Medium</td>\n",
              "      <td>4</td>\n",
              "      <td>100</td>\n",
              "      <td>adam</td>\n",
              "      <td>relu</td>\n",
              "      <td>0.927083</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.066787</td>\n",
              "      <td>0.358531</td>\n",
              "      <td>0.086957</td>\n",
              "      <td>0.024180</td>\n",
              "      <td>0.267960</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>High</td>\n",
              "      <td>8</td>\n",
              "      <td>20</td>\n",
              "      <td>adam</td>\n",
              "      <td>relu</td>\n",
              "      <td>0.947917</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.043443</td>\n",
              "      <td>0.310039</td>\n",
              "      <td>0.086957</td>\n",
              "      <td>0.024180</td>\n",
              "      <td>0.267960</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>High</td>\n",
              "      <td>8</td>\n",
              "      <td>20</td>\n",
              "      <td>adam</td>\n",
              "      <td>tanh</td>\n",
              "      <td>0.947917</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.043443</td>\n",
              "      <td>0.310039</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.143117</td>\n",
              "      <td>0.925911</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>High</td>\n",
              "      <td>8</td>\n",
              "      <td>20</td>\n",
              "      <td>adam</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>0.947917</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.043443</td>\n",
              "      <td>0.310039</td>\n",
              "      <td>0.043478</td>\n",
              "      <td>0.007717</td>\n",
              "      <td>0.209912</td>\n",
              "      <td>0.724797</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>High</td>\n",
              "      <td>8</td>\n",
              "      <td>100</td>\n",
              "      <td>adam</td>\n",
              "      <td>relu</td>\n",
              "      <td>0.854167</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.043443</td>\n",
              "      <td>0.310039</td>\n",
              "      <td>0.130435</td>\n",
              "      <td>0.045377</td>\n",
              "      <td>0.321275</td>\n",
              "      <td>0.317857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Simple</td>\n",
              "      <td>2</td>\n",
              "      <td>20</td>\n",
              "      <td>adagrad</td>\n",
              "      <td>relu</td>\n",
              "      <td>0.947917</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.137976</td>\n",
              "      <td>0.086957</td>\n",
              "      <td>0.024180</td>\n",
              "      <td>0.267960</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Simple</td>\n",
              "      <td>2</td>\n",
              "      <td>20</td>\n",
              "      <td>adagrad</td>\n",
              "      <td>tanh</td>\n",
              "      <td>0.947917</td>\n",
              "      <td>0.041667</td>\n",
              "      <td>0.007393</td>\n",
              "      <td>0.202418</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.143117</td>\n",
              "      <td>0.925911</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Simple</td>\n",
              "      <td>2</td>\n",
              "      <td>20</td>\n",
              "      <td>adagrad</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>0.947917</td>\n",
              "      <td>0.041667</td>\n",
              "      <td>0.007393</td>\n",
              "      <td>0.202418</td>\n",
              "      <td>0.173913</td>\n",
              "      <td>0.069787</td>\n",
              "      <td>0.371376</td>\n",
              "      <td>0.190625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Simple</td>\n",
              "      <td>2</td>\n",
              "      <td>100</td>\n",
              "      <td>adagrad</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>0.947917</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.137976</td>\n",
              "      <td>0.217391</td>\n",
              "      <td>0.096640</td>\n",
              "      <td>0.419035</td>\n",
              "      <td>0.109076</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Medium</td>\n",
              "      <td>4</td>\n",
              "      <td>20</td>\n",
              "      <td>adagrad</td>\n",
              "      <td>relu</td>\n",
              "      <td>0.947917</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.137976</td>\n",
              "      <td>0.086957</td>\n",
              "      <td>0.024180</td>\n",
              "      <td>0.267960</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Medium</td>\n",
              "      <td>4</td>\n",
              "      <td>20</td>\n",
              "      <td>adagrad</td>\n",
              "      <td>tanh</td>\n",
              "      <td>0.947917</td>\n",
              "      <td>0.041667</td>\n",
              "      <td>0.007393</td>\n",
              "      <td>0.202418</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.143117</td>\n",
              "      <td>0.925911</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Medium</td>\n",
              "      <td>4</td>\n",
              "      <td>20</td>\n",
              "      <td>adagrad</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>0.947917</td>\n",
              "      <td>0.041667</td>\n",
              "      <td>0.007393</td>\n",
              "      <td>0.202418</td>\n",
              "      <td>0.173913</td>\n",
              "      <td>0.069787</td>\n",
              "      <td>0.371376</td>\n",
              "      <td>0.190625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Medium</td>\n",
              "      <td>4</td>\n",
              "      <td>100</td>\n",
              "      <td>adagrad</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>0.947917</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.137976</td>\n",
              "      <td>0.217391</td>\n",
              "      <td>0.096640</td>\n",
              "      <td>0.419035</td>\n",
              "      <td>0.109076</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-82bd1a86-e085-45b8-8c62-aa3027080336')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-82bd1a86-e085-45b8-8c62-aa3027080336 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-82bd1a86-e085-45b8-8c62-aa3027080336');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-0586cd7c-4a57-4d2c-85d7-116d87de3cf8\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0586cd7c-4a57-4d2c-85d7-116d87de3cf8')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-0586cd7c-4a57-4d2c-85d7-116d87de3cf8 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "display2425Df",
              "summary": "{\n  \"name\": \"display2425Df\",\n  \"rows\": 24,\n  \"fields\": [\n    {\n      \"column\": \"Model Complexity\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Simple\",\n          \"Medium\",\n          \"High\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Layers\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 2,\n        \"max\": 8,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          2,\n          4,\n          8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Epochs\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 35,\n        \"min\": 20,\n        \"max\": 100,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          100,\n          20\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Optimizer\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"adagrad\",\n          \"adam\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Activation\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"relu\",\n          \"tanh\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"val_accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.02806525320898999,\n        \"min\": 0.84375,\n        \"max\": 0.9479166865348816,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.9270833134651184,\n          0.84375\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"val_sensitivity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05537599302824947,\n        \"min\": 0.0,\n        \"max\": 0.16666666666666666,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.16666666666666666,\n          0.08333333333333333\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"val_ci_low\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.021944852133192815,\n        \"min\": 0.0,\n        \"max\": 0.06678676328632946,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.06678676328632946,\n          0.023158815297043348\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"val_ci_high\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.07389370114218613,\n        \"min\": 0.13797620467498026,\n        \"max\": 0.3585307064969907,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.3585307064969907,\n          0.2584880219321069\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_sensitivity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.08108737462959249,\n        \"min\": 0.0,\n        \"max\": 0.21739130434782608,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.17391304347826086,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_ci_low\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.03438934560085732,\n        \"min\": 0.0,\n        \"max\": 0.09663978026586204,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.06978653563062565,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_ci_high\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.105199462471188,\n        \"min\": 0.1431166184504269,\n        \"max\": 0.4190348301626401,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.3713764764022614,\n          0.1431166184504269\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_p_value_vs_baseline\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.33181950431434026,\n        \"min\": 0.10907620929844658,\n        \"max\": 0.9259110640518575,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.19062511254161607,\n          0.9259110640518575\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "yearsTrain = ['2023', '2024']\n",
        "yearsPredict = ['2025']\n",
        "display232425Df = createSeasonalDf(yearsTrain, yearsPredict, completed2025)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vcRVqfL7nGIG",
        "outputId": "1034afd3-9d03-4a13-a569-5417b737af77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The years trained:  ['Year_2023', 'Year_2024']\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.7771 - loss: 0.2934 - val_accuracy: 0.9402 - val_loss: 0.0661\n",
            "Epoch 2/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9491 - loss: 0.0696 - val_accuracy: 0.9402 - val_loss: 0.0582\n",
            "Epoch 3/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9491 - loss: 0.0537 - val_accuracy: 0.9402 - val_loss: 0.0599\n",
            "Epoch 4/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9491 - loss: 0.0552 - val_accuracy: 0.9402 - val_loss: 0.0615\n",
            "Epoch 5/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9491 - loss: 0.0556 - val_accuracy: 0.9402 - val_loss: 0.0677\n",
            "Epoch 6/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9491 - loss: 0.0562 - val_accuracy: 0.9402 - val_loss: 0.0709\n",
            "Epoch 7/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9491 - loss: 0.0548 - val_accuracy: 0.9402 - val_loss: 0.0576\n",
            "Epoch 8/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9491 - loss: 0.0490 - val_accuracy: 0.9402 - val_loss: 0.0514\n",
            "Epoch 9/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0453 - val_accuracy: 0.9402 - val_loss: 0.0491\n",
            "Epoch 10/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0429 - val_accuracy: 0.9402 - val_loss: 0.0466\n",
            "Epoch 11/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0411 - val_accuracy: 0.9402 - val_loss: 0.0443\n",
            "Epoch 12/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0392 - val_accuracy: 0.9402 - val_loss: 0.0428\n",
            "Epoch 13/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0376 - val_accuracy: 0.9402 - val_loss: 0.0413\n",
            "Epoch 14/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0365 - val_accuracy: 0.9402 - val_loss: 0.0400\n",
            "Epoch 15/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9507 - loss: 0.0355 - val_accuracy: 0.9348 - val_loss: 0.0390\n",
            "Epoch 16/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9516 - loss: 0.0349 - val_accuracy: 0.9348 - val_loss: 0.0381\n",
            "Epoch 17/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9598 - loss: 0.0345 - val_accuracy: 0.9402 - val_loss: 0.0374\n",
            "Epoch 18/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9636 - loss: 0.0339 - val_accuracy: 0.9511 - val_loss: 0.0372\n",
            "Epoch 19/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9697 - loss: 0.0333 - val_accuracy: 0.9565 - val_loss: 0.0368\n",
            "Epoch 20/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9655 - loss: 0.0329 - val_accuracy: 0.9565 - val_loss: 0.0366\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9279 - loss: 0.0504 \n",
            "[VALID] acc=0.957 | sens=0.304 (k=7/23, CI95=[0.156,0.509]) vs base 0.375 p=0.7321\n",
            "[TEST ] sens=0.087 (k=2/23, CI95=[0.024,0.268]) vs base 0.087 p=0.5000\n",
            "The years trained:  ['Year_2023', 'Year_2024']\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.8362 - loss: 0.1413 - val_accuracy: 0.9402 - val_loss: 0.0614\n",
            "Epoch 2/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0514 - val_accuracy: 0.9402 - val_loss: 0.0555\n",
            "Epoch 3/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0492 - val_accuracy: 0.9402 - val_loss: 0.0553\n",
            "Epoch 4/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0489 - val_accuracy: 0.9402 - val_loss: 0.0554\n",
            "Epoch 5/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0487 - val_accuracy: 0.9402 - val_loss: 0.0555\n",
            "Epoch 6/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0487 - val_accuracy: 0.9402 - val_loss: 0.0554\n",
            "Epoch 7/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0487 - val_accuracy: 0.9402 - val_loss: 0.0555\n",
            "Epoch 8/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0487 - val_accuracy: 0.9402 - val_loss: 0.0555\n",
            "Epoch 9/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0487 - val_accuracy: 0.9402 - val_loss: 0.0555\n",
            "Epoch 10/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0486 - val_accuracy: 0.9402 - val_loss: 0.0555\n",
            "Epoch 11/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0486 - val_accuracy: 0.9402 - val_loss: 0.0554\n",
            "Epoch 12/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0485 - val_accuracy: 0.9402 - val_loss: 0.0553\n",
            "Epoch 13/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0484 - val_accuracy: 0.9402 - val_loss: 0.0552\n",
            "Epoch 14/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0483 - val_accuracy: 0.9402 - val_loss: 0.0550\n",
            "Epoch 15/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0482 - val_accuracy: 0.9402 - val_loss: 0.0548\n",
            "Epoch 16/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0480 - val_accuracy: 0.9402 - val_loss: 0.0546\n",
            "Epoch 17/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0479 - val_accuracy: 0.9402 - val_loss: 0.0544\n",
            "Epoch 18/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0475 - val_accuracy: 0.9402 - val_loss: 0.0543\n",
            "Epoch 19/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0469 - val_accuracy: 0.9402 - val_loss: 0.0540\n",
            "Epoch 20/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9491 - loss: 0.0461 - val_accuracy: 0.9402 - val_loss: 0.0523\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9555 - loss: 0.0440 \n",
            "[VALID] acc=0.940 | sens=0.348 (k=8/23, CI95=[0.188,0.551]) vs base 0.375 p=0.6200\n",
            "[TEST ] sens=0.087 (k=2/23, CI95=[0.024,0.268]) vs base 0.087 p=0.5000\n",
            "The years trained:  ['Year_2023', 'Year_2024']\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.9149 - loss: 0.2073 - val_accuracy: 0.9402 - val_loss: 0.0649\n",
            "Epoch 2/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0548 - val_accuracy: 0.9402 - val_loss: 0.0568\n",
            "Epoch 3/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0487 - val_accuracy: 0.9402 - val_loss: 0.0562\n",
            "Epoch 4/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0481 - val_accuracy: 0.9402 - val_loss: 0.0559\n",
            "Epoch 5/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0477 - val_accuracy: 0.9402 - val_loss: 0.0555\n",
            "Epoch 6/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0473 - val_accuracy: 0.9402 - val_loss: 0.0549\n",
            "Epoch 7/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0467 - val_accuracy: 0.9402 - val_loss: 0.0535\n",
            "Epoch 8/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0457 - val_accuracy: 0.9402 - val_loss: 0.0513\n",
            "Epoch 9/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0448 - val_accuracy: 0.9402 - val_loss: 0.0490\n",
            "Epoch 10/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0426 - val_accuracy: 0.9402 - val_loss: 0.0460\n",
            "Epoch 11/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0406 - val_accuracy: 0.9402 - val_loss: 0.0436\n",
            "Epoch 12/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0388 - val_accuracy: 0.9402 - val_loss: 0.0416\n",
            "Epoch 13/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9511 - loss: 0.0374 - val_accuracy: 0.9402 - val_loss: 0.0398\n",
            "Epoch 14/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9477 - loss: 0.0356 - val_accuracy: 0.9402 - val_loss: 0.0392\n",
            "Epoch 15/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9545 - loss: 0.0346 - val_accuracy: 0.9402 - val_loss: 0.0378\n",
            "Epoch 16/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9497 - loss: 0.0345 - val_accuracy: 0.9511 - val_loss: 0.0366\n",
            "Epoch 17/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9531 - loss: 0.0330 - val_accuracy: 0.9511 - val_loss: 0.0360\n",
            "Epoch 18/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9567 - loss: 0.0327 - val_accuracy: 0.9565 - val_loss: 0.0352\n",
            "Epoch 19/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9573 - loss: 0.0323 - val_accuracy: 0.9620 - val_loss: 0.0362\n",
            "Epoch 20/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9597 - loss: 0.0317 - val_accuracy: 0.9565 - val_loss: 0.0348\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9262 - loss: 0.0518 \n",
            "[VALID] acc=0.957 | sens=0.348 (k=8/23, CI95=[0.188,0.551]) vs base 0.375 p=0.6200\n",
            "[TEST ] sens=0.087 (k=2/23, CI95=[0.024,0.268]) vs base 0.087 p=0.5000\n",
            "The years trained:  ['Year_2023', 'Year_2024']\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7771 - loss: 0.2934 - val_accuracy: 0.9402 - val_loss: 0.0661\n",
            "Epoch 2/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0696 - val_accuracy: 0.9402 - val_loss: 0.0582\n",
            "Epoch 3/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0537 - val_accuracy: 0.9402 - val_loss: 0.0599\n",
            "Epoch 4/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0552 - val_accuracy: 0.9402 - val_loss: 0.0615\n",
            "Epoch 5/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0556 - val_accuracy: 0.9402 - val_loss: 0.0677\n",
            "Epoch 6/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0562 - val_accuracy: 0.9402 - val_loss: 0.0709\n",
            "Epoch 7/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0548 - val_accuracy: 0.9402 - val_loss: 0.0576\n",
            "Epoch 8/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0490 - val_accuracy: 0.9402 - val_loss: 0.0514\n",
            "Epoch 9/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0453 - val_accuracy: 0.9402 - val_loss: 0.0491\n",
            "Epoch 10/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0429 - val_accuracy: 0.9402 - val_loss: 0.0466\n",
            "Epoch 11/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0411 - val_accuracy: 0.9402 - val_loss: 0.0443\n",
            "Epoch 12/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0392 - val_accuracy: 0.9402 - val_loss: 0.0428\n",
            "Epoch 13/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0376 - val_accuracy: 0.9402 - val_loss: 0.0413\n",
            "Epoch 14/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0365 - val_accuracy: 0.9402 - val_loss: 0.0400\n",
            "Epoch 15/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9507 - loss: 0.0355 - val_accuracy: 0.9348 - val_loss: 0.0390\n",
            "Epoch 16/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9516 - loss: 0.0349 - val_accuracy: 0.9348 - val_loss: 0.0381\n",
            "Epoch 17/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9598 - loss: 0.0345 - val_accuracy: 0.9402 - val_loss: 0.0374\n",
            "Epoch 18/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9636 - loss: 0.0339 - val_accuracy: 0.9511 - val_loss: 0.0372\n",
            "Epoch 19/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9697 - loss: 0.0333 - val_accuracy: 0.9565 - val_loss: 0.0368\n",
            "Epoch 20/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9655 - loss: 0.0329 - val_accuracy: 0.9565 - val_loss: 0.0366\n",
            "Epoch 21/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9623 - loss: 0.0325 - val_accuracy: 0.9565 - val_loss: 0.0363\n",
            "Epoch 22/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9623 - loss: 0.0322 - val_accuracy: 0.9565 - val_loss: 0.0362\n",
            "Epoch 23/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9623 - loss: 0.0318 - val_accuracy: 0.9565 - val_loss: 0.0361\n",
            "Epoch 24/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9624 - loss: 0.0316 - val_accuracy: 0.9565 - val_loss: 0.0360\n",
            "Epoch 25/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9624 - loss: 0.0315 - val_accuracy: 0.9620 - val_loss: 0.0359\n",
            "Epoch 26/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9643 - loss: 0.0313 - val_accuracy: 0.9620 - val_loss: 0.0358\n",
            "Epoch 27/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9643 - loss: 0.0311 - val_accuracy: 0.9620 - val_loss: 0.0358\n",
            "Epoch 28/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9620 - loss: 0.0311 - val_accuracy: 0.9620 - val_loss: 0.0368\n",
            "Epoch 29/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9624 - loss: 0.0317 - val_accuracy: 0.9620 - val_loss: 0.0357\n",
            "Epoch 30/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9616 - loss: 0.0307 - val_accuracy: 0.9620 - val_loss: 0.0356\n",
            "Epoch 31/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9643 - loss: 0.0305 - val_accuracy: 0.9620 - val_loss: 0.0355\n",
            "Epoch 32/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9648 - loss: 0.0306 - val_accuracy: 0.9620 - val_loss: 0.0362\n",
            "Epoch 33/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9628 - loss: 0.0310 - val_accuracy: 0.9620 - val_loss: 0.0359\n",
            "Epoch 34/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9624 - loss: 0.0306 - val_accuracy: 0.9620 - val_loss: 0.0370\n",
            "Epoch 35/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9657 - loss: 0.0311 - val_accuracy: 0.9620 - val_loss: 0.0358\n",
            "Epoch 36/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9614 - loss: 0.0305 - val_accuracy: 0.9565 - val_loss: 0.0359\n",
            "Epoch 37/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9648 - loss: 0.0302 - val_accuracy: 0.9565 - val_loss: 0.0361\n",
            "Epoch 38/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9676 - loss: 0.0302 - val_accuracy: 0.9565 - val_loss: 0.0359\n",
            "Epoch 39/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9669 - loss: 0.0301 - val_accuracy: 0.9565 - val_loss: 0.0353\n",
            "Epoch 40/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9669 - loss: 0.0294 - val_accuracy: 0.9565 - val_loss: 0.0354\n",
            "Epoch 41/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9669 - loss: 0.0293 - val_accuracy: 0.9565 - val_loss: 0.0352\n",
            "Epoch 42/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9669 - loss: 0.0290 - val_accuracy: 0.9565 - val_loss: 0.0351\n",
            "Epoch 43/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9669 - loss: 0.0288 - val_accuracy: 0.9565 - val_loss: 0.0351\n",
            "Epoch 44/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9669 - loss: 0.0286 - val_accuracy: 0.9565 - val_loss: 0.0347\n",
            "Epoch 45/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9677 - loss: 0.0283 - val_accuracy: 0.9565 - val_loss: 0.0345\n",
            "Epoch 46/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9683 - loss: 0.0278 - val_accuracy: 0.9565 - val_loss: 0.0346\n",
            "Epoch 47/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9683 - loss: 0.0275 - val_accuracy: 0.9565 - val_loss: 0.0343\n",
            "Epoch 48/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9676 - loss: 0.0273 - val_accuracy: 0.9565 - val_loss: 0.0357\n",
            "Epoch 49/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9675 - loss: 0.0275 - val_accuracy: 0.9565 - val_loss: 0.0368\n",
            "Epoch 50/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9663 - loss: 0.0281 - val_accuracy: 0.9565 - val_loss: 0.0361\n",
            "Epoch 51/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9683 - loss: 0.0285 - val_accuracy: 0.9565 - val_loss: 0.0348\n",
            "Epoch 52/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9683 - loss: 0.0280 - val_accuracy: 0.9511 - val_loss: 0.0342\n",
            "Epoch 53/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9781 - loss: 0.0277 - val_accuracy: 0.9511 - val_loss: 0.0343\n",
            "Epoch 54/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9759 - loss: 0.0270 - val_accuracy: 0.9511 - val_loss: 0.0346\n",
            "Epoch 55/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9759 - loss: 0.0264 - val_accuracy: 0.9511 - val_loss: 0.0340\n",
            "Epoch 56/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9740 - loss: 0.0262 - val_accuracy: 0.9511 - val_loss: 0.0335\n",
            "Epoch 57/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9740 - loss: 0.0259 - val_accuracy: 0.9511 - val_loss: 0.0333\n",
            "Epoch 58/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9781 - loss: 0.0256 - val_accuracy: 0.9511 - val_loss: 0.0332\n",
            "Epoch 59/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9781 - loss: 0.0252 - val_accuracy: 0.9565 - val_loss: 0.0328\n",
            "Epoch 60/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9781 - loss: 0.0251 - val_accuracy: 0.9565 - val_loss: 0.0326\n",
            "Epoch 61/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9781 - loss: 0.0253 - val_accuracy: 0.9565 - val_loss: 0.0328\n",
            "Epoch 62/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9781 - loss: 0.0255 - val_accuracy: 0.9565 - val_loss: 0.0328\n",
            "Epoch 63/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9683 - loss: 0.0253 - val_accuracy: 0.9620 - val_loss: 0.0327\n",
            "Epoch 64/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9683 - loss: 0.0256 - val_accuracy: 0.9565 - val_loss: 0.0326\n",
            "Epoch 65/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9781 - loss: 0.0248 - val_accuracy: 0.9511 - val_loss: 0.0324\n",
            "Epoch 66/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9781 - loss: 0.0246 - val_accuracy: 0.9565 - val_loss: 0.0325\n",
            "Epoch 67/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9781 - loss: 0.0246 - val_accuracy: 0.9565 - val_loss: 0.0328\n",
            "Epoch 68/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9781 - loss: 0.0247 - val_accuracy: 0.9565 - val_loss: 0.0322\n",
            "Epoch 69/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9781 - loss: 0.0239 - val_accuracy: 0.9565 - val_loss: 0.0323\n",
            "Epoch 70/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9781 - loss: 0.0237 - val_accuracy: 0.9565 - val_loss: 0.0321\n",
            "Epoch 71/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9781 - loss: 0.0236 - val_accuracy: 0.9565 - val_loss: 0.0323\n",
            "Epoch 72/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9781 - loss: 0.0230 - val_accuracy: 0.9565 - val_loss: 0.0322\n",
            "Epoch 73/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9781 - loss: 0.0230 - val_accuracy: 0.9511 - val_loss: 0.0324\n",
            "Epoch 74/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9781 - loss: 0.0229 - val_accuracy: 0.9565 - val_loss: 0.0325\n",
            "Epoch 75/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9781 - loss: 0.0230 - val_accuracy: 0.9565 - val_loss: 0.0321\n",
            "Epoch 76/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9781 - loss: 0.0225 - val_accuracy: 0.9565 - val_loss: 0.0323\n",
            "Epoch 77/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9781 - loss: 0.0224 - val_accuracy: 0.9565 - val_loss: 0.0324\n",
            "Epoch 78/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9781 - loss: 0.0222 - val_accuracy: 0.9511 - val_loss: 0.0326\n",
            "Epoch 79/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9781 - loss: 0.0223 - val_accuracy: 0.9565 - val_loss: 0.0330\n",
            "Epoch 80/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9781 - loss: 0.0226 - val_accuracy: 0.9620 - val_loss: 0.0341\n",
            "Epoch 81/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9781 - loss: 0.0224 - val_accuracy: 0.9620 - val_loss: 0.0334\n",
            "Epoch 82/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9781 - loss: 0.0219 - val_accuracy: 0.9620 - val_loss: 0.0333\n",
            "Epoch 83/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9781 - loss: 0.0218 - val_accuracy: 0.9620 - val_loss: 0.0336\n",
            "Epoch 84/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9786 - loss: 0.0217 - val_accuracy: 0.9620 - val_loss: 0.0342\n",
            "Epoch 85/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9786 - loss: 0.0217 - val_accuracy: 0.9620 - val_loss: 0.0342\n",
            "Epoch 86/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9786 - loss: 0.0213 - val_accuracy: 0.9620 - val_loss: 0.0338\n",
            "Epoch 87/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9786 - loss: 0.0213 - val_accuracy: 0.9620 - val_loss: 0.0343\n",
            "Epoch 88/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9786 - loss: 0.0212 - val_accuracy: 0.9620 - val_loss: 0.0337\n",
            "Epoch 89/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9786 - loss: 0.0213 - val_accuracy: 0.9620 - val_loss: 0.0356\n",
            "Epoch 90/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9786 - loss: 0.0213 - val_accuracy: 0.9620 - val_loss: 0.0348\n",
            "Epoch 91/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9786 - loss: 0.0210 - val_accuracy: 0.9620 - val_loss: 0.0358\n",
            "Epoch 92/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9756 - loss: 0.0218 - val_accuracy: 0.9565 - val_loss: 0.0359\n",
            "Epoch 93/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9756 - loss: 0.0222 - val_accuracy: 0.9565 - val_loss: 0.0363\n",
            "Epoch 94/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9756 - loss: 0.0222 - val_accuracy: 0.9565 - val_loss: 0.0364\n",
            "Epoch 95/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9750 - loss: 0.0221 - val_accuracy: 0.9565 - val_loss: 0.0376\n",
            "Epoch 96/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9770 - loss: 0.0222 - val_accuracy: 0.9565 - val_loss: 0.0366\n",
            "Epoch 97/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9770 - loss: 0.0213 - val_accuracy: 0.9565 - val_loss: 0.0367\n",
            "Epoch 98/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9770 - loss: 0.0210 - val_accuracy: 0.9565 - val_loss: 0.0367\n",
            "Epoch 99/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9770 - loss: 0.0208 - val_accuracy: 0.9620 - val_loss: 0.0365\n",
            "Epoch 100/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9799 - loss: 0.0203 - val_accuracy: 0.9620 - val_loss: 0.0358\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9389 - loss: 0.0568 \n",
            "[VALID] acc=0.962 | sens=0.348 (k=8/23, CI95=[0.188,0.551]) vs base 0.375 p=0.6200\n",
            "[TEST ] sens=0.087 (k=2/23, CI95=[0.024,0.268]) vs base 0.087 p=0.5000\n",
            "The years trained:  ['Year_2023', 'Year_2024']\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7771 - loss: 0.2934 - val_accuracy: 0.9402 - val_loss: 0.0661\n",
            "Epoch 2/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0696 - val_accuracy: 0.9402 - val_loss: 0.0582\n",
            "Epoch 3/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0537 - val_accuracy: 0.9402 - val_loss: 0.0599\n",
            "Epoch 4/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0552 - val_accuracy: 0.9402 - val_loss: 0.0615\n",
            "Epoch 5/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0556 - val_accuracy: 0.9402 - val_loss: 0.0677\n",
            "Epoch 6/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0562 - val_accuracy: 0.9402 - val_loss: 0.0709\n",
            "Epoch 7/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0548 - val_accuracy: 0.9402 - val_loss: 0.0576\n",
            "Epoch 8/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0490 - val_accuracy: 0.9402 - val_loss: 0.0514\n",
            "Epoch 9/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0453 - val_accuracy: 0.9402 - val_loss: 0.0491\n",
            "Epoch 10/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0429 - val_accuracy: 0.9402 - val_loss: 0.0466\n",
            "Epoch 11/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0411 - val_accuracy: 0.9402 - val_loss: 0.0443\n",
            "Epoch 12/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0392 - val_accuracy: 0.9402 - val_loss: 0.0428\n",
            "Epoch 13/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0376 - val_accuracy: 0.9402 - val_loss: 0.0413\n",
            "Epoch 14/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0365 - val_accuracy: 0.9402 - val_loss: 0.0400\n",
            "Epoch 15/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9507 - loss: 0.0355 - val_accuracy: 0.9348 - val_loss: 0.0390\n",
            "Epoch 16/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9516 - loss: 0.0349 - val_accuracy: 0.9348 - val_loss: 0.0381\n",
            "Epoch 17/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9598 - loss: 0.0345 - val_accuracy: 0.9402 - val_loss: 0.0374\n",
            "Epoch 18/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9636 - loss: 0.0339 - val_accuracy: 0.9511 - val_loss: 0.0372\n",
            "Epoch 19/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9697 - loss: 0.0333 - val_accuracy: 0.9565 - val_loss: 0.0368\n",
            "Epoch 20/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9655 - loss: 0.0329 - val_accuracy: 0.9565 - val_loss: 0.0366\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9279 - loss: 0.0504 \n",
            "[VALID] acc=0.957 | sens=0.304 (k=7/23, CI95=[0.156,0.509]) vs base 0.609 p=0.9809\n",
            "[TEST ] sens=0.087 (k=2/23, CI95=[0.024,0.268]) vs base 0.087 p=0.5000\n",
            "The years trained:  ['Year_2023', 'Year_2024']\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.8362 - loss: 0.1413 - val_accuracy: 0.9402 - val_loss: 0.0614\n",
            "Epoch 2/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0514 - val_accuracy: 0.9402 - val_loss: 0.0555\n",
            "Epoch 3/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0492 - val_accuracy: 0.9402 - val_loss: 0.0553\n",
            "Epoch 4/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0489 - val_accuracy: 0.9402 - val_loss: 0.0554\n",
            "Epoch 5/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0487 - val_accuracy: 0.9402 - val_loss: 0.0555\n",
            "Epoch 6/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0487 - val_accuracy: 0.9402 - val_loss: 0.0554\n",
            "Epoch 7/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0487 - val_accuracy: 0.9402 - val_loss: 0.0555\n",
            "Epoch 8/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0487 - val_accuracy: 0.9402 - val_loss: 0.0555\n",
            "Epoch 9/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0487 - val_accuracy: 0.9402 - val_loss: 0.0555\n",
            "Epoch 10/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0486 - val_accuracy: 0.9402 - val_loss: 0.0555\n",
            "Epoch 11/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0486 - val_accuracy: 0.9402 - val_loss: 0.0554\n",
            "Epoch 12/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0485 - val_accuracy: 0.9402 - val_loss: 0.0553\n",
            "Epoch 13/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0484 - val_accuracy: 0.9402 - val_loss: 0.0552\n",
            "Epoch 14/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0483 - val_accuracy: 0.9402 - val_loss: 0.0550\n",
            "Epoch 15/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0482 - val_accuracy: 0.9402 - val_loss: 0.0548\n",
            "Epoch 16/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0480 - val_accuracy: 0.9402 - val_loss: 0.0546\n",
            "Epoch 17/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0479 - val_accuracy: 0.9402 - val_loss: 0.0544\n",
            "Epoch 18/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0475 - val_accuracy: 0.9402 - val_loss: 0.0543\n",
            "Epoch 19/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0469 - val_accuracy: 0.9402 - val_loss: 0.0540\n",
            "Epoch 20/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0461 - val_accuracy: 0.9402 - val_loss: 0.0523\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9555 - loss: 0.0440 \n",
            "[VALID] acc=0.940 | sens=0.348 (k=8/23, CI95=[0.188,0.551]) vs base 0.609 p=0.9617\n",
            "[TEST ] sens=0.087 (k=2/23, CI95=[0.024,0.268]) vs base 0.087 p=0.5000\n",
            "The years trained:  ['Year_2023', 'Year_2024']\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.9149 - loss: 0.2073 - val_accuracy: 0.9402 - val_loss: 0.0649\n",
            "Epoch 2/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0548 - val_accuracy: 0.9402 - val_loss: 0.0568\n",
            "Epoch 3/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0487 - val_accuracy: 0.9402 - val_loss: 0.0562\n",
            "Epoch 4/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0481 - val_accuracy: 0.9402 - val_loss: 0.0559\n",
            "Epoch 5/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0477 - val_accuracy: 0.9402 - val_loss: 0.0555\n",
            "Epoch 6/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0473 - val_accuracy: 0.9402 - val_loss: 0.0549\n",
            "Epoch 7/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0467 - val_accuracy: 0.9402 - val_loss: 0.0535\n",
            "Epoch 8/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0457 - val_accuracy: 0.9402 - val_loss: 0.0513\n",
            "Epoch 9/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0448 - val_accuracy: 0.9402 - val_loss: 0.0490\n",
            "Epoch 10/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0426 - val_accuracy: 0.9402 - val_loss: 0.0460\n",
            "Epoch 11/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0406 - val_accuracy: 0.9402 - val_loss: 0.0436\n",
            "Epoch 12/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0388 - val_accuracy: 0.9402 - val_loss: 0.0416\n",
            "Epoch 13/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9511 - loss: 0.0374 - val_accuracy: 0.9402 - val_loss: 0.0398\n",
            "Epoch 14/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9477 - loss: 0.0356 - val_accuracy: 0.9402 - val_loss: 0.0392\n",
            "Epoch 15/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9545 - loss: 0.0346 - val_accuracy: 0.9402 - val_loss: 0.0378\n",
            "Epoch 16/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9497 - loss: 0.0345 - val_accuracy: 0.9511 - val_loss: 0.0366\n",
            "Epoch 17/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9531 - loss: 0.0330 - val_accuracy: 0.9511 - val_loss: 0.0360\n",
            "Epoch 18/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9567 - loss: 0.0327 - val_accuracy: 0.9565 - val_loss: 0.0352\n",
            "Epoch 19/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9573 - loss: 0.0323 - val_accuracy: 0.9620 - val_loss: 0.0362\n",
            "Epoch 20/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9597 - loss: 0.0317 - val_accuracy: 0.9565 - val_loss: 0.0348\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9262 - loss: 0.0518 \n",
            "[VALID] acc=0.957 | sens=0.348 (k=8/23, CI95=[0.188,0.551]) vs base 0.609 p=0.9617\n",
            "[TEST ] sens=0.087 (k=2/23, CI95=[0.024,0.268]) vs base 0.087 p=0.5000\n",
            "The years trained:  ['Year_2023', 'Year_2024']\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7771 - loss: 0.2934 - val_accuracy: 0.9402 - val_loss: 0.0661\n",
            "Epoch 2/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0696 - val_accuracy: 0.9402 - val_loss: 0.0582\n",
            "Epoch 3/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0537 - val_accuracy: 0.9402 - val_loss: 0.0599\n",
            "Epoch 4/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0552 - val_accuracy: 0.9402 - val_loss: 0.0615\n",
            "Epoch 5/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0556 - val_accuracy: 0.9402 - val_loss: 0.0677\n",
            "Epoch 6/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0562 - val_accuracy: 0.9402 - val_loss: 0.0709\n",
            "Epoch 7/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0548 - val_accuracy: 0.9402 - val_loss: 0.0576\n",
            "Epoch 8/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0490 - val_accuracy: 0.9402 - val_loss: 0.0514\n",
            "Epoch 9/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0453 - val_accuracy: 0.9402 - val_loss: 0.0491\n",
            "Epoch 10/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0429 - val_accuracy: 0.9402 - val_loss: 0.0466\n",
            "Epoch 11/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0411 - val_accuracy: 0.9402 - val_loss: 0.0443\n",
            "Epoch 12/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0392 - val_accuracy: 0.9402 - val_loss: 0.0428\n",
            "Epoch 13/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0376 - val_accuracy: 0.9402 - val_loss: 0.0413\n",
            "Epoch 14/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0365 - val_accuracy: 0.9402 - val_loss: 0.0400\n",
            "Epoch 15/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9507 - loss: 0.0355 - val_accuracy: 0.9348 - val_loss: 0.0390\n",
            "Epoch 16/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9516 - loss: 0.0349 - val_accuracy: 0.9348 - val_loss: 0.0381\n",
            "Epoch 17/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9598 - loss: 0.0345 - val_accuracy: 0.9402 - val_loss: 0.0374\n",
            "Epoch 18/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9636 - loss: 0.0339 - val_accuracy: 0.9511 - val_loss: 0.0372\n",
            "Epoch 19/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9697 - loss: 0.0333 - val_accuracy: 0.9565 - val_loss: 0.0368\n",
            "Epoch 20/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9655 - loss: 0.0329 - val_accuracy: 0.9565 - val_loss: 0.0366\n",
            "Epoch 21/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9623 - loss: 0.0325 - val_accuracy: 0.9565 - val_loss: 0.0363\n",
            "Epoch 22/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9623 - loss: 0.0322 - val_accuracy: 0.9565 - val_loss: 0.0362\n",
            "Epoch 23/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9623 - loss: 0.0318 - val_accuracy: 0.9565 - val_loss: 0.0361\n",
            "Epoch 24/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9624 - loss: 0.0316 - val_accuracy: 0.9565 - val_loss: 0.0360\n",
            "Epoch 25/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9624 - loss: 0.0315 - val_accuracy: 0.9620 - val_loss: 0.0359\n",
            "Epoch 26/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9643 - loss: 0.0313 - val_accuracy: 0.9620 - val_loss: 0.0358\n",
            "Epoch 27/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9643 - loss: 0.0311 - val_accuracy: 0.9620 - val_loss: 0.0358\n",
            "Epoch 28/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9620 - loss: 0.0311 - val_accuracy: 0.9620 - val_loss: 0.0368\n",
            "Epoch 29/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9624 - loss: 0.0317 - val_accuracy: 0.9620 - val_loss: 0.0357\n",
            "Epoch 30/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9616 - loss: 0.0307 - val_accuracy: 0.9620 - val_loss: 0.0356\n",
            "Epoch 31/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9643 - loss: 0.0305 - val_accuracy: 0.9620 - val_loss: 0.0355\n",
            "Epoch 32/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9648 - loss: 0.0306 - val_accuracy: 0.9620 - val_loss: 0.0362\n",
            "Epoch 33/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9628 - loss: 0.0310 - val_accuracy: 0.9620 - val_loss: 0.0359\n",
            "Epoch 34/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9624 - loss: 0.0306 - val_accuracy: 0.9620 - val_loss: 0.0370\n",
            "Epoch 35/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9657 - loss: 0.0311 - val_accuracy: 0.9620 - val_loss: 0.0358\n",
            "Epoch 36/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9614 - loss: 0.0305 - val_accuracy: 0.9565 - val_loss: 0.0359\n",
            "Epoch 37/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9648 - loss: 0.0302 - val_accuracy: 0.9565 - val_loss: 0.0361\n",
            "Epoch 38/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9676 - loss: 0.0302 - val_accuracy: 0.9565 - val_loss: 0.0359\n",
            "Epoch 39/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9669 - loss: 0.0301 - val_accuracy: 0.9565 - val_loss: 0.0353\n",
            "Epoch 40/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9669 - loss: 0.0294 - val_accuracy: 0.9565 - val_loss: 0.0354\n",
            "Epoch 41/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9669 - loss: 0.0293 - val_accuracy: 0.9565 - val_loss: 0.0352\n",
            "Epoch 42/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9669 - loss: 0.0290 - val_accuracy: 0.9565 - val_loss: 0.0351\n",
            "Epoch 43/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9669 - loss: 0.0288 - val_accuracy: 0.9565 - val_loss: 0.0351\n",
            "Epoch 44/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9669 - loss: 0.0286 - val_accuracy: 0.9565 - val_loss: 0.0347\n",
            "Epoch 45/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9677 - loss: 0.0283 - val_accuracy: 0.9565 - val_loss: 0.0345\n",
            "Epoch 46/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9683 - loss: 0.0278 - val_accuracy: 0.9565 - val_loss: 0.0346\n",
            "Epoch 47/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9683 - loss: 0.0275 - val_accuracy: 0.9565 - val_loss: 0.0343\n",
            "Epoch 48/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9676 - loss: 0.0273 - val_accuracy: 0.9565 - val_loss: 0.0357\n",
            "Epoch 49/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9675 - loss: 0.0275 - val_accuracy: 0.9565 - val_loss: 0.0368\n",
            "Epoch 50/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9663 - loss: 0.0281 - val_accuracy: 0.9565 - val_loss: 0.0361\n",
            "Epoch 51/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9683 - loss: 0.0285 - val_accuracy: 0.9565 - val_loss: 0.0348\n",
            "Epoch 52/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9683 - loss: 0.0280 - val_accuracy: 0.9511 - val_loss: 0.0342\n",
            "Epoch 53/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9781 - loss: 0.0277 - val_accuracy: 0.9511 - val_loss: 0.0343\n",
            "Epoch 54/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9759 - loss: 0.0270 - val_accuracy: 0.9511 - val_loss: 0.0346\n",
            "Epoch 55/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9759 - loss: 0.0264 - val_accuracy: 0.9511 - val_loss: 0.0340\n",
            "Epoch 56/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9740 - loss: 0.0262 - val_accuracy: 0.9511 - val_loss: 0.0335\n",
            "Epoch 57/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9740 - loss: 0.0259 - val_accuracy: 0.9511 - val_loss: 0.0333\n",
            "Epoch 58/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9781 - loss: 0.0256 - val_accuracy: 0.9511 - val_loss: 0.0332\n",
            "Epoch 59/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9781 - loss: 0.0252 - val_accuracy: 0.9565 - val_loss: 0.0328\n",
            "Epoch 60/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9781 - loss: 0.0251 - val_accuracy: 0.9565 - val_loss: 0.0326\n",
            "Epoch 61/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9781 - loss: 0.0253 - val_accuracy: 0.9565 - val_loss: 0.0328\n",
            "Epoch 62/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9781 - loss: 0.0255 - val_accuracy: 0.9565 - val_loss: 0.0328\n",
            "Epoch 63/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9683 - loss: 0.0253 - val_accuracy: 0.9620 - val_loss: 0.0327\n",
            "Epoch 64/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9683 - loss: 0.0256 - val_accuracy: 0.9565 - val_loss: 0.0326\n",
            "Epoch 65/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9781 - loss: 0.0248 - val_accuracy: 0.9511 - val_loss: 0.0324\n",
            "Epoch 66/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9781 - loss: 0.0246 - val_accuracy: 0.9565 - val_loss: 0.0325\n",
            "Epoch 67/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9781 - loss: 0.0246 - val_accuracy: 0.9565 - val_loss: 0.0328\n",
            "Epoch 68/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9781 - loss: 0.0247 - val_accuracy: 0.9565 - val_loss: 0.0322\n",
            "Epoch 69/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9781 - loss: 0.0239 - val_accuracy: 0.9565 - val_loss: 0.0323\n",
            "Epoch 70/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9781 - loss: 0.0237 - val_accuracy: 0.9565 - val_loss: 0.0321\n",
            "Epoch 71/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9781 - loss: 0.0236 - val_accuracy: 0.9565 - val_loss: 0.0323\n",
            "Epoch 72/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9781 - loss: 0.0230 - val_accuracy: 0.9565 - val_loss: 0.0322\n",
            "Epoch 73/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9781 - loss: 0.0230 - val_accuracy: 0.9511 - val_loss: 0.0324\n",
            "Epoch 74/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9781 - loss: 0.0229 - val_accuracy: 0.9565 - val_loss: 0.0325\n",
            "Epoch 75/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9781 - loss: 0.0230 - val_accuracy: 0.9565 - val_loss: 0.0321\n",
            "Epoch 76/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9781 - loss: 0.0225 - val_accuracy: 0.9565 - val_loss: 0.0323\n",
            "Epoch 77/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9781 - loss: 0.0224 - val_accuracy: 0.9565 - val_loss: 0.0324\n",
            "Epoch 78/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9781 - loss: 0.0222 - val_accuracy: 0.9511 - val_loss: 0.0326\n",
            "Epoch 79/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9781 - loss: 0.0223 - val_accuracy: 0.9565 - val_loss: 0.0330\n",
            "Epoch 80/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9781 - loss: 0.0226 - val_accuracy: 0.9620 - val_loss: 0.0341\n",
            "Epoch 81/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9781 - loss: 0.0224 - val_accuracy: 0.9620 - val_loss: 0.0334\n",
            "Epoch 82/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9781 - loss: 0.0219 - val_accuracy: 0.9620 - val_loss: 0.0333\n",
            "Epoch 83/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9781 - loss: 0.0218 - val_accuracy: 0.9620 - val_loss: 0.0336\n",
            "Epoch 84/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9786 - loss: 0.0217 - val_accuracy: 0.9620 - val_loss: 0.0342\n",
            "Epoch 85/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9786 - loss: 0.0217 - val_accuracy: 0.9620 - val_loss: 0.0342\n",
            "Epoch 86/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9786 - loss: 0.0213 - val_accuracy: 0.9620 - val_loss: 0.0338\n",
            "Epoch 87/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9786 - loss: 0.0213 - val_accuracy: 0.9620 - val_loss: 0.0343\n",
            "Epoch 88/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9786 - loss: 0.0212 - val_accuracy: 0.9620 - val_loss: 0.0337\n",
            "Epoch 89/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9786 - loss: 0.0213 - val_accuracy: 0.9620 - val_loss: 0.0356\n",
            "Epoch 90/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9786 - loss: 0.0213 - val_accuracy: 0.9620 - val_loss: 0.0348\n",
            "Epoch 91/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9786 - loss: 0.0210 - val_accuracy: 0.9620 - val_loss: 0.0358\n",
            "Epoch 92/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9756 - loss: 0.0218 - val_accuracy: 0.9565 - val_loss: 0.0359\n",
            "Epoch 93/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9756 - loss: 0.0222 - val_accuracy: 0.9565 - val_loss: 0.0363\n",
            "Epoch 94/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9756 - loss: 0.0222 - val_accuracy: 0.9565 - val_loss: 0.0364\n",
            "Epoch 95/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9750 - loss: 0.0221 - val_accuracy: 0.9565 - val_loss: 0.0376\n",
            "Epoch 96/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9770 - loss: 0.0222 - val_accuracy: 0.9565 - val_loss: 0.0366\n",
            "Epoch 97/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9770 - loss: 0.0213 - val_accuracy: 0.9565 - val_loss: 0.0367\n",
            "Epoch 98/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9770 - loss: 0.0210 - val_accuracy: 0.9565 - val_loss: 0.0367\n",
            "Epoch 99/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9770 - loss: 0.0208 - val_accuracy: 0.9620 - val_loss: 0.0365\n",
            "Epoch 100/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9799 - loss: 0.0203 - val_accuracy: 0.9620 - val_loss: 0.0358\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9389 - loss: 0.0568 \n",
            "[VALID] acc=0.962 | sens=0.348 (k=8/23, CI95=[0.188,0.551]) vs base 0.609 p=0.9617\n",
            "[TEST ] sens=0.087 (k=2/23, CI95=[0.024,0.268]) vs base 0.087 p=0.5000\n",
            "The years trained:  ['Year_2023', 'Year_2024']\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.8163 - loss: 0.1498 - val_accuracy: 0.9402 - val_loss: 0.0561\n",
            "Epoch 2/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0510 - val_accuracy: 0.9402 - val_loss: 0.0560\n",
            "Epoch 3/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9491 - loss: 0.0491 - val_accuracy: 0.9402 - val_loss: 0.0556\n",
            "Epoch 4/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0488 - val_accuracy: 0.9402 - val_loss: 0.0554\n",
            "Epoch 5/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0486 - val_accuracy: 0.9402 - val_loss: 0.0552\n",
            "Epoch 6/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0484 - val_accuracy: 0.9402 - val_loss: 0.0550\n",
            "Epoch 7/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9491 - loss: 0.0482 - val_accuracy: 0.9402 - val_loss: 0.0545\n",
            "Epoch 8/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0477 - val_accuracy: 0.9402 - val_loss: 0.0539\n",
            "Epoch 9/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9491 - loss: 0.0471 - val_accuracy: 0.9402 - val_loss: 0.0528\n",
            "Epoch 10/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9491 - loss: 0.0462 - val_accuracy: 0.9402 - val_loss: 0.0512\n",
            "Epoch 11/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0448 - val_accuracy: 0.9402 - val_loss: 0.0487\n",
            "Epoch 12/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0427 - val_accuracy: 0.9402 - val_loss: 0.0462\n",
            "Epoch 13/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9491 - loss: 0.0406 - val_accuracy: 0.9402 - val_loss: 0.0434\n",
            "Epoch 14/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0378 - val_accuracy: 0.9293 - val_loss: 0.0424\n",
            "Epoch 15/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9551 - loss: 0.0371 - val_accuracy: 0.9402 - val_loss: 0.0389\n",
            "Epoch 16/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9614 - loss: 0.0343 - val_accuracy: 0.9348 - val_loss: 0.0373\n",
            "Epoch 17/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9705 - loss: 0.0336 - val_accuracy: 0.9511 - val_loss: 0.0359\n",
            "Epoch 18/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9644 - loss: 0.0332 - val_accuracy: 0.9565 - val_loss: 0.0357\n",
            "Epoch 19/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9625 - loss: 0.0337 - val_accuracy: 0.9402 - val_loss: 0.0390\n",
            "Epoch 20/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9724 - loss: 0.0351 - val_accuracy: 0.9402 - val_loss: 0.0460\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9555 - loss: 0.0489 \n",
            "[VALID] acc=0.940 | sens=0.348 (k=8/23, CI95=[0.188,0.551]) vs base 0.375 p=0.6200\n",
            "[TEST ] sens=0.087 (k=2/23, CI95=[0.024,0.268]) vs base 0.087 p=0.5000\n",
            "The years trained:  ['Year_2023', 'Year_2024']\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.8658 - loss: 0.5064 - val_accuracy: 0.9402 - val_loss: 0.0670\n",
            "Epoch 2/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0520 - val_accuracy: 0.9402 - val_loss: 0.0559\n",
            "Epoch 3/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9491 - loss: 0.0490 - val_accuracy: 0.9402 - val_loss: 0.0565\n",
            "Epoch 4/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9491 - loss: 0.0486 - val_accuracy: 0.9402 - val_loss: 0.0556\n",
            "Epoch 5/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9491 - loss: 0.0484 - val_accuracy: 0.9402 - val_loss: 0.0554\n",
            "Epoch 6/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9491 - loss: 0.0482 - val_accuracy: 0.9402 - val_loss: 0.0550\n",
            "Epoch 7/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9491 - loss: 0.0480 - val_accuracy: 0.9402 - val_loss: 0.0545\n",
            "Epoch 8/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9491 - loss: 0.0478 - val_accuracy: 0.9402 - val_loss: 0.0538\n",
            "Epoch 9/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9491 - loss: 0.0478 - val_accuracy: 0.9402 - val_loss: 0.0531\n",
            "Epoch 10/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9491 - loss: 0.0469 - val_accuracy: 0.9402 - val_loss: 0.0522\n",
            "Epoch 11/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9491 - loss: 0.0468 - val_accuracy: 0.9402 - val_loss: 0.0510\n",
            "Epoch 12/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9491 - loss: 0.0454 - val_accuracy: 0.9402 - val_loss: 0.0503\n",
            "Epoch 13/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9491 - loss: 0.0455 - val_accuracy: 0.9402 - val_loss: 0.0489\n",
            "Epoch 14/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9491 - loss: 0.0441 - val_accuracy: 0.9402 - val_loss: 0.0469\n",
            "Epoch 15/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0413 - val_accuracy: 0.9402 - val_loss: 0.0494\n",
            "Epoch 16/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0433 - val_accuracy: 0.9402 - val_loss: 0.0430\n",
            "Epoch 17/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0395 - val_accuracy: 0.9402 - val_loss: 0.0395\n",
            "Epoch 18/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9486 - loss: 0.0357 - val_accuracy: 0.9511 - val_loss: 0.0374\n",
            "Epoch 19/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9589 - loss: 0.0357 - val_accuracy: 0.9402 - val_loss: 0.0430\n",
            "Epoch 20/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9528 - loss: 0.0378 - val_accuracy: 0.9620 - val_loss: 0.0366\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9209 - loss: 0.0562 \n",
            "[VALID] acc=0.962 | sens=0.348 (k=8/23, CI95=[0.188,0.551]) vs base 0.375 p=0.6200\n",
            "[TEST ] sens=0.087 (k=2/23, CI95=[0.024,0.268]) vs base 0.087 p=0.5000\n",
            "The years trained:  ['Year_2023', 'Year_2024']\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.7448 - loss: 0.2394 - val_accuracy: 0.8967 - val_loss: 0.0783\n",
            "Epoch 2/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9205 - loss: 0.0667 - val_accuracy: 0.9402 - val_loss: 0.0609\n",
            "Epoch 3/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9491 - loss: 0.0536 - val_accuracy: 0.9402 - val_loss: 0.0564\n",
            "Epoch 4/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0494 - val_accuracy: 0.9402 - val_loss: 0.0566\n",
            "Epoch 5/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0487 - val_accuracy: 0.9402 - val_loss: 0.0559\n",
            "Epoch 6/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0483 - val_accuracy: 0.9402 - val_loss: 0.0558\n",
            "Epoch 7/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0480 - val_accuracy: 0.9402 - val_loss: 0.0553\n",
            "Epoch 8/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0477 - val_accuracy: 0.9402 - val_loss: 0.0547\n",
            "Epoch 9/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0472 - val_accuracy: 0.9402 - val_loss: 0.0532\n",
            "Epoch 10/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0456 - val_accuracy: 0.9402 - val_loss: 0.0517\n",
            "Epoch 11/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0437 - val_accuracy: 0.9402 - val_loss: 0.0491\n",
            "Epoch 12/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0411 - val_accuracy: 0.9402 - val_loss: 0.0374\n",
            "Epoch 13/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9565 - loss: 0.0371 - val_accuracy: 0.9402 - val_loss: 0.0532\n",
            "Epoch 14/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9549 - loss: 0.0390 - val_accuracy: 0.9620 - val_loss: 0.0341\n",
            "Epoch 15/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9547 - loss: 0.0348 - val_accuracy: 0.9674 - val_loss: 0.0312\n",
            "Epoch 16/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9573 - loss: 0.0326 - val_accuracy: 0.9620 - val_loss: 0.0346\n",
            "Epoch 17/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9572 - loss: 0.0347 - val_accuracy: 0.9565 - val_loss: 0.0325\n",
            "Epoch 18/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9566 - loss: 0.0332 - val_accuracy: 0.9620 - val_loss: 0.0327\n",
            "Epoch 19/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9541 - loss: 0.0356 - val_accuracy: 0.9620 - val_loss: 0.0334\n",
            "Epoch 20/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9551 - loss: 0.0341 - val_accuracy: 0.9620 - val_loss: 0.0308\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9209 - loss: 0.0571 \n",
            "[VALID] acc=0.962 | sens=0.348 (k=8/23, CI95=[0.188,0.551]) vs base 0.375 p=0.6200\n",
            "[TEST ] sens=0.087 (k=2/23, CI95=[0.024,0.268]) vs base 0.087 p=0.5000\n",
            "The years trained:  ['Year_2023', 'Year_2024']\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.8163 - loss: 0.1498 - val_accuracy: 0.9402 - val_loss: 0.0561\n",
            "Epoch 2/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0510 - val_accuracy: 0.9402 - val_loss: 0.0560\n",
            "Epoch 3/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0491 - val_accuracy: 0.9402 - val_loss: 0.0556\n",
            "Epoch 4/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0488 - val_accuracy: 0.9402 - val_loss: 0.0554\n",
            "Epoch 5/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0486 - val_accuracy: 0.9402 - val_loss: 0.0552\n",
            "Epoch 6/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0484 - val_accuracy: 0.9402 - val_loss: 0.0550\n",
            "Epoch 7/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0482 - val_accuracy: 0.9402 - val_loss: 0.0545\n",
            "Epoch 8/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9491 - loss: 0.0477 - val_accuracy: 0.9402 - val_loss: 0.0539\n",
            "Epoch 9/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0471 - val_accuracy: 0.9402 - val_loss: 0.0528\n",
            "Epoch 10/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0462 - val_accuracy: 0.9402 - val_loss: 0.0512\n",
            "Epoch 11/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0448 - val_accuracy: 0.9402 - val_loss: 0.0487\n",
            "Epoch 12/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0427 - val_accuracy: 0.9402 - val_loss: 0.0462\n",
            "Epoch 13/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0406 - val_accuracy: 0.9402 - val_loss: 0.0434\n",
            "Epoch 14/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0378 - val_accuracy: 0.9293 - val_loss: 0.0424\n",
            "Epoch 15/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9551 - loss: 0.0371 - val_accuracy: 0.9402 - val_loss: 0.0389\n",
            "Epoch 16/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9614 - loss: 0.0343 - val_accuracy: 0.9348 - val_loss: 0.0373\n",
            "Epoch 17/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9705 - loss: 0.0336 - val_accuracy: 0.9511 - val_loss: 0.0359\n",
            "Epoch 18/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9644 - loss: 0.0332 - val_accuracy: 0.9565 - val_loss: 0.0357\n",
            "Epoch 19/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9625 - loss: 0.0337 - val_accuracy: 0.9402 - val_loss: 0.0390\n",
            "Epoch 20/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9724 - loss: 0.0351 - val_accuracy: 0.9402 - val_loss: 0.0460\n",
            "Epoch 21/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9552 - loss: 0.0389 - val_accuracy: 0.9620 - val_loss: 0.0348\n",
            "Epoch 22/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9589 - loss: 0.0332 - val_accuracy: 0.9620 - val_loss: 0.0342\n",
            "Epoch 23/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9589 - loss: 0.0324 - val_accuracy: 0.9620 - val_loss: 0.0329\n",
            "Epoch 24/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9589 - loss: 0.0318 - val_accuracy: 0.9620 - val_loss: 0.0332\n",
            "Epoch 25/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9592 - loss: 0.0310 - val_accuracy: 0.9620 - val_loss: 0.0328\n",
            "Epoch 26/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9589 - loss: 0.0323 - val_accuracy: 0.9620 - val_loss: 0.0333\n",
            "Epoch 27/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9592 - loss: 0.0316 - val_accuracy: 0.9620 - val_loss: 0.0349\n",
            "Epoch 28/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9589 - loss: 0.0326 - val_accuracy: 0.9620 - val_loss: 0.0336\n",
            "Epoch 29/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9603 - loss: 0.0327 - val_accuracy: 0.9620 - val_loss: 0.0323\n",
            "Epoch 30/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9584 - loss: 0.0332 - val_accuracy: 0.9565 - val_loss: 0.0324\n",
            "Epoch 31/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9601 - loss: 0.0300 - val_accuracy: 0.9565 - val_loss: 0.0356\n",
            "Epoch 32/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9707 - loss: 0.0288 - val_accuracy: 0.9565 - val_loss: 0.0385\n",
            "Epoch 33/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9722 - loss: 0.0288 - val_accuracy: 0.9565 - val_loss: 0.0356\n",
            "Epoch 34/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9697 - loss: 0.0287 - val_accuracy: 0.9620 - val_loss: 0.0317\n",
            "Epoch 35/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9744 - loss: 0.0278 - val_accuracy: 0.9620 - val_loss: 0.0314\n",
            "Epoch 36/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9695 - loss: 0.0266 - val_accuracy: 0.9620 - val_loss: 0.0313\n",
            "Epoch 37/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9665 - loss: 0.0267 - val_accuracy: 0.9620 - val_loss: 0.0326\n",
            "Epoch 38/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9665 - loss: 0.0275 - val_accuracy: 0.9620 - val_loss: 0.0315\n",
            "Epoch 39/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9665 - loss: 0.0262 - val_accuracy: 0.9620 - val_loss: 0.0323\n",
            "Epoch 40/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9679 - loss: 0.0263 - val_accuracy: 0.9620 - val_loss: 0.0317\n",
            "Epoch 41/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9679 - loss: 0.0257 - val_accuracy: 0.9620 - val_loss: 0.0332\n",
            "Epoch 42/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9697 - loss: 0.0262 - val_accuracy: 0.9620 - val_loss: 0.0324\n",
            "Epoch 43/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9697 - loss: 0.0252 - val_accuracy: 0.9620 - val_loss: 0.0329\n",
            "Epoch 44/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9698 - loss: 0.0251 - val_accuracy: 0.9620 - val_loss: 0.0332\n",
            "Epoch 45/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9698 - loss: 0.0249 - val_accuracy: 0.9620 - val_loss: 0.0335\n",
            "Epoch 46/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9698 - loss: 0.0246 - val_accuracy: 0.9620 - val_loss: 0.0330\n",
            "Epoch 47/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9698 - loss: 0.0238 - val_accuracy: 0.9620 - val_loss: 0.0333\n",
            "Epoch 48/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9698 - loss: 0.0236 - val_accuracy: 0.9620 - val_loss: 0.0325\n",
            "Epoch 49/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9747 - loss: 0.0227 - val_accuracy: 0.9620 - val_loss: 0.0315\n",
            "Epoch 50/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9796 - loss: 0.0218 - val_accuracy: 0.9620 - val_loss: 0.0336\n",
            "Epoch 51/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9747 - loss: 0.0226 - val_accuracy: 0.9620 - val_loss: 0.0320\n",
            "Epoch 52/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9796 - loss: 0.0212 - val_accuracy: 0.9620 - val_loss: 0.0312\n",
            "Epoch 53/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9786 - loss: 0.0211 - val_accuracy: 0.9620 - val_loss: 0.0352\n",
            "Epoch 54/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9747 - loss: 0.0220 - val_accuracy: 0.9620 - val_loss: 0.0312\n",
            "Epoch 55/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9786 - loss: 0.0211 - val_accuracy: 0.9620 - val_loss: 0.0334\n",
            "Epoch 56/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9796 - loss: 0.0207 - val_accuracy: 0.9620 - val_loss: 0.0316\n",
            "Epoch 57/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9763 - loss: 0.0213 - val_accuracy: 0.9511 - val_loss: 0.0380\n",
            "Epoch 58/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9725 - loss: 0.0227 - val_accuracy: 0.9620 - val_loss: 0.0313\n",
            "Epoch 59/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9759 - loss: 0.0217 - val_accuracy: 0.9348 - val_loss: 0.0454\n",
            "Epoch 60/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9698 - loss: 0.0232 - val_accuracy: 0.9620 - val_loss: 0.0304\n",
            "Epoch 61/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9764 - loss: 0.0209 - val_accuracy: 0.9348 - val_loss: 0.0470\n",
            "Epoch 62/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9698 - loss: 0.0237 - val_accuracy: 0.9674 - val_loss: 0.0325\n",
            "Epoch 63/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9781 - loss: 0.0204 - val_accuracy: 0.9620 - val_loss: 0.0306\n",
            "Epoch 64/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9757 - loss: 0.0206 - val_accuracy: 0.9620 - val_loss: 0.0301\n",
            "Epoch 65/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9770 - loss: 0.0209 - val_accuracy: 0.9565 - val_loss: 0.0382\n",
            "Epoch 66/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9730 - loss: 0.0225 - val_accuracy: 0.9620 - val_loss: 0.0316\n",
            "Epoch 67/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9760 - loss: 0.0212 - val_accuracy: 0.9511 - val_loss: 0.0330\n",
            "Epoch 68/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9778 - loss: 0.0215 - val_accuracy: 0.9620 - val_loss: 0.0353\n",
            "Epoch 69/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9773 - loss: 0.0226 - val_accuracy: 0.9565 - val_loss: 0.0388\n",
            "Epoch 70/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9755 - loss: 0.0220 - val_accuracy: 0.9620 - val_loss: 0.0333\n",
            "Epoch 71/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9730 - loss: 0.0233 - val_accuracy: 0.9620 - val_loss: 0.0319\n",
            "Epoch 72/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9745 - loss: 0.0229 - val_accuracy: 0.9620 - val_loss: 0.0328\n",
            "Epoch 73/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9777 - loss: 0.0223 - val_accuracy: 0.9565 - val_loss: 0.0410\n",
            "Epoch 74/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9696 - loss: 0.0288 - val_accuracy: 0.9565 - val_loss: 0.0410\n",
            "Epoch 75/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9620 - loss: 0.0312 - val_accuracy: 0.9565 - val_loss: 0.0415\n",
            "Epoch 76/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9643 - loss: 0.0289 - val_accuracy: 0.9511 - val_loss: 0.0444\n",
            "Epoch 77/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9595 - loss: 0.0328 - val_accuracy: 0.9511 - val_loss: 0.0467\n",
            "Epoch 78/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9514 - loss: 0.0400 - val_accuracy: 0.9565 - val_loss: 0.0321\n",
            "Epoch 79/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9775 - loss: 0.0214 - val_accuracy: 0.9511 - val_loss: 0.0440\n",
            "Epoch 80/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9620 - loss: 0.0343 - val_accuracy: 0.9511 - val_loss: 0.0447\n",
            "Epoch 81/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9519 - loss: 0.0378 - val_accuracy: 0.9620 - val_loss: 0.0300\n",
            "Epoch 82/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9798 - loss: 0.0214 - val_accuracy: 0.9565 - val_loss: 0.0373\n",
            "Epoch 83/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9770 - loss: 0.0217 - val_accuracy: 0.9565 - val_loss: 0.0420\n",
            "Epoch 84/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9631 - loss: 0.0319 - val_accuracy: 0.9511 - val_loss: 0.0428\n",
            "Epoch 85/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9610 - loss: 0.0341 - val_accuracy: 0.9565 - val_loss: 0.0317\n",
            "Epoch 86/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9792 - loss: 0.0215 - val_accuracy: 0.9565 - val_loss: 0.0378\n",
            "Epoch 87/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9770 - loss: 0.0215 - val_accuracy: 0.9565 - val_loss: 0.0411\n",
            "Epoch 88/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9664 - loss: 0.0265 - val_accuracy: 0.9565 - val_loss: 0.0418\n",
            "Epoch 89/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9597 - loss: 0.0298 - val_accuracy: 0.9620 - val_loss: 0.0310\n",
            "Epoch 90/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9771 - loss: 0.0217 - val_accuracy: 0.9565 - val_loss: 0.0373\n",
            "Epoch 91/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9772 - loss: 0.0195 - val_accuracy: 0.9565 - val_loss: 0.0413\n",
            "Epoch 92/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9772 - loss: 0.0215 - val_accuracy: 0.9565 - val_loss: 0.0405\n",
            "Epoch 93/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9773 - loss: 0.0205 - val_accuracy: 0.9565 - val_loss: 0.0409\n",
            "Epoch 94/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9773 - loss: 0.0206 - val_accuracy: 0.9565 - val_loss: 0.0414\n",
            "Epoch 95/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9780 - loss: 0.0201 - val_accuracy: 0.9511 - val_loss: 0.0387\n",
            "Epoch 96/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9773 - loss: 0.0191 - val_accuracy: 0.9565 - val_loss: 0.0404\n",
            "Epoch 97/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9773 - loss: 0.0185 - val_accuracy: 0.9565 - val_loss: 0.0414\n",
            "Epoch 98/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9774 - loss: 0.0183 - val_accuracy: 0.9565 - val_loss: 0.0421\n",
            "Epoch 99/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9780 - loss: 0.0190 - val_accuracy: 0.9511 - val_loss: 0.0370\n",
            "Epoch 100/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9802 - loss: 0.0173 - val_accuracy: 0.9565 - val_loss: 0.0395\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9271 - loss: 0.0637 \n",
            "[VALID] acc=0.957 | sens=0.304 (k=7/23, CI95=[0.156,0.509]) vs base 0.375 p=0.7321\n",
            "[TEST ] sens=0.087 (k=2/23, CI95=[0.024,0.268]) vs base 0.087 p=0.5000\n",
            "The years trained:  ['Year_2023', 'Year_2024']\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8768 - loss: 0.1726 - val_accuracy: 0.9402 - val_loss: 0.0746\n",
            "Epoch 2/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0645 - val_accuracy: 0.9402 - val_loss: 0.0710\n",
            "Epoch 3/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0625 - val_accuracy: 0.9402 - val_loss: 0.0692\n",
            "Epoch 4/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0613 - val_accuracy: 0.9402 - val_loss: 0.0679\n",
            "Epoch 5/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0605 - val_accuracy: 0.9402 - val_loss: 0.0671\n",
            "Epoch 6/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0598 - val_accuracy: 0.9402 - val_loss: 0.0663\n",
            "Epoch 7/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0593 - val_accuracy: 0.9402 - val_loss: 0.0656\n",
            "Epoch 8/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0589 - val_accuracy: 0.9402 - val_loss: 0.0650\n",
            "Epoch 9/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0585 - val_accuracy: 0.9402 - val_loss: 0.0645\n",
            "Epoch 10/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0581 - val_accuracy: 0.9402 - val_loss: 0.0641\n",
            "Epoch 11/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0578 - val_accuracy: 0.9402 - val_loss: 0.0637\n",
            "Epoch 12/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0575 - val_accuracy: 0.9402 - val_loss: 0.0633\n",
            "Epoch 13/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0572 - val_accuracy: 0.9402 - val_loss: 0.0630\n",
            "Epoch 14/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0570 - val_accuracy: 0.9402 - val_loss: 0.0627\n",
            "Epoch 15/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0567 - val_accuracy: 0.9402 - val_loss: 0.0624\n",
            "Epoch 16/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0565 - val_accuracy: 0.9402 - val_loss: 0.0621\n",
            "Epoch 17/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0563 - val_accuracy: 0.9402 - val_loss: 0.0619\n",
            "Epoch 18/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0561 - val_accuracy: 0.9402 - val_loss: 0.0617\n",
            "Epoch 19/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0560 - val_accuracy: 0.9402 - val_loss: 0.0615\n",
            "Epoch 20/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0558 - val_accuracy: 0.9402 - val_loss: 0.0613\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9555 - loss: 0.0514 \n",
            "[VALID] acc=0.940 | sens=0.087 (k=2/23, CI95=[0.024,0.268]) vs base 0.375 p=0.9922\n",
            "[TEST ] sens=0.043 (k=1/23, CI95=[0.008,0.210]) vs base 0.087 p=0.7248\n",
            "The years trained:  ['Year_2023', 'Year_2024']\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9491 - loss: 0.1001 - val_accuracy: 0.9402 - val_loss: 0.0594\n",
            "Epoch 2/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9491 - loss: 0.0548 - val_accuracy: 0.9402 - val_loss: 0.0577\n",
            "Epoch 3/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9491 - loss: 0.0530 - val_accuracy: 0.9402 - val_loss: 0.0570\n",
            "Epoch 4/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9491 - loss: 0.0521 - val_accuracy: 0.9402 - val_loss: 0.0566\n",
            "Epoch 5/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9491 - loss: 0.0515 - val_accuracy: 0.9402 - val_loss: 0.0563\n",
            "Epoch 6/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9491 - loss: 0.0511 - val_accuracy: 0.9402 - val_loss: 0.0561\n",
            "Epoch 7/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9491 - loss: 0.0509 - val_accuracy: 0.9402 - val_loss: 0.0559\n",
            "Epoch 8/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9491 - loss: 0.0507 - val_accuracy: 0.9402 - val_loss: 0.0558\n",
            "Epoch 9/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0505 - val_accuracy: 0.9402 - val_loss: 0.0557\n",
            "Epoch 10/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0503 - val_accuracy: 0.9402 - val_loss: 0.0556\n",
            "Epoch 11/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0502 - val_accuracy: 0.9402 - val_loss: 0.0555\n",
            "Epoch 12/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0500 - val_accuracy: 0.9402 - val_loss: 0.0554\n",
            "Epoch 13/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0499 - val_accuracy: 0.9402 - val_loss: 0.0552\n",
            "Epoch 14/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0497 - val_accuracy: 0.9402 - val_loss: 0.0551\n",
            "Epoch 15/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0495 - val_accuracy: 0.9402 - val_loss: 0.0551\n",
            "Epoch 16/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0494 - val_accuracy: 0.9402 - val_loss: 0.0550\n",
            "Epoch 17/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0493 - val_accuracy: 0.9402 - val_loss: 0.0550\n",
            "Epoch 18/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0493 - val_accuracy: 0.9402 - val_loss: 0.0549\n",
            "Epoch 19/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0492 - val_accuracy: 0.9402 - val_loss: 0.0549\n",
            "Epoch 20/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0491 - val_accuracy: 0.9402 - val_loss: 0.0548\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9555 - loss: 0.0455 \n",
            "[VALID] acc=0.940 | sens=0.217 (k=5/23, CI95=[0.097,0.419]) vs base 0.375 p=0.9000\n",
            "[TEST ] sens=0.043 (k=1/23, CI95=[0.008,0.210]) vs base 0.087 p=0.7248\n",
            "The years trained:  ['Year_2023', 'Year_2024']\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9491 - loss: 0.2104 - val_accuracy: 0.9402 - val_loss: 0.0648\n",
            "Epoch 2/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0599 - val_accuracy: 0.9402 - val_loss: 0.0641\n",
            "Epoch 3/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0590 - val_accuracy: 0.9402 - val_loss: 0.0635\n",
            "Epoch 4/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0583 - val_accuracy: 0.9402 - val_loss: 0.0629\n",
            "Epoch 5/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0576 - val_accuracy: 0.9402 - val_loss: 0.0624\n",
            "Epoch 6/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0569 - val_accuracy: 0.9402 - val_loss: 0.0619\n",
            "Epoch 7/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0564 - val_accuracy: 0.9402 - val_loss: 0.0615\n",
            "Epoch 8/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0558 - val_accuracy: 0.9402 - val_loss: 0.0612\n",
            "Epoch 9/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0554 - val_accuracy: 0.9402 - val_loss: 0.0608\n",
            "Epoch 10/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0549 - val_accuracy: 0.9402 - val_loss: 0.0605\n",
            "Epoch 11/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0546 - val_accuracy: 0.9402 - val_loss: 0.0602\n",
            "Epoch 12/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0542 - val_accuracy: 0.9402 - val_loss: 0.0600\n",
            "Epoch 13/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0539 - val_accuracy: 0.9402 - val_loss: 0.0597\n",
            "Epoch 14/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0536 - val_accuracy: 0.9402 - val_loss: 0.0595\n",
            "Epoch 15/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0533 - val_accuracy: 0.9402 - val_loss: 0.0593\n",
            "Epoch 16/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0530 - val_accuracy: 0.9402 - val_loss: 0.0591\n",
            "Epoch 17/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0528 - val_accuracy: 0.9402 - val_loss: 0.0589\n",
            "Epoch 18/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0525 - val_accuracy: 0.9402 - val_loss: 0.0587\n",
            "Epoch 19/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0523 - val_accuracy: 0.9402 - val_loss: 0.0586\n",
            "Epoch 20/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0521 - val_accuracy: 0.9402 - val_loss: 0.0584\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9555 - loss: 0.0468 \n",
            "[VALID] acc=0.940 | sens=0.087 (k=2/23, CI95=[0.024,0.268]) vs base 0.375 p=0.9922\n",
            "[TEST ] sens=0.087 (k=2/23, CI95=[0.024,0.268]) vs base 0.087 p=0.5000\n",
            "The years trained:  ['Year_2023', 'Year_2024']\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9491 - loss: 0.2104 - val_accuracy: 0.9402 - val_loss: 0.0648\n",
            "Epoch 2/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9491 - loss: 0.0599 - val_accuracy: 0.9402 - val_loss: 0.0641\n",
            "Epoch 3/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9491 - loss: 0.0590 - val_accuracy: 0.9402 - val_loss: 0.0635\n",
            "Epoch 4/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9491 - loss: 0.0583 - val_accuracy: 0.9402 - val_loss: 0.0629\n",
            "Epoch 5/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9491 - loss: 0.0576 - val_accuracy: 0.9402 - val_loss: 0.0624\n",
            "Epoch 6/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9491 - loss: 0.0569 - val_accuracy: 0.9402 - val_loss: 0.0619\n",
            "Epoch 7/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9491 - loss: 0.0564 - val_accuracy: 0.9402 - val_loss: 0.0615\n",
            "Epoch 8/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9491 - loss: 0.0558 - val_accuracy: 0.9402 - val_loss: 0.0612\n",
            "Epoch 9/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9491 - loss: 0.0554 - val_accuracy: 0.9402 - val_loss: 0.0608\n",
            "Epoch 10/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9491 - loss: 0.0549 - val_accuracy: 0.9402 - val_loss: 0.0605\n",
            "Epoch 11/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0546 - val_accuracy: 0.9402 - val_loss: 0.0602\n",
            "Epoch 12/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0542 - val_accuracy: 0.9402 - val_loss: 0.0600\n",
            "Epoch 13/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0539 - val_accuracy: 0.9402 - val_loss: 0.0597\n",
            "Epoch 14/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0536 - val_accuracy: 0.9402 - val_loss: 0.0595\n",
            "Epoch 15/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0533 - val_accuracy: 0.9402 - val_loss: 0.0593\n",
            "Epoch 16/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0530 - val_accuracy: 0.9402 - val_loss: 0.0591\n",
            "Epoch 17/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0528 - val_accuracy: 0.9402 - val_loss: 0.0589\n",
            "Epoch 18/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0525 - val_accuracy: 0.9402 - val_loss: 0.0587\n",
            "Epoch 19/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0523 - val_accuracy: 0.9402 - val_loss: 0.0586\n",
            "Epoch 20/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0521 - val_accuracy: 0.9402 - val_loss: 0.0584\n",
            "Epoch 21/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0520 - val_accuracy: 0.9402 - val_loss: 0.0583\n",
            "Epoch 22/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0518 - val_accuracy: 0.9402 - val_loss: 0.0582\n",
            "Epoch 23/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0516 - val_accuracy: 0.9402 - val_loss: 0.0581\n",
            "Epoch 24/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0515 - val_accuracy: 0.9402 - val_loss: 0.0580\n",
            "Epoch 25/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0513 - val_accuracy: 0.9402 - val_loss: 0.0579\n",
            "Epoch 26/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0512 - val_accuracy: 0.9402 - val_loss: 0.0578\n",
            "Epoch 27/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0511 - val_accuracy: 0.9402 - val_loss: 0.0577\n",
            "Epoch 28/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0510 - val_accuracy: 0.9402 - val_loss: 0.0576\n",
            "Epoch 29/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0509 - val_accuracy: 0.9402 - val_loss: 0.0575\n",
            "Epoch 30/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0508 - val_accuracy: 0.9402 - val_loss: 0.0574\n",
            "Epoch 31/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0507 - val_accuracy: 0.9402 - val_loss: 0.0574\n",
            "Epoch 32/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0506 - val_accuracy: 0.9402 - val_loss: 0.0573\n",
            "Epoch 33/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0505 - val_accuracy: 0.9402 - val_loss: 0.0572\n",
            "Epoch 34/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0504 - val_accuracy: 0.9402 - val_loss: 0.0572\n",
            "Epoch 35/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0503 - val_accuracy: 0.9402 - val_loss: 0.0571\n",
            "Epoch 36/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0503 - val_accuracy: 0.9402 - val_loss: 0.0571\n",
            "Epoch 37/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0502 - val_accuracy: 0.9402 - val_loss: 0.0570\n",
            "Epoch 38/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0501 - val_accuracy: 0.9402 - val_loss: 0.0569\n",
            "Epoch 39/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0500 - val_accuracy: 0.9402 - val_loss: 0.0569\n",
            "Epoch 40/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0500 - val_accuracy: 0.9402 - val_loss: 0.0568\n",
            "Epoch 41/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0499 - val_accuracy: 0.9402 - val_loss: 0.0568\n",
            "Epoch 42/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0499 - val_accuracy: 0.9402 - val_loss: 0.0568\n",
            "Epoch 43/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0498 - val_accuracy: 0.9402 - val_loss: 0.0567\n",
            "Epoch 44/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0498 - val_accuracy: 0.9402 - val_loss: 0.0567\n",
            "Epoch 45/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0497 - val_accuracy: 0.9402 - val_loss: 0.0566\n",
            "Epoch 46/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0497 - val_accuracy: 0.9402 - val_loss: 0.0566\n",
            "Epoch 47/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0496 - val_accuracy: 0.9402 - val_loss: 0.0566\n",
            "Epoch 48/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0496 - val_accuracy: 0.9402 - val_loss: 0.0565\n",
            "Epoch 49/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0495 - val_accuracy: 0.9402 - val_loss: 0.0565\n",
            "Epoch 50/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0495 - val_accuracy: 0.9402 - val_loss: 0.0564\n",
            "Epoch 51/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0494 - val_accuracy: 0.9402 - val_loss: 0.0564\n",
            "Epoch 52/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0494 - val_accuracy: 0.9402 - val_loss: 0.0564\n",
            "Epoch 53/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0494 - val_accuracy: 0.9402 - val_loss: 0.0563\n",
            "Epoch 54/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0493 - val_accuracy: 0.9402 - val_loss: 0.0563\n",
            "Epoch 55/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0493 - val_accuracy: 0.9402 - val_loss: 0.0563\n",
            "Epoch 56/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0493 - val_accuracy: 0.9402 - val_loss: 0.0562\n",
            "Epoch 57/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0492 - val_accuracy: 0.9402 - val_loss: 0.0562\n",
            "Epoch 58/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9491 - loss: 0.0492 - val_accuracy: 0.9402 - val_loss: 0.0562\n",
            "Epoch 59/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9491 - loss: 0.0492 - val_accuracy: 0.9402 - val_loss: 0.0562\n",
            "Epoch 60/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9491 - loss: 0.0491 - val_accuracy: 0.9402 - val_loss: 0.0561\n",
            "Epoch 61/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9491 - loss: 0.0491 - val_accuracy: 0.9402 - val_loss: 0.0561\n",
            "Epoch 62/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9491 - loss: 0.0491 - val_accuracy: 0.9402 - val_loss: 0.0561\n",
            "Epoch 63/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9491 - loss: 0.0491 - val_accuracy: 0.9402 - val_loss: 0.0561\n",
            "Epoch 64/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9491 - loss: 0.0490 - val_accuracy: 0.9402 - val_loss: 0.0560\n",
            "Epoch 65/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9491 - loss: 0.0490 - val_accuracy: 0.9402 - val_loss: 0.0560\n",
            "Epoch 66/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9491 - loss: 0.0490 - val_accuracy: 0.9402 - val_loss: 0.0560\n",
            "Epoch 67/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9491 - loss: 0.0490 - val_accuracy: 0.9402 - val_loss: 0.0560\n",
            "Epoch 68/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0489 - val_accuracy: 0.9402 - val_loss: 0.0559\n",
            "Epoch 69/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0489 - val_accuracy: 0.9402 - val_loss: 0.0559\n",
            "Epoch 70/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0489 - val_accuracy: 0.9402 - val_loss: 0.0559\n",
            "Epoch 71/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0489 - val_accuracy: 0.9402 - val_loss: 0.0559\n",
            "Epoch 72/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0488 - val_accuracy: 0.9402 - val_loss: 0.0559\n",
            "Epoch 73/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0488 - val_accuracy: 0.9402 - val_loss: 0.0558\n",
            "Epoch 74/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0488 - val_accuracy: 0.9402 - val_loss: 0.0558\n",
            "Epoch 75/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0488 - val_accuracy: 0.9402 - val_loss: 0.0558\n",
            "Epoch 76/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0488 - val_accuracy: 0.9402 - val_loss: 0.0558\n",
            "Epoch 77/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0487 - val_accuracy: 0.9402 - val_loss: 0.0558\n",
            "Epoch 78/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0487 - val_accuracy: 0.9402 - val_loss: 0.0557\n",
            "Epoch 79/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0487 - val_accuracy: 0.9402 - val_loss: 0.0557\n",
            "Epoch 80/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0487 - val_accuracy: 0.9402 - val_loss: 0.0557\n",
            "Epoch 81/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0487 - val_accuracy: 0.9402 - val_loss: 0.0557\n",
            "Epoch 82/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0487 - val_accuracy: 0.9402 - val_loss: 0.0557\n",
            "Epoch 83/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0486 - val_accuracy: 0.9402 - val_loss: 0.0557\n",
            "Epoch 84/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0486 - val_accuracy: 0.9402 - val_loss: 0.0556\n",
            "Epoch 85/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0486 - val_accuracy: 0.9402 - val_loss: 0.0556\n",
            "Epoch 86/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0486 - val_accuracy: 0.9402 - val_loss: 0.0556\n",
            "Epoch 87/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0486 - val_accuracy: 0.9402 - val_loss: 0.0556\n",
            "Epoch 88/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0486 - val_accuracy: 0.9402 - val_loss: 0.0556\n",
            "Epoch 89/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0486 - val_accuracy: 0.9402 - val_loss: 0.0556\n",
            "Epoch 90/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0485 - val_accuracy: 0.9402 - val_loss: 0.0556\n",
            "Epoch 91/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0485 - val_accuracy: 0.9402 - val_loss: 0.0556\n",
            "Epoch 92/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0485 - val_accuracy: 0.9402 - val_loss: 0.0555\n",
            "Epoch 93/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0485 - val_accuracy: 0.9402 - val_loss: 0.0555\n",
            "Epoch 94/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0485 - val_accuracy: 0.9402 - val_loss: 0.0555\n",
            "Epoch 95/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0485 - val_accuracy: 0.9402 - val_loss: 0.0555\n",
            "Epoch 96/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0485 - val_accuracy: 0.9402 - val_loss: 0.0555\n",
            "Epoch 97/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0485 - val_accuracy: 0.9402 - val_loss: 0.0555\n",
            "Epoch 98/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9491 - loss: 0.0484 - val_accuracy: 0.9402 - val_loss: 0.0555\n",
            "Epoch 99/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0484 - val_accuracy: 0.9402 - val_loss: 0.0555\n",
            "Epoch 100/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0484 - val_accuracy: 0.9402 - val_loss: 0.0554\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9555 - loss: 0.0428 \n",
            "[VALID] acc=0.940 | sens=0.043 (k=1/23, CI95=[0.008,0.210]) vs base 0.375 p=0.9979\n",
            "[TEST ] sens=0.043 (k=1/23, CI95=[0.008,0.210]) vs base 0.087 p=0.7248\n",
            "The years trained:  ['Year_2023', 'Year_2024']\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8768 - loss: 0.1726 - val_accuracy: 0.9402 - val_loss: 0.0746\n",
            "Epoch 2/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0645 - val_accuracy: 0.9402 - val_loss: 0.0710\n",
            "Epoch 3/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0625 - val_accuracy: 0.9402 - val_loss: 0.0692\n",
            "Epoch 4/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9491 - loss: 0.0613 - val_accuracy: 0.9402 - val_loss: 0.0679\n",
            "Epoch 5/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9491 - loss: 0.0605 - val_accuracy: 0.9402 - val_loss: 0.0671\n",
            "Epoch 6/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9491 - loss: 0.0598 - val_accuracy: 0.9402 - val_loss: 0.0663\n",
            "Epoch 7/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9491 - loss: 0.0593 - val_accuracy: 0.9402 - val_loss: 0.0656\n",
            "Epoch 8/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9491 - loss: 0.0589 - val_accuracy: 0.9402 - val_loss: 0.0650\n",
            "Epoch 9/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9491 - loss: 0.0585 - val_accuracy: 0.9402 - val_loss: 0.0645\n",
            "Epoch 10/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9491 - loss: 0.0581 - val_accuracy: 0.9402 - val_loss: 0.0641\n",
            "Epoch 11/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9491 - loss: 0.0578 - val_accuracy: 0.9402 - val_loss: 0.0637\n",
            "Epoch 12/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9491 - loss: 0.0575 - val_accuracy: 0.9402 - val_loss: 0.0633\n",
            "Epoch 13/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9491 - loss: 0.0572 - val_accuracy: 0.9402 - val_loss: 0.0630\n",
            "Epoch 14/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9491 - loss: 0.0570 - val_accuracy: 0.9402 - val_loss: 0.0627\n",
            "Epoch 15/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0567 - val_accuracy: 0.9402 - val_loss: 0.0624\n",
            "Epoch 16/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0565 - val_accuracy: 0.9402 - val_loss: 0.0621\n",
            "Epoch 17/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0563 - val_accuracy: 0.9402 - val_loss: 0.0619\n",
            "Epoch 18/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0561 - val_accuracy: 0.9402 - val_loss: 0.0617\n",
            "Epoch 19/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0560 - val_accuracy: 0.9402 - val_loss: 0.0615\n",
            "Epoch 20/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0558 - val_accuracy: 0.9402 - val_loss: 0.0613\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9555 - loss: 0.0514 \n",
            "[VALID] acc=0.940 | sens=0.087 (k=2/23, CI95=[0.024,0.268]) vs base 0.609 p=0.9999\n",
            "[TEST ] sens=0.043 (k=1/23, CI95=[0.008,0.210]) vs base 0.087 p=0.7248\n",
            "The years trained:  ['Year_2023', 'Year_2024']\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9491 - loss: 0.1001 - val_accuracy: 0.9402 - val_loss: 0.0594\n",
            "Epoch 2/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0548 - val_accuracy: 0.9402 - val_loss: 0.0577\n",
            "Epoch 3/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0530 - val_accuracy: 0.9402 - val_loss: 0.0570\n",
            "Epoch 4/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0521 - val_accuracy: 0.9402 - val_loss: 0.0566\n",
            "Epoch 5/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0515 - val_accuracy: 0.9402 - val_loss: 0.0563\n",
            "Epoch 6/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0511 - val_accuracy: 0.9402 - val_loss: 0.0561\n",
            "Epoch 7/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0509 - val_accuracy: 0.9402 - val_loss: 0.0559\n",
            "Epoch 8/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0507 - val_accuracy: 0.9402 - val_loss: 0.0558\n",
            "Epoch 9/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0505 - val_accuracy: 0.9402 - val_loss: 0.0557\n",
            "Epoch 10/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0503 - val_accuracy: 0.9402 - val_loss: 0.0556\n",
            "Epoch 11/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0502 - val_accuracy: 0.9402 - val_loss: 0.0555\n",
            "Epoch 12/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0500 - val_accuracy: 0.9402 - val_loss: 0.0554\n",
            "Epoch 13/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0499 - val_accuracy: 0.9402 - val_loss: 0.0552\n",
            "Epoch 14/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0497 - val_accuracy: 0.9402 - val_loss: 0.0551\n",
            "Epoch 15/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0495 - val_accuracy: 0.9402 - val_loss: 0.0551\n",
            "Epoch 16/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0494 - val_accuracy: 0.9402 - val_loss: 0.0550\n",
            "Epoch 17/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0493 - val_accuracy: 0.9402 - val_loss: 0.0550\n",
            "Epoch 18/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0493 - val_accuracy: 0.9402 - val_loss: 0.0549\n",
            "Epoch 19/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0492 - val_accuracy: 0.9402 - val_loss: 0.0549\n",
            "Epoch 20/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0491 - val_accuracy: 0.9402 - val_loss: 0.0548\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9555 - loss: 0.0455 \n",
            "[VALID] acc=0.940 | sens=0.217 (k=5/23, CI95=[0.097,0.419]) vs base 0.609 p=0.9965\n",
            "[TEST ] sens=0.043 (k=1/23, CI95=[0.008,0.210]) vs base 0.087 p=0.7248\n",
            "The years trained:  ['Year_2023', 'Year_2024']\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9491 - loss: 0.2104 - val_accuracy: 0.9402 - val_loss: 0.0648\n",
            "Epoch 2/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0599 - val_accuracy: 0.9402 - val_loss: 0.0641\n",
            "Epoch 3/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0590 - val_accuracy: 0.9402 - val_loss: 0.0635\n",
            "Epoch 4/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0583 - val_accuracy: 0.9402 - val_loss: 0.0629\n",
            "Epoch 5/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0576 - val_accuracy: 0.9402 - val_loss: 0.0624\n",
            "Epoch 6/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9491 - loss: 0.0569 - val_accuracy: 0.9402 - val_loss: 0.0619\n",
            "Epoch 7/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9491 - loss: 0.0564 - val_accuracy: 0.9402 - val_loss: 0.0615\n",
            "Epoch 8/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9491 - loss: 0.0558 - val_accuracy: 0.9402 - val_loss: 0.0612\n",
            "Epoch 9/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9491 - loss: 0.0554 - val_accuracy: 0.9402 - val_loss: 0.0608\n",
            "Epoch 10/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9491 - loss: 0.0549 - val_accuracy: 0.9402 - val_loss: 0.0605\n",
            "Epoch 11/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9491 - loss: 0.0546 - val_accuracy: 0.9402 - val_loss: 0.0602\n",
            "Epoch 12/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9491 - loss: 0.0542 - val_accuracy: 0.9402 - val_loss: 0.0600\n",
            "Epoch 13/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9491 - loss: 0.0539 - val_accuracy: 0.9402 - val_loss: 0.0597\n",
            "Epoch 14/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9491 - loss: 0.0536 - val_accuracy: 0.9402 - val_loss: 0.0595\n",
            "Epoch 15/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9491 - loss: 0.0533 - val_accuracy: 0.9402 - val_loss: 0.0593\n",
            "Epoch 16/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9491 - loss: 0.0530 - val_accuracy: 0.9402 - val_loss: 0.0591\n",
            "Epoch 17/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9491 - loss: 0.0528 - val_accuracy: 0.9402 - val_loss: 0.0589\n",
            "Epoch 18/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0525 - val_accuracy: 0.9402 - val_loss: 0.0587\n",
            "Epoch 19/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0523 - val_accuracy: 0.9402 - val_loss: 0.0586\n",
            "Epoch 20/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0521 - val_accuracy: 0.9402 - val_loss: 0.0584\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9555 - loss: 0.0468 \n",
            "[VALID] acc=0.940 | sens=0.087 (k=2/23, CI95=[0.024,0.268]) vs base 0.609 p=0.9999\n",
            "[TEST ] sens=0.087 (k=2/23, CI95=[0.024,0.268]) vs base 0.087 p=0.5000\n",
            "The years trained:  ['Year_2023', 'Year_2024']\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9491 - loss: 0.2104 - val_accuracy: 0.9402 - val_loss: 0.0648\n",
            "Epoch 2/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9491 - loss: 0.0599 - val_accuracy: 0.9402 - val_loss: 0.0641\n",
            "Epoch 3/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0590 - val_accuracy: 0.9402 - val_loss: 0.0635\n",
            "Epoch 4/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0583 - val_accuracy: 0.9402 - val_loss: 0.0629\n",
            "Epoch 5/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0576 - val_accuracy: 0.9402 - val_loss: 0.0624\n",
            "Epoch 6/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0569 - val_accuracy: 0.9402 - val_loss: 0.0619\n",
            "Epoch 7/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0564 - val_accuracy: 0.9402 - val_loss: 0.0615\n",
            "Epoch 8/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0558 - val_accuracy: 0.9402 - val_loss: 0.0612\n",
            "Epoch 9/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0554 - val_accuracy: 0.9402 - val_loss: 0.0608\n",
            "Epoch 10/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0549 - val_accuracy: 0.9402 - val_loss: 0.0605\n",
            "Epoch 11/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0546 - val_accuracy: 0.9402 - val_loss: 0.0602\n",
            "Epoch 12/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0542 - val_accuracy: 0.9402 - val_loss: 0.0600\n",
            "Epoch 13/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0539 - val_accuracy: 0.9402 - val_loss: 0.0597\n",
            "Epoch 14/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0536 - val_accuracy: 0.9402 - val_loss: 0.0595\n",
            "Epoch 15/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0533 - val_accuracy: 0.9402 - val_loss: 0.0593\n",
            "Epoch 16/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0530 - val_accuracy: 0.9402 - val_loss: 0.0591\n",
            "Epoch 17/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0528 - val_accuracy: 0.9402 - val_loss: 0.0589\n",
            "Epoch 18/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0525 - val_accuracy: 0.9402 - val_loss: 0.0587\n",
            "Epoch 19/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0523 - val_accuracy: 0.9402 - val_loss: 0.0586\n",
            "Epoch 20/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0521 - val_accuracy: 0.9402 - val_loss: 0.0584\n",
            "Epoch 21/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0520 - val_accuracy: 0.9402 - val_loss: 0.0583\n",
            "Epoch 22/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0518 - val_accuracy: 0.9402 - val_loss: 0.0582\n",
            "Epoch 23/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0516 - val_accuracy: 0.9402 - val_loss: 0.0581\n",
            "Epoch 24/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0515 - val_accuracy: 0.9402 - val_loss: 0.0580\n",
            "Epoch 25/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0513 - val_accuracy: 0.9402 - val_loss: 0.0579\n",
            "Epoch 26/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0512 - val_accuracy: 0.9402 - val_loss: 0.0578\n",
            "Epoch 27/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0511 - val_accuracy: 0.9402 - val_loss: 0.0577\n",
            "Epoch 28/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0510 - val_accuracy: 0.9402 - val_loss: 0.0576\n",
            "Epoch 29/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0509 - val_accuracy: 0.9402 - val_loss: 0.0575\n",
            "Epoch 30/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0508 - val_accuracy: 0.9402 - val_loss: 0.0574\n",
            "Epoch 31/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0507 - val_accuracy: 0.9402 - val_loss: 0.0574\n",
            "Epoch 32/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0506 - val_accuracy: 0.9402 - val_loss: 0.0573\n",
            "Epoch 33/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0505 - val_accuracy: 0.9402 - val_loss: 0.0572\n",
            "Epoch 34/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0504 - val_accuracy: 0.9402 - val_loss: 0.0572\n",
            "Epoch 35/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9491 - loss: 0.0503 - val_accuracy: 0.9402 - val_loss: 0.0571\n",
            "Epoch 36/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9491 - loss: 0.0503 - val_accuracy: 0.9402 - val_loss: 0.0571\n",
            "Epoch 37/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9491 - loss: 0.0502 - val_accuracy: 0.9402 - val_loss: 0.0570\n",
            "Epoch 38/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9491 - loss: 0.0501 - val_accuracy: 0.9402 - val_loss: 0.0569\n",
            "Epoch 39/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9491 - loss: 0.0500 - val_accuracy: 0.9402 - val_loss: 0.0569\n",
            "Epoch 40/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9491 - loss: 0.0500 - val_accuracy: 0.9402 - val_loss: 0.0568\n",
            "Epoch 41/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9491 - loss: 0.0499 - val_accuracy: 0.9402 - val_loss: 0.0568\n",
            "Epoch 42/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9491 - loss: 0.0499 - val_accuracy: 0.9402 - val_loss: 0.0568\n",
            "Epoch 43/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9491 - loss: 0.0498 - val_accuracy: 0.9402 - val_loss: 0.0567\n",
            "Epoch 44/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9491 - loss: 0.0498 - val_accuracy: 0.9402 - val_loss: 0.0567\n",
            "Epoch 45/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9491 - loss: 0.0497 - val_accuracy: 0.9402 - val_loss: 0.0566\n",
            "Epoch 46/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0497 - val_accuracy: 0.9402 - val_loss: 0.0566\n",
            "Epoch 47/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0496 - val_accuracy: 0.9402 - val_loss: 0.0566\n",
            "Epoch 48/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0496 - val_accuracy: 0.9402 - val_loss: 0.0565\n",
            "Epoch 49/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0495 - val_accuracy: 0.9402 - val_loss: 0.0565\n",
            "Epoch 50/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0495 - val_accuracy: 0.9402 - val_loss: 0.0564\n",
            "Epoch 51/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0494 - val_accuracy: 0.9402 - val_loss: 0.0564\n",
            "Epoch 52/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0494 - val_accuracy: 0.9402 - val_loss: 0.0564\n",
            "Epoch 53/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0494 - val_accuracy: 0.9402 - val_loss: 0.0563\n",
            "Epoch 54/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0493 - val_accuracy: 0.9402 - val_loss: 0.0563\n",
            "Epoch 55/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0493 - val_accuracy: 0.9402 - val_loss: 0.0563\n",
            "Epoch 56/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0493 - val_accuracy: 0.9402 - val_loss: 0.0562\n",
            "Epoch 57/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0492 - val_accuracy: 0.9402 - val_loss: 0.0562\n",
            "Epoch 58/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0492 - val_accuracy: 0.9402 - val_loss: 0.0562\n",
            "Epoch 59/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0492 - val_accuracy: 0.9402 - val_loss: 0.0562\n",
            "Epoch 60/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0491 - val_accuracy: 0.9402 - val_loss: 0.0561\n",
            "Epoch 61/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0491 - val_accuracy: 0.9402 - val_loss: 0.0561\n",
            "Epoch 62/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0491 - val_accuracy: 0.9402 - val_loss: 0.0561\n",
            "Epoch 63/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0491 - val_accuracy: 0.9402 - val_loss: 0.0561\n",
            "Epoch 64/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0490 - val_accuracy: 0.9402 - val_loss: 0.0560\n",
            "Epoch 65/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0490 - val_accuracy: 0.9402 - val_loss: 0.0560\n",
            "Epoch 66/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0490 - val_accuracy: 0.9402 - val_loss: 0.0560\n",
            "Epoch 67/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0490 - val_accuracy: 0.9402 - val_loss: 0.0560\n",
            "Epoch 68/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0489 - val_accuracy: 0.9402 - val_loss: 0.0559\n",
            "Epoch 69/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0489 - val_accuracy: 0.9402 - val_loss: 0.0559\n",
            "Epoch 70/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0489 - val_accuracy: 0.9402 - val_loss: 0.0559\n",
            "Epoch 71/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0489 - val_accuracy: 0.9402 - val_loss: 0.0559\n",
            "Epoch 72/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0488 - val_accuracy: 0.9402 - val_loss: 0.0559\n",
            "Epoch 73/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0488 - val_accuracy: 0.9402 - val_loss: 0.0558\n",
            "Epoch 74/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0488 - val_accuracy: 0.9402 - val_loss: 0.0558\n",
            "Epoch 75/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0488 - val_accuracy: 0.9402 - val_loss: 0.0558\n",
            "Epoch 76/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0488 - val_accuracy: 0.9402 - val_loss: 0.0558\n",
            "Epoch 77/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0487 - val_accuracy: 0.9402 - val_loss: 0.0558\n",
            "Epoch 78/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0487 - val_accuracy: 0.9402 - val_loss: 0.0557\n",
            "Epoch 79/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0487 - val_accuracy: 0.9402 - val_loss: 0.0557\n",
            "Epoch 80/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0487 - val_accuracy: 0.9402 - val_loss: 0.0557\n",
            "Epoch 81/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0487 - val_accuracy: 0.9402 - val_loss: 0.0557\n",
            "Epoch 82/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0487 - val_accuracy: 0.9402 - val_loss: 0.0557\n",
            "Epoch 83/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0486 - val_accuracy: 0.9402 - val_loss: 0.0557\n",
            "Epoch 84/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0486 - val_accuracy: 0.9402 - val_loss: 0.0556\n",
            "Epoch 85/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0486 - val_accuracy: 0.9402 - val_loss: 0.0556\n",
            "Epoch 86/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0486 - val_accuracy: 0.9402 - val_loss: 0.0556\n",
            "Epoch 87/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0486 - val_accuracy: 0.9402 - val_loss: 0.0556\n",
            "Epoch 88/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9491 - loss: 0.0486 - val_accuracy: 0.9402 - val_loss: 0.0556\n",
            "Epoch 89/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0486 - val_accuracy: 0.9402 - val_loss: 0.0556\n",
            "Epoch 90/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0485 - val_accuracy: 0.9402 - val_loss: 0.0556\n",
            "Epoch 91/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9491 - loss: 0.0485 - val_accuracy: 0.9402 - val_loss: 0.0556\n",
            "Epoch 92/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9491 - loss: 0.0485 - val_accuracy: 0.9402 - val_loss: 0.0555\n",
            "Epoch 93/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9491 - loss: 0.0485 - val_accuracy: 0.9402 - val_loss: 0.0555\n",
            "Epoch 94/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9491 - loss: 0.0485 - val_accuracy: 0.9402 - val_loss: 0.0555\n",
            "Epoch 95/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9491 - loss: 0.0485 - val_accuracy: 0.9402 - val_loss: 0.0555\n",
            "Epoch 96/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9491 - loss: 0.0485 - val_accuracy: 0.9402 - val_loss: 0.0555\n",
            "Epoch 97/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9491 - loss: 0.0485 - val_accuracy: 0.9402 - val_loss: 0.0555\n",
            "Epoch 98/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9491 - loss: 0.0484 - val_accuracy: 0.9402 - val_loss: 0.0555\n",
            "Epoch 99/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9491 - loss: 0.0484 - val_accuracy: 0.9402 - val_loss: 0.0555\n",
            "Epoch 100/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9491 - loss: 0.0484 - val_accuracy: 0.9402 - val_loss: 0.0554\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9555 - loss: 0.0428 \n",
            "[VALID] acc=0.940 | sens=0.043 (k=1/23, CI95=[0.008,0.210]) vs base 0.609 p=1.0000\n",
            "[TEST ] sens=0.043 (k=1/23, CI95=[0.008,0.210]) vs base 0.087 p=0.7248\n",
            "The years trained:  ['Year_2023', 'Year_2024']\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.8163 - loss: 0.1202 - val_accuracy: 0.9402 - val_loss: 0.0552\n",
            "Epoch 2/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0484 - val_accuracy: 0.9402 - val_loss: 0.0554\n",
            "Epoch 3/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0486 - val_accuracy: 0.9402 - val_loss: 0.0552\n",
            "Epoch 4/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0485 - val_accuracy: 0.9402 - val_loss: 0.0550\n",
            "Epoch 5/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0483 - val_accuracy: 0.9402 - val_loss: 0.0549\n",
            "Epoch 6/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0483 - val_accuracy: 0.9402 - val_loss: 0.0549\n",
            "Epoch 7/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9491 - loss: 0.0482 - val_accuracy: 0.9402 - val_loss: 0.0550\n",
            "Epoch 8/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0481 - val_accuracy: 0.9402 - val_loss: 0.0550\n",
            "Epoch 9/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0482 - val_accuracy: 0.9402 - val_loss: 0.0549\n",
            "Epoch 10/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0481 - val_accuracy: 0.9402 - val_loss: 0.0548\n",
            "Epoch 11/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0481 - val_accuracy: 0.9402 - val_loss: 0.0548\n",
            "Epoch 12/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0480 - val_accuracy: 0.9402 - val_loss: 0.0547\n",
            "Epoch 13/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0480 - val_accuracy: 0.9402 - val_loss: 0.0548\n",
            "Epoch 14/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0480 - val_accuracy: 0.9402 - val_loss: 0.0548\n",
            "Epoch 15/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0479 - val_accuracy: 0.9402 - val_loss: 0.0547\n",
            "Epoch 16/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0479 - val_accuracy: 0.9402 - val_loss: 0.0547\n",
            "Epoch 17/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9491 - loss: 0.0479 - val_accuracy: 0.9402 - val_loss: 0.0547\n",
            "Epoch 18/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0479 - val_accuracy: 0.9402 - val_loss: 0.0546\n",
            "Epoch 19/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.0479 - val_accuracy: 0.9402 - val_loss: 0.0547\n",
            "Epoch 20/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0479 - val_accuracy: 0.9402 - val_loss: 0.0547\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9555 - loss: 0.0426 \n",
            "[VALID] acc=0.940 | sens=0.261 (k=6/23, CI95=[0.125,0.465]) vs base 0.375 p=0.8273\n",
            "[TEST ] sens=0.087 (k=2/23, CI95=[0.024,0.268]) vs base 0.087 p=0.5000\n",
            "The years trained:  ['Year_2023', 'Year_2024']\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 24ms/step - accuracy: 0.8779 - loss: 0.1873 - val_accuracy: 0.9402 - val_loss: 0.0576\n",
            "Epoch 2/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9491 - loss: 0.0500 - val_accuracy: 0.9402 - val_loss: 0.0572\n",
            "Epoch 3/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9491 - loss: 0.0497 - val_accuracy: 0.9402 - val_loss: 0.0570\n",
            "Epoch 4/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9491 - loss: 0.0494 - val_accuracy: 0.9402 - val_loss: 0.0567\n",
            "Epoch 5/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9491 - loss: 0.0493 - val_accuracy: 0.9402 - val_loss: 0.0565\n",
            "Epoch 6/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9491 - loss: 0.0491 - val_accuracy: 0.9402 - val_loss: 0.0564\n",
            "Epoch 7/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9491 - loss: 0.0489 - val_accuracy: 0.9402 - val_loss: 0.0564\n",
            "Epoch 8/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9491 - loss: 0.0488 - val_accuracy: 0.9402 - val_loss: 0.0563\n",
            "Epoch 9/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9491 - loss: 0.0488 - val_accuracy: 0.9402 - val_loss: 0.0562\n",
            "Epoch 10/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9491 - loss: 0.0486 - val_accuracy: 0.9402 - val_loss: 0.0561\n",
            "Epoch 11/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9491 - loss: 0.0485 - val_accuracy: 0.9402 - val_loss: 0.0560\n",
            "Epoch 12/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9491 - loss: 0.0484 - val_accuracy: 0.9402 - val_loss: 0.0559\n",
            "Epoch 13/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9491 - loss: 0.0484 - val_accuracy: 0.9402 - val_loss: 0.0559\n",
            "Epoch 14/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9491 - loss: 0.0483 - val_accuracy: 0.9402 - val_loss: 0.0559\n",
            "Epoch 15/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9491 - loss: 0.0483 - val_accuracy: 0.9402 - val_loss: 0.0559\n",
            "Epoch 16/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9491 - loss: 0.0482 - val_accuracy: 0.9402 - val_loss: 0.0559\n",
            "Epoch 17/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9491 - loss: 0.0482 - val_accuracy: 0.9402 - val_loss: 0.0558\n",
            "Epoch 18/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9491 - loss: 0.0481 - val_accuracy: 0.9402 - val_loss: 0.0558\n",
            "Epoch 19/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9491 - loss: 0.0481 - val_accuracy: 0.9402 - val_loss: 0.0558\n",
            "Epoch 20/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9491 - loss: 0.0480 - val_accuracy: 0.9402 - val_loss: 0.0557\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9555 - loss: 0.0445 \n",
            "[VALID] acc=0.940 | sens=0.217 (k=5/23, CI95=[0.097,0.419]) vs base 0.375 p=0.9000\n",
            "[TEST ] sens=0.000 (k=0/23, CI95=[0.000,0.143]) vs base 0.087 p=0.9259\n",
            "The years trained:  ['Year_2023', 'Year_2024']\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.6042 - loss: 0.3038 - val_accuracy: 0.8750 - val_loss: 0.1075\n",
            "Epoch 2/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8741 - loss: 0.1001 - val_accuracy: 0.8750 - val_loss: 0.1045\n",
            "Epoch 3/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8803 - loss: 0.0976 - val_accuracy: 0.8750 - val_loss: 0.1023\n",
            "Epoch 4/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8803 - loss: 0.0954 - val_accuracy: 0.8750 - val_loss: 0.1002\n",
            "Epoch 5/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8825 - loss: 0.0933 - val_accuracy: 0.8750 - val_loss: 0.0983\n",
            "Epoch 6/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8825 - loss: 0.0913 - val_accuracy: 0.8750 - val_loss: 0.0965\n",
            "Epoch 7/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8875 - loss: 0.0895 - val_accuracy: 0.8750 - val_loss: 0.0947\n",
            "Epoch 8/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8887 - loss: 0.0877 - val_accuracy: 0.8750 - val_loss: 0.0931\n",
            "Epoch 9/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8887 - loss: 0.0860 - val_accuracy: 0.8804 - val_loss: 0.0916\n",
            "Epoch 10/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8887 - loss: 0.0845 - val_accuracy: 0.8804 - val_loss: 0.0902\n",
            "Epoch 11/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8893 - loss: 0.0831 - val_accuracy: 0.8804 - val_loss: 0.0889\n",
            "Epoch 12/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8900 - loss: 0.0817 - val_accuracy: 0.8967 - val_loss: 0.0876\n",
            "Epoch 13/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8912 - loss: 0.0805 - val_accuracy: 0.8967 - val_loss: 0.0865\n",
            "Epoch 14/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8951 - loss: 0.0793 - val_accuracy: 0.8967 - val_loss: 0.0853\n",
            "Epoch 15/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8951 - loss: 0.0781 - val_accuracy: 0.8967 - val_loss: 0.0843\n",
            "Epoch 16/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8951 - loss: 0.0771 - val_accuracy: 0.8967 - val_loss: 0.0833\n",
            "Epoch 17/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8951 - loss: 0.0761 - val_accuracy: 0.8967 - val_loss: 0.0823\n",
            "Epoch 18/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8973 - loss: 0.0751 - val_accuracy: 0.8967 - val_loss: 0.0814\n",
            "Epoch 19/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8978 - loss: 0.0742 - val_accuracy: 0.8967 - val_loss: 0.0805\n",
            "Epoch 20/20\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9014 - loss: 0.0733 - val_accuracy: 0.8967 - val_loss: 0.0797\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8914 - loss: 0.0713 \n",
            "[VALID] acc=0.897 | sens=0.043 (k=1/23, CI95=[0.008,0.210]) vs base 0.375 p=0.9979\n",
            "[TEST ] sens=0.000 (k=0/23, CI95=[0.000,0.143]) vs base 0.087 p=0.9259\n",
            "The years trained:  ['Year_2023', 'Year_2024']\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.8163 - loss: 0.1202 - val_accuracy: 0.9402 - val_loss: 0.0552\n",
            "Epoch 2/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9491 - loss: 0.0484 - val_accuracy: 0.9402 - val_loss: 0.0554\n",
            "Epoch 3/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0486 - val_accuracy: 0.9402 - val_loss: 0.0552\n",
            "Epoch 4/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0485 - val_accuracy: 0.9402 - val_loss: 0.0550\n",
            "Epoch 5/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0483 - val_accuracy: 0.9402 - val_loss: 0.0549\n",
            "Epoch 6/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0483 - val_accuracy: 0.9402 - val_loss: 0.0549\n",
            "Epoch 7/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0482 - val_accuracy: 0.9402 - val_loss: 0.0550\n",
            "Epoch 8/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0481 - val_accuracy: 0.9402 - val_loss: 0.0550\n",
            "Epoch 9/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9491 - loss: 0.0482 - val_accuracy: 0.9402 - val_loss: 0.0549\n",
            "Epoch 10/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0481 - val_accuracy: 0.9402 - val_loss: 0.0548\n",
            "Epoch 11/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0481 - val_accuracy: 0.9402 - val_loss: 0.0548\n",
            "Epoch 12/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0480 - val_accuracy: 0.9402 - val_loss: 0.0547\n",
            "Epoch 13/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9491 - loss: 0.0480 - val_accuracy: 0.9402 - val_loss: 0.0548\n",
            "Epoch 14/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9491 - loss: 0.0480 - val_accuracy: 0.9402 - val_loss: 0.0548\n",
            "Epoch 15/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9491 - loss: 0.0479 - val_accuracy: 0.9402 - val_loss: 0.0547\n",
            "Epoch 16/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0479 - val_accuracy: 0.9402 - val_loss: 0.0547\n",
            "Epoch 17/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9491 - loss: 0.0479 - val_accuracy: 0.9402 - val_loss: 0.0547\n",
            "Epoch 18/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0479 - val_accuracy: 0.9402 - val_loss: 0.0546\n",
            "Epoch 19/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0479 - val_accuracy: 0.9402 - val_loss: 0.0547\n",
            "Epoch 20/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0479 - val_accuracy: 0.9402 - val_loss: 0.0547\n",
            "Epoch 21/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0479 - val_accuracy: 0.9402 - val_loss: 0.0547\n",
            "Epoch 22/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9491 - loss: 0.0478 - val_accuracy: 0.9402 - val_loss: 0.0547\n",
            "Epoch 23/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0478 - val_accuracy: 0.9402 - val_loss: 0.0547\n",
            "Epoch 24/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9491 - loss: 0.0479 - val_accuracy: 0.9402 - val_loss: 0.0546\n",
            "Epoch 25/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9491 - loss: 0.0478 - val_accuracy: 0.9402 - val_loss: 0.0547\n",
            "Epoch 26/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9491 - loss: 0.0478 - val_accuracy: 0.9402 - val_loss: 0.0547\n",
            "Epoch 27/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9491 - loss: 0.0478 - val_accuracy: 0.9402 - val_loss: 0.0546\n",
            "Epoch 28/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9491 - loss: 0.0478 - val_accuracy: 0.9402 - val_loss: 0.0546\n",
            "Epoch 29/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9491 - loss: 0.0478 - val_accuracy: 0.9402 - val_loss: 0.0546\n",
            "Epoch 30/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9491 - loss: 0.0478 - val_accuracy: 0.9402 - val_loss: 0.0546\n",
            "Epoch 31/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9491 - loss: 0.0478 - val_accuracy: 0.9402 - val_loss: 0.0546\n",
            "Epoch 32/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9491 - loss: 0.0477 - val_accuracy: 0.9402 - val_loss: 0.0545\n",
            "Epoch 33/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9491 - loss: 0.0477 - val_accuracy: 0.9402 - val_loss: 0.0545\n",
            "Epoch 34/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0477 - val_accuracy: 0.9402 - val_loss: 0.0546\n",
            "Epoch 35/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0477 - val_accuracy: 0.9402 - val_loss: 0.0546\n",
            "Epoch 36/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9491 - loss: 0.0477 - val_accuracy: 0.9402 - val_loss: 0.0545\n",
            "Epoch 37/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0477 - val_accuracy: 0.9402 - val_loss: 0.0544\n",
            "Epoch 38/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0477 - val_accuracy: 0.9402 - val_loss: 0.0545\n",
            "Epoch 39/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0477 - val_accuracy: 0.9402 - val_loss: 0.0545\n",
            "Epoch 40/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0477 - val_accuracy: 0.9402 - val_loss: 0.0545\n",
            "Epoch 41/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9491 - loss: 0.0477 - val_accuracy: 0.9402 - val_loss: 0.0544\n",
            "Epoch 42/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0477 - val_accuracy: 0.9402 - val_loss: 0.0544\n",
            "Epoch 43/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9491 - loss: 0.0477 - val_accuracy: 0.9402 - val_loss: 0.0545\n",
            "Epoch 44/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0477 - val_accuracy: 0.9402 - val_loss: 0.0544\n",
            "Epoch 45/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0476 - val_accuracy: 0.9402 - val_loss: 0.0545\n",
            "Epoch 46/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9491 - loss: 0.0476 - val_accuracy: 0.9402 - val_loss: 0.0544\n",
            "Epoch 47/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0476 - val_accuracy: 0.9402 - val_loss: 0.0544\n",
            "Epoch 48/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9491 - loss: 0.0476 - val_accuracy: 0.9402 - val_loss: 0.0543\n",
            "Epoch 49/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0476 - val_accuracy: 0.9402 - val_loss: 0.0545\n",
            "Epoch 50/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9491 - loss: 0.0475 - val_accuracy: 0.9402 - val_loss: 0.0543\n",
            "Epoch 51/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0476 - val_accuracy: 0.9402 - val_loss: 0.0543\n",
            "Epoch 52/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0475 - val_accuracy: 0.9402 - val_loss: 0.0543\n",
            "Epoch 53/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9491 - loss: 0.0476 - val_accuracy: 0.9402 - val_loss: 0.0544\n",
            "Epoch 54/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9491 - loss: 0.0475 - val_accuracy: 0.9402 - val_loss: 0.0544\n",
            "Epoch 55/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9491 - loss: 0.0476 - val_accuracy: 0.9402 - val_loss: 0.0544\n",
            "Epoch 56/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0475 - val_accuracy: 0.9402 - val_loss: 0.0544\n",
            "Epoch 57/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0475 - val_accuracy: 0.9402 - val_loss: 0.0543\n",
            "Epoch 58/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9491 - loss: 0.0475 - val_accuracy: 0.9402 - val_loss: 0.0544\n",
            "Epoch 59/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0475 - val_accuracy: 0.9402 - val_loss: 0.0542\n",
            "Epoch 60/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0475 - val_accuracy: 0.9402 - val_loss: 0.0542\n",
            "Epoch 61/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0475 - val_accuracy: 0.9402 - val_loss: 0.0543\n",
            "Epoch 62/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9491 - loss: 0.0475 - val_accuracy: 0.9402 - val_loss: 0.0542\n",
            "Epoch 63/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9491 - loss: 0.0475 - val_accuracy: 0.9402 - val_loss: 0.0543\n",
            "Epoch 64/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9491 - loss: 0.0475 - val_accuracy: 0.9402 - val_loss: 0.0543\n",
            "Epoch 65/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9491 - loss: 0.0475 - val_accuracy: 0.9402 - val_loss: 0.0541\n",
            "Epoch 66/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9491 - loss: 0.0474 - val_accuracy: 0.9402 - val_loss: 0.0541\n",
            "Epoch 67/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0474 - val_accuracy: 0.9402 - val_loss: 0.0541\n",
            "Epoch 68/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9491 - loss: 0.0474 - val_accuracy: 0.9402 - val_loss: 0.0542\n",
            "Epoch 69/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0475 - val_accuracy: 0.9402 - val_loss: 0.0541\n",
            "Epoch 70/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9491 - loss: 0.0474 - val_accuracy: 0.9402 - val_loss: 0.0543\n",
            "Epoch 71/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9491 - loss: 0.0475 - val_accuracy: 0.9402 - val_loss: 0.0541\n",
            "Epoch 72/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9491 - loss: 0.0474 - val_accuracy: 0.9402 - val_loss: 0.0543\n",
            "Epoch 73/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9491 - loss: 0.0474 - val_accuracy: 0.9402 - val_loss: 0.0542\n",
            "Epoch 74/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9491 - loss: 0.0474 - val_accuracy: 0.9402 - val_loss: 0.0542\n",
            "Epoch 75/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9491 - loss: 0.0474 - val_accuracy: 0.9402 - val_loss: 0.0542\n",
            "Epoch 76/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9491 - loss: 0.0474 - val_accuracy: 0.9402 - val_loss: 0.0541\n",
            "Epoch 77/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9491 - loss: 0.0474 - val_accuracy: 0.9402 - val_loss: 0.0542\n",
            "Epoch 78/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9491 - loss: 0.0474 - val_accuracy: 0.9402 - val_loss: 0.0542\n",
            "Epoch 79/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9491 - loss: 0.0473 - val_accuracy: 0.9402 - val_loss: 0.0540\n",
            "Epoch 80/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9491 - loss: 0.0473 - val_accuracy: 0.9402 - val_loss: 0.0542\n",
            "Epoch 81/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0474 - val_accuracy: 0.9402 - val_loss: 0.0541\n",
            "Epoch 82/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0474 - val_accuracy: 0.9402 - val_loss: 0.0542\n",
            "Epoch 83/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0474 - val_accuracy: 0.9402 - val_loss: 0.0540\n",
            "Epoch 84/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9491 - loss: 0.0473 - val_accuracy: 0.9402 - val_loss: 0.0541\n",
            "Epoch 85/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9491 - loss: 0.0474 - val_accuracy: 0.9402 - val_loss: 0.0541\n",
            "Epoch 86/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0474 - val_accuracy: 0.9402 - val_loss: 0.0540\n",
            "Epoch 87/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0473 - val_accuracy: 0.9402 - val_loss: 0.0541\n",
            "Epoch 88/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9491 - loss: 0.0474 - val_accuracy: 0.9402 - val_loss: 0.0542\n",
            "Epoch 89/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9491 - loss: 0.0473 - val_accuracy: 0.9402 - val_loss: 0.0540\n",
            "Epoch 90/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0473 - val_accuracy: 0.9402 - val_loss: 0.0542\n",
            "Epoch 91/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9491 - loss: 0.0473 - val_accuracy: 0.9402 - val_loss: 0.0541\n",
            "Epoch 92/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9491 - loss: 0.0473 - val_accuracy: 0.9402 - val_loss: 0.0541\n",
            "Epoch 93/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9491 - loss: 0.0473 - val_accuracy: 0.9402 - val_loss: 0.0541\n",
            "Epoch 94/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0473 - val_accuracy: 0.9402 - val_loss: 0.0540\n",
            "Epoch 95/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0473 - val_accuracy: 0.9402 - val_loss: 0.0541\n",
            "Epoch 96/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9491 - loss: 0.0472 - val_accuracy: 0.9402 - val_loss: 0.0541\n",
            "Epoch 97/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0473 - val_accuracy: 0.9402 - val_loss: 0.0539\n",
            "Epoch 98/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9491 - loss: 0.0472 - val_accuracy: 0.9402 - val_loss: 0.0540\n",
            "Epoch 99/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9491 - loss: 0.0472 - val_accuracy: 0.9402 - val_loss: 0.0540\n",
            "Epoch 100/100\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9491 - loss: 0.0472 - val_accuracy: 0.9402 - val_loss: 0.0541\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9555 - loss: 0.0425 \n",
            "[VALID] acc=0.940 | sens=0.261 (k=6/23, CI95=[0.125,0.465]) vs base 0.375 p=0.8273\n",
            "[TEST ] sens=0.087 (k=2/23, CI95=[0.024,0.268]) vs base 0.087 p=0.5000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "yearsTrain = ['2022', '2023']\n",
        "yearsPredict = ['2024']\n",
        "display222324Df = createSeasonalDf(yearsTrain, yearsPredict, df_encoded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ls7fJWnenTIs",
        "outputId": "c074c91a-88ea-4851-c93b-5c7bad5eec12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The years trained:  ['Year_2022', 'Year_2023']\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.7852 - loss: 0.2701 - val_accuracy: 0.9716 - val_loss: 0.0329\n",
            "Epoch 2/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.0684 - val_accuracy: 0.9716 - val_loss: 0.0402\n",
            "Epoch 3/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.0595 - val_accuracy: 0.9716 - val_loss: 0.0297\n",
            "Epoch 4/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0594 - val_accuracy: 0.9716 - val_loss: 0.0254\n",
            "Epoch 5/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.0614 - val_accuracy: 0.9716 - val_loss: 0.0265\n",
            "Epoch 6/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9455 - loss: 0.0599 - val_accuracy: 0.9716 - val_loss: 0.0230\n",
            "Epoch 7/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9455 - loss: 0.0572 - val_accuracy: 0.9716 - val_loss: 0.0214\n",
            "Epoch 8/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9455 - loss: 0.0532 - val_accuracy: 0.9716 - val_loss: 0.0201\n",
            "Epoch 9/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9455 - loss: 0.0489 - val_accuracy: 0.9716 - val_loss: 0.0187\n",
            "Epoch 10/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9455 - loss: 0.0450 - val_accuracy: 0.9716 - val_loss: 0.0178\n",
            "Epoch 11/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9455 - loss: 0.0415 - val_accuracy: 0.9716 - val_loss: 0.0207\n",
            "Epoch 12/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9451 - loss: 0.0372 - val_accuracy: 0.9716 - val_loss: 0.0195\n",
            "Epoch 13/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9479 - loss: 0.0344 - val_accuracy: 0.9716 - val_loss: 0.0196\n",
            "Epoch 14/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9578 - loss: 0.0312 - val_accuracy: 0.9773 - val_loss: 0.0172\n",
            "Epoch 15/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9756 - loss: 0.0280 - val_accuracy: 0.9830 - val_loss: 0.0150\n",
            "Epoch 16/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9772 - loss: 0.0259 - val_accuracy: 0.9886 - val_loss: 0.0140\n",
            "Epoch 17/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9772 - loss: 0.0248 - val_accuracy: 0.9886 - val_loss: 0.0135\n",
            "Epoch 18/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9772 - loss: 0.0242 - val_accuracy: 0.9886 - val_loss: 0.0136\n",
            "Epoch 19/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9772 - loss: 0.0239 - val_accuracy: 0.9886 - val_loss: 0.0139\n",
            "Epoch 20/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9772 - loss: 0.0239 - val_accuracy: 0.9886 - val_loss: 0.0132\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9586 - loss: 0.0409 \n",
            "[VALID] acc=0.989 | sens=0.208 (k=5/24, CI95=[0.092,0.405]) vs base 0.864 p=1.0000\n",
            "[TEST ] sens=0.375 (k=9/24, CI95=[0.212,0.573]) vs base 0.375 p=0.5000\n",
            "The years trained:  ['Year_2022', 'Year_2023']\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.8725 - loss: 0.1478 - val_accuracy: 0.9716 - val_loss: 0.0303\n",
            "Epoch 2/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.0543 - val_accuracy: 0.9716 - val_loss: 0.0283\n",
            "Epoch 3/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0516 - val_accuracy: 0.9716 - val_loss: 0.0291\n",
            "Epoch 4/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0508 - val_accuracy: 0.9716 - val_loss: 0.0281\n",
            "Epoch 5/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.0497 - val_accuracy: 0.9716 - val_loss: 0.0290\n",
            "Epoch 6/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.0490 - val_accuracy: 0.9716 - val_loss: 0.0316\n",
            "Epoch 7/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.0482 - val_accuracy: 0.9716 - val_loss: 0.0315\n",
            "Epoch 8/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0445 - val_accuracy: 0.9716 - val_loss: 0.0472\n",
            "Epoch 9/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0479 - val_accuracy: 0.9716 - val_loss: 0.0217\n",
            "Epoch 10/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9458 - loss: 0.0374 - val_accuracy: 0.9659 - val_loss: 0.0217\n",
            "Epoch 11/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9497 - loss: 0.0337 - val_accuracy: 0.9886 - val_loss: 0.0276\n",
            "Epoch 12/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9554 - loss: 0.0328 - val_accuracy: 0.9886 - val_loss: 0.0197\n",
            "Epoch 13/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9770 - loss: 0.0283 - val_accuracy: 0.9886 - val_loss: 0.0208\n",
            "Epoch 14/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9770 - loss: 0.0266 - val_accuracy: 0.9886 - val_loss: 0.0185\n",
            "Epoch 15/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9769 - loss: 0.0260 - val_accuracy: 0.9886 - val_loss: 0.0151\n",
            "Epoch 16/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9764 - loss: 0.0279 - val_accuracy: 0.9716 - val_loss: 0.0284\n",
            "Epoch 17/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9683 - loss: 0.0322 - val_accuracy: 0.9886 - val_loss: 0.0151\n",
            "Epoch 18/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9742 - loss: 0.0233 - val_accuracy: 0.9886 - val_loss: 0.0205\n",
            "Epoch 19/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9755 - loss: 0.0268 - val_accuracy: 0.9830 - val_loss: 0.0139\n",
            "Epoch 20/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9772 - loss: 0.0227 - val_accuracy: 0.9886 - val_loss: 0.0161\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9643 - loss: 0.0441 \n",
            "[VALID] acc=0.989 | sens=0.208 (k=5/24, CI95=[0.092,0.405]) vs base 0.864 p=1.0000\n",
            "[TEST ] sens=0.375 (k=9/24, CI95=[0.212,0.573]) vs base 0.375 p=0.5000\n",
            "The years trained:  ['Year_2022', 'Year_2023']\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.8806 - loss: 0.2183 - val_accuracy: 0.9716 - val_loss: 0.0453\n",
            "Epoch 2/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9455 - loss: 0.0613 - val_accuracy: 0.9716 - val_loss: 0.0337\n",
            "Epoch 3/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9455 - loss: 0.0529 - val_accuracy: 0.9716 - val_loss: 0.0319\n",
            "Epoch 4/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9455 - loss: 0.0522 - val_accuracy: 0.9716 - val_loss: 0.0305\n",
            "Epoch 5/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9455 - loss: 0.0516 - val_accuracy: 0.9716 - val_loss: 0.0301\n",
            "Epoch 6/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9455 - loss: 0.0511 - val_accuracy: 0.9716 - val_loss: 0.0300\n",
            "Epoch 7/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9455 - loss: 0.0503 - val_accuracy: 0.9716 - val_loss: 0.0291\n",
            "Epoch 8/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9455 - loss: 0.0491 - val_accuracy: 0.9716 - val_loss: 0.0263\n",
            "Epoch 9/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9455 - loss: 0.0474 - val_accuracy: 0.9716 - val_loss: 0.0240\n",
            "Epoch 10/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9455 - loss: 0.0449 - val_accuracy: 0.9716 - val_loss: 0.0326\n",
            "Epoch 11/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9455 - loss: 0.0407 - val_accuracy: 0.9716 - val_loss: 0.0192\n",
            "Epoch 12/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9467 - loss: 0.0342 - val_accuracy: 0.9716 - val_loss: 0.0166\n",
            "Epoch 13/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9524 - loss: 0.0306 - val_accuracy: 0.9659 - val_loss: 0.0176\n",
            "Epoch 14/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9663 - loss: 0.0284 - val_accuracy: 0.9830 - val_loss: 0.0137\n",
            "Epoch 15/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9672 - loss: 0.0254 - val_accuracy: 0.9886 - val_loss: 0.0134\n",
            "Epoch 16/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9772 - loss: 0.0231 - val_accuracy: 0.9886 - val_loss: 0.0123\n",
            "Epoch 17/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9772 - loss: 0.0223 - val_accuracy: 0.9886 - val_loss: 0.0122\n",
            "Epoch 18/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9772 - loss: 0.0216 - val_accuracy: 0.9886 - val_loss: 0.0121\n",
            "Epoch 19/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9772 - loss: 0.0214 - val_accuracy: 0.9886 - val_loss: 0.0120\n",
            "Epoch 20/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9772 - loss: 0.0206 - val_accuracy: 0.9886 - val_loss: 0.0120\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9586 - loss: 0.0405 \n",
            "[VALID] acc=0.989 | sens=0.208 (k=5/24, CI95=[0.092,0.405]) vs base 0.864 p=1.0000\n",
            "[TEST ] sens=0.375 (k=9/24, CI95=[0.212,0.573]) vs base 0.375 p=0.5000\n",
            "The years trained:  ['Year_2022', 'Year_2023']\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.7852 - loss: 0.2701 - val_accuracy: 0.9716 - val_loss: 0.0329\n",
            "Epoch 2/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0684 - val_accuracy: 0.9716 - val_loss: 0.0402\n",
            "Epoch 3/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.0595 - val_accuracy: 0.9716 - val_loss: 0.0297\n",
            "Epoch 4/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.0594 - val_accuracy: 0.9716 - val_loss: 0.0254\n",
            "Epoch 5/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.0614 - val_accuracy: 0.9716 - val_loss: 0.0265\n",
            "Epoch 6/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.0599 - val_accuracy: 0.9716 - val_loss: 0.0230\n",
            "Epoch 7/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0572 - val_accuracy: 0.9716 - val_loss: 0.0214\n",
            "Epoch 8/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0532 - val_accuracy: 0.9716 - val_loss: 0.0201\n",
            "Epoch 9/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.0489 - val_accuracy: 0.9716 - val_loss: 0.0187\n",
            "Epoch 10/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.0450 - val_accuracy: 0.9716 - val_loss: 0.0178\n",
            "Epoch 11/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0415 - val_accuracy: 0.9716 - val_loss: 0.0207\n",
            "Epoch 12/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9451 - loss: 0.0372 - val_accuracy: 0.9716 - val_loss: 0.0195\n",
            "Epoch 13/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9479 - loss: 0.0344 - val_accuracy: 0.9716 - val_loss: 0.0196\n",
            "Epoch 14/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9578 - loss: 0.0312 - val_accuracy: 0.9773 - val_loss: 0.0172\n",
            "Epoch 15/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9756 - loss: 0.0280 - val_accuracy: 0.9830 - val_loss: 0.0150\n",
            "Epoch 16/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9772 - loss: 0.0259 - val_accuracy: 0.9886 - val_loss: 0.0140\n",
            "Epoch 17/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9772 - loss: 0.0248 - val_accuracy: 0.9886 - val_loss: 0.0135\n",
            "Epoch 18/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9772 - loss: 0.0242 - val_accuracy: 0.9886 - val_loss: 0.0136\n",
            "Epoch 19/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9772 - loss: 0.0239 - val_accuracy: 0.9886 - val_loss: 0.0139\n",
            "Epoch 20/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9772 - loss: 0.0239 - val_accuracy: 0.9886 - val_loss: 0.0132\n",
            "Epoch 21/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9772 - loss: 0.0234 - val_accuracy: 0.9886 - val_loss: 0.0141\n",
            "Epoch 22/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9772 - loss: 0.0238 - val_accuracy: 0.9886 - val_loss: 0.0144\n",
            "Epoch 23/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9772 - loss: 0.0238 - val_accuracy: 0.9886 - val_loss: 0.0147\n",
            "Epoch 24/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9772 - loss: 0.0240 - val_accuracy: 0.9886 - val_loss: 0.0149\n",
            "Epoch 25/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9772 - loss: 0.0239 - val_accuracy: 0.9886 - val_loss: 0.0144\n",
            "Epoch 26/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9772 - loss: 0.0236 - val_accuracy: 0.9886 - val_loss: 0.0153\n",
            "Epoch 27/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9772 - loss: 0.0237 - val_accuracy: 0.9886 - val_loss: 0.0160\n",
            "Epoch 28/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9772 - loss: 0.0242 - val_accuracy: 0.9886 - val_loss: 0.0155\n",
            "Epoch 29/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9772 - loss: 0.0235 - val_accuracy: 0.9886 - val_loss: 0.0149\n",
            "Epoch 30/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9772 - loss: 0.0232 - val_accuracy: 0.9886 - val_loss: 0.0157\n",
            "Epoch 31/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9772 - loss: 0.0236 - val_accuracy: 0.9886 - val_loss: 0.0152\n",
            "Epoch 32/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9772 - loss: 0.0232 - val_accuracy: 0.9886 - val_loss: 0.0152\n",
            "Epoch 33/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9772 - loss: 0.0231 - val_accuracy: 0.9886 - val_loss: 0.0153\n",
            "Epoch 34/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9772 - loss: 0.0231 - val_accuracy: 0.9886 - val_loss: 0.0152\n",
            "Epoch 35/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9772 - loss: 0.0230 - val_accuracy: 0.9886 - val_loss: 0.0152\n",
            "Epoch 36/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9772 - loss: 0.0229 - val_accuracy: 0.9886 - val_loss: 0.0149\n",
            "Epoch 37/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9772 - loss: 0.0227 - val_accuracy: 0.9886 - val_loss: 0.0150\n",
            "Epoch 38/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9772 - loss: 0.0227 - val_accuracy: 0.9886 - val_loss: 0.0149\n",
            "Epoch 39/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9772 - loss: 0.0225 - val_accuracy: 0.9886 - val_loss: 0.0148\n",
            "Epoch 40/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9772 - loss: 0.0224 - val_accuracy: 0.9886 - val_loss: 0.0147\n",
            "Epoch 41/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9772 - loss: 0.0223 - val_accuracy: 0.9886 - val_loss: 0.0146\n",
            "Epoch 42/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9772 - loss: 0.0222 - val_accuracy: 0.9886 - val_loss: 0.0147\n",
            "Epoch 43/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9772 - loss: 0.0222 - val_accuracy: 0.9886 - val_loss: 0.0146\n",
            "Epoch 44/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9772 - loss: 0.0220 - val_accuracy: 0.9886 - val_loss: 0.0146\n",
            "Epoch 45/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9772 - loss: 0.0220 - val_accuracy: 0.9886 - val_loss: 0.0146\n",
            "Epoch 46/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9772 - loss: 0.0219 - val_accuracy: 0.9886 - val_loss: 0.0144\n",
            "Epoch 47/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9772 - loss: 0.0217 - val_accuracy: 0.9886 - val_loss: 0.0144\n",
            "Epoch 48/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9772 - loss: 0.0217 - val_accuracy: 0.9886 - val_loss: 0.0144\n",
            "Epoch 49/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9772 - loss: 0.0211 - val_accuracy: 0.9886 - val_loss: 0.0147\n",
            "Epoch 50/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9772 - loss: 0.0219 - val_accuracy: 0.9886 - val_loss: 0.0140\n",
            "Epoch 51/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9772 - loss: 0.0212 - val_accuracy: 0.9886 - val_loss: 0.0142\n",
            "Epoch 52/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9772 - loss: 0.0213 - val_accuracy: 0.9886 - val_loss: 0.0143\n",
            "Epoch 53/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9772 - loss: 0.0212 - val_accuracy: 0.9886 - val_loss: 0.0141\n",
            "Epoch 54/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9772 - loss: 0.0210 - val_accuracy: 0.9886 - val_loss: 0.0137\n",
            "Epoch 55/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9772 - loss: 0.0207 - val_accuracy: 0.9886 - val_loss: 0.0141\n",
            "Epoch 56/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9772 - loss: 0.0208 - val_accuracy: 0.9886 - val_loss: 0.0139\n",
            "Epoch 57/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9772 - loss: 0.0206 - val_accuracy: 0.9886 - val_loss: 0.0140\n",
            "Epoch 58/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9772 - loss: 0.0207 - val_accuracy: 0.9886 - val_loss: 0.0140\n",
            "Epoch 59/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9772 - loss: 0.0205 - val_accuracy: 0.9886 - val_loss: 0.0141\n",
            "Epoch 60/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9772 - loss: 0.0205 - val_accuracy: 0.9886 - val_loss: 0.0136\n",
            "Epoch 61/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9772 - loss: 0.0201 - val_accuracy: 0.9886 - val_loss: 0.0141\n",
            "Epoch 62/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9772 - loss: 0.0203 - val_accuracy: 0.9886 - val_loss: 0.0140\n",
            "Epoch 63/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9772 - loss: 0.0200 - val_accuracy: 0.9886 - val_loss: 0.0150\n",
            "Epoch 64/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9772 - loss: 0.0218 - val_accuracy: 0.9886 - val_loss: 0.0162\n",
            "Epoch 65/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9772 - loss: 0.0207 - val_accuracy: 0.9886 - val_loss: 0.0136\n",
            "Epoch 66/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9772 - loss: 0.0194 - val_accuracy: 0.9886 - val_loss: 0.0139\n",
            "Epoch 67/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9772 - loss: 0.0198 - val_accuracy: 0.9886 - val_loss: 0.0140\n",
            "Epoch 68/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9772 - loss: 0.0197 - val_accuracy: 0.9886 - val_loss: 0.0140\n",
            "Epoch 69/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9772 - loss: 0.0197 - val_accuracy: 0.9886 - val_loss: 0.0140\n",
            "Epoch 70/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9772 - loss: 0.0196 - val_accuracy: 0.9886 - val_loss: 0.0140\n",
            "Epoch 71/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9772 - loss: 0.0196 - val_accuracy: 0.9886 - val_loss: 0.0140\n",
            "Epoch 72/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9772 - loss: 0.0194 - val_accuracy: 0.9886 - val_loss: 0.0142\n",
            "Epoch 73/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9772 - loss: 0.0194 - val_accuracy: 0.9886 - val_loss: 0.0141\n",
            "Epoch 74/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9772 - loss: 0.0193 - val_accuracy: 0.9886 - val_loss: 0.0144\n",
            "Epoch 75/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9795 - loss: 0.0194 - val_accuracy: 0.9886 - val_loss: 0.0141\n",
            "Epoch 76/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9795 - loss: 0.0192 - val_accuracy: 0.9886 - val_loss: 0.0147\n",
            "Epoch 77/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9795 - loss: 0.0193 - val_accuracy: 0.9886 - val_loss: 0.0141\n",
            "Epoch 78/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9817 - loss: 0.0190 - val_accuracy: 0.9886 - val_loss: 0.0147\n",
            "Epoch 79/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9817 - loss: 0.0192 - val_accuracy: 0.9886 - val_loss: 0.0143\n",
            "Epoch 80/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9817 - loss: 0.0189 - val_accuracy: 0.9886 - val_loss: 0.0146\n",
            "Epoch 81/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9817 - loss: 0.0189 - val_accuracy: 0.9886 - val_loss: 0.0143\n",
            "Epoch 82/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9817 - loss: 0.0186 - val_accuracy: 0.9830 - val_loss: 0.0147\n",
            "Epoch 83/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9817 - loss: 0.0190 - val_accuracy: 0.9886 - val_loss: 0.0140\n",
            "Epoch 84/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9817 - loss: 0.0183 - val_accuracy: 0.9830 - val_loss: 0.0149\n",
            "Epoch 85/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9817 - loss: 0.0189 - val_accuracy: 0.9830 - val_loss: 0.0145\n",
            "Epoch 86/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9817 - loss: 0.0186 - val_accuracy: 0.9830 - val_loss: 0.0147\n",
            "Epoch 87/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9817 - loss: 0.0186 - val_accuracy: 0.9830 - val_loss: 0.0146\n",
            "Epoch 88/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9817 - loss: 0.0186 - val_accuracy: 0.9830 - val_loss: 0.0153\n",
            "Epoch 89/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9817 - loss: 0.0187 - val_accuracy: 0.9830 - val_loss: 0.0147\n",
            "Epoch 90/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9817 - loss: 0.0185 - val_accuracy: 0.9830 - val_loss: 0.0151\n",
            "Epoch 91/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9817 - loss: 0.0189 - val_accuracy: 0.9830 - val_loss: 0.0152\n",
            "Epoch 92/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9817 - loss: 0.0190 - val_accuracy: 0.9830 - val_loss: 0.0157\n",
            "Epoch 93/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9817 - loss: 0.0191 - val_accuracy: 0.9830 - val_loss: 0.0157\n",
            "Epoch 94/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9817 - loss: 0.0193 - val_accuracy: 0.9830 - val_loss: 0.0168\n",
            "Epoch 95/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9817 - loss: 0.0197 - val_accuracy: 0.9830 - val_loss: 0.0187\n",
            "Epoch 96/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9824 - loss: 0.0206 - val_accuracy: 0.9830 - val_loss: 0.0242\n",
            "Epoch 97/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9836 - loss: 0.0231 - val_accuracy: 0.9830 - val_loss: 0.0324\n",
            "Epoch 98/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9820 - loss: 0.0272 - val_accuracy: 0.9830 - val_loss: 0.0303\n",
            "Epoch 99/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9798 - loss: 0.0297 - val_accuracy: 0.9830 - val_loss: 0.0148\n",
            "Epoch 100/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9782 - loss: 0.0238 - val_accuracy: 0.9886 - val_loss: 0.0135\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9621 - loss: 0.0387 \n",
            "[VALID] acc=0.989 | sens=0.167 (k=4/24, CI95=[0.067,0.359]) vs base 0.864 p=1.0000\n",
            "[TEST ] sens=0.375 (k=9/24, CI95=[0.212,0.573]) vs base 0.375 p=0.5000\n",
            "The years trained:  ['Year_2022', 'Year_2023']\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.7852 - loss: 0.2701 - val_accuracy: 0.9716 - val_loss: 0.0329\n",
            "Epoch 2/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0684 - val_accuracy: 0.9716 - val_loss: 0.0402\n",
            "Epoch 3/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.0595 - val_accuracy: 0.9716 - val_loss: 0.0297\n",
            "Epoch 4/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0594 - val_accuracy: 0.9716 - val_loss: 0.0254\n",
            "Epoch 5/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0614 - val_accuracy: 0.9716 - val_loss: 0.0265\n",
            "Epoch 6/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.0599 - val_accuracy: 0.9716 - val_loss: 0.0230\n",
            "Epoch 7/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.0572 - val_accuracy: 0.9716 - val_loss: 0.0214\n",
            "Epoch 8/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.0532 - val_accuracy: 0.9716 - val_loss: 0.0201\n",
            "Epoch 9/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.0489 - val_accuracy: 0.9716 - val_loss: 0.0187\n",
            "Epoch 10/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0450 - val_accuracy: 0.9716 - val_loss: 0.0178\n",
            "Epoch 11/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.0415 - val_accuracy: 0.9716 - val_loss: 0.0207\n",
            "Epoch 12/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9451 - loss: 0.0372 - val_accuracy: 0.9716 - val_loss: 0.0195\n",
            "Epoch 13/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9479 - loss: 0.0344 - val_accuracy: 0.9716 - val_loss: 0.0196\n",
            "Epoch 14/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9578 - loss: 0.0312 - val_accuracy: 0.9773 - val_loss: 0.0172\n",
            "Epoch 15/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9756 - loss: 0.0280 - val_accuracy: 0.9830 - val_loss: 0.0150\n",
            "Epoch 16/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9772 - loss: 0.0259 - val_accuracy: 0.9886 - val_loss: 0.0140\n",
            "Epoch 17/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9772 - loss: 0.0248 - val_accuracy: 0.9886 - val_loss: 0.0135\n",
            "Epoch 18/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9772 - loss: 0.0242 - val_accuracy: 0.9886 - val_loss: 0.0136\n",
            "Epoch 19/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9772 - loss: 0.0239 - val_accuracy: 0.9886 - val_loss: 0.0139\n",
            "Epoch 20/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9772 - loss: 0.0239 - val_accuracy: 0.9886 - val_loss: 0.0132\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9586 - loss: 0.0409 \n",
            "[VALID] acc=0.989 | sens=0.208 (k=5/24, CI95=[0.092,0.405]) vs base 0.756 p=0.9999\n",
            "[TEST ] sens=0.375 (k=9/24, CI95=[0.212,0.573]) vs base 0.375 p=0.5000\n",
            "The years trained:  ['Year_2022', 'Year_2023']\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.8725 - loss: 0.1478 - val_accuracy: 0.9716 - val_loss: 0.0303\n",
            "Epoch 2/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9455 - loss: 0.0543 - val_accuracy: 0.9716 - val_loss: 0.0283\n",
            "Epoch 3/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9455 - loss: 0.0516 - val_accuracy: 0.9716 - val_loss: 0.0291\n",
            "Epoch 4/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9455 - loss: 0.0508 - val_accuracy: 0.9716 - val_loss: 0.0281\n",
            "Epoch 5/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9455 - loss: 0.0497 - val_accuracy: 0.9716 - val_loss: 0.0290\n",
            "Epoch 6/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9455 - loss: 0.0490 - val_accuracy: 0.9716 - val_loss: 0.0316\n",
            "Epoch 7/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9455 - loss: 0.0482 - val_accuracy: 0.9716 - val_loss: 0.0315\n",
            "Epoch 8/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9455 - loss: 0.0445 - val_accuracy: 0.9716 - val_loss: 0.0472\n",
            "Epoch 9/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9455 - loss: 0.0479 - val_accuracy: 0.9716 - val_loss: 0.0217\n",
            "Epoch 10/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9458 - loss: 0.0374 - val_accuracy: 0.9659 - val_loss: 0.0217\n",
            "Epoch 11/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9497 - loss: 0.0337 - val_accuracy: 0.9886 - val_loss: 0.0276\n",
            "Epoch 12/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9554 - loss: 0.0328 - val_accuracy: 0.9886 - val_loss: 0.0197\n",
            "Epoch 13/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9770 - loss: 0.0283 - val_accuracy: 0.9886 - val_loss: 0.0208\n",
            "Epoch 14/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9770 - loss: 0.0266 - val_accuracy: 0.9886 - val_loss: 0.0185\n",
            "Epoch 15/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9769 - loss: 0.0260 - val_accuracy: 0.9886 - val_loss: 0.0151\n",
            "Epoch 16/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9764 - loss: 0.0279 - val_accuracy: 0.9716 - val_loss: 0.0284\n",
            "Epoch 17/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9683 - loss: 0.0322 - val_accuracy: 0.9886 - val_loss: 0.0151\n",
            "Epoch 18/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9742 - loss: 0.0233 - val_accuracy: 0.9886 - val_loss: 0.0205\n",
            "Epoch 19/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9755 - loss: 0.0268 - val_accuracy: 0.9830 - val_loss: 0.0139\n",
            "Epoch 20/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9772 - loss: 0.0227 - val_accuracy: 0.9886 - val_loss: 0.0161\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9643 - loss: 0.0441 \n",
            "[VALID] acc=0.989 | sens=0.208 (k=5/24, CI95=[0.092,0.405]) vs base 0.756 p=0.9999\n",
            "[TEST ] sens=0.375 (k=9/24, CI95=[0.212,0.573]) vs base 0.375 p=0.5000\n",
            "The years trained:  ['Year_2022', 'Year_2023']\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.8806 - loss: 0.2183 - val_accuracy: 0.9716 - val_loss: 0.0453\n",
            "Epoch 2/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.0613 - val_accuracy: 0.9716 - val_loss: 0.0337\n",
            "Epoch 3/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0529 - val_accuracy: 0.9716 - val_loss: 0.0319\n",
            "Epoch 4/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0522 - val_accuracy: 0.9716 - val_loss: 0.0305\n",
            "Epoch 5/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.0516 - val_accuracy: 0.9716 - val_loss: 0.0301\n",
            "Epoch 6/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0511 - val_accuracy: 0.9716 - val_loss: 0.0300\n",
            "Epoch 7/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0503 - val_accuracy: 0.9716 - val_loss: 0.0291\n",
            "Epoch 8/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.0491 - val_accuracy: 0.9716 - val_loss: 0.0263\n",
            "Epoch 9/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0474 - val_accuracy: 0.9716 - val_loss: 0.0240\n",
            "Epoch 10/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.0449 - val_accuracy: 0.9716 - val_loss: 0.0326\n",
            "Epoch 11/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.0407 - val_accuracy: 0.9716 - val_loss: 0.0192\n",
            "Epoch 12/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9467 - loss: 0.0342 - val_accuracy: 0.9716 - val_loss: 0.0166\n",
            "Epoch 13/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9524 - loss: 0.0306 - val_accuracy: 0.9659 - val_loss: 0.0176\n",
            "Epoch 14/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9663 - loss: 0.0284 - val_accuracy: 0.9830 - val_loss: 0.0137\n",
            "Epoch 15/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9672 - loss: 0.0254 - val_accuracy: 0.9886 - val_loss: 0.0134\n",
            "Epoch 16/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9772 - loss: 0.0231 - val_accuracy: 0.9886 - val_loss: 0.0123\n",
            "Epoch 17/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9772 - loss: 0.0223 - val_accuracy: 0.9886 - val_loss: 0.0122\n",
            "Epoch 18/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9772 - loss: 0.0216 - val_accuracy: 0.9886 - val_loss: 0.0121\n",
            "Epoch 19/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9772 - loss: 0.0214 - val_accuracy: 0.9886 - val_loss: 0.0120\n",
            "Epoch 20/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9772 - loss: 0.0206 - val_accuracy: 0.9886 - val_loss: 0.0120\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9586 - loss: 0.0405 \n",
            "[VALID] acc=0.989 | sens=0.208 (k=5/24, CI95=[0.092,0.405]) vs base 0.756 p=0.9999\n",
            "[TEST ] sens=0.375 (k=9/24, CI95=[0.212,0.573]) vs base 0.375 p=0.5000\n",
            "The years trained:  ['Year_2022', 'Year_2023']\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.7852 - loss: 0.2701 - val_accuracy: 0.9716 - val_loss: 0.0329\n",
            "Epoch 2/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9455 - loss: 0.0684 - val_accuracy: 0.9716 - val_loss: 0.0402\n",
            "Epoch 3/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9455 - loss: 0.0595 - val_accuracy: 0.9716 - val_loss: 0.0297\n",
            "Epoch 4/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9455 - loss: 0.0594 - val_accuracy: 0.9716 - val_loss: 0.0254\n",
            "Epoch 5/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9455 - loss: 0.0614 - val_accuracy: 0.9716 - val_loss: 0.0265\n",
            "Epoch 6/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9455 - loss: 0.0599 - val_accuracy: 0.9716 - val_loss: 0.0230\n",
            "Epoch 7/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9455 - loss: 0.0572 - val_accuracy: 0.9716 - val_loss: 0.0214\n",
            "Epoch 8/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9455 - loss: 0.0532 - val_accuracy: 0.9716 - val_loss: 0.0201\n",
            "Epoch 9/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9455 - loss: 0.0489 - val_accuracy: 0.9716 - val_loss: 0.0187\n",
            "Epoch 10/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.0450 - val_accuracy: 0.9716 - val_loss: 0.0178\n",
            "Epoch 11/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0415 - val_accuracy: 0.9716 - val_loss: 0.0207\n",
            "Epoch 12/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9451 - loss: 0.0372 - val_accuracy: 0.9716 - val_loss: 0.0195\n",
            "Epoch 13/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9479 - loss: 0.0344 - val_accuracy: 0.9716 - val_loss: 0.0196\n",
            "Epoch 14/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9578 - loss: 0.0312 - val_accuracy: 0.9773 - val_loss: 0.0172\n",
            "Epoch 15/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9756 - loss: 0.0280 - val_accuracy: 0.9830 - val_loss: 0.0150\n",
            "Epoch 16/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9772 - loss: 0.0259 - val_accuracy: 0.9886 - val_loss: 0.0140\n",
            "Epoch 17/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9772 - loss: 0.0248 - val_accuracy: 0.9886 - val_loss: 0.0135\n",
            "Epoch 18/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9772 - loss: 0.0242 - val_accuracy: 0.9886 - val_loss: 0.0136\n",
            "Epoch 19/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9772 - loss: 0.0239 - val_accuracy: 0.9886 - val_loss: 0.0139\n",
            "Epoch 20/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9772 - loss: 0.0239 - val_accuracy: 0.9886 - val_loss: 0.0132\n",
            "Epoch 21/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9772 - loss: 0.0234 - val_accuracy: 0.9886 - val_loss: 0.0141\n",
            "Epoch 22/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9772 - loss: 0.0238 - val_accuracy: 0.9886 - val_loss: 0.0144\n",
            "Epoch 23/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9772 - loss: 0.0238 - val_accuracy: 0.9886 - val_loss: 0.0147\n",
            "Epoch 24/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9772 - loss: 0.0240 - val_accuracy: 0.9886 - val_loss: 0.0149\n",
            "Epoch 25/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9772 - loss: 0.0239 - val_accuracy: 0.9886 - val_loss: 0.0144\n",
            "Epoch 26/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9772 - loss: 0.0236 - val_accuracy: 0.9886 - val_loss: 0.0153\n",
            "Epoch 27/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9772 - loss: 0.0237 - val_accuracy: 0.9886 - val_loss: 0.0160\n",
            "Epoch 28/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9772 - loss: 0.0242 - val_accuracy: 0.9886 - val_loss: 0.0155\n",
            "Epoch 29/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9772 - loss: 0.0235 - val_accuracy: 0.9886 - val_loss: 0.0149\n",
            "Epoch 30/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9772 - loss: 0.0232 - val_accuracy: 0.9886 - val_loss: 0.0157\n",
            "Epoch 31/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9772 - loss: 0.0236 - val_accuracy: 0.9886 - val_loss: 0.0152\n",
            "Epoch 32/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9772 - loss: 0.0232 - val_accuracy: 0.9886 - val_loss: 0.0152\n",
            "Epoch 33/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9772 - loss: 0.0231 - val_accuracy: 0.9886 - val_loss: 0.0153\n",
            "Epoch 34/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9772 - loss: 0.0231 - val_accuracy: 0.9886 - val_loss: 0.0152\n",
            "Epoch 35/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9772 - loss: 0.0230 - val_accuracy: 0.9886 - val_loss: 0.0152\n",
            "Epoch 36/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9772 - loss: 0.0229 - val_accuracy: 0.9886 - val_loss: 0.0149\n",
            "Epoch 37/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9772 - loss: 0.0227 - val_accuracy: 0.9886 - val_loss: 0.0150\n",
            "Epoch 38/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9772 - loss: 0.0227 - val_accuracy: 0.9886 - val_loss: 0.0149\n",
            "Epoch 39/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9772 - loss: 0.0225 - val_accuracy: 0.9886 - val_loss: 0.0148\n",
            "Epoch 40/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9772 - loss: 0.0224 - val_accuracy: 0.9886 - val_loss: 0.0147\n",
            "Epoch 41/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9772 - loss: 0.0223 - val_accuracy: 0.9886 - val_loss: 0.0146\n",
            "Epoch 42/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9772 - loss: 0.0222 - val_accuracy: 0.9886 - val_loss: 0.0147\n",
            "Epoch 43/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9772 - loss: 0.0222 - val_accuracy: 0.9886 - val_loss: 0.0146\n",
            "Epoch 44/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9772 - loss: 0.0220 - val_accuracy: 0.9886 - val_loss: 0.0146\n",
            "Epoch 45/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9772 - loss: 0.0220 - val_accuracy: 0.9886 - val_loss: 0.0146\n",
            "Epoch 46/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9772 - loss: 0.0219 - val_accuracy: 0.9886 - val_loss: 0.0144\n",
            "Epoch 47/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9772 - loss: 0.0217 - val_accuracy: 0.9886 - val_loss: 0.0144\n",
            "Epoch 48/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9772 - loss: 0.0217 - val_accuracy: 0.9886 - val_loss: 0.0144\n",
            "Epoch 49/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9772 - loss: 0.0211 - val_accuracy: 0.9886 - val_loss: 0.0147\n",
            "Epoch 50/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9772 - loss: 0.0219 - val_accuracy: 0.9886 - val_loss: 0.0140\n",
            "Epoch 51/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9772 - loss: 0.0212 - val_accuracy: 0.9886 - val_loss: 0.0142\n",
            "Epoch 52/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9772 - loss: 0.0213 - val_accuracy: 0.9886 - val_loss: 0.0143\n",
            "Epoch 53/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9772 - loss: 0.0212 - val_accuracy: 0.9886 - val_loss: 0.0141\n",
            "Epoch 54/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9772 - loss: 0.0210 - val_accuracy: 0.9886 - val_loss: 0.0137\n",
            "Epoch 55/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9772 - loss: 0.0207 - val_accuracy: 0.9886 - val_loss: 0.0141\n",
            "Epoch 56/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9772 - loss: 0.0208 - val_accuracy: 0.9886 - val_loss: 0.0139\n",
            "Epoch 57/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9772 - loss: 0.0206 - val_accuracy: 0.9886 - val_loss: 0.0140\n",
            "Epoch 58/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9772 - loss: 0.0207 - val_accuracy: 0.9886 - val_loss: 0.0140\n",
            "Epoch 59/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9772 - loss: 0.0205 - val_accuracy: 0.9886 - val_loss: 0.0141\n",
            "Epoch 60/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9772 - loss: 0.0205 - val_accuracy: 0.9886 - val_loss: 0.0136\n",
            "Epoch 61/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9772 - loss: 0.0201 - val_accuracy: 0.9886 - val_loss: 0.0141\n",
            "Epoch 62/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9772 - loss: 0.0203 - val_accuracy: 0.9886 - val_loss: 0.0140\n",
            "Epoch 63/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9772 - loss: 0.0200 - val_accuracy: 0.9886 - val_loss: 0.0150\n",
            "Epoch 64/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9772 - loss: 0.0218 - val_accuracy: 0.9886 - val_loss: 0.0162\n",
            "Epoch 65/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9772 - loss: 0.0207 - val_accuracy: 0.9886 - val_loss: 0.0136\n",
            "Epoch 66/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9772 - loss: 0.0194 - val_accuracy: 0.9886 - val_loss: 0.0139\n",
            "Epoch 67/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9772 - loss: 0.0198 - val_accuracy: 0.9886 - val_loss: 0.0140\n",
            "Epoch 68/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9772 - loss: 0.0197 - val_accuracy: 0.9886 - val_loss: 0.0140\n",
            "Epoch 69/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9772 - loss: 0.0197 - val_accuracy: 0.9886 - val_loss: 0.0140\n",
            "Epoch 70/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9772 - loss: 0.0196 - val_accuracy: 0.9886 - val_loss: 0.0140\n",
            "Epoch 71/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9772 - loss: 0.0196 - val_accuracy: 0.9886 - val_loss: 0.0140\n",
            "Epoch 72/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9772 - loss: 0.0194 - val_accuracy: 0.9886 - val_loss: 0.0142\n",
            "Epoch 73/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9772 - loss: 0.0194 - val_accuracy: 0.9886 - val_loss: 0.0141\n",
            "Epoch 74/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9772 - loss: 0.0193 - val_accuracy: 0.9886 - val_loss: 0.0144\n",
            "Epoch 75/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9795 - loss: 0.0194 - val_accuracy: 0.9886 - val_loss: 0.0141\n",
            "Epoch 76/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9795 - loss: 0.0192 - val_accuracy: 0.9886 - val_loss: 0.0147\n",
            "Epoch 77/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9795 - loss: 0.0193 - val_accuracy: 0.9886 - val_loss: 0.0141\n",
            "Epoch 78/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9817 - loss: 0.0190 - val_accuracy: 0.9886 - val_loss: 0.0147\n",
            "Epoch 79/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9817 - loss: 0.0192 - val_accuracy: 0.9886 - val_loss: 0.0143\n",
            "Epoch 80/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9817 - loss: 0.0189 - val_accuracy: 0.9886 - val_loss: 0.0146\n",
            "Epoch 81/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9817 - loss: 0.0189 - val_accuracy: 0.9886 - val_loss: 0.0143\n",
            "Epoch 82/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9817 - loss: 0.0186 - val_accuracy: 0.9830 - val_loss: 0.0147\n",
            "Epoch 83/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9817 - loss: 0.0190 - val_accuracy: 0.9886 - val_loss: 0.0140\n",
            "Epoch 84/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9817 - loss: 0.0183 - val_accuracy: 0.9830 - val_loss: 0.0149\n",
            "Epoch 85/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9817 - loss: 0.0189 - val_accuracy: 0.9830 - val_loss: 0.0145\n",
            "Epoch 86/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9817 - loss: 0.0186 - val_accuracy: 0.9830 - val_loss: 0.0147\n",
            "Epoch 87/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9817 - loss: 0.0186 - val_accuracy: 0.9830 - val_loss: 0.0146\n",
            "Epoch 88/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9817 - loss: 0.0186 - val_accuracy: 0.9830 - val_loss: 0.0153\n",
            "Epoch 89/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9817 - loss: 0.0187 - val_accuracy: 0.9830 - val_loss: 0.0147\n",
            "Epoch 90/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9817 - loss: 0.0185 - val_accuracy: 0.9830 - val_loss: 0.0151\n",
            "Epoch 91/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9817 - loss: 0.0189 - val_accuracy: 0.9830 - val_loss: 0.0152\n",
            "Epoch 92/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9817 - loss: 0.0190 - val_accuracy: 0.9830 - val_loss: 0.0157\n",
            "Epoch 93/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9817 - loss: 0.0191 - val_accuracy: 0.9830 - val_loss: 0.0157\n",
            "Epoch 94/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9817 - loss: 0.0193 - val_accuracy: 0.9830 - val_loss: 0.0168\n",
            "Epoch 95/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9817 - loss: 0.0197 - val_accuracy: 0.9830 - val_loss: 0.0187\n",
            "Epoch 96/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9824 - loss: 0.0206 - val_accuracy: 0.9830 - val_loss: 0.0242\n",
            "Epoch 97/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9836 - loss: 0.0231 - val_accuracy: 0.9830 - val_loss: 0.0324\n",
            "Epoch 98/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9820 - loss: 0.0272 - val_accuracy: 0.9830 - val_loss: 0.0303\n",
            "Epoch 99/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9798 - loss: 0.0297 - val_accuracy: 0.9830 - val_loss: 0.0148\n",
            "Epoch 100/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9782 - loss: 0.0238 - val_accuracy: 0.9886 - val_loss: 0.0135\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9621 - loss: 0.0387 \n",
            "[VALID] acc=0.989 | sens=0.167 (k=4/24, CI95=[0.067,0.359]) vs base 0.756 p=1.0000\n",
            "[TEST ] sens=0.375 (k=9/24, CI95=[0.212,0.573]) vs base 0.375 p=0.5000\n",
            "The years trained:  ['Year_2022', 'Year_2023']\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 0.8288 - loss: 0.1469 - val_accuracy: 0.9716 - val_loss: 0.0286\n",
            "Epoch 2/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9455 - loss: 0.0539 - val_accuracy: 0.9716 - val_loss: 0.0286\n",
            "Epoch 3/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9455 - loss: 0.0562 - val_accuracy: 0.9716 - val_loss: 0.0278\n",
            "Epoch 4/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9455 - loss: 0.0595 - val_accuracy: 0.9716 - val_loss: 0.0467\n",
            "Epoch 5/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9455 - loss: 0.0558 - val_accuracy: 0.9716 - val_loss: 0.0326\n",
            "Epoch 6/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0510 - val_accuracy: 0.9716 - val_loss: 0.0382\n",
            "Epoch 7/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0510 - val_accuracy: 0.9716 - val_loss: 0.0341\n",
            "Epoch 8/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.0489 - val_accuracy: 0.9716 - val_loss: 0.0328\n",
            "Epoch 9/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0470 - val_accuracy: 0.9716 - val_loss: 0.0257\n",
            "Epoch 10/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0446 - val_accuracy: 0.9716 - val_loss: 0.0210\n",
            "Epoch 11/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0429 - val_accuracy: 0.9716 - val_loss: 0.0204\n",
            "Epoch 12/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.0370 - val_accuracy: 0.9716 - val_loss: 0.0187\n",
            "Epoch 13/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9495 - loss: 0.0339 - val_accuracy: 0.9716 - val_loss: 0.0174\n",
            "Epoch 14/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9556 - loss: 0.0298 - val_accuracy: 0.9659 - val_loss: 0.0161\n",
            "Epoch 15/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9728 - loss: 0.0270 - val_accuracy: 0.9830 - val_loss: 0.0169\n",
            "Epoch 16/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9775 - loss: 0.0260 - val_accuracy: 0.9830 - val_loss: 0.0165\n",
            "Epoch 17/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9763 - loss: 0.0258 - val_accuracy: 0.9886 - val_loss: 0.0159\n",
            "Epoch 18/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9763 - loss: 0.0242 - val_accuracy: 0.9830 - val_loss: 0.0185\n",
            "Epoch 19/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9744 - loss: 0.0248 - val_accuracy: 0.9886 - val_loss: 0.0138\n",
            "Epoch 20/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9726 - loss: 0.0231 - val_accuracy: 0.9886 - val_loss: 0.0120\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9586 - loss: 0.0363 \n",
            "[VALID] acc=0.989 | sens=0.208 (k=5/24, CI95=[0.092,0.405]) vs base 0.864 p=1.0000\n",
            "[TEST ] sens=0.375 (k=9/24, CI95=[0.212,0.573]) vs base 0.375 p=0.5000\n",
            "The years trained:  ['Year_2022', 'Year_2023']\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.8373 - loss: 0.5032 - val_accuracy: 0.9716 - val_loss: 0.0387\n",
            "Epoch 2/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0617 - val_accuracy: 0.9716 - val_loss: 0.0285\n",
            "Epoch 3/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0534 - val_accuracy: 0.9716 - val_loss: 0.0298\n",
            "Epoch 4/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0528 - val_accuracy: 0.9716 - val_loss: 0.0303\n",
            "Epoch 5/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0533 - val_accuracy: 0.9716 - val_loss: 0.0275\n",
            "Epoch 6/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0525 - val_accuracy: 0.9716 - val_loss: 0.0270\n",
            "Epoch 7/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0521 - val_accuracy: 0.9716 - val_loss: 0.0267\n",
            "Epoch 8/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0510 - val_accuracy: 0.9716 - val_loss: 0.0263\n",
            "Epoch 9/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9455 - loss: 0.0502 - val_accuracy: 0.9716 - val_loss: 0.0260\n",
            "Epoch 10/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9455 - loss: 0.0492 - val_accuracy: 0.9716 - val_loss: 0.0270\n",
            "Epoch 11/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9455 - loss: 0.0474 - val_accuracy: 0.9716 - val_loss: 0.0344\n",
            "Epoch 12/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9455 - loss: 0.0443 - val_accuracy: 0.9716 - val_loss: 0.0218\n",
            "Epoch 13/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9455 - loss: 0.0376 - val_accuracy: 0.9716 - val_loss: 0.0186\n",
            "Epoch 14/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9461 - loss: 0.0325 - val_accuracy: 0.9886 - val_loss: 0.0149\n",
            "Epoch 15/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9750 - loss: 0.0282 - val_accuracy: 0.9830 - val_loss: 0.0194\n",
            "Epoch 16/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9730 - loss: 0.0290 - val_accuracy: 0.9886 - val_loss: 0.0134\n",
            "Epoch 17/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9768 - loss: 0.0249 - val_accuracy: 0.9886 - val_loss: 0.0125\n",
            "Epoch 18/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9772 - loss: 0.0234 - val_accuracy: 0.9886 - val_loss: 0.0144\n",
            "Epoch 19/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9768 - loss: 0.0243 - val_accuracy: 0.9886 - val_loss: 0.0162\n",
            "Epoch 20/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9768 - loss: 0.0246 - val_accuracy: 0.9886 - val_loss: 0.0116\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9586 - loss: 0.0387 \n",
            "[VALID] acc=0.989 | sens=0.208 (k=5/24, CI95=[0.092,0.405]) vs base 0.864 p=1.0000\n",
            "[TEST ] sens=0.375 (k=9/24, CI95=[0.212,0.573]) vs base 0.375 p=0.5000\n",
            "The years trained:  ['Year_2022', 'Year_2023']\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7441 - loss: 0.2445 - val_accuracy: 0.9432 - val_loss: 0.0494\n",
            "Epoch 2/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9131 - loss: 0.0719 - val_accuracy: 0.9716 - val_loss: 0.0357\n",
            "Epoch 3/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9455 - loss: 0.0539 - val_accuracy: 0.9716 - val_loss: 0.0293\n",
            "Epoch 4/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0521 - val_accuracy: 0.9716 - val_loss: 0.0297\n",
            "Epoch 5/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9455 - loss: 0.0514 - val_accuracy: 0.9716 - val_loss: 0.0302\n",
            "Epoch 6/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0511 - val_accuracy: 0.9716 - val_loss: 0.0289\n",
            "Epoch 7/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0506 - val_accuracy: 0.9716 - val_loss: 0.0276\n",
            "Epoch 8/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0492 - val_accuracy: 0.9716 - val_loss: 0.0262\n",
            "Epoch 9/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0473 - val_accuracy: 0.9716 - val_loss: 0.0324\n",
            "Epoch 10/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9457 - loss: 0.0415 - val_accuracy: 0.9886 - val_loss: 0.0195\n",
            "Epoch 11/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9590 - loss: 0.0305 - val_accuracy: 0.9659 - val_loss: 0.0190\n",
            "Epoch 12/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9610 - loss: 0.0284 - val_accuracy: 0.9659 - val_loss: 0.0209\n",
            "Epoch 13/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9703 - loss: 0.0250 - val_accuracy: 0.9886 - val_loss: 0.0108\n",
            "Epoch 14/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9760 - loss: 0.0213 - val_accuracy: 0.9886 - val_loss: 0.0113\n",
            "Epoch 15/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9768 - loss: 0.0205 - val_accuracy: 0.9886 - val_loss: 0.0115\n",
            "Epoch 16/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9772 - loss: 0.0199 - val_accuracy: 0.9886 - val_loss: 0.0115\n",
            "Epoch 17/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9768 - loss: 0.0199 - val_accuracy: 0.9886 - val_loss: 0.0118\n",
            "Epoch 18/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9772 - loss: 0.0193 - val_accuracy: 0.9886 - val_loss: 0.0121\n",
            "Epoch 19/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9768 - loss: 0.0193 - val_accuracy: 0.9886 - val_loss: 0.0124\n",
            "Epoch 20/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9772 - loss: 0.0188 - val_accuracy: 0.9886 - val_loss: 0.0120\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9540 - loss: 0.0422 \n",
            "[VALID] acc=0.989 | sens=0.167 (k=4/24, CI95=[0.067,0.359]) vs base 0.864 p=1.0000\n",
            "[TEST ] sens=0.375 (k=9/24, CI95=[0.212,0.573]) vs base 0.375 p=0.5000\n",
            "The years trained:  ['Year_2022', 'Year_2023']\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - accuracy: 0.8288 - loss: 0.1469 - val_accuracy: 0.9716 - val_loss: 0.0286\n",
            "Epoch 2/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9455 - loss: 0.0539 - val_accuracy: 0.9716 - val_loss: 0.0286\n",
            "Epoch 3/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9455 - loss: 0.0562 - val_accuracy: 0.9716 - val_loss: 0.0278\n",
            "Epoch 4/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9455 - loss: 0.0595 - val_accuracy: 0.9716 - val_loss: 0.0467\n",
            "Epoch 5/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0558 - val_accuracy: 0.9716 - val_loss: 0.0326\n",
            "Epoch 6/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0510 - val_accuracy: 0.9716 - val_loss: 0.0382\n",
            "Epoch 7/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0510 - val_accuracy: 0.9716 - val_loss: 0.0341\n",
            "Epoch 8/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9455 - loss: 0.0489 - val_accuracy: 0.9716 - val_loss: 0.0328\n",
            "Epoch 9/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0470 - val_accuracy: 0.9716 - val_loss: 0.0257\n",
            "Epoch 10/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0446 - val_accuracy: 0.9716 - val_loss: 0.0210\n",
            "Epoch 11/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0429 - val_accuracy: 0.9716 - val_loss: 0.0204\n",
            "Epoch 12/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0370 - val_accuracy: 0.9716 - val_loss: 0.0187\n",
            "Epoch 13/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9495 - loss: 0.0339 - val_accuracy: 0.9716 - val_loss: 0.0174\n",
            "Epoch 14/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9556 - loss: 0.0298 - val_accuracy: 0.9659 - val_loss: 0.0161\n",
            "Epoch 15/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9728 - loss: 0.0270 - val_accuracy: 0.9830 - val_loss: 0.0169\n",
            "Epoch 16/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9775 - loss: 0.0260 - val_accuracy: 0.9830 - val_loss: 0.0165\n",
            "Epoch 17/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9763 - loss: 0.0258 - val_accuracy: 0.9886 - val_loss: 0.0159\n",
            "Epoch 18/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9763 - loss: 0.0242 - val_accuracy: 0.9830 - val_loss: 0.0185\n",
            "Epoch 19/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9744 - loss: 0.0248 - val_accuracy: 0.9886 - val_loss: 0.0138\n",
            "Epoch 20/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9726 - loss: 0.0231 - val_accuracy: 0.9886 - val_loss: 0.0120\n",
            "Epoch 21/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9757 - loss: 0.0203 - val_accuracy: 0.9886 - val_loss: 0.0118\n",
            "Epoch 22/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9752 - loss: 0.0198 - val_accuracy: 0.9886 - val_loss: 0.0120\n",
            "Epoch 23/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9759 - loss: 0.0203 - val_accuracy: 0.9886 - val_loss: 0.0136\n",
            "Epoch 24/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9748 - loss: 0.0212 - val_accuracy: 0.9886 - val_loss: 0.0120\n",
            "Epoch 25/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9752 - loss: 0.0189 - val_accuracy: 0.9886 - val_loss: 0.0119\n",
            "Epoch 26/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9768 - loss: 0.0187 - val_accuracy: 0.9886 - val_loss: 0.0117\n",
            "Epoch 27/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9774 - loss: 0.0182 - val_accuracy: 0.9886 - val_loss: 0.0119\n",
            "Epoch 28/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9774 - loss: 0.0179 - val_accuracy: 0.9886 - val_loss: 0.0117\n",
            "Epoch 29/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9774 - loss: 0.0174 - val_accuracy: 0.9886 - val_loss: 0.0120\n",
            "Epoch 30/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9779 - loss: 0.0175 - val_accuracy: 0.9886 - val_loss: 0.0117\n",
            "Epoch 31/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9781 - loss: 0.0167 - val_accuracy: 0.9886 - val_loss: 0.0122\n",
            "Epoch 32/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9783 - loss: 0.0172 - val_accuracy: 0.9886 - val_loss: 0.0119\n",
            "Epoch 33/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9793 - loss: 0.0165 - val_accuracy: 0.9886 - val_loss: 0.0122\n",
            "Epoch 34/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9805 - loss: 0.0164 - val_accuracy: 0.9886 - val_loss: 0.0120\n",
            "Epoch 35/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9818 - loss: 0.0150 - val_accuracy: 0.9886 - val_loss: 0.0124\n",
            "Epoch 36/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9841 - loss: 0.0145 - val_accuracy: 0.9886 - val_loss: 0.0122\n",
            "Epoch 37/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9870 - loss: 0.0141 - val_accuracy: 0.9886 - val_loss: 0.0125\n",
            "Epoch 38/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9889 - loss: 0.0138 - val_accuracy: 0.9886 - val_loss: 0.0130\n",
            "Epoch 39/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9889 - loss: 0.0135 - val_accuracy: 0.9886 - val_loss: 0.0127\n",
            "Epoch 40/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9889 - loss: 0.0129 - val_accuracy: 0.9886 - val_loss: 0.0130\n",
            "Epoch 41/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9889 - loss: 0.0127 - val_accuracy: 0.9886 - val_loss: 0.0141\n",
            "Epoch 42/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9889 - loss: 0.0131 - val_accuracy: 0.9886 - val_loss: 0.0139\n",
            "Epoch 43/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9879 - loss: 0.0124 - val_accuracy: 0.9773 - val_loss: 0.0154\n",
            "Epoch 44/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9894 - loss: 0.0120 - val_accuracy: 0.9773 - val_loss: 0.0174\n",
            "Epoch 45/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9879 - loss: 0.0127 - val_accuracy: 0.9773 - val_loss: 0.0186\n",
            "Epoch 46/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9840 - loss: 0.0144 - val_accuracy: 0.9886 - val_loss: 0.0137\n",
            "Epoch 47/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9677 - loss: 0.0297 - val_accuracy: 0.9716 - val_loss: 0.0240\n",
            "Epoch 48/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9458 - loss: 0.0406 - val_accuracy: 0.9716 - val_loss: 0.0175\n",
            "Epoch 49/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9804 - loss: 0.0252 - val_accuracy: 0.9773 - val_loss: 0.0135\n",
            "Epoch 50/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9820 - loss: 0.0179 - val_accuracy: 0.9886 - val_loss: 0.0127\n",
            "Epoch 51/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9843 - loss: 0.0147 - val_accuracy: 0.9886 - val_loss: 0.0143\n",
            "Epoch 52/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9850 - loss: 0.0149 - val_accuracy: 0.9773 - val_loss: 0.0145\n",
            "Epoch 53/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9748 - loss: 0.0210 - val_accuracy: 0.9830 - val_loss: 0.0141\n",
            "Epoch 54/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9796 - loss: 0.0164 - val_accuracy: 0.9886 - val_loss: 0.0110\n",
            "Epoch 55/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9750 - loss: 0.0204 - val_accuracy: 0.9830 - val_loss: 0.0132\n",
            "Epoch 56/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9803 - loss: 0.0194 - val_accuracy: 0.9830 - val_loss: 0.0133\n",
            "Epoch 57/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9841 - loss: 0.0148 - val_accuracy: 0.9830 - val_loss: 0.0143\n",
            "Epoch 58/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9830 - loss: 0.0134 - val_accuracy: 0.9830 - val_loss: 0.0148\n",
            "Epoch 59/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9859 - loss: 0.0129 - val_accuracy: 0.9773 - val_loss: 0.0192\n",
            "Epoch 60/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9894 - loss: 0.0117 - val_accuracy: 0.9773 - val_loss: 0.0192\n",
            "Epoch 61/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9894 - loss: 0.0117 - val_accuracy: 0.9716 - val_loss: 0.0246\n",
            "Epoch 62/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9868 - loss: 0.0121 - val_accuracy: 0.9773 - val_loss: 0.0166\n",
            "Epoch 63/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9846 - loss: 0.0130 - val_accuracy: 0.9659 - val_loss: 0.0254\n",
            "Epoch 64/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9864 - loss: 0.0122 - val_accuracy: 0.9602 - val_loss: 0.0294\n",
            "Epoch 65/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9892 - loss: 0.0112 - val_accuracy: 0.9489 - val_loss: 0.0354\n",
            "Epoch 66/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9892 - loss: 0.0108 - val_accuracy: 0.9716 - val_loss: 0.0235\n",
            "Epoch 67/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9789 - loss: 0.0179 - val_accuracy: 0.9886 - val_loss: 0.0091\n",
            "Epoch 68/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9867 - loss: 0.0127 - val_accuracy: 0.9773 - val_loss: 0.0169\n",
            "Epoch 69/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9809 - loss: 0.0155 - val_accuracy: 0.9773 - val_loss: 0.0150\n",
            "Epoch 70/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9806 - loss: 0.0171 - val_accuracy: 0.9943 - val_loss: 0.0088\n",
            "Epoch 71/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9872 - loss: 0.0130 - val_accuracy: 0.9943 - val_loss: 0.0096\n",
            "Epoch 72/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9867 - loss: 0.0124 - val_accuracy: 0.9886 - val_loss: 0.0120\n",
            "Epoch 73/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9875 - loss: 0.0127 - val_accuracy: 0.9886 - val_loss: 0.0104\n",
            "Epoch 74/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9875 - loss: 0.0119 - val_accuracy: 0.9886 - val_loss: 0.0108\n",
            "Epoch 75/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9872 - loss: 0.0119 - val_accuracy: 0.9830 - val_loss: 0.0118\n",
            "Epoch 76/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9882 - loss: 0.0121 - val_accuracy: 0.9773 - val_loss: 0.0180\n",
            "Epoch 77/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9828 - loss: 0.0181 - val_accuracy: 0.9830 - val_loss: 0.0120\n",
            "Epoch 78/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9870 - loss: 0.0134 - val_accuracy: 0.9773 - val_loss: 0.0137\n",
            "Epoch 79/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9791 - loss: 0.0178 - val_accuracy: 0.9773 - val_loss: 0.0185\n",
            "Epoch 80/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9647 - loss: 0.0273 - val_accuracy: 0.9773 - val_loss: 0.0221\n",
            "Epoch 81/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9802 - loss: 0.0203 - val_accuracy: 0.9773 - val_loss: 0.0144\n",
            "Epoch 82/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9722 - loss: 0.0246 - val_accuracy: 0.9773 - val_loss: 0.0177\n",
            "Epoch 83/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9647 - loss: 0.0298 - val_accuracy: 0.9886 - val_loss: 0.0103\n",
            "Epoch 84/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9824 - loss: 0.0153 - val_accuracy: 0.9886 - val_loss: 0.0104\n",
            "Epoch 85/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9785 - loss: 0.0184 - val_accuracy: 0.9886 - val_loss: 0.0108\n",
            "Epoch 86/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9812 - loss: 0.0169 - val_accuracy: 0.9773 - val_loss: 0.0155\n",
            "Epoch 87/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9615 - loss: 0.0284 - val_accuracy: 0.9886 - val_loss: 0.0092\n",
            "Epoch 88/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9853 - loss: 0.0140 - val_accuracy: 0.9943 - val_loss: 0.0110\n",
            "Epoch 89/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9817 - loss: 0.0169 - val_accuracy: 0.9886 - val_loss: 0.0097\n",
            "Epoch 90/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9842 - loss: 0.0151 - val_accuracy: 0.9943 - val_loss: 0.0099\n",
            "Epoch 91/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9836 - loss: 0.0150 - val_accuracy: 0.9830 - val_loss: 0.0129\n",
            "Epoch 92/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9723 - loss: 0.0193 - val_accuracy: 0.9886 - val_loss: 0.0130\n",
            "Epoch 93/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9740 - loss: 0.0194 - val_accuracy: 0.9886 - val_loss: 0.0100\n",
            "Epoch 94/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9868 - loss: 0.0118 - val_accuracy: 0.9943 - val_loss: 0.0106\n",
            "Epoch 95/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9839 - loss: 0.0125 - val_accuracy: 0.9943 - val_loss: 0.0112\n",
            "Epoch 96/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9832 - loss: 0.0149 - val_accuracy: 0.9830 - val_loss: 0.0146\n",
            "Epoch 97/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9730 - loss: 0.0186 - val_accuracy: 0.9943 - val_loss: 0.0107\n",
            "Epoch 98/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9849 - loss: 0.0119 - val_accuracy: 0.9943 - val_loss: 0.0105\n",
            "Epoch 99/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9862 - loss: 0.0114 - val_accuracy: 0.9830 - val_loss: 0.0182\n",
            "Epoch 100/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9857 - loss: 0.0118 - val_accuracy: 0.9773 - val_loss: 0.0185\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9582 - loss: 0.0374 \n",
            "[VALID] acc=0.977 | sens=0.167 (k=4/24, CI95=[0.067,0.359]) vs base 0.864 p=1.0000\n",
            "[TEST ] sens=0.375 (k=9/24, CI95=[0.212,0.573]) vs base 0.375 p=0.5000\n",
            "The years trained:  ['Year_2022', 'Year_2023']\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.8563 - loss: 0.2101 - val_accuracy: 0.9716 - val_loss: 0.0445\n",
            "Epoch 2/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9455 - loss: 0.0655 - val_accuracy: 0.9716 - val_loss: 0.0435\n",
            "Epoch 3/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9455 - loss: 0.0644 - val_accuracy: 0.9716 - val_loss: 0.0429\n",
            "Epoch 4/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0639 - val_accuracy: 0.9716 - val_loss: 0.0432\n",
            "Epoch 5/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0634 - val_accuracy: 0.9716 - val_loss: 0.0428\n",
            "Epoch 6/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0631 - val_accuracy: 0.9716 - val_loss: 0.0424\n",
            "Epoch 7/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.0627 - val_accuracy: 0.9716 - val_loss: 0.0420\n",
            "Epoch 8/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0624 - val_accuracy: 0.9716 - val_loss: 0.0417\n",
            "Epoch 9/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.0621 - val_accuracy: 0.9716 - val_loss: 0.0414\n",
            "Epoch 10/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0618 - val_accuracy: 0.9716 - val_loss: 0.0413\n",
            "Epoch 11/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0615 - val_accuracy: 0.9716 - val_loss: 0.0408\n",
            "Epoch 12/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0612 - val_accuracy: 0.9716 - val_loss: 0.0407\n",
            "Epoch 13/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0609 - val_accuracy: 0.9716 - val_loss: 0.0401\n",
            "Epoch 14/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0604 - val_accuracy: 0.9716 - val_loss: 0.0390\n",
            "Epoch 15/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0598 - val_accuracy: 0.9716 - val_loss: 0.0391\n",
            "Epoch 16/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0595 - val_accuracy: 0.9716 - val_loss: 0.0387\n",
            "Epoch 17/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0592 - val_accuracy: 0.9716 - val_loss: 0.0384\n",
            "Epoch 18/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0590 - val_accuracy: 0.9716 - val_loss: 0.0381\n",
            "Epoch 19/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0588 - val_accuracy: 0.9716 - val_loss: 0.0378\n",
            "Epoch 20/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0585 - val_accuracy: 0.9716 - val_loss: 0.0375\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9466 - loss: 0.0634 \n",
            "[VALID] acc=0.972 | sens=0.000 (k=0/24, CI95=[0.000,0.138]) vs base 0.864 p=1.0000\n",
            "[TEST ] sens=0.083 (k=2/24, CI95=[0.023,0.258]) vs base 0.375 p=0.9919\n",
            "The years trained:  ['Year_2022', 'Year_2023']\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9455 - loss: 0.1194 - val_accuracy: 0.9716 - val_loss: 0.0410\n",
            "Epoch 2/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0570 - val_accuracy: 0.9716 - val_loss: 0.0385\n",
            "Epoch 3/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0555 - val_accuracy: 0.9716 - val_loss: 0.0369\n",
            "Epoch 4/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0547 - val_accuracy: 0.9716 - val_loss: 0.0360\n",
            "Epoch 5/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0541 - val_accuracy: 0.9716 - val_loss: 0.0356\n",
            "Epoch 6/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.0538 - val_accuracy: 0.9716 - val_loss: 0.0351\n",
            "Epoch 7/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0534 - val_accuracy: 0.9716 - val_loss: 0.0347\n",
            "Epoch 8/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0531 - val_accuracy: 0.9716 - val_loss: 0.0342\n",
            "Epoch 9/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.0528 - val_accuracy: 0.9716 - val_loss: 0.0338\n",
            "Epoch 10/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0526 - val_accuracy: 0.9716 - val_loss: 0.0335\n",
            "Epoch 11/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.0524 - val_accuracy: 0.9716 - val_loss: 0.0332\n",
            "Epoch 12/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0522 - val_accuracy: 0.9716 - val_loss: 0.0330\n",
            "Epoch 13/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0520 - val_accuracy: 0.9716 - val_loss: 0.0328\n",
            "Epoch 14/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0519 - val_accuracy: 0.9716 - val_loss: 0.0327\n",
            "Epoch 15/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.0518 - val_accuracy: 0.9716 - val_loss: 0.0325\n",
            "Epoch 16/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0516 - val_accuracy: 0.9716 - val_loss: 0.0323\n",
            "Epoch 17/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.0514 - val_accuracy: 0.9716 - val_loss: 0.0321\n",
            "Epoch 18/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0512 - val_accuracy: 0.9716 - val_loss: 0.0318\n",
            "Epoch 19/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0511 - val_accuracy: 0.9716 - val_loss: 0.0316\n",
            "Epoch 20/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0510 - val_accuracy: 0.9716 - val_loss: 0.0315\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9466 - loss: 0.0525 \n",
            "[VALID] acc=0.972 | sens=0.125 (k=3/24, CI95=[0.043,0.310]) vs base 0.864 p=1.0000\n",
            "[TEST ] sens=0.125 (k=3/24, CI95=[0.043,0.310]) vs base 0.375 p=0.9772\n",
            "The years trained:  ['Year_2022', 'Year_2023']\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9455 - loss: 0.2203 - val_accuracy: 0.9716 - val_loss: 0.0380\n",
            "Epoch 2/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9455 - loss: 0.0638 - val_accuracy: 0.9716 - val_loss: 0.0374\n",
            "Epoch 3/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9455 - loss: 0.0628 - val_accuracy: 0.9716 - val_loss: 0.0367\n",
            "Epoch 4/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9455 - loss: 0.0619 - val_accuracy: 0.9716 - val_loss: 0.0361\n",
            "Epoch 5/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9455 - loss: 0.0612 - val_accuracy: 0.9716 - val_loss: 0.0356\n",
            "Epoch 6/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9455 - loss: 0.0605 - val_accuracy: 0.9716 - val_loss: 0.0350\n",
            "Epoch 7/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9455 - loss: 0.0598 - val_accuracy: 0.9716 - val_loss: 0.0347\n",
            "Epoch 8/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9455 - loss: 0.0592 - val_accuracy: 0.9716 - val_loss: 0.0343\n",
            "Epoch 9/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9455 - loss: 0.0587 - val_accuracy: 0.9716 - val_loss: 0.0339\n",
            "Epoch 10/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0583 - val_accuracy: 0.9716 - val_loss: 0.0336\n",
            "Epoch 11/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0578 - val_accuracy: 0.9716 - val_loss: 0.0334\n",
            "Epoch 12/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0575 - val_accuracy: 0.9716 - val_loss: 0.0331\n",
            "Epoch 13/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0571 - val_accuracy: 0.9716 - val_loss: 0.0329\n",
            "Epoch 14/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0568 - val_accuracy: 0.9716 - val_loss: 0.0327\n",
            "Epoch 15/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0565 - val_accuracy: 0.9716 - val_loss: 0.0325\n",
            "Epoch 16/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.0562 - val_accuracy: 0.9716 - val_loss: 0.0323\n",
            "Epoch 17/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0560 - val_accuracy: 0.9716 - val_loss: 0.0321\n",
            "Epoch 18/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0558 - val_accuracy: 0.9716 - val_loss: 0.0320\n",
            "Epoch 19/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0555 - val_accuracy: 0.9716 - val_loss: 0.0318\n",
            "Epoch 20/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0553 - val_accuracy: 0.9716 - val_loss: 0.0317\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9466 - loss: 0.0536 \n",
            "[VALID] acc=0.972 | sens=0.042 (k=1/24, CI95=[0.007,0.202]) vs base 0.864 p=1.0000\n",
            "[TEST ] sens=0.000 (k=0/24, CI95=[0.000,0.138]) vs base 0.375 p=0.9996\n",
            "The years trained:  ['Year_2022', 'Year_2023']\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9455 - loss: 0.1194 - val_accuracy: 0.9716 - val_loss: 0.0410\n",
            "Epoch 2/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0570 - val_accuracy: 0.9716 - val_loss: 0.0385\n",
            "Epoch 3/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.0555 - val_accuracy: 0.9716 - val_loss: 0.0369\n",
            "Epoch 4/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0547 - val_accuracy: 0.9716 - val_loss: 0.0360\n",
            "Epoch 5/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0541 - val_accuracy: 0.9716 - val_loss: 0.0356\n",
            "Epoch 6/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0538 - val_accuracy: 0.9716 - val_loss: 0.0351\n",
            "Epoch 7/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0534 - val_accuracy: 0.9716 - val_loss: 0.0347\n",
            "Epoch 8/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0531 - val_accuracy: 0.9716 - val_loss: 0.0342\n",
            "Epoch 9/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0528 - val_accuracy: 0.9716 - val_loss: 0.0338\n",
            "Epoch 10/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0526 - val_accuracy: 0.9716 - val_loss: 0.0335\n",
            "Epoch 11/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0524 - val_accuracy: 0.9716 - val_loss: 0.0332\n",
            "Epoch 12/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0522 - val_accuracy: 0.9716 - val_loss: 0.0330\n",
            "Epoch 13/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0520 - val_accuracy: 0.9716 - val_loss: 0.0328\n",
            "Epoch 14/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0519 - val_accuracy: 0.9716 - val_loss: 0.0327\n",
            "Epoch 15/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0518 - val_accuracy: 0.9716 - val_loss: 0.0325\n",
            "Epoch 16/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0516 - val_accuracy: 0.9716 - val_loss: 0.0323\n",
            "Epoch 17/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0514 - val_accuracy: 0.9716 - val_loss: 0.0321\n",
            "Epoch 18/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.0512 - val_accuracy: 0.9716 - val_loss: 0.0318\n",
            "Epoch 19/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0511 - val_accuracy: 0.9716 - val_loss: 0.0316\n",
            "Epoch 20/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0510 - val_accuracy: 0.9716 - val_loss: 0.0315\n",
            "Epoch 21/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0509 - val_accuracy: 0.9716 - val_loss: 0.0314\n",
            "Epoch 22/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.0507 - val_accuracy: 0.9716 - val_loss: 0.0313\n",
            "Epoch 23/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0506 - val_accuracy: 0.9716 - val_loss: 0.0312\n",
            "Epoch 24/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0505 - val_accuracy: 0.9716 - val_loss: 0.0312\n",
            "Epoch 25/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0504 - val_accuracy: 0.9716 - val_loss: 0.0311\n",
            "Epoch 26/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0504 - val_accuracy: 0.9716 - val_loss: 0.0311\n",
            "Epoch 27/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0503 - val_accuracy: 0.9716 - val_loss: 0.0310\n",
            "Epoch 28/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0502 - val_accuracy: 0.9716 - val_loss: 0.0309\n",
            "Epoch 29/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0501 - val_accuracy: 0.9716 - val_loss: 0.0308\n",
            "Epoch 30/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0500 - val_accuracy: 0.9716 - val_loss: 0.0307\n",
            "Epoch 31/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0500 - val_accuracy: 0.9716 - val_loss: 0.0307\n",
            "Epoch 32/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0499 - val_accuracy: 0.9716 - val_loss: 0.0306\n",
            "Epoch 33/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9455 - loss: 0.0498 - val_accuracy: 0.9716 - val_loss: 0.0306\n",
            "Epoch 34/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9455 - loss: 0.0498 - val_accuracy: 0.9716 - val_loss: 0.0305\n",
            "Epoch 35/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9455 - loss: 0.0497 - val_accuracy: 0.9716 - val_loss: 0.0304\n",
            "Epoch 36/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9455 - loss: 0.0496 - val_accuracy: 0.9716 - val_loss: 0.0304\n",
            "Epoch 37/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9455 - loss: 0.0495 - val_accuracy: 0.9716 - val_loss: 0.0303\n",
            "Epoch 38/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9455 - loss: 0.0495 - val_accuracy: 0.9716 - val_loss: 0.0302\n",
            "Epoch 39/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9455 - loss: 0.0494 - val_accuracy: 0.9716 - val_loss: 0.0302\n",
            "Epoch 40/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9455 - loss: 0.0494 - val_accuracy: 0.9716 - val_loss: 0.0301\n",
            "Epoch 41/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9455 - loss: 0.0493 - val_accuracy: 0.9716 - val_loss: 0.0301\n",
            "Epoch 42/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9455 - loss: 0.0493 - val_accuracy: 0.9716 - val_loss: 0.0300\n",
            "Epoch 43/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9455 - loss: 0.0492 - val_accuracy: 0.9716 - val_loss: 0.0299\n",
            "Epoch 44/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9455 - loss: 0.0491 - val_accuracy: 0.9716 - val_loss: 0.0299\n",
            "Epoch 45/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0491 - val_accuracy: 0.9716 - val_loss: 0.0298\n",
            "Epoch 46/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0490 - val_accuracy: 0.9716 - val_loss: 0.0298\n",
            "Epoch 47/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0490 - val_accuracy: 0.9716 - val_loss: 0.0298\n",
            "Epoch 48/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0489 - val_accuracy: 0.9716 - val_loss: 0.0297\n",
            "Epoch 49/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0489 - val_accuracy: 0.9716 - val_loss: 0.0297\n",
            "Epoch 50/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0488 - val_accuracy: 0.9716 - val_loss: 0.0296\n",
            "Epoch 51/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0488 - val_accuracy: 0.9716 - val_loss: 0.0296\n",
            "Epoch 52/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.0487 - val_accuracy: 0.9716 - val_loss: 0.0295\n",
            "Epoch 53/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0487 - val_accuracy: 0.9716 - val_loss: 0.0295\n",
            "Epoch 54/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0486 - val_accuracy: 0.9716 - val_loss: 0.0295\n",
            "Epoch 55/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0486 - val_accuracy: 0.9716 - val_loss: 0.0294\n",
            "Epoch 56/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0485 - val_accuracy: 0.9716 - val_loss: 0.0294\n",
            "Epoch 57/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0485 - val_accuracy: 0.9716 - val_loss: 0.0293\n",
            "Epoch 58/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0485 - val_accuracy: 0.9716 - val_loss: 0.0293\n",
            "Epoch 59/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0484 - val_accuracy: 0.9716 - val_loss: 0.0292\n",
            "Epoch 60/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0484 - val_accuracy: 0.9716 - val_loss: 0.0292\n",
            "Epoch 61/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0483 - val_accuracy: 0.9716 - val_loss: 0.0292\n",
            "Epoch 62/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.0483 - val_accuracy: 0.9716 - val_loss: 0.0291\n",
            "Epoch 63/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0482 - val_accuracy: 0.9716 - val_loss: 0.0291\n",
            "Epoch 64/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.0482 - val_accuracy: 0.9716 - val_loss: 0.0291\n",
            "Epoch 65/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.0482 - val_accuracy: 0.9716 - val_loss: 0.0290\n",
            "Epoch 66/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0481 - val_accuracy: 0.9716 - val_loss: 0.0290\n",
            "Epoch 67/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0481 - val_accuracy: 0.9716 - val_loss: 0.0289\n",
            "Epoch 68/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0480 - val_accuracy: 0.9716 - val_loss: 0.0289\n",
            "Epoch 69/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0480 - val_accuracy: 0.9716 - val_loss: 0.0289\n",
            "Epoch 70/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0480 - val_accuracy: 0.9716 - val_loss: 0.0288\n",
            "Epoch 71/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0479 - val_accuracy: 0.9716 - val_loss: 0.0288\n",
            "Epoch 72/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0479 - val_accuracy: 0.9716 - val_loss: 0.0288\n",
            "Epoch 73/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0478 - val_accuracy: 0.9716 - val_loss: 0.0287\n",
            "Epoch 74/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0478 - val_accuracy: 0.9716 - val_loss: 0.0287\n",
            "Epoch 75/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.0478 - val_accuracy: 0.9716 - val_loss: 0.0287\n",
            "Epoch 76/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.0477 - val_accuracy: 0.9716 - val_loss: 0.0287\n",
            "Epoch 77/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.0477 - val_accuracy: 0.9716 - val_loss: 0.0286\n",
            "Epoch 78/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0476 - val_accuracy: 0.9716 - val_loss: 0.0286\n",
            "Epoch 79/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.0476 - val_accuracy: 0.9716 - val_loss: 0.0286\n",
            "Epoch 80/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.0476 - val_accuracy: 0.9716 - val_loss: 0.0285\n",
            "Epoch 81/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0475 - val_accuracy: 0.9716 - val_loss: 0.0285\n",
            "Epoch 82/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0475 - val_accuracy: 0.9716 - val_loss: 0.0285\n",
            "Epoch 83/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0474 - val_accuracy: 0.9716 - val_loss: 0.0284\n",
            "Epoch 84/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0474 - val_accuracy: 0.9716 - val_loss: 0.0284\n",
            "Epoch 85/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.0474 - val_accuracy: 0.9716 - val_loss: 0.0283\n",
            "Epoch 86/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0473 - val_accuracy: 0.9716 - val_loss: 0.0283\n",
            "Epoch 87/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0473 - val_accuracy: 0.9716 - val_loss: 0.0283\n",
            "Epoch 88/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.0472 - val_accuracy: 0.9716 - val_loss: 0.0283\n",
            "Epoch 89/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.0472 - val_accuracy: 0.9716 - val_loss: 0.0282\n",
            "Epoch 90/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0472 - val_accuracy: 0.9716 - val_loss: 0.0282\n",
            "Epoch 91/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0471 - val_accuracy: 0.9716 - val_loss: 0.0282\n",
            "Epoch 92/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0471 - val_accuracy: 0.9716 - val_loss: 0.0282\n",
            "Epoch 93/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0471 - val_accuracy: 0.9716 - val_loss: 0.0281\n",
            "Epoch 94/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9455 - loss: 0.0470 - val_accuracy: 0.9716 - val_loss: 0.0281\n",
            "Epoch 95/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9455 - loss: 0.0470 - val_accuracy: 0.9716 - val_loss: 0.0281\n",
            "Epoch 96/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9455 - loss: 0.0469 - val_accuracy: 0.9716 - val_loss: 0.0280\n",
            "Epoch 97/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9455 - loss: 0.0469 - val_accuracy: 0.9716 - val_loss: 0.0280\n",
            "Epoch 98/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9455 - loss: 0.0469 - val_accuracy: 0.9716 - val_loss: 0.0280\n",
            "Epoch 99/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9455 - loss: 0.0468 - val_accuracy: 0.9716 - val_loss: 0.0280\n",
            "Epoch 100/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9455 - loss: 0.0468 - val_accuracy: 0.9716 - val_loss: 0.0279\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9466 - loss: 0.0501 \n",
            "[VALID] acc=0.972 | sens=0.208 (k=5/24, CI95=[0.092,0.405]) vs base 0.864 p=1.0000\n",
            "[TEST ] sens=0.375 (k=9/24, CI95=[0.212,0.573]) vs base 0.375 p=0.5000\n",
            "The years trained:  ['Year_2022', 'Year_2023']\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8563 - loss: 0.2101 - val_accuracy: 0.9716 - val_loss: 0.0445\n",
            "Epoch 2/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0655 - val_accuracy: 0.9716 - val_loss: 0.0435\n",
            "Epoch 3/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0644 - val_accuracy: 0.9716 - val_loss: 0.0429\n",
            "Epoch 4/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0639 - val_accuracy: 0.9716 - val_loss: 0.0432\n",
            "Epoch 5/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0634 - val_accuracy: 0.9716 - val_loss: 0.0428\n",
            "Epoch 6/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0631 - val_accuracy: 0.9716 - val_loss: 0.0424\n",
            "Epoch 7/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0627 - val_accuracy: 0.9716 - val_loss: 0.0420\n",
            "Epoch 8/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.0624 - val_accuracy: 0.9716 - val_loss: 0.0417\n",
            "Epoch 9/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.0621 - val_accuracy: 0.9716 - val_loss: 0.0414\n",
            "Epoch 10/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0618 - val_accuracy: 0.9716 - val_loss: 0.0413\n",
            "Epoch 11/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0615 - val_accuracy: 0.9716 - val_loss: 0.0408\n",
            "Epoch 12/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0612 - val_accuracy: 0.9716 - val_loss: 0.0407\n",
            "Epoch 13/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0609 - val_accuracy: 0.9716 - val_loss: 0.0401\n",
            "Epoch 14/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0604 - val_accuracy: 0.9716 - val_loss: 0.0390\n",
            "Epoch 15/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0598 - val_accuracy: 0.9716 - val_loss: 0.0391\n",
            "Epoch 16/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0595 - val_accuracy: 0.9716 - val_loss: 0.0387\n",
            "Epoch 17/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0592 - val_accuracy: 0.9716 - val_loss: 0.0384\n",
            "Epoch 18/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0590 - val_accuracy: 0.9716 - val_loss: 0.0381\n",
            "Epoch 19/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0588 - val_accuracy: 0.9716 - val_loss: 0.0378\n",
            "Epoch 20/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0585 - val_accuracy: 0.9716 - val_loss: 0.0375\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9466 - loss: 0.0634 \n",
            "[VALID] acc=0.972 | sens=0.000 (k=0/24, CI95=[0.000,0.138]) vs base 0.756 p=1.0000\n",
            "[TEST ] sens=0.083 (k=2/24, CI95=[0.023,0.258]) vs base 0.375 p=0.9919\n",
            "The years trained:  ['Year_2022', 'Year_2023']\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9455 - loss: 0.1194 - val_accuracy: 0.9716 - val_loss: 0.0410\n",
            "Epoch 2/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0570 - val_accuracy: 0.9716 - val_loss: 0.0385\n",
            "Epoch 3/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0555 - val_accuracy: 0.9716 - val_loss: 0.0369\n",
            "Epoch 4/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0547 - val_accuracy: 0.9716 - val_loss: 0.0360\n",
            "Epoch 5/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0541 - val_accuracy: 0.9716 - val_loss: 0.0356\n",
            "Epoch 6/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0538 - val_accuracy: 0.9716 - val_loss: 0.0351\n",
            "Epoch 7/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0534 - val_accuracy: 0.9716 - val_loss: 0.0347\n",
            "Epoch 8/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0531 - val_accuracy: 0.9716 - val_loss: 0.0342\n",
            "Epoch 9/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0528 - val_accuracy: 0.9716 - val_loss: 0.0338\n",
            "Epoch 10/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0526 - val_accuracy: 0.9716 - val_loss: 0.0335\n",
            "Epoch 11/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0524 - val_accuracy: 0.9716 - val_loss: 0.0332\n",
            "Epoch 12/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0522 - val_accuracy: 0.9716 - val_loss: 0.0330\n",
            "Epoch 13/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0520 - val_accuracy: 0.9716 - val_loss: 0.0328\n",
            "Epoch 14/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0519 - val_accuracy: 0.9716 - val_loss: 0.0327\n",
            "Epoch 15/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0518 - val_accuracy: 0.9716 - val_loss: 0.0325\n",
            "Epoch 16/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0516 - val_accuracy: 0.9716 - val_loss: 0.0323\n",
            "Epoch 17/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0514 - val_accuracy: 0.9716 - val_loss: 0.0321\n",
            "Epoch 18/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0512 - val_accuracy: 0.9716 - val_loss: 0.0318\n",
            "Epoch 19/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0511 - val_accuracy: 0.9716 - val_loss: 0.0316\n",
            "Epoch 20/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9455 - loss: 0.0510 - val_accuracy: 0.9716 - val_loss: 0.0315\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9466 - loss: 0.0525 \n",
            "[VALID] acc=0.972 | sens=0.125 (k=3/24, CI95=[0.043,0.310]) vs base 0.756 p=1.0000\n",
            "[TEST ] sens=0.125 (k=3/24, CI95=[0.043,0.310]) vs base 0.375 p=0.9772\n",
            "The years trained:  ['Year_2022', 'Year_2023']\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9455 - loss: 0.2203 - val_accuracy: 0.9716 - val_loss: 0.0380\n",
            "Epoch 2/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9455 - loss: 0.0638 - val_accuracy: 0.9716 - val_loss: 0.0374\n",
            "Epoch 3/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9455 - loss: 0.0628 - val_accuracy: 0.9716 - val_loss: 0.0367\n",
            "Epoch 4/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0619 - val_accuracy: 0.9716 - val_loss: 0.0361\n",
            "Epoch 5/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.0612 - val_accuracy: 0.9716 - val_loss: 0.0356\n",
            "Epoch 6/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.0605 - val_accuracy: 0.9716 - val_loss: 0.0350\n",
            "Epoch 7/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0598 - val_accuracy: 0.9716 - val_loss: 0.0347\n",
            "Epoch 8/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0592 - val_accuracy: 0.9716 - val_loss: 0.0343\n",
            "Epoch 9/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0587 - val_accuracy: 0.9716 - val_loss: 0.0339\n",
            "Epoch 10/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0583 - val_accuracy: 0.9716 - val_loss: 0.0336\n",
            "Epoch 11/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0578 - val_accuracy: 0.9716 - val_loss: 0.0334\n",
            "Epoch 12/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0575 - val_accuracy: 0.9716 - val_loss: 0.0331\n",
            "Epoch 13/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0571 - val_accuracy: 0.9716 - val_loss: 0.0329\n",
            "Epoch 14/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.0568 - val_accuracy: 0.9716 - val_loss: 0.0327\n",
            "Epoch 15/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.0565 - val_accuracy: 0.9716 - val_loss: 0.0325\n",
            "Epoch 16/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.0562 - val_accuracy: 0.9716 - val_loss: 0.0323\n",
            "Epoch 17/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.0560 - val_accuracy: 0.9716 - val_loss: 0.0321\n",
            "Epoch 18/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.0558 - val_accuracy: 0.9716 - val_loss: 0.0320\n",
            "Epoch 19/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.0555 - val_accuracy: 0.9716 - val_loss: 0.0318\n",
            "Epoch 20/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9455 - loss: 0.0553 - val_accuracy: 0.9716 - val_loss: 0.0317\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9466 - loss: 0.0536 \n",
            "[VALID] acc=0.972 | sens=0.042 (k=1/24, CI95=[0.007,0.202]) vs base 0.756 p=1.0000\n",
            "[TEST ] sens=0.000 (k=0/24, CI95=[0.000,0.138]) vs base 0.375 p=0.9996\n",
            "The years trained:  ['Year_2022', 'Year_2023']\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9455 - loss: 0.1194 - val_accuracy: 0.9716 - val_loss: 0.0410\n",
            "Epoch 2/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0570 - val_accuracy: 0.9716 - val_loss: 0.0385\n",
            "Epoch 3/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0555 - val_accuracy: 0.9716 - val_loss: 0.0369\n",
            "Epoch 4/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0547 - val_accuracy: 0.9716 - val_loss: 0.0360\n",
            "Epoch 5/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0541 - val_accuracy: 0.9716 - val_loss: 0.0356\n",
            "Epoch 6/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.0538 - val_accuracy: 0.9716 - val_loss: 0.0351\n",
            "Epoch 7/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0534 - val_accuracy: 0.9716 - val_loss: 0.0347\n",
            "Epoch 8/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0531 - val_accuracy: 0.9716 - val_loss: 0.0342\n",
            "Epoch 9/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.0528 - val_accuracy: 0.9716 - val_loss: 0.0338\n",
            "Epoch 10/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.0526 - val_accuracy: 0.9716 - val_loss: 0.0335\n",
            "Epoch 11/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.0524 - val_accuracy: 0.9716 - val_loss: 0.0332\n",
            "Epoch 12/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.0522 - val_accuracy: 0.9716 - val_loss: 0.0330\n",
            "Epoch 13/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.0520 - val_accuracy: 0.9716 - val_loss: 0.0328\n",
            "Epoch 14/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.0519 - val_accuracy: 0.9716 - val_loss: 0.0327\n",
            "Epoch 15/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9455 - loss: 0.0518 - val_accuracy: 0.9716 - val_loss: 0.0325\n",
            "Epoch 16/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9455 - loss: 0.0516 - val_accuracy: 0.9716 - val_loss: 0.0323\n",
            "Epoch 17/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9455 - loss: 0.0514 - val_accuracy: 0.9716 - val_loss: 0.0321\n",
            "Epoch 18/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9455 - loss: 0.0512 - val_accuracy: 0.9716 - val_loss: 0.0318\n",
            "Epoch 19/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9455 - loss: 0.0511 - val_accuracy: 0.9716 - val_loss: 0.0316\n",
            "Epoch 20/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9455 - loss: 0.0510 - val_accuracy: 0.9716 - val_loss: 0.0315\n",
            "Epoch 21/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9455 - loss: 0.0509 - val_accuracy: 0.9716 - val_loss: 0.0314\n",
            "Epoch 22/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9455 - loss: 0.0507 - val_accuracy: 0.9716 - val_loss: 0.0313\n",
            "Epoch 23/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9455 - loss: 0.0506 - val_accuracy: 0.9716 - val_loss: 0.0312\n",
            "Epoch 24/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9455 - loss: 0.0505 - val_accuracy: 0.9716 - val_loss: 0.0312\n",
            "Epoch 25/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9455 - loss: 0.0504 - val_accuracy: 0.9716 - val_loss: 0.0311\n",
            "Epoch 26/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9455 - loss: 0.0504 - val_accuracy: 0.9716 - val_loss: 0.0311\n",
            "Epoch 27/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9455 - loss: 0.0503 - val_accuracy: 0.9716 - val_loss: 0.0310\n",
            "Epoch 28/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.0502 - val_accuracy: 0.9716 - val_loss: 0.0309\n",
            "Epoch 29/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.0501 - val_accuracy: 0.9716 - val_loss: 0.0308\n",
            "Epoch 30/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.0500 - val_accuracy: 0.9716 - val_loss: 0.0307\n",
            "Epoch 31/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0500 - val_accuracy: 0.9716 - val_loss: 0.0307\n",
            "Epoch 32/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.0499 - val_accuracy: 0.9716 - val_loss: 0.0306\n",
            "Epoch 33/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.0498 - val_accuracy: 0.9716 - val_loss: 0.0306\n",
            "Epoch 34/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.0498 - val_accuracy: 0.9716 - val_loss: 0.0305\n",
            "Epoch 35/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.0497 - val_accuracy: 0.9716 - val_loss: 0.0304\n",
            "Epoch 36/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0496 - val_accuracy: 0.9716 - val_loss: 0.0304\n",
            "Epoch 37/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.0495 - val_accuracy: 0.9716 - val_loss: 0.0303\n",
            "Epoch 38/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.0495 - val_accuracy: 0.9716 - val_loss: 0.0302\n",
            "Epoch 39/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0494 - val_accuracy: 0.9716 - val_loss: 0.0302\n",
            "Epoch 40/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.0494 - val_accuracy: 0.9716 - val_loss: 0.0301\n",
            "Epoch 41/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.0493 - val_accuracy: 0.9716 - val_loss: 0.0301\n",
            "Epoch 42/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.0493 - val_accuracy: 0.9716 - val_loss: 0.0300\n",
            "Epoch 43/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.0492 - val_accuracy: 0.9716 - val_loss: 0.0299\n",
            "Epoch 44/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9455 - loss: 0.0491 - val_accuracy: 0.9716 - val_loss: 0.0299\n",
            "Epoch 45/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.0491 - val_accuracy: 0.9716 - val_loss: 0.0298\n",
            "Epoch 46/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.0490 - val_accuracy: 0.9716 - val_loss: 0.0298\n",
            "Epoch 47/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.0490 - val_accuracy: 0.9716 - val_loss: 0.0298\n",
            "Epoch 48/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0489 - val_accuracy: 0.9716 - val_loss: 0.0297\n",
            "Epoch 49/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.0489 - val_accuracy: 0.9716 - val_loss: 0.0297\n",
            "Epoch 50/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.0488 - val_accuracy: 0.9716 - val_loss: 0.0296\n",
            "Epoch 51/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.0488 - val_accuracy: 0.9716 - val_loss: 0.0296\n",
            "Epoch 52/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.0487 - val_accuracy: 0.9716 - val_loss: 0.0295\n",
            "Epoch 53/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.0487 - val_accuracy: 0.9716 - val_loss: 0.0295\n",
            "Epoch 54/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.0486 - val_accuracy: 0.9716 - val_loss: 0.0295\n",
            "Epoch 55/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.0486 - val_accuracy: 0.9716 - val_loss: 0.0294\n",
            "Epoch 56/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0485 - val_accuracy: 0.9716 - val_loss: 0.0294\n",
            "Epoch 57/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0485 - val_accuracy: 0.9716 - val_loss: 0.0293\n",
            "Epoch 58/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.0485 - val_accuracy: 0.9716 - val_loss: 0.0293\n",
            "Epoch 59/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.0484 - val_accuracy: 0.9716 - val_loss: 0.0292\n",
            "Epoch 60/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.0484 - val_accuracy: 0.9716 - val_loss: 0.0292\n",
            "Epoch 61/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.0483 - val_accuracy: 0.9716 - val_loss: 0.0292\n",
            "Epoch 62/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.0483 - val_accuracy: 0.9716 - val_loss: 0.0291\n",
            "Epoch 63/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.0482 - val_accuracy: 0.9716 - val_loss: 0.0291\n",
            "Epoch 64/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0482 - val_accuracy: 0.9716 - val_loss: 0.0291\n",
            "Epoch 65/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.0482 - val_accuracy: 0.9716 - val_loss: 0.0290\n",
            "Epoch 66/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.0481 - val_accuracy: 0.9716 - val_loss: 0.0290\n",
            "Epoch 67/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.0481 - val_accuracy: 0.9716 - val_loss: 0.0289\n",
            "Epoch 68/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.0480 - val_accuracy: 0.9716 - val_loss: 0.0289\n",
            "Epoch 69/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9455 - loss: 0.0480 - val_accuracy: 0.9716 - val_loss: 0.0289\n",
            "Epoch 70/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9455 - loss: 0.0480 - val_accuracy: 0.9716 - val_loss: 0.0288\n",
            "Epoch 71/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9455 - loss: 0.0479 - val_accuracy: 0.9716 - val_loss: 0.0288\n",
            "Epoch 72/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9455 - loss: 0.0479 - val_accuracy: 0.9716 - val_loss: 0.0288\n",
            "Epoch 73/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9455 - loss: 0.0478 - val_accuracy: 0.9716 - val_loss: 0.0287\n",
            "Epoch 74/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9455 - loss: 0.0478 - val_accuracy: 0.9716 - val_loss: 0.0287\n",
            "Epoch 75/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9455 - loss: 0.0478 - val_accuracy: 0.9716 - val_loss: 0.0287\n",
            "Epoch 76/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9455 - loss: 0.0477 - val_accuracy: 0.9716 - val_loss: 0.0287\n",
            "Epoch 77/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9455 - loss: 0.0477 - val_accuracy: 0.9716 - val_loss: 0.0286\n",
            "Epoch 78/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9455 - loss: 0.0476 - val_accuracy: 0.9716 - val_loss: 0.0286\n",
            "Epoch 79/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9455 - loss: 0.0476 - val_accuracy: 0.9716 - val_loss: 0.0286\n",
            "Epoch 80/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9455 - loss: 0.0476 - val_accuracy: 0.9716 - val_loss: 0.0285\n",
            "Epoch 81/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.0475 - val_accuracy: 0.9716 - val_loss: 0.0285\n",
            "Epoch 82/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.0475 - val_accuracy: 0.9716 - val_loss: 0.0285\n",
            "Epoch 83/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9455 - loss: 0.0474 - val_accuracy: 0.9716 - val_loss: 0.0284\n",
            "Epoch 84/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0474 - val_accuracy: 0.9716 - val_loss: 0.0284\n",
            "Epoch 85/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.0474 - val_accuracy: 0.9716 - val_loss: 0.0283\n",
            "Epoch 86/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.0473 - val_accuracy: 0.9716 - val_loss: 0.0283\n",
            "Epoch 87/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0473 - val_accuracy: 0.9716 - val_loss: 0.0283\n",
            "Epoch 88/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0472 - val_accuracy: 0.9716 - val_loss: 0.0283\n",
            "Epoch 89/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.0472 - val_accuracy: 0.9716 - val_loss: 0.0282\n",
            "Epoch 90/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.0472 - val_accuracy: 0.9716 - val_loss: 0.0282\n",
            "Epoch 91/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0471 - val_accuracy: 0.9716 - val_loss: 0.0282\n",
            "Epoch 92/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0471 - val_accuracy: 0.9716 - val_loss: 0.0282\n",
            "Epoch 93/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9455 - loss: 0.0471 - val_accuracy: 0.9716 - val_loss: 0.0281\n",
            "Epoch 94/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.0470 - val_accuracy: 0.9716 - val_loss: 0.0281\n",
            "Epoch 95/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.0470 - val_accuracy: 0.9716 - val_loss: 0.0281\n",
            "Epoch 96/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.0469 - val_accuracy: 0.9716 - val_loss: 0.0280\n",
            "Epoch 97/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0469 - val_accuracy: 0.9716 - val_loss: 0.0280\n",
            "Epoch 98/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.0469 - val_accuracy: 0.9716 - val_loss: 0.0280\n",
            "Epoch 99/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.0468 - val_accuracy: 0.9716 - val_loss: 0.0280\n",
            "Epoch 100/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0468 - val_accuracy: 0.9716 - val_loss: 0.0279\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9466 - loss: 0.0501 \n",
            "[VALID] acc=0.972 | sens=0.208 (k=5/24, CI95=[0.092,0.405]) vs base 0.756 p=0.9999\n",
            "[TEST ] sens=0.375 (k=9/24, CI95=[0.212,0.573]) vs base 0.375 p=0.5000\n",
            "The years trained:  ['Year_2022', 'Year_2023']\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.8288 - loss: 0.1156 - val_accuracy: 0.9716 - val_loss: 0.0362\n",
            "Epoch 2/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9455 - loss: 0.0520 - val_accuracy: 0.9716 - val_loss: 0.0354\n",
            "Epoch 3/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9455 - loss: 0.0518 - val_accuracy: 0.9716 - val_loss: 0.0352\n",
            "Epoch 4/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0518 - val_accuracy: 0.9716 - val_loss: 0.0353\n",
            "Epoch 5/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0515 - val_accuracy: 0.9716 - val_loss: 0.0351\n",
            "Epoch 6/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0513 - val_accuracy: 0.9716 - val_loss: 0.0347\n",
            "Epoch 7/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9455 - loss: 0.0514 - val_accuracy: 0.9716 - val_loss: 0.0345\n",
            "Epoch 8/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9455 - loss: 0.0513 - val_accuracy: 0.9716 - val_loss: 0.0344\n",
            "Epoch 9/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9455 - loss: 0.0512 - val_accuracy: 0.9716 - val_loss: 0.0341\n",
            "Epoch 10/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0510 - val_accuracy: 0.9716 - val_loss: 0.0340\n",
            "Epoch 11/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9455 - loss: 0.0511 - val_accuracy: 0.9716 - val_loss: 0.0338\n",
            "Epoch 12/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9455 - loss: 0.0508 - val_accuracy: 0.9716 - val_loss: 0.0335\n",
            "Epoch 13/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9455 - loss: 0.0509 - val_accuracy: 0.9716 - val_loss: 0.0335\n",
            "Epoch 14/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9455 - loss: 0.0509 - val_accuracy: 0.9716 - val_loss: 0.0335\n",
            "Epoch 15/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9455 - loss: 0.0507 - val_accuracy: 0.9716 - val_loss: 0.0332\n",
            "Epoch 16/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9455 - loss: 0.0507 - val_accuracy: 0.9716 - val_loss: 0.0330\n",
            "Epoch 17/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9455 - loss: 0.0507 - val_accuracy: 0.9716 - val_loss: 0.0330\n",
            "Epoch 18/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9455 - loss: 0.0505 - val_accuracy: 0.9716 - val_loss: 0.0329\n",
            "Epoch 19/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9455 - loss: 0.0506 - val_accuracy: 0.9716 - val_loss: 0.0327\n",
            "Epoch 20/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9455 - loss: 0.0506 - val_accuracy: 0.9716 - val_loss: 0.0326\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9466 - loss: 0.0505 \n",
            "[VALID] acc=0.972 | sens=0.167 (k=4/24, CI95=[0.067,0.359]) vs base 0.864 p=1.0000\n",
            "[TEST ] sens=0.375 (k=9/24, CI95=[0.212,0.573]) vs base 0.375 p=0.5000\n",
            "The years trained:  ['Year_2022', 'Year_2023']\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.8942 - loss: 0.1166 - val_accuracy: 0.9716 - val_loss: 0.0436\n",
            "Epoch 2/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9455 - loss: 0.0549 - val_accuracy: 0.9716 - val_loss: 0.0422\n",
            "Epoch 3/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9455 - loss: 0.0543 - val_accuracy: 0.9716 - val_loss: 0.0414\n",
            "Epoch 4/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9455 - loss: 0.0539 - val_accuracy: 0.9716 - val_loss: 0.0408\n",
            "Epoch 5/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9455 - loss: 0.0535 - val_accuracy: 0.9716 - val_loss: 0.0403\n",
            "Epoch 6/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0531 - val_accuracy: 0.9716 - val_loss: 0.0398\n",
            "Epoch 7/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9455 - loss: 0.0528 - val_accuracy: 0.9716 - val_loss: 0.0398\n",
            "Epoch 8/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9455 - loss: 0.0527 - val_accuracy: 0.9716 - val_loss: 0.0394\n",
            "Epoch 9/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9455 - loss: 0.0526 - val_accuracy: 0.9716 - val_loss: 0.0390\n",
            "Epoch 10/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0525 - val_accuracy: 0.9716 - val_loss: 0.0387\n",
            "Epoch 11/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9455 - loss: 0.0524 - val_accuracy: 0.9716 - val_loss: 0.0384\n",
            "Epoch 12/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0522 - val_accuracy: 0.9716 - val_loss: 0.0381\n",
            "Epoch 13/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9455 - loss: 0.0522 - val_accuracy: 0.9716 - val_loss: 0.0378\n",
            "Epoch 14/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0521 - val_accuracy: 0.9716 - val_loss: 0.0377\n",
            "Epoch 15/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9455 - loss: 0.0520 - val_accuracy: 0.9716 - val_loss: 0.0374\n",
            "Epoch 16/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0519 - val_accuracy: 0.9716 - val_loss: 0.0372\n",
            "Epoch 17/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0518 - val_accuracy: 0.9716 - val_loss: 0.0370\n",
            "Epoch 18/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0517 - val_accuracy: 0.9716 - val_loss: 0.0368\n",
            "Epoch 19/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9455 - loss: 0.0517 - val_accuracy: 0.9716 - val_loss: 0.0367\n",
            "Epoch 20/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9455 - loss: 0.0516 - val_accuracy: 0.9716 - val_loss: 0.0365\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9466 - loss: 0.0536 \n",
            "[VALID] acc=0.972 | sens=0.083 (k=2/24, CI95=[0.023,0.258]) vs base 0.864 p=1.0000\n",
            "[TEST ] sens=0.000 (k=0/24, CI95=[0.000,0.138]) vs base 0.375 p=0.9996\n",
            "The years trained:  ['Year_2022', 'Year_2023']\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.5634 - loss: 0.3175 - val_accuracy: 0.9148 - val_loss: 0.0706\n",
            "Epoch 2/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8710 - loss: 0.1080 - val_accuracy: 0.9205 - val_loss: 0.0666\n",
            "Epoch 3/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8726 - loss: 0.1049 - val_accuracy: 0.9205 - val_loss: 0.0645\n",
            "Epoch 4/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8730 - loss: 0.1022 - val_accuracy: 0.9205 - val_loss: 0.0626\n",
            "Epoch 5/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8789 - loss: 0.0998 - val_accuracy: 0.9261 - val_loss: 0.0609\n",
            "Epoch 6/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8829 - loss: 0.0976 - val_accuracy: 0.9318 - val_loss: 0.0592\n",
            "Epoch 7/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8829 - loss: 0.0954 - val_accuracy: 0.9318 - val_loss: 0.0577\n",
            "Epoch 8/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8843 - loss: 0.0935 - val_accuracy: 0.9375 - val_loss: 0.0563\n",
            "Epoch 9/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8843 - loss: 0.0917 - val_accuracy: 0.9432 - val_loss: 0.0550\n",
            "Epoch 10/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8871 - loss: 0.0900 - val_accuracy: 0.9432 - val_loss: 0.0538\n",
            "Epoch 11/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8876 - loss: 0.0884 - val_accuracy: 0.9432 - val_loss: 0.0526\n",
            "Epoch 12/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8891 - loss: 0.0868 - val_accuracy: 0.9432 - val_loss: 0.0515\n",
            "Epoch 13/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8892 - loss: 0.0853 - val_accuracy: 0.9432 - val_loss: 0.0504\n",
            "Epoch 14/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8892 - loss: 0.0839 - val_accuracy: 0.9432 - val_loss: 0.0494\n",
            "Epoch 15/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8892 - loss: 0.0826 - val_accuracy: 0.9432 - val_loss: 0.0485\n",
            "Epoch 16/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8892 - loss: 0.0813 - val_accuracy: 0.9432 - val_loss: 0.0475\n",
            "Epoch 17/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8892 - loss: 0.0801 - val_accuracy: 0.9432 - val_loss: 0.0467\n",
            "Epoch 18/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8897 - loss: 0.0790 - val_accuracy: 0.9432 - val_loss: 0.0459\n",
            "Epoch 19/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8978 - loss: 0.0779 - val_accuracy: 0.9432 - val_loss: 0.0452\n",
            "Epoch 20/20\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8978 - loss: 0.0769 - val_accuracy: 0.9432 - val_loss: 0.0445\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9071 - loss: 0.0694 \n",
            "[VALID] acc=0.943 | sens=0.000 (k=0/24, CI95=[0.000,0.138]) vs base 0.864 p=1.0000\n",
            "[TEST ] sens=0.000 (k=0/24, CI95=[0.000,0.138]) vs base 0.375 p=0.9996\n",
            "The years trained:  ['Year_2022', 'Year_2023']\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.8288 - loss: 0.1156 - val_accuracy: 0.9716 - val_loss: 0.0362\n",
            "Epoch 2/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9455 - loss: 0.0520 - val_accuracy: 0.9716 - val_loss: 0.0354\n",
            "Epoch 3/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0518 - val_accuracy: 0.9716 - val_loss: 0.0352\n",
            "Epoch 4/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0518 - val_accuracy: 0.9716 - val_loss: 0.0353\n",
            "Epoch 5/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0515 - val_accuracy: 0.9716 - val_loss: 0.0351\n",
            "Epoch 6/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0513 - val_accuracy: 0.9716 - val_loss: 0.0347\n",
            "Epoch 7/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9455 - loss: 0.0514 - val_accuracy: 0.9716 - val_loss: 0.0345\n",
            "Epoch 8/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9455 - loss: 0.0513 - val_accuracy: 0.9716 - val_loss: 0.0344\n",
            "Epoch 9/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0512 - val_accuracy: 0.9716 - val_loss: 0.0341\n",
            "Epoch 10/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0510 - val_accuracy: 0.9716 - val_loss: 0.0340\n",
            "Epoch 11/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9455 - loss: 0.0511 - val_accuracy: 0.9716 - val_loss: 0.0338\n",
            "Epoch 12/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9455 - loss: 0.0508 - val_accuracy: 0.9716 - val_loss: 0.0335\n",
            "Epoch 13/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0509 - val_accuracy: 0.9716 - val_loss: 0.0335\n",
            "Epoch 14/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0509 - val_accuracy: 0.9716 - val_loss: 0.0335\n",
            "Epoch 15/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0507 - val_accuracy: 0.9716 - val_loss: 0.0332\n",
            "Epoch 16/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9455 - loss: 0.0507 - val_accuracy: 0.9716 - val_loss: 0.0330\n",
            "Epoch 17/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9455 - loss: 0.0507 - val_accuracy: 0.9716 - val_loss: 0.0330\n",
            "Epoch 18/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9455 - loss: 0.0505 - val_accuracy: 0.9716 - val_loss: 0.0329\n",
            "Epoch 19/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9455 - loss: 0.0506 - val_accuracy: 0.9716 - val_loss: 0.0327\n",
            "Epoch 20/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9455 - loss: 0.0506 - val_accuracy: 0.9716 - val_loss: 0.0326\n",
            "Epoch 21/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9455 - loss: 0.0505 - val_accuracy: 0.9716 - val_loss: 0.0326\n",
            "Epoch 22/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9455 - loss: 0.0504 - val_accuracy: 0.9716 - val_loss: 0.0326\n",
            "Epoch 23/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9455 - loss: 0.0505 - val_accuracy: 0.9716 - val_loss: 0.0324\n",
            "Epoch 24/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0503 - val_accuracy: 0.9716 - val_loss: 0.0323\n",
            "Epoch 25/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9455 - loss: 0.0503 - val_accuracy: 0.9716 - val_loss: 0.0322\n",
            "Epoch 26/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0502 - val_accuracy: 0.9716 - val_loss: 0.0323\n",
            "Epoch 27/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0503 - val_accuracy: 0.9716 - val_loss: 0.0322\n",
            "Epoch 28/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0502 - val_accuracy: 0.9716 - val_loss: 0.0321\n",
            "Epoch 29/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9455 - loss: 0.0501 - val_accuracy: 0.9716 - val_loss: 0.0319\n",
            "Epoch 30/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0503 - val_accuracy: 0.9716 - val_loss: 0.0319\n",
            "Epoch 31/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0501 - val_accuracy: 0.9716 - val_loss: 0.0318\n",
            "Epoch 32/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0500 - val_accuracy: 0.9716 - val_loss: 0.0318\n",
            "Epoch 33/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0501 - val_accuracy: 0.9716 - val_loss: 0.0318\n",
            "Epoch 34/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9455 - loss: 0.0500 - val_accuracy: 0.9716 - val_loss: 0.0317\n",
            "Epoch 35/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9455 - loss: 0.0499 - val_accuracy: 0.9716 - val_loss: 0.0317\n",
            "Epoch 36/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9455 - loss: 0.0499 - val_accuracy: 0.9716 - val_loss: 0.0316\n",
            "Epoch 37/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0499 - val_accuracy: 0.9716 - val_loss: 0.0315\n",
            "Epoch 38/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9455 - loss: 0.0499 - val_accuracy: 0.9716 - val_loss: 0.0314\n",
            "Epoch 39/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9455 - loss: 0.0498 - val_accuracy: 0.9716 - val_loss: 0.0315\n",
            "Epoch 40/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0498 - val_accuracy: 0.9716 - val_loss: 0.0314\n",
            "Epoch 41/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0497 - val_accuracy: 0.9716 - val_loss: 0.0314\n",
            "Epoch 42/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9455 - loss: 0.0497 - val_accuracy: 0.9716 - val_loss: 0.0313\n",
            "Epoch 43/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0497 - val_accuracy: 0.9716 - val_loss: 0.0313\n",
            "Epoch 44/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9455 - loss: 0.0497 - val_accuracy: 0.9716 - val_loss: 0.0313\n",
            "Epoch 45/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0497 - val_accuracy: 0.9716 - val_loss: 0.0311\n",
            "Epoch 46/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0497 - val_accuracy: 0.9716 - val_loss: 0.0311\n",
            "Epoch 47/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0496 - val_accuracy: 0.9716 - val_loss: 0.0311\n",
            "Epoch 48/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9455 - loss: 0.0495 - val_accuracy: 0.9716 - val_loss: 0.0311\n",
            "Epoch 49/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0496 - val_accuracy: 0.9716 - val_loss: 0.0311\n",
            "Epoch 50/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0496 - val_accuracy: 0.9716 - val_loss: 0.0309\n",
            "Epoch 51/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0495 - val_accuracy: 0.9716 - val_loss: 0.0309\n",
            "Epoch 52/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9455 - loss: 0.0495 - val_accuracy: 0.9716 - val_loss: 0.0309\n",
            "Epoch 53/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0494 - val_accuracy: 0.9716 - val_loss: 0.0309\n",
            "Epoch 54/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0494 - val_accuracy: 0.9716 - val_loss: 0.0311\n",
            "Epoch 55/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0496 - val_accuracy: 0.9716 - val_loss: 0.0309\n",
            "Epoch 56/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9455 - loss: 0.0494 - val_accuracy: 0.9716 - val_loss: 0.0308\n",
            "Epoch 57/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0494 - val_accuracy: 0.9716 - val_loss: 0.0309\n",
            "Epoch 58/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0494 - val_accuracy: 0.9716 - val_loss: 0.0310\n",
            "Epoch 59/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9455 - loss: 0.0495 - val_accuracy: 0.9716 - val_loss: 0.0307\n",
            "Epoch 60/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9455 - loss: 0.0493 - val_accuracy: 0.9716 - val_loss: 0.0306\n",
            "Epoch 61/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9455 - loss: 0.0494 - val_accuracy: 0.9716 - val_loss: 0.0306\n",
            "Epoch 62/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9455 - loss: 0.0493 - val_accuracy: 0.9716 - val_loss: 0.0307\n",
            "Epoch 63/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9455 - loss: 0.0492 - val_accuracy: 0.9716 - val_loss: 0.0306\n",
            "Epoch 64/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9455 - loss: 0.0492 - val_accuracy: 0.9716 - val_loss: 0.0306\n",
            "Epoch 65/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9455 - loss: 0.0492 - val_accuracy: 0.9716 - val_loss: 0.0306\n",
            "Epoch 66/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9455 - loss: 0.0492 - val_accuracy: 0.9716 - val_loss: 0.0309\n",
            "Epoch 67/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9455 - loss: 0.0494 - val_accuracy: 0.9716 - val_loss: 0.0305\n",
            "Epoch 68/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9455 - loss: 0.0492 - val_accuracy: 0.9716 - val_loss: 0.0307\n",
            "Epoch 69/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9455 - loss: 0.0492 - val_accuracy: 0.9716 - val_loss: 0.0305\n",
            "Epoch 70/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9455 - loss: 0.0491 - val_accuracy: 0.9716 - val_loss: 0.0305\n",
            "Epoch 71/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0491 - val_accuracy: 0.9716 - val_loss: 0.0305\n",
            "Epoch 72/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9455 - loss: 0.0491 - val_accuracy: 0.9716 - val_loss: 0.0307\n",
            "Epoch 73/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9455 - loss: 0.0493 - val_accuracy: 0.9716 - val_loss: 0.0304\n",
            "Epoch 74/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9455 - loss: 0.0490 - val_accuracy: 0.9716 - val_loss: 0.0305\n",
            "Epoch 75/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0490 - val_accuracy: 0.9716 - val_loss: 0.0308\n",
            "Epoch 76/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9455 - loss: 0.0491 - val_accuracy: 0.9716 - val_loss: 0.0303\n",
            "Epoch 77/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9455 - loss: 0.0489 - val_accuracy: 0.9716 - val_loss: 0.0303\n",
            "Epoch 78/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0489 - val_accuracy: 0.9716 - val_loss: 0.0306\n",
            "Epoch 79/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0492 - val_accuracy: 0.9716 - val_loss: 0.0303\n",
            "Epoch 80/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9455 - loss: 0.0489 - val_accuracy: 0.9716 - val_loss: 0.0307\n",
            "Epoch 81/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0490 - val_accuracy: 0.9716 - val_loss: 0.0302\n",
            "Epoch 82/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0489 - val_accuracy: 0.9716 - val_loss: 0.0302\n",
            "Epoch 83/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0488 - val_accuracy: 0.9716 - val_loss: 0.0303\n",
            "Epoch 84/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0488 - val_accuracy: 0.9716 - val_loss: 0.0303\n",
            "Epoch 85/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9455 - loss: 0.0488 - val_accuracy: 0.9716 - val_loss: 0.0303\n",
            "Epoch 86/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0488 - val_accuracy: 0.9716 - val_loss: 0.0304\n",
            "Epoch 87/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0489 - val_accuracy: 0.9716 - val_loss: 0.0301\n",
            "Epoch 88/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0487 - val_accuracy: 0.9716 - val_loss: 0.0308\n",
            "Epoch 89/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0488 - val_accuracy: 0.9716 - val_loss: 0.0300\n",
            "Epoch 90/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9455 - loss: 0.0486 - val_accuracy: 0.9716 - val_loss: 0.0301\n",
            "Epoch 91/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9455 - loss: 0.0487 - val_accuracy: 0.9716 - val_loss: 0.0307\n",
            "Epoch 92/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0488 - val_accuracy: 0.9716 - val_loss: 0.0299\n",
            "Epoch 93/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9455 - loss: 0.0486 - val_accuracy: 0.9716 - val_loss: 0.0300\n",
            "Epoch 94/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0486 - val_accuracy: 0.9716 - val_loss: 0.0304\n",
            "Epoch 95/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9455 - loss: 0.0486 - val_accuracy: 0.9716 - val_loss: 0.0300\n",
            "Epoch 96/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0486 - val_accuracy: 0.9716 - val_loss: 0.0303\n",
            "Epoch 97/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0486 - val_accuracy: 0.9716 - val_loss: 0.0306\n",
            "Epoch 98/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9455 - loss: 0.0486 - val_accuracy: 0.9716 - val_loss: 0.0300\n",
            "Epoch 99/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9455 - loss: 0.0485 - val_accuracy: 0.9716 - val_loss: 0.0299\n",
            "Epoch 100/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9455 - loss: 0.0485 - val_accuracy: 0.9716 - val_loss: 0.0299\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9466 - loss: 0.0492 \n",
            "[VALID] acc=0.972 | sens=0.167 (k=4/24, CI95=[0.067,0.359]) vs base 0.864 p=1.0000\n",
            "[TEST ] sens=0.375 (k=9/24, CI95=[0.212,0.573]) vs base 0.375 p=0.5000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display2425Df.head(100)"
      ],
      "metadata": {
        "id": "lhFFs6OsofRk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 839
        },
        "outputId": "c51a5933-8cf8-41e6-eced-88e67216a3bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Model Complexity  Layers  Epochs Optimizer Activation  val_accuracy  \\\n",
              "0            Simple       2      20      adam       relu      0.947917   \n",
              "1            Simple       2      20      adam       tanh      0.947917   \n",
              "2            Simple       2      20      adam    sigmoid      0.947917   \n",
              "3            Simple       2     100      adam       relu      0.927083   \n",
              "4            Medium       4      20      adam       relu      0.947917   \n",
              "5            Medium       4      20      adam       tanh      0.947917   \n",
              "6            Medium       4      20      adam    sigmoid      0.947917   \n",
              "7            Medium       4     100      adam       relu      0.927083   \n",
              "8              High       8      20      adam       relu      0.947917   \n",
              "9              High       8      20      adam       tanh      0.947917   \n",
              "10             High       8      20      adam    sigmoid      0.947917   \n",
              "11             High       8     100      adam       relu      0.854167   \n",
              "12           Simple       2      20   adagrad       relu      0.947917   \n",
              "13           Simple       2      20   adagrad       tanh      0.947917   \n",
              "14           Simple       2      20   adagrad    sigmoid      0.947917   \n",
              "15           Simple       2     100   adagrad    sigmoid      0.947917   \n",
              "16           Medium       4      20   adagrad       relu      0.947917   \n",
              "17           Medium       4      20   adagrad       tanh      0.947917   \n",
              "18           Medium       4      20   adagrad    sigmoid      0.947917   \n",
              "19           Medium       4     100   adagrad    sigmoid      0.947917   \n",
              "20             High       8      20   adagrad       relu      0.947917   \n",
              "21             High       8      20   adagrad       tanh      0.947917   \n",
              "22             High       8      20   adagrad    sigmoid      0.843750   \n",
              "23             High       8     100   adagrad       relu      0.947917   \n",
              "\n",
              "    val_sensitivity  val_ci_low  val_ci_high  test_sensitivity  test_ci_low  \\\n",
              "0          0.125000    0.043443     0.310039          0.173913     0.069787   \n",
              "1          0.125000    0.043443     0.310039          0.000000     0.000000   \n",
              "2          0.125000    0.043443     0.310039          0.173913     0.069787   \n",
              "3          0.166667    0.066787     0.358531          0.086957     0.024180   \n",
              "4          0.125000    0.043443     0.310039          0.173913     0.069787   \n",
              "5          0.125000    0.043443     0.310039          0.000000     0.000000   \n",
              "6          0.125000    0.043443     0.310039          0.173913     0.069787   \n",
              "7          0.166667    0.066787     0.358531          0.086957     0.024180   \n",
              "8          0.125000    0.043443     0.310039          0.086957     0.024180   \n",
              "9          0.125000    0.043443     0.310039          0.000000     0.000000   \n",
              "10         0.125000    0.043443     0.310039          0.043478     0.007717   \n",
              "11         0.125000    0.043443     0.310039          0.130435     0.045377   \n",
              "12         0.000000    0.000000     0.137976          0.086957     0.024180   \n",
              "13         0.041667    0.007393     0.202418          0.000000     0.000000   \n",
              "14         0.041667    0.007393     0.202418          0.173913     0.069787   \n",
              "15         0.000000    0.000000     0.137976          0.217391     0.096640   \n",
              "16         0.000000    0.000000     0.137976          0.086957     0.024180   \n",
              "17         0.041667    0.007393     0.202418          0.000000     0.000000   \n",
              "18         0.041667    0.007393     0.202418          0.173913     0.069787   \n",
              "19         0.000000    0.000000     0.137976          0.217391     0.096640   \n",
              "20         0.125000    0.043443     0.310039          0.000000     0.000000   \n",
              "21         0.041667    0.007393     0.202418          0.000000     0.000000   \n",
              "22         0.083333    0.023159     0.258488          0.000000     0.000000   \n",
              "23         0.125000    0.043443     0.310039          0.000000     0.000000   \n",
              "\n",
              "    test_ci_high  test_p_value_vs_baseline  \n",
              "0       0.371376                  0.190625  \n",
              "1       0.143117                  0.925911  \n",
              "2       0.371376                  0.190625  \n",
              "3       0.267960                  0.500000  \n",
              "4       0.371376                  0.190625  \n",
              "5       0.143117                  0.925911  \n",
              "6       0.371376                  0.190625  \n",
              "7       0.267960                  0.500000  \n",
              "8       0.267960                  0.500000  \n",
              "9       0.143117                  0.925911  \n",
              "10      0.209912                  0.724797  \n",
              "11      0.321275                  0.317857  \n",
              "12      0.267960                  0.500000  \n",
              "13      0.143117                  0.925911  \n",
              "14      0.371376                  0.190625  \n",
              "15      0.419035                  0.109076  \n",
              "16      0.267960                  0.500000  \n",
              "17      0.143117                  0.925911  \n",
              "18      0.371376                  0.190625  \n",
              "19      0.419035                  0.109076  \n",
              "20      0.143117                  0.925911  \n",
              "21      0.143117                  0.925911  \n",
              "22      0.143117                  0.925911  \n",
              "23      0.143117                  0.925911  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4584e2ed-eecb-43f2-b347-2a8a9c9f9358\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model Complexity</th>\n",
              "      <th>Layers</th>\n",
              "      <th>Epochs</th>\n",
              "      <th>Optimizer</th>\n",
              "      <th>Activation</th>\n",
              "      <th>val_accuracy</th>\n",
              "      <th>val_sensitivity</th>\n",
              "      <th>val_ci_low</th>\n",
              "      <th>val_ci_high</th>\n",
              "      <th>test_sensitivity</th>\n",
              "      <th>test_ci_low</th>\n",
              "      <th>test_ci_high</th>\n",
              "      <th>test_p_value_vs_baseline</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Simple</td>\n",
              "      <td>2</td>\n",
              "      <td>20</td>\n",
              "      <td>adam</td>\n",
              "      <td>relu</td>\n",
              "      <td>0.947917</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.043443</td>\n",
              "      <td>0.310039</td>\n",
              "      <td>0.173913</td>\n",
              "      <td>0.069787</td>\n",
              "      <td>0.371376</td>\n",
              "      <td>0.190625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Simple</td>\n",
              "      <td>2</td>\n",
              "      <td>20</td>\n",
              "      <td>adam</td>\n",
              "      <td>tanh</td>\n",
              "      <td>0.947917</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.043443</td>\n",
              "      <td>0.310039</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.143117</td>\n",
              "      <td>0.925911</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Simple</td>\n",
              "      <td>2</td>\n",
              "      <td>20</td>\n",
              "      <td>adam</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>0.947917</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.043443</td>\n",
              "      <td>0.310039</td>\n",
              "      <td>0.173913</td>\n",
              "      <td>0.069787</td>\n",
              "      <td>0.371376</td>\n",
              "      <td>0.190625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Simple</td>\n",
              "      <td>2</td>\n",
              "      <td>100</td>\n",
              "      <td>adam</td>\n",
              "      <td>relu</td>\n",
              "      <td>0.927083</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.066787</td>\n",
              "      <td>0.358531</td>\n",
              "      <td>0.086957</td>\n",
              "      <td>0.024180</td>\n",
              "      <td>0.267960</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Medium</td>\n",
              "      <td>4</td>\n",
              "      <td>20</td>\n",
              "      <td>adam</td>\n",
              "      <td>relu</td>\n",
              "      <td>0.947917</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.043443</td>\n",
              "      <td>0.310039</td>\n",
              "      <td>0.173913</td>\n",
              "      <td>0.069787</td>\n",
              "      <td>0.371376</td>\n",
              "      <td>0.190625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Medium</td>\n",
              "      <td>4</td>\n",
              "      <td>20</td>\n",
              "      <td>adam</td>\n",
              "      <td>tanh</td>\n",
              "      <td>0.947917</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.043443</td>\n",
              "      <td>0.310039</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.143117</td>\n",
              "      <td>0.925911</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Medium</td>\n",
              "      <td>4</td>\n",
              "      <td>20</td>\n",
              "      <td>adam</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>0.947917</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.043443</td>\n",
              "      <td>0.310039</td>\n",
              "      <td>0.173913</td>\n",
              "      <td>0.069787</td>\n",
              "      <td>0.371376</td>\n",
              "      <td>0.190625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Medium</td>\n",
              "      <td>4</td>\n",
              "      <td>100</td>\n",
              "      <td>adam</td>\n",
              "      <td>relu</td>\n",
              "      <td>0.927083</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.066787</td>\n",
              "      <td>0.358531</td>\n",
              "      <td>0.086957</td>\n",
              "      <td>0.024180</td>\n",
              "      <td>0.267960</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>High</td>\n",
              "      <td>8</td>\n",
              "      <td>20</td>\n",
              "      <td>adam</td>\n",
              "      <td>relu</td>\n",
              "      <td>0.947917</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.043443</td>\n",
              "      <td>0.310039</td>\n",
              "      <td>0.086957</td>\n",
              "      <td>0.024180</td>\n",
              "      <td>0.267960</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>High</td>\n",
              "      <td>8</td>\n",
              "      <td>20</td>\n",
              "      <td>adam</td>\n",
              "      <td>tanh</td>\n",
              "      <td>0.947917</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.043443</td>\n",
              "      <td>0.310039</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.143117</td>\n",
              "      <td>0.925911</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>High</td>\n",
              "      <td>8</td>\n",
              "      <td>20</td>\n",
              "      <td>adam</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>0.947917</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.043443</td>\n",
              "      <td>0.310039</td>\n",
              "      <td>0.043478</td>\n",
              "      <td>0.007717</td>\n",
              "      <td>0.209912</td>\n",
              "      <td>0.724797</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>High</td>\n",
              "      <td>8</td>\n",
              "      <td>100</td>\n",
              "      <td>adam</td>\n",
              "      <td>relu</td>\n",
              "      <td>0.854167</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.043443</td>\n",
              "      <td>0.310039</td>\n",
              "      <td>0.130435</td>\n",
              "      <td>0.045377</td>\n",
              "      <td>0.321275</td>\n",
              "      <td>0.317857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Simple</td>\n",
              "      <td>2</td>\n",
              "      <td>20</td>\n",
              "      <td>adagrad</td>\n",
              "      <td>relu</td>\n",
              "      <td>0.947917</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.137976</td>\n",
              "      <td>0.086957</td>\n",
              "      <td>0.024180</td>\n",
              "      <td>0.267960</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Simple</td>\n",
              "      <td>2</td>\n",
              "      <td>20</td>\n",
              "      <td>adagrad</td>\n",
              "      <td>tanh</td>\n",
              "      <td>0.947917</td>\n",
              "      <td>0.041667</td>\n",
              "      <td>0.007393</td>\n",
              "      <td>0.202418</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.143117</td>\n",
              "      <td>0.925911</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Simple</td>\n",
              "      <td>2</td>\n",
              "      <td>20</td>\n",
              "      <td>adagrad</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>0.947917</td>\n",
              "      <td>0.041667</td>\n",
              "      <td>0.007393</td>\n",
              "      <td>0.202418</td>\n",
              "      <td>0.173913</td>\n",
              "      <td>0.069787</td>\n",
              "      <td>0.371376</td>\n",
              "      <td>0.190625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Simple</td>\n",
              "      <td>2</td>\n",
              "      <td>100</td>\n",
              "      <td>adagrad</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>0.947917</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.137976</td>\n",
              "      <td>0.217391</td>\n",
              "      <td>0.096640</td>\n",
              "      <td>0.419035</td>\n",
              "      <td>0.109076</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Medium</td>\n",
              "      <td>4</td>\n",
              "      <td>20</td>\n",
              "      <td>adagrad</td>\n",
              "      <td>relu</td>\n",
              "      <td>0.947917</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.137976</td>\n",
              "      <td>0.086957</td>\n",
              "      <td>0.024180</td>\n",
              "      <td>0.267960</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Medium</td>\n",
              "      <td>4</td>\n",
              "      <td>20</td>\n",
              "      <td>adagrad</td>\n",
              "      <td>tanh</td>\n",
              "      <td>0.947917</td>\n",
              "      <td>0.041667</td>\n",
              "      <td>0.007393</td>\n",
              "      <td>0.202418</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.143117</td>\n",
              "      <td>0.925911</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Medium</td>\n",
              "      <td>4</td>\n",
              "      <td>20</td>\n",
              "      <td>adagrad</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>0.947917</td>\n",
              "      <td>0.041667</td>\n",
              "      <td>0.007393</td>\n",
              "      <td>0.202418</td>\n",
              "      <td>0.173913</td>\n",
              "      <td>0.069787</td>\n",
              "      <td>0.371376</td>\n",
              "      <td>0.190625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Medium</td>\n",
              "      <td>4</td>\n",
              "      <td>100</td>\n",
              "      <td>adagrad</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>0.947917</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.137976</td>\n",
              "      <td>0.217391</td>\n",
              "      <td>0.096640</td>\n",
              "      <td>0.419035</td>\n",
              "      <td>0.109076</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>High</td>\n",
              "      <td>8</td>\n",
              "      <td>20</td>\n",
              "      <td>adagrad</td>\n",
              "      <td>relu</td>\n",
              "      <td>0.947917</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.043443</td>\n",
              "      <td>0.310039</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.143117</td>\n",
              "      <td>0.925911</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>High</td>\n",
              "      <td>8</td>\n",
              "      <td>20</td>\n",
              "      <td>adagrad</td>\n",
              "      <td>tanh</td>\n",
              "      <td>0.947917</td>\n",
              "      <td>0.041667</td>\n",
              "      <td>0.007393</td>\n",
              "      <td>0.202418</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.143117</td>\n",
              "      <td>0.925911</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>High</td>\n",
              "      <td>8</td>\n",
              "      <td>20</td>\n",
              "      <td>adagrad</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>0.843750</td>\n",
              "      <td>0.083333</td>\n",
              "      <td>0.023159</td>\n",
              "      <td>0.258488</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.143117</td>\n",
              "      <td>0.925911</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>High</td>\n",
              "      <td>8</td>\n",
              "      <td>100</td>\n",
              "      <td>adagrad</td>\n",
              "      <td>relu</td>\n",
              "      <td>0.947917</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.043443</td>\n",
              "      <td>0.310039</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.143117</td>\n",
              "      <td>0.925911</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4584e2ed-eecb-43f2-b347-2a8a9c9f9358')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4584e2ed-eecb-43f2-b347-2a8a9c9f9358 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4584e2ed-eecb-43f2-b347-2a8a9c9f9358');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-134426aa-4811-4f2b-a897-ac51b9a44414\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-134426aa-4811-4f2b-a897-ac51b9a44414')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-134426aa-4811-4f2b-a897-ac51b9a44414 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "display2425Df",
              "summary": "{\n  \"name\": \"display2425Df\",\n  \"rows\": 24,\n  \"fields\": [\n    {\n      \"column\": \"Model Complexity\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Simple\",\n          \"Medium\",\n          \"High\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Layers\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 2,\n        \"max\": 8,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          2,\n          4,\n          8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Epochs\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 35,\n        \"min\": 20,\n        \"max\": 100,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          100,\n          20\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Optimizer\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"adagrad\",\n          \"adam\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Activation\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"relu\",\n          \"tanh\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"val_accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.02806525320898999,\n        \"min\": 0.84375,\n        \"max\": 0.9479166865348816,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.9270833134651184,\n          0.84375\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"val_sensitivity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05537599302824947,\n        \"min\": 0.0,\n        \"max\": 0.16666666666666666,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.16666666666666666,\n          0.08333333333333333\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"val_ci_low\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.021944852133192815,\n        \"min\": 0.0,\n        \"max\": 0.06678676328632946,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.06678676328632946,\n          0.023158815297043348\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"val_ci_high\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.07389370114218613,\n        \"min\": 0.13797620467498026,\n        \"max\": 0.3585307064969907,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.3585307064969907,\n          0.2584880219321069\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_sensitivity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.08108737462959249,\n        \"min\": 0.0,\n        \"max\": 0.21739130434782608,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.17391304347826086,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_ci_low\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.03438934560085732,\n        \"min\": 0.0,\n        \"max\": 0.09663978026586204,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.06978653563062565,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_ci_high\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.105199462471188,\n        \"min\": 0.1431166184504269,\n        \"max\": 0.4190348301626401,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.3713764764022614,\n          0.1431166184504269\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_p_value_vs_baseline\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.33181950431434026,\n        \"min\": 0.10907620929844658,\n        \"max\": 0.9259110640518575,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.19062511254161607,\n          0.9259110640518575\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display2425Df['Biggest Winner Naive Test Sensitivity'] = .087\n",
        "display2425Df['Previous Winner Naive Test Sensitivity'] = .087\n",
        "display2425Df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "id": "4i8ejHPD0hOw",
        "outputId": "5d252532-b369-49a8-db63-0d2b6356344c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  Model Complexity  Layers  Epochs Optimizer Activation  val_accuracy  \\\n",
              "0           Simple       2      20      adam       relu      0.947917   \n",
              "1           Simple       2      20      adam       tanh      0.947917   \n",
              "2           Simple       2      20      adam    sigmoid      0.947917   \n",
              "3           Simple       2     100      adam       relu      0.927083   \n",
              "4           Medium       4      20      adam       relu      0.947917   \n",
              "\n",
              "   val_sensitivity  val_ci_low  val_ci_high  test_sensitivity  test_ci_low  \\\n",
              "0         0.125000    0.043443     0.310039          0.173913     0.069787   \n",
              "1         0.125000    0.043443     0.310039          0.000000     0.000000   \n",
              "2         0.125000    0.043443     0.310039          0.173913     0.069787   \n",
              "3         0.166667    0.066787     0.358531          0.086957     0.024180   \n",
              "4         0.125000    0.043443     0.310039          0.173913     0.069787   \n",
              "\n",
              "   test_ci_high  test_p_value_vs_baseline  \\\n",
              "0      0.371376                  0.190625   \n",
              "1      0.143117                  0.925911   \n",
              "2      0.371376                  0.190625   \n",
              "3      0.267960                  0.500000   \n",
              "4      0.371376                  0.190625   \n",
              "\n",
              "   Biggest Winner Naive Test Sensitivity  \\\n",
              "0                                  0.087   \n",
              "1                                  0.087   \n",
              "2                                  0.087   \n",
              "3                                  0.087   \n",
              "4                                  0.087   \n",
              "\n",
              "   Previous Winner Naive Test Sensitivity  \n",
              "0                                   0.087  \n",
              "1                                   0.087  \n",
              "2                                   0.087  \n",
              "3                                   0.087  \n",
              "4                                   0.087  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fefd08f5-e480-42e1-bbad-ec87bc9e6921\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model Complexity</th>\n",
              "      <th>Layers</th>\n",
              "      <th>Epochs</th>\n",
              "      <th>Optimizer</th>\n",
              "      <th>Activation</th>\n",
              "      <th>val_accuracy</th>\n",
              "      <th>val_sensitivity</th>\n",
              "      <th>val_ci_low</th>\n",
              "      <th>val_ci_high</th>\n",
              "      <th>test_sensitivity</th>\n",
              "      <th>test_ci_low</th>\n",
              "      <th>test_ci_high</th>\n",
              "      <th>test_p_value_vs_baseline</th>\n",
              "      <th>Biggest Winner Naive Test Sensitivity</th>\n",
              "      <th>Previous Winner Naive Test Sensitivity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Simple</td>\n",
              "      <td>2</td>\n",
              "      <td>20</td>\n",
              "      <td>adam</td>\n",
              "      <td>relu</td>\n",
              "      <td>0.947917</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.043443</td>\n",
              "      <td>0.310039</td>\n",
              "      <td>0.173913</td>\n",
              "      <td>0.069787</td>\n",
              "      <td>0.371376</td>\n",
              "      <td>0.190625</td>\n",
              "      <td>0.087</td>\n",
              "      <td>0.087</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Simple</td>\n",
              "      <td>2</td>\n",
              "      <td>20</td>\n",
              "      <td>adam</td>\n",
              "      <td>tanh</td>\n",
              "      <td>0.947917</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.043443</td>\n",
              "      <td>0.310039</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.143117</td>\n",
              "      <td>0.925911</td>\n",
              "      <td>0.087</td>\n",
              "      <td>0.087</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Simple</td>\n",
              "      <td>2</td>\n",
              "      <td>20</td>\n",
              "      <td>adam</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>0.947917</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.043443</td>\n",
              "      <td>0.310039</td>\n",
              "      <td>0.173913</td>\n",
              "      <td>0.069787</td>\n",
              "      <td>0.371376</td>\n",
              "      <td>0.190625</td>\n",
              "      <td>0.087</td>\n",
              "      <td>0.087</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Simple</td>\n",
              "      <td>2</td>\n",
              "      <td>100</td>\n",
              "      <td>adam</td>\n",
              "      <td>relu</td>\n",
              "      <td>0.927083</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.066787</td>\n",
              "      <td>0.358531</td>\n",
              "      <td>0.086957</td>\n",
              "      <td>0.024180</td>\n",
              "      <td>0.267960</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.087</td>\n",
              "      <td>0.087</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Medium</td>\n",
              "      <td>4</td>\n",
              "      <td>20</td>\n",
              "      <td>adam</td>\n",
              "      <td>relu</td>\n",
              "      <td>0.947917</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.043443</td>\n",
              "      <td>0.310039</td>\n",
              "      <td>0.173913</td>\n",
              "      <td>0.069787</td>\n",
              "      <td>0.371376</td>\n",
              "      <td>0.190625</td>\n",
              "      <td>0.087</td>\n",
              "      <td>0.087</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fefd08f5-e480-42e1-bbad-ec87bc9e6921')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-fefd08f5-e480-42e1-bbad-ec87bc9e6921 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-fefd08f5-e480-42e1-bbad-ec87bc9e6921');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-5b09daec-6bb4-4aa1-9cf0-8bb90610d3df\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5b09daec-6bb4-4aa1-9cf0-8bb90610d3df')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-5b09daec-6bb4-4aa1-9cf0-8bb90610d3df button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "display2425Df",
              "summary": "{\n  \"name\": \"display2425Df\",\n  \"rows\": 24,\n  \"fields\": [\n    {\n      \"column\": \"Model Complexity\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Simple\",\n          \"Medium\",\n          \"High\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Layers\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 2,\n        \"max\": 8,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          2,\n          4,\n          8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Epochs\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 35,\n        \"min\": 20,\n        \"max\": 100,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          100,\n          20\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Optimizer\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"adagrad\",\n          \"adam\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Activation\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"relu\",\n          \"tanh\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"val_accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.02806525320898999,\n        \"min\": 0.84375,\n        \"max\": 0.9479166865348816,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.9270833134651184,\n          0.84375\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"val_sensitivity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05537599302824947,\n        \"min\": 0.0,\n        \"max\": 0.16666666666666666,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.16666666666666666,\n          0.08333333333333333\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"val_ci_low\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.021944852133192815,\n        \"min\": 0.0,\n        \"max\": 0.06678676328632946,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.06678676328632946,\n          0.023158815297043348\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"val_ci_high\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.07389370114218613,\n        \"min\": 0.13797620467498026,\n        \"max\": 0.3585307064969907,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.3585307064969907,\n          0.2584880219321069\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_sensitivity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.08108737462959249,\n        \"min\": 0.0,\n        \"max\": 0.21739130434782608,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.17391304347826086,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_ci_low\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.03438934560085732,\n        \"min\": 0.0,\n        \"max\": 0.09663978026586204,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.06978653563062565,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_ci_high\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.105199462471188,\n        \"min\": 0.1431166184504269,\n        \"max\": 0.4190348301626401,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.3713764764022614,\n          0.1431166184504269\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_p_value_vs_baseline\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.33181950431434026,\n        \"min\": 0.10907620929844658,\n        \"max\": 0.9259110640518575,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.19062511254161607,\n          0.9259110640518575\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Biggest Winner Naive Test Sensitivity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.4176269004663433e-17,\n        \"min\": 0.087,\n        \"max\": 0.087,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.087\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Previous Winner Naive Test Sensitivity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.4176269004663433e-17,\n        \"min\": 0.087,\n        \"max\": 0.087,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.087\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display232425Df['Biggest Winner Naive Test Sensitivity'] = .087\n",
        "display232425Df['Previous Winner Naive Test Sensitivity'] = .087\n",
        "display232425Df.head(20)"
      ],
      "metadata": {
        "id": "diBZ8h6-nnsi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        },
        "outputId": "913c235d-7629-4e60-bc2a-b9bcb09276ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Model Complexity  Layers  Epochs Optimizer Activation  val_accuracy  \\\n",
              "0            Simple       2      20      adam       relu      0.956522   \n",
              "1            Simple       2      20      adam       tanh      0.940217   \n",
              "2            Simple       2      20      adam    sigmoid      0.956522   \n",
              "3            Simple       2     100      adam       relu      0.961957   \n",
              "4            Medium       4      20      adam       relu      0.956522   \n",
              "5            Medium       4      20      adam       tanh      0.940217   \n",
              "6            Medium       4      20      adam    sigmoid      0.956522   \n",
              "7            Medium       4     100      adam       relu      0.961957   \n",
              "8              High       8      20      adam       relu      0.940217   \n",
              "9              High       8      20      adam       tanh      0.961957   \n",
              "10             High       8      20      adam    sigmoid      0.961957   \n",
              "11             High       8     100      adam       relu      0.956522   \n",
              "12           Simple       2      20   adagrad       relu      0.940217   \n",
              "13           Simple       2      20   adagrad       tanh      0.940217   \n",
              "14           Simple       2      20   adagrad    sigmoid      0.940217   \n",
              "15           Simple       2     100   adagrad    sigmoid      0.940217   \n",
              "16           Medium       4      20   adagrad       relu      0.940217   \n",
              "17           Medium       4      20   adagrad       tanh      0.940217   \n",
              "18           Medium       4      20   adagrad    sigmoid      0.940217   \n",
              "19           Medium       4     100   adagrad    sigmoid      0.940217   \n",
              "\n",
              "    val_sensitivity  val_ci_low  val_ci_high  test_sensitivity  test_ci_low  \\\n",
              "0          0.304348    0.156040     0.508658          0.086957     0.024180   \n",
              "1          0.347826    0.188113     0.551097          0.086957     0.024180   \n",
              "2          0.347826    0.188113     0.551097          0.086957     0.024180   \n",
              "3          0.347826    0.188113     0.551097          0.086957     0.024180   \n",
              "4          0.304348    0.156040     0.508658          0.086957     0.024180   \n",
              "5          0.347826    0.188113     0.551097          0.086957     0.024180   \n",
              "6          0.347826    0.188113     0.551097          0.086957     0.024180   \n",
              "7          0.347826    0.188113     0.551097          0.086957     0.024180   \n",
              "8          0.347826    0.188113     0.551097          0.086957     0.024180   \n",
              "9          0.347826    0.188113     0.551097          0.086957     0.024180   \n",
              "10         0.347826    0.188113     0.551097          0.086957     0.024180   \n",
              "11         0.304348    0.156040     0.508658          0.086957     0.024180   \n",
              "12         0.086957    0.024180     0.267960          0.043478     0.007717   \n",
              "13         0.217391    0.096640     0.419035          0.043478     0.007717   \n",
              "14         0.086957    0.024180     0.267960          0.086957     0.024180   \n",
              "15         0.043478    0.007717     0.209912          0.043478     0.007717   \n",
              "16         0.086957    0.024180     0.267960          0.043478     0.007717   \n",
              "17         0.217391    0.096640     0.419035          0.043478     0.007717   \n",
              "18         0.086957    0.024180     0.267960          0.086957     0.024180   \n",
              "19         0.043478    0.007717     0.209912          0.043478     0.007717   \n",
              "\n",
              "    test_ci_high  test_p_value_vs_baseline  \\\n",
              "0       0.267960                  0.500000   \n",
              "1       0.267960                  0.500000   \n",
              "2       0.267960                  0.500000   \n",
              "3       0.267960                  0.500000   \n",
              "4       0.267960                  0.500000   \n",
              "5       0.267960                  0.500000   \n",
              "6       0.267960                  0.500000   \n",
              "7       0.267960                  0.500000   \n",
              "8       0.267960                  0.500000   \n",
              "9       0.267960                  0.500000   \n",
              "10      0.267960                  0.500000   \n",
              "11      0.267960                  0.500000   \n",
              "12      0.209912                  0.724797   \n",
              "13      0.209912                  0.724797   \n",
              "14      0.267960                  0.500000   \n",
              "15      0.209912                  0.724797   \n",
              "16      0.209912                  0.724797   \n",
              "17      0.209912                  0.724797   \n",
              "18      0.267960                  0.500000   \n",
              "19      0.209912                  0.724797   \n",
              "\n",
              "    Biggest Winner Naive Test Sensitivity  \\\n",
              "0                                   0.087   \n",
              "1                                   0.087   \n",
              "2                                   0.087   \n",
              "3                                   0.087   \n",
              "4                                   0.087   \n",
              "5                                   0.087   \n",
              "6                                   0.087   \n",
              "7                                   0.087   \n",
              "8                                   0.087   \n",
              "9                                   0.087   \n",
              "10                                  0.087   \n",
              "11                                  0.087   \n",
              "12                                  0.087   \n",
              "13                                  0.087   \n",
              "14                                  0.087   \n",
              "15                                  0.087   \n",
              "16                                  0.087   \n",
              "17                                  0.087   \n",
              "18                                  0.087   \n",
              "19                                  0.087   \n",
              "\n",
              "    Previous Winner Naive Test Sensitivity  \n",
              "0                                    0.087  \n",
              "1                                    0.087  \n",
              "2                                    0.087  \n",
              "3                                    0.087  \n",
              "4                                    0.087  \n",
              "5                                    0.087  \n",
              "6                                    0.087  \n",
              "7                                    0.087  \n",
              "8                                    0.087  \n",
              "9                                    0.087  \n",
              "10                                   0.087  \n",
              "11                                   0.087  \n",
              "12                                   0.087  \n",
              "13                                   0.087  \n",
              "14                                   0.087  \n",
              "15                                   0.087  \n",
              "16                                   0.087  \n",
              "17                                   0.087  \n",
              "18                                   0.087  \n",
              "19                                   0.087  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-daf51fca-0444-4148-bd77-e17e9b6fa6b1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model Complexity</th>\n",
              "      <th>Layers</th>\n",
              "      <th>Epochs</th>\n",
              "      <th>Optimizer</th>\n",
              "      <th>Activation</th>\n",
              "      <th>val_accuracy</th>\n",
              "      <th>val_sensitivity</th>\n",
              "      <th>val_ci_low</th>\n",
              "      <th>val_ci_high</th>\n",
              "      <th>test_sensitivity</th>\n",
              "      <th>test_ci_low</th>\n",
              "      <th>test_ci_high</th>\n",
              "      <th>test_p_value_vs_baseline</th>\n",
              "      <th>Biggest Winner Naive Test Sensitivity</th>\n",
              "      <th>Previous Winner Naive Test Sensitivity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Simple</td>\n",
              "      <td>2</td>\n",
              "      <td>20</td>\n",
              "      <td>adam</td>\n",
              "      <td>relu</td>\n",
              "      <td>0.956522</td>\n",
              "      <td>0.304348</td>\n",
              "      <td>0.156040</td>\n",
              "      <td>0.508658</td>\n",
              "      <td>0.086957</td>\n",
              "      <td>0.024180</td>\n",
              "      <td>0.267960</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.087</td>\n",
              "      <td>0.087</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Simple</td>\n",
              "      <td>2</td>\n",
              "      <td>20</td>\n",
              "      <td>adam</td>\n",
              "      <td>tanh</td>\n",
              "      <td>0.940217</td>\n",
              "      <td>0.347826</td>\n",
              "      <td>0.188113</td>\n",
              "      <td>0.551097</td>\n",
              "      <td>0.086957</td>\n",
              "      <td>0.024180</td>\n",
              "      <td>0.267960</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.087</td>\n",
              "      <td>0.087</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Simple</td>\n",
              "      <td>2</td>\n",
              "      <td>20</td>\n",
              "      <td>adam</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>0.956522</td>\n",
              "      <td>0.347826</td>\n",
              "      <td>0.188113</td>\n",
              "      <td>0.551097</td>\n",
              "      <td>0.086957</td>\n",
              "      <td>0.024180</td>\n",
              "      <td>0.267960</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.087</td>\n",
              "      <td>0.087</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Simple</td>\n",
              "      <td>2</td>\n",
              "      <td>100</td>\n",
              "      <td>adam</td>\n",
              "      <td>relu</td>\n",
              "      <td>0.961957</td>\n",
              "      <td>0.347826</td>\n",
              "      <td>0.188113</td>\n",
              "      <td>0.551097</td>\n",
              "      <td>0.086957</td>\n",
              "      <td>0.024180</td>\n",
              "      <td>0.267960</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.087</td>\n",
              "      <td>0.087</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Medium</td>\n",
              "      <td>4</td>\n",
              "      <td>20</td>\n",
              "      <td>adam</td>\n",
              "      <td>relu</td>\n",
              "      <td>0.956522</td>\n",
              "      <td>0.304348</td>\n",
              "      <td>0.156040</td>\n",
              "      <td>0.508658</td>\n",
              "      <td>0.086957</td>\n",
              "      <td>0.024180</td>\n",
              "      <td>0.267960</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.087</td>\n",
              "      <td>0.087</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Medium</td>\n",
              "      <td>4</td>\n",
              "      <td>20</td>\n",
              "      <td>adam</td>\n",
              "      <td>tanh</td>\n",
              "      <td>0.940217</td>\n",
              "      <td>0.347826</td>\n",
              "      <td>0.188113</td>\n",
              "      <td>0.551097</td>\n",
              "      <td>0.086957</td>\n",
              "      <td>0.024180</td>\n",
              "      <td>0.267960</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.087</td>\n",
              "      <td>0.087</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Medium</td>\n",
              "      <td>4</td>\n",
              "      <td>20</td>\n",
              "      <td>adam</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>0.956522</td>\n",
              "      <td>0.347826</td>\n",
              "      <td>0.188113</td>\n",
              "      <td>0.551097</td>\n",
              "      <td>0.086957</td>\n",
              "      <td>0.024180</td>\n",
              "      <td>0.267960</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.087</td>\n",
              "      <td>0.087</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Medium</td>\n",
              "      <td>4</td>\n",
              "      <td>100</td>\n",
              "      <td>adam</td>\n",
              "      <td>relu</td>\n",
              "      <td>0.961957</td>\n",
              "      <td>0.347826</td>\n",
              "      <td>0.188113</td>\n",
              "      <td>0.551097</td>\n",
              "      <td>0.086957</td>\n",
              "      <td>0.024180</td>\n",
              "      <td>0.267960</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.087</td>\n",
              "      <td>0.087</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>High</td>\n",
              "      <td>8</td>\n",
              "      <td>20</td>\n",
              "      <td>adam</td>\n",
              "      <td>relu</td>\n",
              "      <td>0.940217</td>\n",
              "      <td>0.347826</td>\n",
              "      <td>0.188113</td>\n",
              "      <td>0.551097</td>\n",
              "      <td>0.086957</td>\n",
              "      <td>0.024180</td>\n",
              "      <td>0.267960</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.087</td>\n",
              "      <td>0.087</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>High</td>\n",
              "      <td>8</td>\n",
              "      <td>20</td>\n",
              "      <td>adam</td>\n",
              "      <td>tanh</td>\n",
              "      <td>0.961957</td>\n",
              "      <td>0.347826</td>\n",
              "      <td>0.188113</td>\n",
              "      <td>0.551097</td>\n",
              "      <td>0.086957</td>\n",
              "      <td>0.024180</td>\n",
              "      <td>0.267960</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.087</td>\n",
              "      <td>0.087</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>High</td>\n",
              "      <td>8</td>\n",
              "      <td>20</td>\n",
              "      <td>adam</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>0.961957</td>\n",
              "      <td>0.347826</td>\n",
              "      <td>0.188113</td>\n",
              "      <td>0.551097</td>\n",
              "      <td>0.086957</td>\n",
              "      <td>0.024180</td>\n",
              "      <td>0.267960</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.087</td>\n",
              "      <td>0.087</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>High</td>\n",
              "      <td>8</td>\n",
              "      <td>100</td>\n",
              "      <td>adam</td>\n",
              "      <td>relu</td>\n",
              "      <td>0.956522</td>\n",
              "      <td>0.304348</td>\n",
              "      <td>0.156040</td>\n",
              "      <td>0.508658</td>\n",
              "      <td>0.086957</td>\n",
              "      <td>0.024180</td>\n",
              "      <td>0.267960</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.087</td>\n",
              "      <td>0.087</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Simple</td>\n",
              "      <td>2</td>\n",
              "      <td>20</td>\n",
              "      <td>adagrad</td>\n",
              "      <td>relu</td>\n",
              "      <td>0.940217</td>\n",
              "      <td>0.086957</td>\n",
              "      <td>0.024180</td>\n",
              "      <td>0.267960</td>\n",
              "      <td>0.043478</td>\n",
              "      <td>0.007717</td>\n",
              "      <td>0.209912</td>\n",
              "      <td>0.724797</td>\n",
              "      <td>0.087</td>\n",
              "      <td>0.087</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Simple</td>\n",
              "      <td>2</td>\n",
              "      <td>20</td>\n",
              "      <td>adagrad</td>\n",
              "      <td>tanh</td>\n",
              "      <td>0.940217</td>\n",
              "      <td>0.217391</td>\n",
              "      <td>0.096640</td>\n",
              "      <td>0.419035</td>\n",
              "      <td>0.043478</td>\n",
              "      <td>0.007717</td>\n",
              "      <td>0.209912</td>\n",
              "      <td>0.724797</td>\n",
              "      <td>0.087</td>\n",
              "      <td>0.087</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Simple</td>\n",
              "      <td>2</td>\n",
              "      <td>20</td>\n",
              "      <td>adagrad</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>0.940217</td>\n",
              "      <td>0.086957</td>\n",
              "      <td>0.024180</td>\n",
              "      <td>0.267960</td>\n",
              "      <td>0.086957</td>\n",
              "      <td>0.024180</td>\n",
              "      <td>0.267960</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.087</td>\n",
              "      <td>0.087</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Simple</td>\n",
              "      <td>2</td>\n",
              "      <td>100</td>\n",
              "      <td>adagrad</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>0.940217</td>\n",
              "      <td>0.043478</td>\n",
              "      <td>0.007717</td>\n",
              "      <td>0.209912</td>\n",
              "      <td>0.043478</td>\n",
              "      <td>0.007717</td>\n",
              "      <td>0.209912</td>\n",
              "      <td>0.724797</td>\n",
              "      <td>0.087</td>\n",
              "      <td>0.087</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Medium</td>\n",
              "      <td>4</td>\n",
              "      <td>20</td>\n",
              "      <td>adagrad</td>\n",
              "      <td>relu</td>\n",
              "      <td>0.940217</td>\n",
              "      <td>0.086957</td>\n",
              "      <td>0.024180</td>\n",
              "      <td>0.267960</td>\n",
              "      <td>0.043478</td>\n",
              "      <td>0.007717</td>\n",
              "      <td>0.209912</td>\n",
              "      <td>0.724797</td>\n",
              "      <td>0.087</td>\n",
              "      <td>0.087</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Medium</td>\n",
              "      <td>4</td>\n",
              "      <td>20</td>\n",
              "      <td>adagrad</td>\n",
              "      <td>tanh</td>\n",
              "      <td>0.940217</td>\n",
              "      <td>0.217391</td>\n",
              "      <td>0.096640</td>\n",
              "      <td>0.419035</td>\n",
              "      <td>0.043478</td>\n",
              "      <td>0.007717</td>\n",
              "      <td>0.209912</td>\n",
              "      <td>0.724797</td>\n",
              "      <td>0.087</td>\n",
              "      <td>0.087</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Medium</td>\n",
              "      <td>4</td>\n",
              "      <td>20</td>\n",
              "      <td>adagrad</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>0.940217</td>\n",
              "      <td>0.086957</td>\n",
              "      <td>0.024180</td>\n",
              "      <td>0.267960</td>\n",
              "      <td>0.086957</td>\n",
              "      <td>0.024180</td>\n",
              "      <td>0.267960</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.087</td>\n",
              "      <td>0.087</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Medium</td>\n",
              "      <td>4</td>\n",
              "      <td>100</td>\n",
              "      <td>adagrad</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>0.940217</td>\n",
              "      <td>0.043478</td>\n",
              "      <td>0.007717</td>\n",
              "      <td>0.209912</td>\n",
              "      <td>0.043478</td>\n",
              "      <td>0.007717</td>\n",
              "      <td>0.209912</td>\n",
              "      <td>0.724797</td>\n",
              "      <td>0.087</td>\n",
              "      <td>0.087</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-daf51fca-0444-4148-bd77-e17e9b6fa6b1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-daf51fca-0444-4148-bd77-e17e9b6fa6b1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-daf51fca-0444-4148-bd77-e17e9b6fa6b1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-3c0e6abc-f3a8-42ff-b77e-9393369c94aa\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3c0e6abc-f3a8-42ff-b77e-9393369c94aa')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-3c0e6abc-f3a8-42ff-b77e-9393369c94aa button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "display232425Df",
              "summary": "{\n  \"name\": \"display232425Df\",\n  \"rows\": 24,\n  \"fields\": [\n    {\n      \"column\": \"Model Complexity\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Simple\",\n          \"Medium\",\n          \"High\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Layers\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 2,\n        \"max\": 8,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          2,\n          4,\n          8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Epochs\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 35,\n        \"min\": 20,\n        \"max\": 100,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          100,\n          20\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Optimizer\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"adagrad\",\n          \"adam\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Activation\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"relu\",\n          \"tanh\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"val_accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.013923450098308438,\n        \"min\": 0.89673912525177,\n        \"max\": 0.9619565010070801,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.9402173757553101,\n          0.89673912525177\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"val_sensitivity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.11957237762830161,\n        \"min\": 0.043478260869565216,\n        \"max\": 0.34782608695652173,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.30434782608695654,\n          0.34782608695652173\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"val_ci_low\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.07275808298442057,\n        \"min\": 0.007716666143453163,\n        \"max\": 0.18811275938797728,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.1560402445321402,\n          0.18811275938797728\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"val_ci_high\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.13245725006446452,\n        \"min\": 0.20991155070258882,\n        \"max\": 0.5510966462273699,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.5086575626875921,\n          0.5510966462273699\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_sensitivity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.02842880644166498,\n        \"min\": 0.0,\n        \"max\": 0.08695652173913043,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.08695652173913043,\n          0.043478260869565216\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_ci_low\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.009073379588515373,\n        \"min\": 0.0,\n        \"max\": 0.024180004484220335,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.024180004484220335,\n          0.007716666143453163\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_ci_high\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.03983131843819528,\n        \"min\": 0.1431166184504269,\n        \"max\": 0.2679598107574366,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.2679598107574366,\n          0.20991155070258882\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_p_value_vs_baseline\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1420692798319645,\n        \"min\": 0.5,\n        \"max\": 0.9259110640518575,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.5,\n          0.7247966673871199\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Biggest Winner Naive Test Sensitivity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.4176269004663433e-17,\n        \"min\": 0.087,\n        \"max\": 0.087,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.087\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Previous Winner Naive Test Sensitivity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.4176269004663433e-17,\n        \"min\": 0.087,\n        \"max\": 0.087,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.087\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display222324Df['Biggest Winner Naive Test Sensitivity'] = .375\n",
        "display222324Df['Previous Winner Naive Test Sensitivity'] = .167\n",
        "display222324Df.head(20)"
      ],
      "metadata": {
        "id": "jf9NeWBYobaa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        },
        "outputId": "ef4221f6-3f85-4a20-ad16-5dc1604c65b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Model Complexity  Layers  Epochs Optimizer Activation  val_accuracy  \\\n",
              "0            Simple       2      20      adam       relu      0.988636   \n",
              "1            Simple       2      20      adam       tanh      0.988636   \n",
              "2            Simple       2      20      adam    sigmoid      0.988636   \n",
              "3            Simple       2     100      adam       relu      0.988636   \n",
              "4            Medium       4      20      adam       relu      0.988636   \n",
              "5            Medium       4      20      adam       tanh      0.988636   \n",
              "6            Medium       4      20      adam    sigmoid      0.988636   \n",
              "7            Medium       4     100      adam       relu      0.988636   \n",
              "8              High       8      20      adam       relu      0.988636   \n",
              "9              High       8      20      adam       tanh      0.988636   \n",
              "10             High       8      20      adam    sigmoid      0.988636   \n",
              "11             High       8     100      adam       relu      0.977273   \n",
              "12           Simple       2      20   adagrad       relu      0.971591   \n",
              "13           Simple       2      20   adagrad       tanh      0.971591   \n",
              "14           Simple       2      20   adagrad    sigmoid      0.971591   \n",
              "15           Simple       2     100   adagrad       tanh      0.971591   \n",
              "16           Medium       4      20   adagrad       relu      0.971591   \n",
              "17           Medium       4      20   adagrad       tanh      0.971591   \n",
              "18           Medium       4      20   adagrad    sigmoid      0.971591   \n",
              "19           Medium       4     100   adagrad       tanh      0.971591   \n",
              "\n",
              "    val_sensitivity  val_ci_low  val_ci_high  test_sensitivity  test_ci_low  \\\n",
              "0          0.208333    0.092448     0.404705          0.375000     0.211594   \n",
              "1          0.208333    0.092448     0.404705          0.375000     0.211594   \n",
              "2          0.208333    0.092448     0.404705          0.375000     0.211594   \n",
              "3          0.166667    0.066787     0.358531          0.375000     0.211594   \n",
              "4          0.208333    0.092448     0.404705          0.375000     0.211594   \n",
              "5          0.208333    0.092448     0.404705          0.375000     0.211594   \n",
              "6          0.208333    0.092448     0.404705          0.375000     0.211594   \n",
              "7          0.166667    0.066787     0.358531          0.375000     0.211594   \n",
              "8          0.208333    0.092448     0.404705          0.375000     0.211594   \n",
              "9          0.208333    0.092448     0.404705          0.375000     0.211594   \n",
              "10         0.166667    0.066787     0.358531          0.375000     0.211594   \n",
              "11         0.166667    0.066787     0.358531          0.375000     0.211594   \n",
              "12         0.000000    0.000000     0.137976          0.083333     0.023159   \n",
              "13         0.125000    0.043443     0.310039          0.125000     0.043443   \n",
              "14         0.041667    0.007393     0.202418          0.000000     0.000000   \n",
              "15         0.208333    0.092448     0.404705          0.375000     0.211594   \n",
              "16         0.000000    0.000000     0.137976          0.083333     0.023159   \n",
              "17         0.125000    0.043443     0.310039          0.125000     0.043443   \n",
              "18         0.041667    0.007393     0.202418          0.000000     0.000000   \n",
              "19         0.208333    0.092448     0.404705          0.375000     0.211594   \n",
              "\n",
              "    test_ci_high  test_p_value_vs_baseline  \\\n",
              "0       0.572900                  0.500000   \n",
              "1       0.572900                  0.500000   \n",
              "2       0.572900                  0.500000   \n",
              "3       0.572900                  0.500000   \n",
              "4       0.572900                  0.500000   \n",
              "5       0.572900                  0.500000   \n",
              "6       0.572900                  0.500000   \n",
              "7       0.572900                  0.500000   \n",
              "8       0.572900                  0.500000   \n",
              "9       0.572900                  0.500000   \n",
              "10      0.572900                  0.500000   \n",
              "11      0.572900                  0.500000   \n",
              "12      0.258488                  0.991890   \n",
              "13      0.310039                  0.977250   \n",
              "14      0.137976                  0.999563   \n",
              "15      0.572900                  0.500000   \n",
              "16      0.258488                  0.991890   \n",
              "17      0.310039                  0.977250   \n",
              "18      0.137976                  0.999563   \n",
              "19      0.572900                  0.500000   \n",
              "\n",
              "    Biggest Winner Naive Test Sensitivity  \\\n",
              "0                                   0.375   \n",
              "1                                   0.375   \n",
              "2                                   0.375   \n",
              "3                                   0.375   \n",
              "4                                   0.375   \n",
              "5                                   0.375   \n",
              "6                                   0.375   \n",
              "7                                   0.375   \n",
              "8                                   0.375   \n",
              "9                                   0.375   \n",
              "10                                  0.375   \n",
              "11                                  0.375   \n",
              "12                                  0.375   \n",
              "13                                  0.375   \n",
              "14                                  0.375   \n",
              "15                                  0.375   \n",
              "16                                  0.375   \n",
              "17                                  0.375   \n",
              "18                                  0.375   \n",
              "19                                  0.375   \n",
              "\n",
              "    Previous Winner Naive Test Sensitivity  \n",
              "0                                    0.167  \n",
              "1                                    0.167  \n",
              "2                                    0.167  \n",
              "3                                    0.167  \n",
              "4                                    0.167  \n",
              "5                                    0.167  \n",
              "6                                    0.167  \n",
              "7                                    0.167  \n",
              "8                                    0.167  \n",
              "9                                    0.167  \n",
              "10                                   0.167  \n",
              "11                                   0.167  \n",
              "12                                   0.167  \n",
              "13                                   0.167  \n",
              "14                                   0.167  \n",
              "15                                   0.167  \n",
              "16                                   0.167  \n",
              "17                                   0.167  \n",
              "18                                   0.167  \n",
              "19                                   0.167  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4b3d0c58-d282-4dbe-9418-47f720f5d473\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model Complexity</th>\n",
              "      <th>Layers</th>\n",
              "      <th>Epochs</th>\n",
              "      <th>Optimizer</th>\n",
              "      <th>Activation</th>\n",
              "      <th>val_accuracy</th>\n",
              "      <th>val_sensitivity</th>\n",
              "      <th>val_ci_low</th>\n",
              "      <th>val_ci_high</th>\n",
              "      <th>test_sensitivity</th>\n",
              "      <th>test_ci_low</th>\n",
              "      <th>test_ci_high</th>\n",
              "      <th>test_p_value_vs_baseline</th>\n",
              "      <th>Biggest Winner Naive Test Sensitivity</th>\n",
              "      <th>Previous Winner Naive Test Sensitivity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Simple</td>\n",
              "      <td>2</td>\n",
              "      <td>20</td>\n",
              "      <td>adam</td>\n",
              "      <td>relu</td>\n",
              "      <td>0.988636</td>\n",
              "      <td>0.208333</td>\n",
              "      <td>0.092448</td>\n",
              "      <td>0.404705</td>\n",
              "      <td>0.375000</td>\n",
              "      <td>0.211594</td>\n",
              "      <td>0.572900</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.375</td>\n",
              "      <td>0.167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Simple</td>\n",
              "      <td>2</td>\n",
              "      <td>20</td>\n",
              "      <td>adam</td>\n",
              "      <td>tanh</td>\n",
              "      <td>0.988636</td>\n",
              "      <td>0.208333</td>\n",
              "      <td>0.092448</td>\n",
              "      <td>0.404705</td>\n",
              "      <td>0.375000</td>\n",
              "      <td>0.211594</td>\n",
              "      <td>0.572900</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.375</td>\n",
              "      <td>0.167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Simple</td>\n",
              "      <td>2</td>\n",
              "      <td>20</td>\n",
              "      <td>adam</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>0.988636</td>\n",
              "      <td>0.208333</td>\n",
              "      <td>0.092448</td>\n",
              "      <td>0.404705</td>\n",
              "      <td>0.375000</td>\n",
              "      <td>0.211594</td>\n",
              "      <td>0.572900</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.375</td>\n",
              "      <td>0.167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Simple</td>\n",
              "      <td>2</td>\n",
              "      <td>100</td>\n",
              "      <td>adam</td>\n",
              "      <td>relu</td>\n",
              "      <td>0.988636</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.066787</td>\n",
              "      <td>0.358531</td>\n",
              "      <td>0.375000</td>\n",
              "      <td>0.211594</td>\n",
              "      <td>0.572900</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.375</td>\n",
              "      <td>0.167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Medium</td>\n",
              "      <td>4</td>\n",
              "      <td>20</td>\n",
              "      <td>adam</td>\n",
              "      <td>relu</td>\n",
              "      <td>0.988636</td>\n",
              "      <td>0.208333</td>\n",
              "      <td>0.092448</td>\n",
              "      <td>0.404705</td>\n",
              "      <td>0.375000</td>\n",
              "      <td>0.211594</td>\n",
              "      <td>0.572900</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.375</td>\n",
              "      <td>0.167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Medium</td>\n",
              "      <td>4</td>\n",
              "      <td>20</td>\n",
              "      <td>adam</td>\n",
              "      <td>tanh</td>\n",
              "      <td>0.988636</td>\n",
              "      <td>0.208333</td>\n",
              "      <td>0.092448</td>\n",
              "      <td>0.404705</td>\n",
              "      <td>0.375000</td>\n",
              "      <td>0.211594</td>\n",
              "      <td>0.572900</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.375</td>\n",
              "      <td>0.167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Medium</td>\n",
              "      <td>4</td>\n",
              "      <td>20</td>\n",
              "      <td>adam</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>0.988636</td>\n",
              "      <td>0.208333</td>\n",
              "      <td>0.092448</td>\n",
              "      <td>0.404705</td>\n",
              "      <td>0.375000</td>\n",
              "      <td>0.211594</td>\n",
              "      <td>0.572900</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.375</td>\n",
              "      <td>0.167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Medium</td>\n",
              "      <td>4</td>\n",
              "      <td>100</td>\n",
              "      <td>adam</td>\n",
              "      <td>relu</td>\n",
              "      <td>0.988636</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.066787</td>\n",
              "      <td>0.358531</td>\n",
              "      <td>0.375000</td>\n",
              "      <td>0.211594</td>\n",
              "      <td>0.572900</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.375</td>\n",
              "      <td>0.167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>High</td>\n",
              "      <td>8</td>\n",
              "      <td>20</td>\n",
              "      <td>adam</td>\n",
              "      <td>relu</td>\n",
              "      <td>0.988636</td>\n",
              "      <td>0.208333</td>\n",
              "      <td>0.092448</td>\n",
              "      <td>0.404705</td>\n",
              "      <td>0.375000</td>\n",
              "      <td>0.211594</td>\n",
              "      <td>0.572900</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.375</td>\n",
              "      <td>0.167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>High</td>\n",
              "      <td>8</td>\n",
              "      <td>20</td>\n",
              "      <td>adam</td>\n",
              "      <td>tanh</td>\n",
              "      <td>0.988636</td>\n",
              "      <td>0.208333</td>\n",
              "      <td>0.092448</td>\n",
              "      <td>0.404705</td>\n",
              "      <td>0.375000</td>\n",
              "      <td>0.211594</td>\n",
              "      <td>0.572900</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.375</td>\n",
              "      <td>0.167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>High</td>\n",
              "      <td>8</td>\n",
              "      <td>20</td>\n",
              "      <td>adam</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>0.988636</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.066787</td>\n",
              "      <td>0.358531</td>\n",
              "      <td>0.375000</td>\n",
              "      <td>0.211594</td>\n",
              "      <td>0.572900</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.375</td>\n",
              "      <td>0.167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>High</td>\n",
              "      <td>8</td>\n",
              "      <td>100</td>\n",
              "      <td>adam</td>\n",
              "      <td>relu</td>\n",
              "      <td>0.977273</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.066787</td>\n",
              "      <td>0.358531</td>\n",
              "      <td>0.375000</td>\n",
              "      <td>0.211594</td>\n",
              "      <td>0.572900</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.375</td>\n",
              "      <td>0.167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Simple</td>\n",
              "      <td>2</td>\n",
              "      <td>20</td>\n",
              "      <td>adagrad</td>\n",
              "      <td>relu</td>\n",
              "      <td>0.971591</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.137976</td>\n",
              "      <td>0.083333</td>\n",
              "      <td>0.023159</td>\n",
              "      <td>0.258488</td>\n",
              "      <td>0.991890</td>\n",
              "      <td>0.375</td>\n",
              "      <td>0.167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Simple</td>\n",
              "      <td>2</td>\n",
              "      <td>20</td>\n",
              "      <td>adagrad</td>\n",
              "      <td>tanh</td>\n",
              "      <td>0.971591</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.043443</td>\n",
              "      <td>0.310039</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.043443</td>\n",
              "      <td>0.310039</td>\n",
              "      <td>0.977250</td>\n",
              "      <td>0.375</td>\n",
              "      <td>0.167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Simple</td>\n",
              "      <td>2</td>\n",
              "      <td>20</td>\n",
              "      <td>adagrad</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>0.971591</td>\n",
              "      <td>0.041667</td>\n",
              "      <td>0.007393</td>\n",
              "      <td>0.202418</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.137976</td>\n",
              "      <td>0.999563</td>\n",
              "      <td>0.375</td>\n",
              "      <td>0.167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Simple</td>\n",
              "      <td>2</td>\n",
              "      <td>100</td>\n",
              "      <td>adagrad</td>\n",
              "      <td>tanh</td>\n",
              "      <td>0.971591</td>\n",
              "      <td>0.208333</td>\n",
              "      <td>0.092448</td>\n",
              "      <td>0.404705</td>\n",
              "      <td>0.375000</td>\n",
              "      <td>0.211594</td>\n",
              "      <td>0.572900</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.375</td>\n",
              "      <td>0.167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Medium</td>\n",
              "      <td>4</td>\n",
              "      <td>20</td>\n",
              "      <td>adagrad</td>\n",
              "      <td>relu</td>\n",
              "      <td>0.971591</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.137976</td>\n",
              "      <td>0.083333</td>\n",
              "      <td>0.023159</td>\n",
              "      <td>0.258488</td>\n",
              "      <td>0.991890</td>\n",
              "      <td>0.375</td>\n",
              "      <td>0.167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Medium</td>\n",
              "      <td>4</td>\n",
              "      <td>20</td>\n",
              "      <td>adagrad</td>\n",
              "      <td>tanh</td>\n",
              "      <td>0.971591</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.043443</td>\n",
              "      <td>0.310039</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.043443</td>\n",
              "      <td>0.310039</td>\n",
              "      <td>0.977250</td>\n",
              "      <td>0.375</td>\n",
              "      <td>0.167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Medium</td>\n",
              "      <td>4</td>\n",
              "      <td>20</td>\n",
              "      <td>adagrad</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>0.971591</td>\n",
              "      <td>0.041667</td>\n",
              "      <td>0.007393</td>\n",
              "      <td>0.202418</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.137976</td>\n",
              "      <td>0.999563</td>\n",
              "      <td>0.375</td>\n",
              "      <td>0.167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Medium</td>\n",
              "      <td>4</td>\n",
              "      <td>100</td>\n",
              "      <td>adagrad</td>\n",
              "      <td>tanh</td>\n",
              "      <td>0.971591</td>\n",
              "      <td>0.208333</td>\n",
              "      <td>0.092448</td>\n",
              "      <td>0.404705</td>\n",
              "      <td>0.375000</td>\n",
              "      <td>0.211594</td>\n",
              "      <td>0.572900</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.375</td>\n",
              "      <td>0.167</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4b3d0c58-d282-4dbe-9418-47f720f5d473')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4b3d0c58-d282-4dbe-9418-47f720f5d473 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4b3d0c58-d282-4dbe-9418-47f720f5d473');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-6589f349-11ed-46be-b165-238b1a2c0046\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6589f349-11ed-46be-b165-238b1a2c0046')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-6589f349-11ed-46be-b165-238b1a2c0046 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "display222324Df",
              "summary": "{\n  \"name\": \"display222324Df\",\n  \"rows\": 24,\n  \"fields\": [\n    {\n      \"column\": \"Model Complexity\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Simple\",\n          \"Medium\",\n          \"High\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Layers\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 2,\n        \"max\": 8,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          2,\n          4,\n          8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Epochs\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 35,\n        \"min\": 20,\n        \"max\": 100,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          100,\n          20\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Optimizer\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"adagrad\",\n          \"adam\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Activation\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"relu\",\n          \"tanh\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"val_accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.011236835282999692,\n        \"min\": 0.9431818127632141,\n        \"max\": 0.9886363744735718,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.9772727489471436,\n          0.9431818127632141\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"val_sensitivity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.07574110492886549,\n        \"min\": 0.0,\n        \"max\": 0.20833333333333334,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.20833333333333334,\n          0.16666666666666666\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"val_ci_low\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.03553410603518083,\n        \"min\": 0.0,\n        \"max\": 0.09244825352851854,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.09244825352851854,\n          0.06678676328632946\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"val_ci_high\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.09549672569662976,\n        \"min\": 0.13797620467498026,\n        \"max\": 0.40470453253188665,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.40470453253188665,\n          0.3585307064969907\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_sensitivity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1587412112266595,\n        \"min\": 0.0,\n        \"max\": 0.375,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.08333333333333333,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_ci_low\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.09448053097952402,\n        \"min\": 0.0,\n        \"max\": 0.21159367559548778,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.023158815297043348,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_ci_high\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1797959783396465,\n        \"min\": 0.13797620467498026,\n        \"max\": 0.5729003755732573,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.2584880219321069,\n          0.13797620467498026\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_p_value_vs_baseline\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.23701226017578056,\n        \"min\": 0.5,\n        \"max\": 0.9995629563943508,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.9918900159983217,\n          0.9995629563943508\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Biggest Winner Naive Test Sensitivity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.375,\n        \"max\": 0.375,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.375\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Previous Winner Naive Test Sensitivity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8.50576140279806e-17,\n        \"min\": 0.167,\n        \"max\": 0.167,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.167\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display222324Df.to_csv('df222324.csv', index=False)\n",
        "display232425Df.to_csv('df232425.csv', index=False)\n",
        "display2425Df.to_csv('df2425.csv', index=False)"
      ],
      "metadata": {
        "id": "DTQ2zJUeyL7N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NGp2ZCIx1jdl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callingFunctiontThatDonnotExist()"
      ],
      "metadata": {
        "id": "-iYIVFiDfetR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Simple Model\n"
      ],
      "metadata": {
        "id": "nrECciW0aO-5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Need to create helper functions to get desired stats"
      ],
      "metadata": {
        "id": "JaM8UCIEPUKm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "\n",
        "def createSimpleModel(x_train, y_train, x_valid, y_valid, x_test, y_test,\n",
        "                      activFunction, optimizer, epochsNum):\n",
        "    n_features = x_train.shape[1]\n",
        "\n",
        "    model = keras.models.Sequential([\n",
        "        keras.layers.Input(shape=(n_features,)),\n",
        "        keras.layers.Dense(128, activation=\"relu\"),\n",
        "        keras.layers.Dense(64, activation=activFunction),  # you sweep this\n",
        "        keras.layers.Dense(1, activation=\"sigmoid\")        # prob of win\n",
        "    ])\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss=keras.losses.BinaryCrossentropy(),\n",
        "        metrics=[\"accuracy\"]\n",
        "    )\n",
        "\n",
        "    history = model.fit(\n",
        "        x_train, y_train,\n",
        "        epochs=epochsNum,\n",
        "        validation_data=(x_valid, y_valid),\n",
        "        shuffle=False,\n",
        "        verbose=0\n",
        "    )\n",
        "\n",
        "    # optional: silent test evaluate; you can remove if not needed\n",
        "    _ = model.evaluate(x_test, y_test, verbose=0)\n",
        "\n",
        "    return model, history\n"
      ],
      "metadata": {
        "id": "EWHNbVaJTqDP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from statsmodels.stats.proportion import proportions_ztest, proportion_confint\n",
        "\n",
        "def _wilson_ci(k, n, alpha=0.05):\n",
        "    low, high = proportion_confint(count=k, nobs=n, alpha=alpha, method=\"wilson\")\n",
        "    return float(low), float(high)\n",
        "\n",
        "def _two_prop_pvalue(model_p, base_p, n_model, n_base=None, alternative=\"larger\"):\n",
        "    if n_base is None: n_base = n_model\n",
        "    k_model = int(round(model_p * n_model))\n",
        "    k_base  = int(round(base_p  * n_base))\n",
        "    k_model = max(0, min(k_model, n_model))\n",
        "    k_base  = max(0, min(k_base,  n_base))\n",
        "    stat, p = proportions_ztest([k_model, k_base], [n_model, n_base], alternative=alternative)\n",
        "    return float(p), float(stat)\n",
        "\n",
        "def _race_level_sensitivity(df_with_preds, track_prefix=\"Track_\", driver_prefix=\"Driver_\"):\n",
        "    track_cols  = [c for c in df_with_preds.columns if c.startswith(track_prefix)]\n",
        "    driver_cols = [c for c in df_with_preds.columns if c.startswith(driver_prefix)]\n",
        "    tmp = df_with_preds.copy()\n",
        "    if \"track\" not in tmp.columns:\n",
        "        tmp[\"track\"] = tmp[track_cols].idxmax(axis=1).str.replace(track_prefix, \"\", regex=False)\n",
        "    if \"Driver\" not in tmp.columns and driver_cols:\n",
        "        tmp[\"Driver\"] = tmp[driver_cols].idxmax(axis=1).str.replace(driver_prefix, \"\", regex=False)\n",
        "    picks = tmp.loc[tmp.groupby(\"track\")[\"predicted\"].idxmax()].copy()\n",
        "    k_correct = int((picks[\"win\"] == 1).sum())\n",
        "    n_races   = picks[\"track\"].nunique()\n",
        "    sens = k_correct / n_races if n_races > 0 else 0.0\n",
        "    return sens, k_correct, n_races, picks\n"
      ],
      "metadata": {
        "id": "stfqwyH3PXj-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def trainSimpleModel(yearsTrain, yearsPredict, partyDf, activFunction, optimizer, epochs):\n",
        "    # ... your determinism + data prep stays the same up to the split ...\n",
        "\n",
        "    x_train, x_valid, y_train, y_valid = train_test_split(x, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    dfTest = partyDf[(partyDf['Year_'+ yearsPredict[0]] == 1)]\n",
        "    x_test = dfTest.drop(columns=['win', 'Position', 'RaceOrder'])\n",
        "    y_test = dfTest['win']\n",
        "\n",
        "    # === Build & train model (UPDATED) ===\n",
        "    model, history = createSimpleModel(\n",
        "        x_train.values, y_train.values,\n",
        "        x_valid.values, y_valid.values,\n",
        "        x_test.values, y_test.values,\n",
        "        activFunction, optimizer, epochs\n",
        "    )\n",
        "\n",
        "    # ---------- VALIDATION METRICS ----------\n",
        "    y_valid_pred_prob = model.predict(x_valid.values, verbose=0).ravel()\n",
        "\n",
        "    # row-level validation accuracy (threshold 0.5)\n",
        "    y_valid_bin = (y_valid_pred_prob >= 0.5).astype(int)\n",
        "    val_accuracy = float((y_valid_bin == y_valid.astype(int).values).mean())\n",
        "\n",
        "    # race-level validation sensitivity + CI + p-value\n",
        "    df_valid = x_valid.copy()\n",
        "    df_valid[\"win\"] = y_valid.values\n",
        "    df_valid[\"predicted\"] = y_valid_pred_prob\n",
        "\n",
        "    val_sens, val_k, val_n, _ = _race_level_sensitivity(df_valid)\n",
        "    val_ci_low, val_ci_high = _wilson_ci(val_k, val_n)\n",
        "\n",
        "    # baseline for validation (equal-chance among ~20 drivers; change if you have a specific naive)\n",
        "    if yearsTrain[0] == '2022':\n",
        "      baseline_val_p = 19 / 22.0\n",
        "    elif yearsTrain[0] == '2023':\n",
        "      baseline_val_p = 9 / 24.0\n",
        "    else:\n",
        "       baseline_val_p = 9 / 24.0\n",
        "\n",
        "    val_p_value, val_z = _two_prop_pvalue(val_sens, baseline_val_p, n_model=val_n, alternative=\"larger\")\n",
        "\n",
        "    print(f\"[VALID] acc={val_accuracy:.3f} | sens={val_sens:.3f} \"\n",
        "          f\"(k={val_k}/{val_n}, CI95=[{val_ci_low:.3f},{val_ci_high:.3f}]) \"\n",
        "          f\"vs base {baseline_val_p:.3f} p={val_p_value:.4f}\")\n",
        "\n",
        "    # ---------- TEST METRICS (your existing logic + CI + p-value) ----------\n",
        "    comparePredictions = partyDf[(partyDf['Year_'+ yearsPredict[0]] == 1)].copy()\n",
        "    comparePredictions['predicted'] = model.predict(x_test.values, verbose=0)\n",
        "\n",
        "    track_cols = [c for c in comparePredictions.columns if c.startswith(\"Track_\")]\n",
        "    year_cols  = [c for c in comparePredictions.columns if c.startswith(\"Year_\")]\n",
        "    team_cols  = [c for c in comparePredictions.columns if c.startswith(\"Team_\")]\n",
        "    driver_cols= [c for c in comparePredictions.columns if c.startswith(\"Driver_\")]\n",
        "\n",
        "    comparePredictions[\"track\"]  = comparePredictions[track_cols].idxmax(axis=1).str.replace(\"Track_\", \"\", regex=False)\n",
        "    comparePredictions[\"Driver\"] = comparePredictions[driver_cols].idxmax(axis=1).str.replace(\"Driver_\", \"\", regex=False)\n",
        "\n",
        "    comparePredictions[\"predicted_winner\"] = (\n",
        "        comparePredictions.groupby(\"track\")[\"predicted\"]\n",
        "                          .transform(lambda x: x == x.max())\n",
        "                          .astype(int)\n",
        "    )\n",
        "\n",
        "    sortedcomparePredictions = comparePredictions.sort_values([\"track\", \"predicted\"], ascending=[True, False])\n",
        "    cols_to_drop = track_cols + year_cols + team_cols + driver_cols + ['Laps']\n",
        "    finalResultsDf = sortedcomparePredictions.drop(cols_to_drop, axis=1)\n",
        "\n",
        "    totalAmountGuessedCorrectly = finalResultsDf[\n",
        "        (finalResultsDf['predicted_winner'] == 1) & (finalResultsDf['win'] == 1)\n",
        "    ].shape[0]\n",
        "\n",
        "    numRaces = finalResultsDf['track'].nunique()\n",
        "    percentage_correct = totalAmountGuessedCorrectly / numRaces if numRaces > 0 else 0.0\n",
        "\n",
        "    # test CI + p-value\n",
        "    test_k = int(totalAmountGuessedCorrectly)\n",
        "    test_n = int(numRaces)\n",
        "    test_sens = float(percentage_correct)\n",
        "    test_ci_low, test_ci_high = _wilson_ci(test_k, test_n)\n",
        "    if yearsPredict[0] == '2024':\n",
        "      baseline_test_p = 9 / 24.0\n",
        "    else:\n",
        "      baseline_test_p = 2 / 23\n",
        "\n",
        "    test_p_value, test_z = _two_prop_pvalue(test_sens, baseline_test_p, n_model=test_n, alternative=\"larger\")\n",
        "\n",
        "    print(f\"[TEST ] sens={test_sens:.3f} (k={test_k}/{test_n}, CI95=[{test_ci_low:.3f},{test_ci_high:.3f}]) \"\n",
        "          f\"vs base {baseline_test_p:.3f} p={test_p_value:.4f}\")\n",
        "\n",
        "    # (Optional) also surface val acc from Keras history, last epoch:\n",
        "    hist_val_acc = float(history.history.get(\"val_accuracy\", [np.nan])[-1])\n",
        "\n",
        "    metrics = {\n",
        "        #\"val_accuracy_row\": val_accuracy,              # row-level acc (thresholded)\n",
        "        \"val_accuracy_keras\": hist_val_acc,            # Keras-reported val accuracy\n",
        "        \"val_sensitivity\": val_sens,\n",
        "        \"val_ci_low\": val_ci_low, \"val_ci_high\": val_ci_high,\n",
        "        \"val_p_value_vs_baseline\": val_p_value,\n",
        "        \"test_sensitivity\": test_sens,\n",
        "        \"test_ci_low\": test_ci_low, \"test_ci_high\": test_ci_high,\n",
        "        \"test_p_value_vs_baseline\": test_p_value\n",
        "        #\"val_races\": val_n, \"test_races\": test_n\n",
        "    }\n",
        "\n",
        "    return finalResultsDf, finalResultsDf[(finalResultsDf['predicted_winner']==1)|(finalResultsDf['win']==1)].sort_values('track'), metrics\n"
      ],
      "metadata": {
        "id": "UiVejnAjRJqo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def makeModel(yearsTrain, yearsPredict, passDf, epochs):\n",
        "  optimizers = ['adam', 'adagrad']\n",
        "  activations = ['relu', 'tanh', 'sigmoid']\n",
        "  complexs = ['Simple', 'Medium', 'High']\n",
        "  displayDf = pd.createDataframe()\n",
        "\n",
        "  for optimizer in optimizers:\n",
        "    for activation in activations:\n",
        "      for complexity in complexs:\n",
        "        displayDf['Model Complexity'] = complexity\n",
        "        if complexity == 'Simple':\n",
        "          df, smallDf, metrics = trainSimpleModel(yearsTrain, yearsPredict, passDf, activation, optimizer, epochs)\n",
        "          displayDf['Layers'] = 2\n",
        "        elif complexity == 'Medium':\n",
        "          df, smallDf, metrics = trainMediumModel(yearsTrain, yearsPredict, passDf, activation, optimizer, epochs)\n",
        "          displayDf['Layers'] = 4\n",
        "        else:\n",
        "          df, smallDf, metrics = trainHighModel(yearsTrain, yearsPredict, passDf, activation, optimizer, epochs)\n",
        "          displayDf['Layers'] = 4\n",
        "\n",
        "        displayDf['Epochs'] = epochs\n",
        "        displayDf['optimizer'] = optimizer\n",
        "        displayDf['activation'] = activation\n",
        "        displayDf['complexity'] = complexity\n",
        "        displayDf['val_accuracy_keras'] = metrics['val_accuracy_keras']\n",
        "        displayDf['val_sensitivity'] = metrics['val_sensitivity']\n",
        "        displayDf['val_ci_low'] = metrics['val_ci_low']\n",
        "        displayDf['val_ci_high'] = metrics['val_ci_high']\n",
        "        displayDf['val_p_value_vs_baseline'] = metrics['val_p_value_vs_baseline']\n",
        "        displayDf['test_sensitivity'] = metrics['test_sensitivity']\n",
        "        displayDf['test_ci_low'] = metrics['test_ci_low']\n",
        "        displayDf['test_ci_high'] = metrics['test_ci_high']\n",
        "        displayDf['test_p_value_vs_baseline'] = metrics['test_p_value_vs_baseline']\n",
        "\n"
      ],
      "metadata": {
        "id": "Ff3GHSUSY3GU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yearsTrain = ['2022', '2023']\n",
        "yearsPredict = ['2024']\n",
        "\n",
        "df, smallDf, metrics = trainSimpleModel(yearsTrain, yearsPredict, df_encoded, \"relu\", \"adam\", 20)\n",
        "print(metrics)\n",
        "\n",
        "#smallDf.head(100)"
      ],
      "metadata": {
        "id": "NI6QuZkWRPPG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(100)"
      ],
      "metadata": {
        "id": "eVUIWzv-T-Ky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "smallDf.head(100)"
      ],
      "metadata": {
        "id": "fEr460KZUDxk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simple model Functions"
      ],
      "metadata": {
        "id": "A0fEYkmNS22P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def createSimpleModel(x_train, y_train, x_valid, y_valid, x_test, y_test, activFunction, optimizer, epochsNum):\n",
        "    model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[73, 1]),\n",
        "    keras.layers.Dense(32, activation=\"relu\"),\n",
        "    keras.layers.Dense(32, activation= activFunction),\n",
        "    keras.layers.Dense(1)\n",
        "    ])\n",
        "\n",
        "    model.compile(loss=\"mse\", optimizer=optimizer, metrics = [\"accuracy\"])\n",
        "    history = model.fit(x_train, y_train, epochs=epochsNum,\n",
        "                        validation_data=(x_valid, y_valid), shuffle = False)\n",
        "    model.evaluate(x_test, y_test)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "BQEoh7bLTEjH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yearsTrain = ['2022', '2023']\n",
        "yearsPredict = ['2024']\n",
        "\n",
        "def trainSimpleModel(yearsTrain, yearsPredict, partyDf,  activFunction, optimizer, epochs):\n",
        "  # 1) Determinism\n",
        "  os.environ[\"PYTHONHASHSEED\"] = \"42\"\n",
        "  np.random.seed(42)\n",
        "  random.seed(42)\n",
        "  try:\n",
        "      tf.random.set_seed(42)\n",
        "      # TF 2.12+: deterministic ops\n",
        "      tf.config.experimental.enable_op_determinism(True)\n",
        "  except Exception:\n",
        "      pass\n",
        "\n",
        "\n",
        "  dfs = []\n",
        "  #get data from all training years\n",
        "  for year in yearsTrain:\n",
        "      dfs.append(partyDf[partyDf['Year_' + year] == 1])\n",
        "\n",
        "  # Combine all selected years into one DataFrame\n",
        "  trainDf = pd.concat(dfs, ignore_index=True)\n",
        "\n",
        "  x = trainDf.drop(columns=['win', 'Position', 'RaceOrder'])\n",
        "  y = trainDf['win']\n",
        "\n",
        "  #extract the columns that have a one included in the x df\n",
        "  year_cols = [c for c in x.columns if c.startswith(\"Year_\")]\n",
        "\n",
        "  includedTrainingYears = []\n",
        "  for col in year_cols:\n",
        "      if (x[col] == 1).any():   # check if there is any row with a 1 in this column\n",
        "          includedTrainingYears.append(col)\n",
        "\n",
        "  print(\"The years trained: \", includedTrainingYears)\n",
        "\n",
        "\n",
        "  #split the training data accordingly\n",
        "  x_train, x_valid, y_train, y_valid = train_test_split(x, y, test_size=0.2, random_state=42)\n",
        "  #get the test data, so the data for the next year you would want to predict\n",
        "  dfTest = partyDf[(partyDf['Year_'+ yearsPredict[0]] == 1)]\n",
        "  x_test = dfTest.drop(columns=['win', 'Position', 'RaceOrder'])\n",
        "  y_test = dfTest['win']\n",
        "\n",
        "  #extract the columns that have a one included in the x df\n",
        "\n",
        "  includedTestingYears = []\n",
        "  for col in year_cols:\n",
        "      if (x_test[col] == 1).any():   # check if there is any row with a 1 in this column\n",
        "          includedTestingYears.append(col)\n",
        "\n",
        "  print(\"The years tested: \", includedTestingYears)\n",
        "\n",
        "  model = createSimpleModel(x_train, y_train, x_valid, y_valid, x_test, y_test,  activFunction, optimizer, epochs)\n",
        "\n",
        "  #extract the actual winning rows in the data and weather or not my model predicted them to win\n",
        "  comparePredictions = partyDf[(partyDf['Year_'+ yearsPredict[0]] == 1)]\n",
        "\n",
        "  #now the predictions are inputed for each row\n",
        "  comparePredictions['predicted'] = model.predict(x_test)\n",
        "  # Identify one-hot columns\n",
        "  track_cols = [c for c in comparePredictions.columns if c.startswith(\"Track_\")]\n",
        "  year_cols = [c for c in comparePredictions.columns if c.startswith(\"Year_\")]\n",
        "  team_cols = [c for c in comparePredictions.columns if c.startswith(\"Team_\")]\n",
        "  driver_cols = [c for c in comparePredictions.columns if c.startswith(\"Driver_\")]\n",
        "\n",
        "  # Recover track names from one-hot encoding\n",
        "  comparePredictions[\"track\"] = comparePredictions[track_cols].idxmax(axis=1).str.replace(\"Track_\", \"\", regex=False)\n",
        "  comparePredictions[\"Driver\"] = comparePredictions[driver_cols].idxmax(axis=1).str.replace(\"Driver_\", \"\", regex=False)\n",
        "\n",
        "  # Sort so the highest prediction in each group comes first\n",
        "  # Flag 1 for the row(s) with the highest predicted score per track, else 0\n",
        "  comparePredictions[\"predicted_winner\"] = (\n",
        "      comparePredictions.groupby(\"track\")[\"predicted\"]\n",
        "                .transform(lambda x: x == x.max())\n",
        "                .astype(int)\n",
        "  )\n",
        "\n",
        "  sortedcomparePredictions = comparePredictions.sort_values([\"track\", \"predicted\"], ascending=[True, False])\n",
        "  #remove exess columns\n",
        "  cols_to_drop = track_cols + year_cols + team_cols + driver_cols + ['Laps']\n",
        "  finalResultsDf = sortedcomparePredictions.drop(cols_to_drop, axis=1)\n",
        "\n",
        "\n",
        "\n",
        "  # Count rows where model predicted winner AND they actually won\n",
        "  totalAmountGuessedCorrectly = finalResultsDf[\n",
        "      (finalResultsDf['predicted_winner'] == 1) &\n",
        "      (finalResultsDf['win'] == 1)\n",
        "  ].shape[0]\n",
        "\n",
        "  numRaces = finalResultsDf['track'].nunique()\n",
        "  print(\"The amount guessed correctly:\", totalAmountGuessedCorrectly, \" out of \", numRaces, \" races.\")\n",
        "\n",
        "\n",
        "  # Calculate percentage of races predicted correctly\n",
        "  # (assuming 'track' identifies unique races in your 2024 set)\n",
        "\n",
        "  percentage_correct = totalAmountGuessedCorrectly / numRaces\n",
        "  print(\"The percentage guessed correctly:\", percentage_correct)\n",
        "\n",
        "  smallerDf = finalResultsDf[(finalResultsDf['predicted_winner'] == 1 ) | (finalResultsDf['win'] == 1)].sort_values('track')\n",
        "\n",
        "\n",
        "  return finalResultsDf, smallerDf\n",
        "\n"
      ],
      "metadata": {
        "id": "sZp19WMsTjsP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test with Adam Optimizer"
      ],
      "metadata": {
        "id": "6c1QV6CJk-rf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train 2022 and 2023 data for 2024"
      ],
      "metadata": {
        "id": "4ZuL5lEqUeKZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "yearsTrain = ['2022', '2023']\n",
        "yearsPredict = ['2024']\n",
        "\n",
        "df, smallDf = trainSimpleModel(yearsTrain, yearsPredict, df_encoded, \"relu\", \"adam\", 20)\n",
        "smallDf.head(100)"
      ],
      "metadata": {
        "id": "rPLNciPzTnMN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yearsTrain = ['2022', '2023']\n",
        "yearsPredict = ['2024']\n",
        "\n",
        "df, smallDf = trainSimpleModel(yearsTrain, yearsPredict, df_encoded, \"sigmoid\", \"adam\", 20)\n",
        "smallDf.head(100)"
      ],
      "metadata": {
        "id": "hjxJnZ5xTw6q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yearsTrain = ['2022', '2023']\n",
        "yearsPredict = ['2024']\n",
        "\n",
        "df, smallDf = trainSimpleModel(yearsTrain, yearsPredict, df_encoded, \"tanh\", \"adam\", 20)\n",
        "smallDf.head(100)"
      ],
      "metadata": {
        "id": "Fu6-An9xTzF6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train on 2024 predict 2025"
      ],
      "metadata": {
        "id": "3mZn1IXZVA59"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "yearsTrain = ['2024']\n",
        "yearsPredict = ['2025']\n",
        "\n",
        "df, smallDf = trainSimpleModel(yearsTrain, yearsPredict, completed2025, \"relu\", \"adam\", 20)\n",
        "smallDf.head(100)"
      ],
      "metadata": {
        "id": "ypcKXj8HVEqD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yearsTrain = ['2024']\n",
        "yearsPredict = ['2025']\n",
        "\n",
        "df, smallDf = trainSimpleModel(yearsTrain, yearsPredict, completed2025, \"sigmoid\", \"adam\", 20)\n",
        "smallDf.head(100)"
      ],
      "metadata": {
        "id": "GZdvbVskVI4o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yearsTrain = ['2024']\n",
        "yearsPredict = ['2025']\n",
        "\n",
        "df, smallDf = trainSimpleModel(yearsTrain, yearsPredict, completed2025, \"tanh\", \"adam\", 20)\n",
        "smallDf.head(100)"
      ],
      "metadata": {
        "id": "Tu3pY17bVJq3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train on 23 and 24 to predict 25"
      ],
      "metadata": {
        "id": "U19_5RhMWIH-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "yearsTrain = ['2023', '2024']\n",
        "yearsPredict = ['2025']\n",
        "\n",
        "df, smallDf = trainSimpleModel(yearsTrain, yearsPredict, completed2025, \"relu\", \"adam\", 20)\n",
        "smallDf.head(100)"
      ],
      "metadata": {
        "id": "FohwQMTDWLqB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yearsTrain = ['2023', '2024']\n",
        "yearsPredict = ['2025']\n",
        "\n",
        "df, smallDf = trainSimpleModel(yearsTrain, yearsPredict, completed2025, \"sigmoid\", \"adam\", 20)\n",
        "smallDf.head(100)"
      ],
      "metadata": {
        "id": "4QTkUFJoWPnJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yearsTrain = ['2023', '2024']\n",
        "yearsPredict = ['2025']\n",
        "\n",
        "df, smallDf = trainSimpleModel(yearsTrain, yearsPredict, completed2025, \"tanh\", \"adam\", 20)\n",
        "smallDf.head(100)"
      ],
      "metadata": {
        "id": "Z6fJ1V2OWUBP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test with Adagrad(learning_rate=5e-3)\n",
        "Adagrad usually performs well with lots of one hot encoding (majority of my dataset)."
      ],
      "metadata": {
        "id": "SFptpcFamMmf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train 2022 and 2023 data for 2024"
      ],
      "metadata": {
        "id": "QVbr_alHnN9G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adagrad\n",
        "yearsTrain = ['2022', '2023']\n",
        "yearsPredict = ['2024']\n",
        "\n",
        "opt = Adagrad(learning_rate=5e-3)\n",
        "\n",
        "df, smallDf = trainSimpleModel(yearsTrain, yearsPredict, df_encoded, \"relu\", opt, 20)\n",
        "smallDf.head(100)"
      ],
      "metadata": {
        "id": "3fBykGKQmQBe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from tensorflow.keras.optimizers import Adagrad\n",
        "yearsTrain = ['2022', '2023']\n",
        "yearsPredict = ['2024']\n",
        "\n",
        "opt = Adagrad(learning_rate=5e-3)\n",
        "\n",
        "df, smallDf = trainSimpleModel(yearsTrain, yearsPredict, df_encoded, \"sigmoid\", opt, 20)\n",
        "smallDf.head(100)"
      ],
      "metadata": {
        "id": "stSd3nLInR93"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yearsTrain = ['2022', '2023']\n",
        "yearsPredict = ['2024']\n",
        "\n",
        "opt = Adagrad(learning_rate=5e-3)\n",
        "\n",
        "df, smallDf = trainSimpleModel(yearsTrain, yearsPredict, df_encoded, \"tanh\", opt, 20)\n",
        "smallDf.head(100)"
      ],
      "metadata": {
        "id": "VJeZA9nvnWBf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train 2023/2024 for 2025"
      ],
      "metadata": {
        "id": "WT11RKM5nY_m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "yearsTrain = ['2023', '2024']\n",
        "yearsPredict = ['2025']\n",
        "\n",
        "opt = Adagrad(learning_rate=5e-3)\n",
        "\n",
        "df, smallDf = trainSimpleModel(yearsTrain, yearsPredict, completed2025, \"relu\", opt, 20)\n",
        "smallDf.head(100)"
      ],
      "metadata": {
        "id": "ajtOBJuTnbyP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yearsTrain = ['2023', '2024']\n",
        "yearsPredict = ['2025']\n",
        "\n",
        "opt = Adagrad(learning_rate=5e-3)\n",
        "\n",
        "df, smallDf = trainSimpleModel(yearsTrain, yearsPredict, completed2025, \"sigmoid\", opt, 20)\n",
        "smallDf.head(100)"
      ],
      "metadata": {
        "id": "lFAW50qGnjmi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yearsTrain = ['2023', '2024']\n",
        "yearsPredict = ['2025']\n",
        "\n",
        "opt = Adagrad(learning_rate=5e-3)\n",
        "\n",
        "df, smallDf = trainSimpleModel(yearsTrain, yearsPredict, completed2025, \"tanh\", opt, 20)\n",
        "smallDf.head(100)"
      ],
      "metadata": {
        "id": "bMgPz5EVnphp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train 2024 for 2025"
      ],
      "metadata": {
        "id": "_rcMVAkont0J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "yearsTrain = ['2024']\n",
        "yearsPredict = ['2025']\n",
        "\n",
        "opt = Adagrad(learning_rate=5e-3)\n",
        "\n",
        "df, smallDf = trainSimpleModel(yearsTrain, yearsPredict, completed2025, \"relu\", opt, 20)\n",
        "smallDf.head(100)"
      ],
      "metadata": {
        "id": "RxB7eZOBnv_c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yearsTrain = ['2024']\n",
        "yearsPredict = ['2025']\n",
        "\n",
        "opt = Adagrad(learning_rate=5e-3)\n",
        "\n",
        "df, smallDf = trainSimpleModel(yearsTrain, yearsPredict, completed2025, \"sigmoid\", opt, 20)\n",
        "smallDf.head(100)"
      ],
      "metadata": {
        "id": "bo9vhJr0n5N4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yearsTrain = ['2024']\n",
        "yearsPredict = ['2025']\n",
        "\n",
        "opt = Adagrad(learning_rate=5e-3)\n",
        "\n",
        "df, smallDf = trainSimpleModel(yearsTrain, yearsPredict, completed2025, \"tanh\", opt, 20)\n",
        "smallDf.head(100)"
      ],
      "metadata": {
        "id": "mfybeHwjn7A8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Medium Complex model"
      ],
      "metadata": {
        "id": "0xOkb5_fT3F4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Medium Complex Models"
      ],
      "metadata": {
        "id": "ZSJNqI2HXPW3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def createMediumModel(x_train, y_train, x_valid, y_valid, x_test, y_test, activFunction, optimizer, epochsNum):\n",
        "    model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[73, 1]),\n",
        "    keras.layers.Dense(32, activation=\"relu\"),\n",
        "    keras.layers.Dense(64, activation=\"relu\"),\n",
        "    keras.layers.Dense(128, activation=\"relu\"),\n",
        "    keras.layers.Dense(32, activation= activFunction),\n",
        "    keras.layers.Dense(1)\n",
        "    ])\n",
        "\n",
        "    model.compile(loss=\"mse\", optimizer=optimizer, metrics = [\"accuracy\"])\n",
        "    history = model.fit(x_train, y_train, epochs=epochsNum,\n",
        "                        validation_data=(x_valid, y_valid), shuffle = False)\n",
        "    model.evaluate(x_test, y_test)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "6AvyFiKBXR19"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yearsTrain = ['2022', '2023']\n",
        "yearsPredict = ['2024']\n",
        "\n",
        "def trainMediumModel(yearsTrain, yearsPredict, partyDf,  activFunction, optimizer, epochs):\n",
        "  # 1) Determinism\n",
        "  os.environ[\"PYTHONHASHSEED\"] = \"42\"\n",
        "  np.random.seed(42)\n",
        "  random.seed(42)\n",
        "  try:\n",
        "      tf.random.set_seed(42)\n",
        "      # TF 2.12+: deterministic ops\n",
        "      tf.config.experimental.enable_op_determinism(True)\n",
        "  except Exception:\n",
        "      pass\n",
        "\n",
        "\n",
        "  dfs = []\n",
        "  #get data from all training years\n",
        "  for year in yearsTrain:\n",
        "      dfs.append(partyDf[partyDf['Year_' + year] == 1])\n",
        "\n",
        "  # Combine all selected years into one DataFrame\n",
        "  trainDf = pd.concat(dfs, ignore_index=True)\n",
        "\n",
        "  x = trainDf.drop(columns=['win', 'Position', 'RaceOrder'])\n",
        "  y = trainDf['win']\n",
        "\n",
        "  #extract the columns that have a one included in the x df\n",
        "  year_cols = [c for c in x.columns if c.startswith(\"Year_\")]\n",
        "\n",
        "  includedTrainingYears = []\n",
        "  for col in year_cols:\n",
        "      if (x[col] == 1).any():   # check if there is any row with a 1 in this column\n",
        "          includedTrainingYears.append(col)\n",
        "\n",
        "  print(\"The years trained: \", includedTrainingYears)\n",
        "\n",
        "\n",
        "  #split the training data accordingly\n",
        "  x_train, x_valid, y_train, y_valid = train_test_split(x, y, test_size=0.2, random_state=42)\n",
        "  #get the test data, so the data for the next year you would want to predict\n",
        "  dfTest = partyDf[(partyDf['Year_'+ yearsPredict[0]] == 1)]\n",
        "  x_test = dfTest.drop(columns=['win', 'Position', 'RaceOrder'])\n",
        "  y_test = dfTest['win']\n",
        "\n",
        "  #extract the columns that have a one included in the x df\n",
        "\n",
        "  includedTestingYears = []\n",
        "  for col in year_cols:\n",
        "      if (x_test[col] == 1).any():   # check if there is any row with a 1 in this column\n",
        "          includedTestingYears.append(col)\n",
        "\n",
        "  print(\"The years tested: \", includedTestingYears)\n",
        "\n",
        "  model = createMediumModel(x_train, y_train, x_valid, y_valid, x_test, y_test,  activFunction, optimizer, epochs)\n",
        "\n",
        "  #extract the actual winning rows in the data and weather or not my model predicted them to win\n",
        "  comparePredictions = partyDf[(partyDf['Year_'+ yearsPredict[0]] == 1)]\n",
        "\n",
        "  #now the predictions are inputed for each row\n",
        "  comparePredictions['predicted'] = model.predict(x_test)\n",
        "  # Identify one-hot columns\n",
        "  track_cols = [c for c in comparePredictions.columns if c.startswith(\"Track_\")]\n",
        "  year_cols = [c for c in comparePredictions.columns if c.startswith(\"Year_\")]\n",
        "  team_cols = [c for c in comparePredictions.columns if c.startswith(\"Team_\")]\n",
        "  driver_cols = [c for c in comparePredictions.columns if c.startswith(\"Driver_\")]\n",
        "\n",
        "  # Recover track names from one-hot encoding\n",
        "  comparePredictions[\"track\"] = comparePredictions[track_cols].idxmax(axis=1).str.replace(\"Track_\", \"\", regex=False)\n",
        "  comparePredictions[\"Driver\"] = comparePredictions[driver_cols].idxmax(axis=1).str.replace(\"Driver_\", \"\", regex=False)\n",
        "\n",
        "  # Sort so the highest prediction in each group comes first\n",
        "  # Flag 1 for the row(s) with the highest predicted score per track, else 0\n",
        "  comparePredictions[\"predicted_winner\"] = (\n",
        "      comparePredictions.groupby(\"track\")[\"predicted\"]\n",
        "                .transform(lambda x: x == x.max())\n",
        "                .astype(int)\n",
        "  )\n",
        "\n",
        "  sortedcomparePredictions = comparePredictions.sort_values([\"track\", \"predicted\"], ascending=[True, False])\n",
        "  #remove exess columns\n",
        "  cols_to_drop = track_cols + year_cols + team_cols + driver_cols + ['Laps']\n",
        "  finalResultsDf = sortedcomparePredictions.drop(cols_to_drop, axis=1)\n",
        "\n",
        "\n",
        "\n",
        "  # Count rows where model predicted winner AND they actually won\n",
        "  totalAmountGuessedCorrectly = finalResultsDf[\n",
        "      (finalResultsDf['predicted_winner'] == 1) &\n",
        "      (finalResultsDf['win'] == 1)\n",
        "  ].shape[0]\n",
        "\n",
        "  numRaces = finalResultsDf['track'].nunique()\n",
        "  print(\"The amount guessed correctly:\", totalAmountGuessedCorrectly, \" out of \", numRaces, \" races.\")\n",
        "\n",
        "\n",
        "  # Calculate percentage of races predicted correctly\n",
        "  # (assuming 'track' identifies unique races in your 2024 set)\n",
        "\n",
        "  percentage_correct = totalAmountGuessedCorrectly / numRaces\n",
        "  print(\"The percentage guessed correctly:\", percentage_correct)\n",
        "\n",
        "  smallerDf = finalResultsDf[(finalResultsDf['predicted_winner'] == 1 ) | (finalResultsDf['win'] == 1)].sort_values('track')\n",
        "\n",
        "\n",
        "  return finalResultsDf, smallerDf\n",
        "\n"
      ],
      "metadata": {
        "id": "YOHrboPhXOgN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test With Adam Optimizer"
      ],
      "metadata": {
        "id": "HdWd3oCKlNYG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train 2022/2023 for model"
      ],
      "metadata": {
        "id": "ABzIRKAeYcta"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "yearsTrain = ['2022', '2023']\n",
        "yearsPredict = ['2024']\n",
        "\n",
        "df, smallDf = trainMediumModel(yearsTrain, yearsPredict, df_encoded, \"relu\", \"adam\", 20)\n",
        "smallDf.head(100)"
      ],
      "metadata": {
        "id": "z51HoGr6aZT0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yearsTrain = ['2022', '2023']\n",
        "yearsPredict = ['2024']\n",
        "\n",
        "df, smallDf = trainMediumModel(yearsTrain, yearsPredict, df_encoded, \"sigmoid\", \"adam\", 20)\n",
        "smallDf.head(100)"
      ],
      "metadata": {
        "id": "-_MvCW9SahyR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yearsTrain = ['2022', '2023']\n",
        "yearsPredict = ['2024']\n",
        "\n",
        "df, smallDf = trainMediumModel(yearsTrain, yearsPredict, df_encoded, \"tanh\", \"adam\", 20)\n",
        "smallDf.head(100)"
      ],
      "metadata": {
        "id": "a6yAXJ6fakd4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train 2023/2024 for 2025"
      ],
      "metadata": {
        "id": "vsbsIrInanaa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "yearsTrain = ['2023', '2024']\n",
        "yearsPredict = ['2025']\n",
        "\n",
        "df, smallDf = trainMediumModel(yearsTrain, yearsPredict, completed2025, \"relu\", \"adam\", 20)\n",
        "smallDf.head(100)"
      ],
      "metadata": {
        "id": "c9tQpVUCarnb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yearsTrain = ['2023', '2024']\n",
        "yearsPredict = ['2025']\n",
        "\n",
        "df, smallDf = trainMediumModel(yearsTrain, yearsPredict, completed2025, \"sigmoid\", \"adam\", 20)\n",
        "smallDf.head(100)"
      ],
      "metadata": {
        "id": "Uv28Ev40awSr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yearsTrain = ['2023', '2024']\n",
        "yearsPredict = ['2025']\n",
        "\n",
        "df, smallDf = trainMediumModel(yearsTrain, yearsPredict, completed2025, \"tanh\", \"adam\", 20)\n",
        "smallDf.head(100)"
      ],
      "metadata": {
        "id": "4T6DFlcbazUa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train 2024 for 2025"
      ],
      "metadata": {
        "id": "3Xy0zrbJa2Gh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "yearsTrain = ['2024']\n",
        "yearsPredict = ['2025']\n",
        "\n",
        "df, smallDf = trainMediumModel(yearsTrain, yearsPredict, completed2025, \"relu\", \"adam\", 20)\n",
        "smallDf.head(100)"
      ],
      "metadata": {
        "id": "eNOxoMyBa4jy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yearsTrain = ['2024']\n",
        "yearsPredict = ['2025']\n",
        "\n",
        "df, smallDf = trainMediumModel(yearsTrain, yearsPredict, completed2025, \"sigmoid\", \"adam\", 20)\n",
        "smallDf.head(100)"
      ],
      "metadata": {
        "id": "ywWbX9d7a62t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yearsTrain = ['2024']\n",
        "yearsPredict = ['2025']\n",
        "\n",
        "df, smallDf = trainMediumModel(yearsTrain, yearsPredict, completed2025, \"tanh\", \"adam\", 20)\n",
        "smallDf.head(100)"
      ],
      "metadata": {
        "id": "W9gcVwLoa997"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Test with Adagrad optimizer"
      ],
      "metadata": {
        "id": "9-nQ0F3UoBCO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train 2022 and 2023 for 2024"
      ],
      "metadata": {
        "id": "zFUJ5hb3oHAW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "yearsTrain = ['2022', '2023']\n",
        "yearsPredict = ['2024']\n",
        "\n",
        "opt = Adagrad(learning_rate=5e-3)\n",
        "\n",
        "df, smallDf = trainMediumModel(yearsTrain, yearsPredict, df_encoded, \"relu\", opt, 20)\n",
        "smallDf.head(100)"
      ],
      "metadata": {
        "id": "14vf3Z5CoEJz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yearsTrain = ['2022', '2023']\n",
        "yearsPredict = ['2024']\n",
        "\n",
        "opt = Adagrad(learning_rate=5e-3)\n",
        "\n",
        "df, smallDf = trainMediumModel(yearsTrain, yearsPredict, df_encoded, \"sigmoid\", opt, 20)\n",
        "smallDf.head(100)"
      ],
      "metadata": {
        "id": "I0OUu5F_oMT7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yearsTrain = ['2022', '2023']\n",
        "yearsPredict = ['2024']\n",
        "\n",
        "opt = Adagrad(learning_rate=5e-3)\n",
        "\n",
        "df, smallDf = trainMediumModel(yearsTrain, yearsPredict, df_encoded, \"tanh\", opt, 20)\n",
        "smallDf.head(100)"
      ],
      "metadata": {
        "id": "LQBmKA7ToOCH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train 2023 and 2024 for 2025"
      ],
      "metadata": {
        "id": "sWSUeo9IoRCh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "yearsTrain = ['2023', '2024']\n",
        "yearsPredict = ['2025']\n",
        "\n",
        "opt = Adagrad(learning_rate=5e-3)\n",
        "\n",
        "df, smallDf = trainMediumModel(yearsTrain, yearsPredict, completed2025, \"relu\", opt, 20)\n",
        "smallDf.head(100)"
      ],
      "metadata": {
        "id": "IrCWrSKgoUBJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yearsTrain = ['2023', '2024']\n",
        "yearsPredict = ['2025']\n",
        "\n",
        "opt = Adagrad(learning_rate=5e-3)\n",
        "\n",
        "df, smallDf = trainMediumModel(yearsTrain, yearsPredict, completed2025, \"sigmoid\", opt, 20)\n",
        "smallDf.head(100)"
      ],
      "metadata": {
        "id": "D3U3dhAYoYqy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yearsTrain = ['2023', '2024']\n",
        "yearsPredict = ['2025']\n",
        "\n",
        "opt = Adagrad(learning_rate=5e-3)\n",
        "\n",
        "df, smallDf = trainMediumModel(yearsTrain, yearsPredict, completed2025, \"tanh\", opt, 20)\n",
        "smallDf.head(100)"
      ],
      "metadata": {
        "id": "rSsUrOiUoaZd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train 2024 for 2025"
      ],
      "metadata": {
        "id": "GS8RIEviocjz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "yearsTrain = ['2024']\n",
        "yearsPredict = ['2025']\n",
        "\n",
        "opt = Adagrad(learning_rate=5e-3)\n",
        "\n",
        "df, smallDf = trainMediumModel(yearsTrain, yearsPredict, completed2025, \"relu\", opt, 20)\n",
        "smallDf.head(100)"
      ],
      "metadata": {
        "id": "Li8_ba3_oeui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yearsTrain = ['2024']\n",
        "yearsPredict = ['2025']\n",
        "\n",
        "opt = Adagrad(learning_rate=5e-3)\n",
        "\n",
        "df, smallDf = trainMediumModel(yearsTrain, yearsPredict, completed2025, \"sigmoid\", opt, 20)\n",
        "smallDf.head(100)"
      ],
      "metadata": {
        "id": "wKg_X6MTog55"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yearsTrain = ['2024']\n",
        "yearsPredict = ['2025']\n",
        "\n",
        "opt = Adagrad(learning_rate=5e-3)\n",
        "\n",
        "df, smallDf = trainMediumModel(yearsTrain, yearsPredict, completed2025, \"tanh\", opt, 20)\n",
        "smallDf.head(100)"
      ],
      "metadata": {
        "id": "UB2mLT-_oiiC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# High Complex models"
      ],
      "metadata": {
        "id": "7ljHqW1sbBcl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## High Complex Model Functions"
      ],
      "metadata": {
        "id": "15DGvjxnbrfx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def createHighModel(x_train, y_train, x_valid, y_valid, x_test, y_test, activFunction, optimizer, epochsNum):\n",
        "    model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[73, 1]),\n",
        "    keras.layers.Dense(32, activation=\"relu\"),\n",
        "    keras.layers.Dense(64, activation=\"relu\"),\n",
        "    keras.layers.Dense(128, activation=\"relu\"),\n",
        "    keras.layers.Dense(256, activation=\"relu\"),\n",
        "    keras.layers.Dense(128, activation=\"relu\"),\n",
        "    keras.layers.Dense(64, activation=\"relu\"),\n",
        "    keras.layers.Dense(32, activation= activFunction),\n",
        "    keras.layers.Dense(1)\n",
        "    ])\n",
        "\n",
        "    model.compile(loss=\"mse\", optimizer=optimizer, metrics = [\"accuracy\"])\n",
        "    history = model.fit(x_train, y_train, epochs=epochsNum,\n",
        "                        validation_data=(x_valid, y_valid), shuffle = False)\n",
        "    model.evaluate(x_test, y_test)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "A91V9jZqbGwc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yearsTrain = ['2022', '2023']\n",
        "yearsPredict = ['2024']\n",
        "\n",
        "def trainHighModel(yearsTrain, yearsPredict, partyDf,  activFunction, optimizer, epochs):\n",
        "  # 1) Determinism\n",
        "  os.environ[\"PYTHONHASHSEED\"] = \"42\"\n",
        "  np.random.seed(42)\n",
        "  random.seed(42)\n",
        "  try:\n",
        "      tf.random.set_seed(42)\n",
        "      # TF 2.12+: deterministic ops\n",
        "      tf.config.experimental.enable_op_determinism(True)\n",
        "  except Exception:\n",
        "      pass\n",
        "\n",
        "\n",
        "  dfs = []\n",
        "  #get data from all training years\n",
        "  for year in yearsTrain:\n",
        "      dfs.append(partyDf[partyDf['Year_' + year] == 1])\n",
        "\n",
        "  # Combine all selected years into one DataFrame\n",
        "  trainDf = pd.concat(dfs, ignore_index=True)\n",
        "\n",
        "  x = trainDf.drop(columns=['win', 'Position', 'RaceOrder'])\n",
        "  y = trainDf['win']\n",
        "\n",
        "  #extract the columns that have a one included in the x df\n",
        "  year_cols = [c for c in x.columns if c.startswith(\"Year_\")]\n",
        "\n",
        "  includedTrainingYears = []\n",
        "  for col in year_cols:\n",
        "      if (x[col] == 1).any():   # check if there is any row with a 1 in this column\n",
        "          includedTrainingYears.append(col)\n",
        "\n",
        "  print(\"The years trained: \", includedTrainingYears)\n",
        "\n",
        "\n",
        "  #split the training data accordingly\n",
        "  x_train, x_valid, y_train, y_valid = train_test_split(x, y, test_size=0.2, random_state=42)\n",
        "  #get the test data, so the data for the next year you would want to predict\n",
        "  dfTest = partyDf[(partyDf['Year_'+ yearsPredict[0]] == 1)]\n",
        "  x_test = dfTest.drop(columns=['win', 'Position', 'RaceOrder'])\n",
        "  y_test = dfTest['win']\n",
        "\n",
        "  #extract the columns that have a one included in the x df\n",
        "\n",
        "  includedTestingYears = []\n",
        "  for col in year_cols:\n",
        "      if (x_test[col] == 1).any():   # check if there is any row with a 1 in this column\n",
        "          includedTestingYears.append(col)\n",
        "\n",
        "  print(\"The years tested: \", includedTestingYears)\n",
        "\n",
        "  model = createHighModel(x_train, y_train, x_valid, y_valid, x_test, y_test,  activFunction, optimizer, epochs)\n",
        "\n",
        "  #extract the actual winning rows in the data and weather or not my model predicted them to win\n",
        "  comparePredictions = partyDf[(partyDf['Year_'+ yearsPredict[0]] == 1)]\n",
        "\n",
        "  #now the predictions are inputed for each row\n",
        "  comparePredictions['predicted'] = model.predict(x_test)\n",
        "  # Identify one-hot columns\n",
        "  track_cols = [c for c in comparePredictions.columns if c.startswith(\"Track_\")]\n",
        "  year_cols = [c for c in comparePredictions.columns if c.startswith(\"Year_\")]\n",
        "  team_cols = [c for c in comparePredictions.columns if c.startswith(\"Team_\")]\n",
        "  driver_cols = [c for c in comparePredictions.columns if c.startswith(\"Driver_\")]\n",
        "\n",
        "  # Recover track names from one-hot encoding\n",
        "  comparePredictions[\"track\"] = comparePredictions[track_cols].idxmax(axis=1).str.replace(\"Track_\", \"\", regex=False)\n",
        "  comparePredictions[\"Driver\"] = comparePredictions[driver_cols].idxmax(axis=1).str.replace(\"Driver_\", \"\", regex=False)\n",
        "\n",
        "  # Sort so the highest prediction in each group comes first\n",
        "  # Flag 1 for the row(s) with the highest predicted score per track, else 0\n",
        "  comparePredictions[\"predicted_winner\"] = (\n",
        "      comparePredictions.groupby(\"track\")[\"predicted\"]\n",
        "                .transform(lambda x: x == x.max())\n",
        "                .astype(int)\n",
        "  )\n",
        "\n",
        "  sortedcomparePredictions = comparePredictions.sort_values([\"track\", \"predicted\"], ascending=[True, False])\n",
        "  #remove exess columns\n",
        "  cols_to_drop = track_cols + year_cols + team_cols + driver_cols + ['Laps']\n",
        "  finalResultsDf = sortedcomparePredictions.drop(cols_to_drop, axis=1)\n",
        "\n",
        "\n",
        "\n",
        "  # Count rows where model predicted winner AND they actually won\n",
        "  totalAmountGuessedCorrectly = finalResultsDf[\n",
        "      (finalResultsDf['predicted_winner'] == 1) &\n",
        "      (finalResultsDf['win'] == 1)\n",
        "  ].shape[0]\n",
        "\n",
        "  numRaces = finalResultsDf['track'].nunique()\n",
        "  print(\"The amount guessed correctly:\", totalAmountGuessedCorrectly, \" out of \", numRaces, \" races.\")\n",
        "\n",
        "\n",
        "  # Calculate percentage of races predicted correctly\n",
        "  # (assuming 'track' identifies unique races in your 2024 set)\n",
        "\n",
        "  percentage_correct = totalAmountGuessedCorrectly / numRaces\n",
        "  print(\"The percentage guessed correctly:\", percentage_correct)\n",
        "\n",
        "  smallerDf = finalResultsDf[(finalResultsDf['predicted_winner'] == 1 ) | (finalResultsDf['win'] == 1)].sort_values('track')\n",
        "\n",
        "\n",
        "  return finalResultsDf, smallerDf\n",
        "\n"
      ],
      "metadata": {
        "id": "U297htVCb7XI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test with Adam Optimizer"
      ],
      "metadata": {
        "id": "VDRAmavflWfN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train 2022 and 2023 for 2024"
      ],
      "metadata": {
        "id": "xxCPdMVydAWy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "yearsTrain = ['2022', '2023']\n",
        "yearsPredict = ['2024']\n",
        "\n",
        "df, smallDf = trainHighModel(yearsTrain, yearsPredict, df_encoded, \"relu\", \"adam\", 20)\n",
        "smallDf.head(100)"
      ],
      "metadata": {
        "id": "5W0phS6EdDI6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yearsTrain = ['2022', '2023']\n",
        "yearsPredict = ['2024']\n",
        "\n",
        "df, smallDf = trainHighModel(yearsTrain, yearsPredict, df_encoded, \"sigmoid\", \"adam\", 20)\n",
        "smallDf.head(100)"
      ],
      "metadata": {
        "id": "ziBaR3opdUPd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yearsTrain = ['2022', '2023']\n",
        "yearsPredict = ['2024']\n",
        "\n",
        "df, smallDf = trainHighModel(yearsTrain, yearsPredict, df_encoded, \"tanh\", \"adam\", 20)\n",
        "smallDf.head(100)"
      ],
      "metadata": {
        "id": "k45mGS9OdWE8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train 2023 and 2024 for 2025"
      ],
      "metadata": {
        "id": "z-MLLgppdYJd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "yearsTrain = ['2023', '2024']\n",
        "yearsPredict = ['2025']\n",
        "\n",
        "df, smallDf = trainHighModel(yearsTrain, yearsPredict, completed2025, \"relu\", \"adam\", 20)\n",
        "smallDf.head(100)"
      ],
      "metadata": {
        "id": "6_RhbzTXdavZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yearsTrain = ['2023', '2024']\n",
        "yearsPredict = ['2025']\n",
        "\n",
        "df, smallDf = trainHighModel(yearsTrain, yearsPredict, completed2025, \"sigmoid\", \"adam\", 20)\n",
        "smallDf.head(100)"
      ],
      "metadata": {
        "id": "ILtlZ-2bdfUl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yearsTrain = ['2023', '2024']\n",
        "yearsPredict = ['2025']\n",
        "\n",
        "df, smallDf = trainHighModel(yearsTrain, yearsPredict, completed2025, \"tanh\", \"adam\", 20)\n",
        "smallDf.head(100)"
      ],
      "metadata": {
        "id": "BCsS5nfMdhh_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train 2024 for 2025"
      ],
      "metadata": {
        "id": "YL9m9wo8djyC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "yearsTrain = ['2024']\n",
        "yearsPredict = ['2025']\n",
        "\n",
        "df, smallDf = trainHighModel(yearsTrain, yearsPredict, completed2025, \"relu\", \"adam\", 20)\n",
        "smallDf.head(100)"
      ],
      "metadata": {
        "id": "esRE5Q0sdo0s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yearsTrain = ['2024']\n",
        "yearsPredict = ['2025']\n",
        "\n",
        "df, smallDf = trainHighModel(yearsTrain, yearsPredict, completed2025, \"sigmoid\", \"adam\", 20)\n",
        "smallDf.head(100)"
      ],
      "metadata": {
        "id": "vGkoIcdvdqsc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yearsTrain = ['2024']\n",
        "yearsPredict = ['2025']\n",
        "\n",
        "df, smallDf = trainHighModel(yearsTrain, yearsPredict, completed2025, \"tanh\", \"adam\", 20)\n",
        "smallDf.head(100)"
      ],
      "metadata": {
        "id": "EsCL78CldtAo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test with Adagrad Optimizer"
      ],
      "metadata": {
        "id": "hfXcTiYCoq0j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train 2022 and 2023 for 2024"
      ],
      "metadata": {
        "id": "MQszWsD5o4Xt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "yearsTrain = ['2022','2023']\n",
        "yearsPredict = ['2024']\n",
        "\n",
        "opt = Adagrad(learning_rate=5e-3)\n",
        "\n",
        "df, smallDf = trainHighModel(yearsTrain, yearsPredict, completed2025, \"relu\", opt, 20)\n",
        "smallDf.head(100)"
      ],
      "metadata": {
        "id": "qm7tXydioyui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yearsTrain = ['2022','2023']\n",
        "yearsPredict = ['2024']\n",
        "\n",
        "opt = Adagrad(learning_rate=5e-3)\n",
        "\n",
        "df, smallDf = trainHighModel(yearsTrain, yearsPredict, completed2025, \"sigmoid\", opt, 20)\n",
        "smallDf.head(100)"
      ],
      "metadata": {
        "id": "GRggj-TjoxDP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yearsTrain = ['2022','2023']\n",
        "yearsPredict = ['2024']\n",
        "\n",
        "opt = Adagrad(learning_rate=5e-3)\n",
        "\n",
        "df, smallDf = trainHighModel(yearsTrain, yearsPredict, completed2025, \"tanh\", opt, 20)\n",
        "smallDf.head(100)"
      ],
      "metadata": {
        "id": "MAGebO0LpEJp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train 2023 and 2024 for 2025"
      ],
      "metadata": {
        "id": "9VUdX0aqpHep"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "yearsTrain = ['2023','2024']\n",
        "yearsPredict = ['2025']\n",
        "\n",
        "opt = Adagrad(learning_rate=5e-3)\n",
        "\n",
        "df, smallDf = trainHighModel(yearsTrain, yearsPredict, completed2025, \"relu\", opt, 20)\n",
        "smallDf.head(100)"
      ],
      "metadata": {
        "id": "IyP5zk81pGqD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yearsTrain = ['2023','2024']\n",
        "yearsPredict = ['2025']\n",
        "\n",
        "opt = Adagrad(learning_rate=5e-3)\n",
        "\n",
        "df, smallDf = trainHighModel(yearsTrain, yearsPredict, completed2025, \"sigmoid\", opt, 20)\n",
        "smallDf.head(100)"
      ],
      "metadata": {
        "id": "I-ZMR36spRfj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yearsTrain = ['2023','2024']\n",
        "yearsPredict = ['2025']\n",
        "\n",
        "opt = Adagrad(learning_rate=5e-3)\n",
        "\n",
        "df, smallDf = trainHighModel(yearsTrain, yearsPredict, completed2025, \"tanh\", opt, 20)\n",
        "smallDf.head(100)"
      ],
      "metadata": {
        "id": "lVL8-efZpUEZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train 2024 for 2025"
      ],
      "metadata": {
        "id": "mWbvXLaVpX5g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "yearsTrain = ['2024']\n",
        "yearsPredict = ['2025']\n",
        "\n",
        "opt = Adagrad(learning_rate=5e-3)\n",
        "\n",
        "df, smallDf = trainHighModel(yearsTrain, yearsPredict, completed2025, \"relu\", opt, 20)\n",
        "smallDf.head(100)"
      ],
      "metadata": {
        "id": "eN9I4tfOpbRF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yearsTrain = ['2024']\n",
        "yearsPredict = ['2025']\n",
        "\n",
        "opt = Adagrad(learning_rate=5e-3)\n",
        "\n",
        "df, smallDf = trainHighModel(yearsTrain, yearsPredict, completed2025, \"sigmoid\", opt, 20)\n",
        "smallDf.head(100)"
      ],
      "metadata": {
        "id": "x3afBHbKpdlf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yearsTrain = ['2024']\n",
        "yearsPredict = ['2025']\n",
        "\n",
        "opt = Adagrad(learning_rate=5e-3)\n",
        "\n",
        "df, smallDf = trainHighModel(yearsTrain, yearsPredict, completed2025, \"tanh\", opt, 20)\n",
        "smallDf.head(100)"
      ],
      "metadata": {
        "id": "mZXApoR2peMS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Longer Epochs for best performer in each category"
      ],
      "metadata": {
        "id": "xkSYK3Eag0xq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test with adam Optimizer"
      ],
      "metadata": {
        "id": "BFPYdiGglflf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Simple Model for 100 epochs: Tanh"
      ],
      "metadata": {
        "id": "Q2cpspUvg9p5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "yearsTrain = ['2022', '2023']\n",
        "yearsPredict = ['2024']\n",
        "\n",
        "df, smallDf = trainSimpleModel(yearsTrain, yearsPredict, df_encoded, \"tanh\", \"adam\", 100)\n",
        "smallDf.head(100)"
      ],
      "metadata": {
        "id": "KJKiTRw_g6_4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yearsTrain = ['2023', '2024']\n",
        "yearsPredict = ['2025']\n",
        "\n",
        "df, smallDf = trainSimpleModel(yearsTrain, yearsPredict, completed2025, \"tanh\", \"adam\", 100)\n",
        "smallDf.head(100)"
      ],
      "metadata": {
        "id": "NDQUHK5RhMB-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yearsTrain = ['2024']\n",
        "yearsPredict = ['2025']\n",
        "\n",
        "df, smallDf = trainSimpleModel(yearsTrain, yearsPredict, completed2025, \"tanh\", \"adam\", 100)\n",
        "smallDf.head(100)"
      ],
      "metadata": {
        "id": "JdalaLukhQ2j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Medium Model for 100 epochs: Sigmoid"
      ],
      "metadata": {
        "id": "FCGBCKO5hWLd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "yearsTrain = ['2022', '2023']\n",
        "yearsPredict = ['2024']\n",
        "\n",
        "df, smallDf = trainMediumModel(yearsTrain, yearsPredict, df_encoded, \"sigmoid\", \"adam\", 100)\n",
        "smallDf.head(100)"
      ],
      "metadata": {
        "id": "XjO0xwcShZo0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yearsTrain = ['2023', '2024']\n",
        "yearsPredict = ['2025']\n",
        "\n",
        "df, smallDf = trainMediumModel(yearsTrain, yearsPredict, completed2025, \"sigmoid\", \"adam\", 100)\n",
        "smallDf.head(100)"
      ],
      "metadata": {
        "id": "ZsxZitByhc3W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yearsTrain = ['2024']\n",
        "yearsPredict = ['2025']\n",
        "\n",
        "df, smallDf = trainMediumModel(yearsTrain, yearsPredict, completed2025, \"sigmoid\", \"adam\", 100)\n",
        "smallDf.head(100)"
      ],
      "metadata": {
        "id": "PD0hg7fMhqZ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### High Model for 100 epochs: relu"
      ],
      "metadata": {
        "id": "RU5fmVqahtBr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "yearsTrain = ['2022', '2023']\n",
        "yearsPredict = ['2024']\n",
        "\n",
        "df, smallDf = trainHighModel(yearsTrain, yearsPredict, df_encoded, \"relu\", \"adam\", 100)\n",
        "smallDf.head(100)"
      ],
      "metadata": {
        "id": "cWrdia_yh3EK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yearsTrain = ['2023', '2024']\n",
        "yearsPredict = ['2025']\n",
        "\n",
        "df, smallDf = trainHighModel(yearsTrain, yearsPredict, completed2025, \"relu\", \"adam\", 100)\n",
        "smallDf.head(100)"
      ],
      "metadata": {
        "id": "rSVul9G8h6XV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yearsTrain = ['2024']\n",
        "yearsPredict = ['2025']\n",
        "\n",
        "df, smallDf = trainHighModel(yearsTrain, yearsPredict, completed2025, \"relu\", \"adam\", 100)\n",
        "smallDf.head(100)"
      ],
      "metadata": {
        "id": "Pe9luOIih-st"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test with Adagrad Optimizer"
      ],
      "metadata": {
        "id": "kGFlg-wg-5m6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train 2022/2023 data for 2024"
      ],
      "metadata": {
        "id": "Ku-oYknK_GwX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "yearsTrain = ['2022','2023']\n",
        "yearsPredict = ['2024']\n",
        "\n",
        "opt = Adagrad(learning_rate=5e-3)\n",
        "\n",
        "df, smallDf = trainSimpleModel(yearsTrain, yearsPredict, completed2025, \"relu\", opt, 100)\n",
        "smallDf.head(100)"
      ],
      "metadata": {
        "id": "k943iDmS-9Iu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yearsTrain = ['2022','2023']\n",
        "yearsPredict = ['2024']\n",
        "\n",
        "opt = Adagrad(learning_rate=5e-3)\n",
        "\n",
        "df, smallDf = trainMediumModel(yearsTrain, yearsPredict, completed2025, \"tanh\", opt, 100)\n",
        "smallDf.head(100)"
      ],
      "metadata": {
        "id": "SrfU8Cmh_OX2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yearsTrain = ['2022','2023']\n",
        "yearsPredict = ['2024']\n",
        "\n",
        "opt = Adagrad(learning_rate=5e-3)\n",
        "\n",
        "df, smallDf = trainHighModel(yearsTrain, yearsPredict, completed2025, \"sigmoid\", opt, 100)\n",
        "smallDf.head(100)"
      ],
      "metadata": {
        "id": "S4qZQjnU_Uke"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train 2023/2024 for 2025"
      ],
      "metadata": {
        "id": "4SZysxaM_X9b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "yearsTrain = ['2023','2024']\n",
        "yearsPredict = ['2025']\n",
        "\n",
        "opt = Adagrad(learning_rate=5e-3)\n",
        "\n",
        "df, smallDf = trainSimpleModel(yearsTrain, yearsPredict, completed2025, \"relu\", opt, 100)\n",
        "smallDf.head(100)"
      ],
      "metadata": {
        "id": "KfhpqGyc_b0l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yearsTrain = ['2023','2024']\n",
        "yearsPredict = ['2025']\n",
        "\n",
        "opt = Adagrad(learning_rate=5e-3)\n",
        "\n",
        "df, smallDf = trainMediumModel(yearsTrain, yearsPredict, completed2025, \"tanh\", opt, 100)\n",
        "smallDf.head(100)"
      ],
      "metadata": {
        "id": "O0QQIQTL_f3G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yearsTrain = ['2023','2024']\n",
        "yearsPredict = ['2025']\n",
        "\n",
        "opt = Adagrad(learning_rate=5e-3)\n",
        "\n",
        "df, smallDf = trainHighModel(yearsTrain, yearsPredict, completed2025, \"sigmoid\", opt, 100)\n",
        "smallDf.head(100)"
      ],
      "metadata": {
        "id": "mY74NJyU_isr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train 2024 for 2025"
      ],
      "metadata": {
        "id": "nyg9ZF-d_mM5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "yearsTrain = ['2024']\n",
        "yearsPredict = ['2025']\n",
        "\n",
        "opt = Adagrad(learning_rate=5e-3)\n",
        "\n",
        "df, smallDf = trainSimpleModel(yearsTrain, yearsPredict, completed2025, \"relu\", opt, 100)\n",
        "smallDf.head(100)"
      ],
      "metadata": {
        "id": "Hj31SLYU_qMG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yearsTrain = ['2024']\n",
        "yearsPredict = ['2025']\n",
        "\n",
        "opt = Adagrad(learning_rate=5e-3)\n",
        "\n",
        "df, smallDf = trainMediumModel(yearsTrain, yearsPredict, completed2025, \"tanh\", opt, 100)\n",
        "smallDf.head(100)"
      ],
      "metadata": {
        "id": "H5p6IMQz_tq-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yearsTrain = ['2023','2024']\n",
        "yearsPredict = ['2025']\n",
        "\n",
        "opt = Adagrad(learning_rate=5e-3)\n",
        "\n",
        "df, smallDf = trainHighModel(yearsTrain, yearsPredict, completed2025, \"sigmoid\", opt, 100)\n",
        "smallDf.head(100)"
      ],
      "metadata": {
        "id": "0XdX3y2U_vjR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Best Models"
      ],
      "metadata": {
        "id": "Qub32JNzBAJ1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The best model for a composite average of the training data is the medium complexity model with a sigmoid activation function and 100 epochs. The best model at predicting the 2025 season based two previous seasons is also this model. Finally, the best model at predicting the next season only based on the previous season is also the medium models with a relu/sigmoid activation function for 20 epochs. I shall use these three models to get their predictions based on the 24/25 data for the bigger one and the 25 data for the smaller ones."
      ],
      "metadata": {
        "id": "LPwk35H8BE01"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "yearsTrain = ['2024', '2025']\n",
        "yearsPredict = ['2026']\n",
        "\n",
        "opt = Adagrad(learning_rate=5e-3)\n",
        "\n",
        "df, smallDf = trainMediumModel(yearsTrain, yearsPredict, completed2026, \"sigmoid\", opt, 100)\n",
        "smallDf.head(100)"
      ],
      "metadata": {
        "id": "Gziv2iNJCOF0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yearsTrain = ['2025']\n",
        "yearsPredict = ['2026']\n",
        "\n",
        "opt = Adagrad(learning_rate=5e-3)\n",
        "\n",
        "df, smallDf = trainMediumModel(yearsTrain, yearsPredict, completed2026, \"sigmoid\", opt, 20)\n",
        "smallDf.head(100)"
      ],
      "metadata": {
        "id": "81P5EDqJCkBc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yearsTrain = ['2025']\n",
        "yearsPredict = ['2026']\n",
        "\n",
        "opt = Adagrad(learning_rate=5e-3)\n",
        "\n",
        "df, smallDf = trainMediumModel(yearsTrain, yearsPredict, completed2026, \"relu\", opt, 20)\n",
        "smallDf.head(100)"
      ],
      "metadata": {
        "id": "NmDRcwwnCsRV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "According to my models, they are predicting that Pierre Gasley will win the Las Vegas Grand Prix in 2026. I consider this highly unlikely as currently Alpine is in last place in the constructors and have won the least amount of points. I do believe Lando Norris winnning the Las Vegas Grand Prix as very likey as he has come up second in the past two World Championships."
      ],
      "metadata": {
        "id": "NurdMmjcDCbg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adagrad\n",
        "yearsTrain = ['2025']\n",
        "yearsPredict = ['2026']\n",
        "\n",
        "opt = Adagrad(learning_rate=5e-3)\n",
        "\n",
        "df, smallDf = trainSimpleModel(yearsTrain, yearsPredict, completed2026, \"tanh\", opt, 100)\n",
        "smallDf.head(100)"
      ],
      "metadata": {
        "id": "P8fKxLfN_0QI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ic7pfvuYBOba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Make Graphs"
      ],
      "metadata": {
        "id": "nKGsvVEFBOvr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "These graphs are to show how many models performed better than the baseline"
      ],
      "metadata": {
        "id": "rD2oMv_sBQdT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_performance_comparison2325(worse_than_naive, equal_to_best_naive, better_than_both_naive):\n",
        "    \"\"\"\n",
        "    Creates a bar plot comparing model performance based on different categories.\n",
        "\n",
        "    Parameters:\n",
        "    - worse_than_naive: Models that performed worse than the naive.\n",
        "    - equal_to_best_naive: Models that performed equal to the best performing naive.\n",
        "    - better_than_both_naive: Models that performed better than both naive hypotheses.\n",
        "    \"\"\"\n",
        "    # Bar labels for the three categories for the legend\n",
        "    categories = ['Worse than Both Naive (Sensitivity < .087)',\n",
        "                  'Equal to Both Naive (Sensitivity = .087)',\n",
        "                  'Better than Both Naive (Sensitivity > .087)']\n",
        "\n",
        "    horizontalLabels = ['Worse than Both Naive',\n",
        "                  'Equal to Both Naive ',\n",
        "                  'Better than Both Naive']\n",
        "\n",
        "    # Values for each bar\n",
        "    values = [worse_than_naive, equal_to_best_naive, better_than_both_naive]\n",
        "\n",
        "    # Color map for each category\n",
        "    colors = ['red', 'grey', 'green']\n",
        "\n",
        "    # Create a bar plot\n",
        "    fig, ax = plt.subplots(figsize=(8, 6))\n",
        "\n",
        "    # Plot bars for each category\n",
        "    bars = ax.bar(horizontalLabels, values, color=colors)\n",
        "\n",
        "    # Add labels, title, and legend\n",
        "    ax.set_ylabel('Number of Models')\n",
        "    ax.set_title('Model Performance Compared to Naive Model Sensitivity (trained on 2023 and 2024 data Predicting 2025).')\n",
        "\n",
        "    # Custom legend with colors corresponding to the bars\n",
        "    ax.legend(bars, categories, loc='upper left')\n",
        "\n",
        "    # Show the plot\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Example usage:\n",
        "plot_performance_comparison2325(8, 15, 1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "6M2uIBKpFYce",
        "outputId": "bec6cc2b-f50f-458d-81cd-1dd657b6bd16"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_performance_comparison24(worse_than_naive, equal_to_best_naive, better_than_both_naive):\n",
        "    \"\"\"\n",
        "    Creates a bar plot comparing model performance based on different categories.\n",
        "\n",
        "    Parameters:\n",
        "    - worse_than_naive: Models that performed worse than the naive.\n",
        "    - equal_to_best_naive: Models that performed equal to the best performing naive.\n",
        "    - better_than_both_naive: Models that performed better than both naive hypotheses.\n",
        "    \"\"\"\n",
        "    # Bar labels for the three categories for the legend\n",
        "    categories = ['Worse than Both Naive (Sensitivity < .167)',\n",
        "                  'Equal to Best Naive (Sensitivity = .375)',\n",
        "                  'Better than Both Naive (Sensitivity > .375)']\n",
        "\n",
        "    horizontalLabels = ['Worse than Both Naive',\n",
        "                  'Equal to Best Naive ',\n",
        "                  'Better than Both Naive']\n",
        "\n",
        "    # Values for each bar\n",
        "    values = [worse_than_naive, equal_to_best_naive, better_than_both_naive]\n",
        "\n",
        "    # Color map for each category\n",
        "    colors = ['red', 'grey', 'green']\n",
        "\n",
        "    # Create a bar plot\n",
        "    fig, ax = plt.subplots(figsize=(8, 6))\n",
        "\n",
        "    # Plot bars for each category\n",
        "    bars = ax.bar(horizontalLabels, values, color=colors)\n",
        "\n",
        "    # Add labels, title, and legend\n",
        "    ax.set_ylabel('Number of Models')\n",
        "    ax.set_title('Model Performance Compared to Naive Model Sensitivity (Trained on 2022 and 2023 Data Predicting 2024).')\n",
        "\n",
        "    # Custom legend with colors corresponding to the bars\n",
        "    ax.legend(bars, categories, loc='upper left')\n",
        "\n",
        "    # Show the plot\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Example usage:\n",
        "plot_performance_comparison24(8, 16, 0)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "MSUfKMnQF1dQ",
        "outputId": "1e639452-e20e-49bf-b707-ce23fcf19726"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_performance_comparison2425(worse_than_naive, equal_to_best_naive, better_than_both_naive):\n",
        "    \"\"\"\n",
        "    Creates a bar plot comparing model performance based on different categories.\n",
        "\n",
        "    Parameters:\n",
        "    - worse_than_naive: Models that performed worse than the naive.\n",
        "    - equal_to_best_naive: Models that performed equal to the best performing naive.\n",
        "    - better_than_both_naive: Models that performed better than both naive hypotheses.\n",
        "    \"\"\"\n",
        "    # Bar labels for the three categories for the legend\n",
        "    categories = ['Worse than Both Naives (Sensitivitiy < .087)',\n",
        "                  'Equal to Both Naives (Sensitivitiy = .087)',\n",
        "                  'Better than Both Naives (Sensitivity > .087)']\n",
        "\n",
        "    horizontalLabels = ['Worse than Both Naive',\n",
        "                  'Equal to Both Naive ',\n",
        "                  'Better than Both Naive']\n",
        "\n",
        "    # Values for each bar\n",
        "    values = [worse_than_naive, equal_to_best_naive, better_than_both_naive]\n",
        "\n",
        "    # Color map for each category\n",
        "    colors = ['red', 'grey', 'green']\n",
        "\n",
        "    # Create a bar plot\n",
        "    fig, ax = plt.subplots(figsize=(8, 6))\n",
        "\n",
        "    # Plot bars for each category\n",
        "    bars = ax.bar(horizontalLabels, values, color=colors)\n",
        "\n",
        "    # Add labels, title, and legend\n",
        "    ax.set_ylabel('Number of Models')\n",
        "    ax.set_title('Model Performance Compared to Naive Model Sensitivity (Trained on 2024 Data Predicting 2025).')\n",
        "\n",
        "    # Custom legend with colors corresponding to the bars\n",
        "    ax.legend(bars, categories, loc='upper left')\n",
        "\n",
        "    # Show the plot\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Example usage:\n",
        "plot_performance_comparison2425(10, 4, 10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "ump-vqrkGOHq",
        "outputId": "ad8b2e4d-5a66-47ed-80a9-ee23146837a3"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_performance_comparisonAv(worse_than_naive, inbetweenNaive, better_than_both_naive):\n",
        "    \"\"\"\n",
        "    Creates a bar plot comparing model performance based on different categories.\n",
        "\n",
        "    Parameters:\n",
        "    - worse_than_naive: Models that performed worse than the naive.\n",
        "    - equal_to_best_naive: Models that performed equal to the best performing naive.\n",
        "    - better_than_both_naive: Models that performed better than both naive hypotheses.\n",
        "    \"\"\"\n",
        "    # Bar labels for the three categories for the legend\n",
        "    categories = ['Worse than Both Naive (Sensitivity < .114)',\n",
        "                  'Inbetween Naives .114 < model < .183',\n",
        "                  'Better than Both Naive (Sensitivity > .183)']\n",
        "\n",
        "    horizontalLabels = ['Worse than Both Naive',\n",
        "                        'Better than only one Naive',\n",
        "                  'Better than Both Naive']\n",
        "\n",
        "    # Values for each bar\n",
        "    values = [worse_than_naive, inbetweenNaive,  better_than_both_naive]\n",
        "\n",
        "    # Color map for each category\n",
        "    colors = ['red', 'pink',  'green']\n",
        "\n",
        "    # Create a bar plot\n",
        "    fig, ax = plt.subplots(figsize=(8, 6))\n",
        "\n",
        "    # Plot bars for each category\n",
        "    bars = ax.bar(horizontalLabels, values, color=colors)\n",
        "\n",
        "    # Add labels, title, and legend\n",
        "    ax.set_ylabel('Number of Models')\n",
        "    ax.set_title('Average Model Performance Compared to Naive Model Sensitivity')\n",
        "\n",
        "    # Custom legend with colors corresponding to the bars\n",
        "    ax.legend(bars, categories, loc='upper left')\n",
        "\n",
        "    # Show the plot\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Example usage:\n",
        "plot_performance_comparisonAv(8, 8, 8)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "sE9OifqEG6Sc",
        "outputId": "4ee5de86-a864-428a-f360-71b6163292b8"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}